{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reestablishing whether we can reproduce same results as before in the check in table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.0000\n",
      "accuracy: 0.0000\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.0, 'accuracy': 0.0}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.2342946720123291}, 'time_per_token': {'mean': 0.011714733624830841}, 'tokens_per_second': {'mean': 89.21172018051148}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:01<02:14,  1.36s/it]\n",
      "Benchmarking MMLU:   2%|▏         | 2/100 [00:01<01:10,  1.39it/s]\n",
      "Benchmarking MMLU:   3%|▎         | 3/100 [00:01<00:49,  1.97it/s]\n",
      "Benchmarking MMLU:   4%|▍         | 4/100 [00:02<00:38,  2.52it/s]\n",
      "Benchmarking MMLU:   5%|▌         | 5/100 [00:02<00:33,  2.86it/s]\n",
      "Benchmarking MMLU:   6%|▌         | 6/100 [00:02<00:28,  3.25it/s]\n",
      "Benchmarking MMLU:   7%|▋         | 7/100 [00:02<00:26,  3.50it/s]\n",
      "Benchmarking MMLU:   8%|▊         | 8/100 [00:03<00:24,  3.75it/s]\n",
      "Benchmarking MMLU:   9%|▉         | 9/100 [00:03<00:23,  3.95it/s]\n",
      "Benchmarking MMLU:  10%|█         | 10/100 [00:03<00:21,  4.13it/s]\n",
      "Benchmarking MMLU:  11%|█         | 11/100 [00:03<00:21,  4.08it/s]\n",
      "Benchmarking MMLU:  12%|█▏        | 12/100 [00:03<00:21,  4.16it/s]\n",
      "Benchmarking MMLU:  13%|█▎        | 13/100 [00:04<00:20,  4.34it/s]\n",
      "Benchmarking MMLU:  14%|█▍        | 14/100 [00:04<00:19,  4.46it/s]\n",
      "Benchmarking MMLU:  15%|█▌        | 15/100 [00:04<00:18,  4.48it/s]\n",
      "Benchmarking MMLU:  16%|█▌        | 16/100 [00:04<00:18,  4.46it/s]\n",
      "Benchmarking MMLU:  17%|█▋        | 17/100 [00:05<00:18,  4.47it/s]\n",
      "Benchmarking MMLU:  18%|█▊        | 18/100 [00:05<00:18,  4.45it/s]\n",
      "Benchmarking MMLU:  19%|█▉        | 19/100 [00:05<00:18,  4.39it/s]\n",
      "Benchmarking MMLU:  20%|██        | 20/100 [00:05<00:18,  4.22it/s]\n",
      "Benchmarking MMLU:  21%|██        | 21/100 [00:06<00:17,  4.41it/s]\n",
      "Benchmarking MMLU:  22%|██▏       | 22/100 [00:06<00:17,  4.53it/s]\n",
      "Benchmarking MMLU:  23%|██▎       | 23/100 [00:06<00:16,  4.54it/s]\n",
      "Benchmarking MMLU:  24%|██▍       | 24/100 [00:06<00:16,  4.62it/s]\n",
      "Benchmarking MMLU:  25%|██▌       | 25/100 [00:06<00:16,  4.62it/s]\n",
      "Benchmarking MMLU:  26%|██▌       | 26/100 [00:07<00:16,  4.61it/s]\n",
      "Benchmarking MMLU:  27%|██▋       | 27/100 [00:07<00:15,  4.56it/s]\n",
      "Benchmarking MMLU:  28%|██▊       | 28/100 [00:07<00:15,  4.57it/s]\n",
      "Benchmarking MMLU:  29%|██▉       | 29/100 [00:07<00:15,  4.51it/s]\n",
      "Benchmarking MMLU:  30%|███       | 30/100 [00:07<00:15,  4.58it/s]\n",
      "Benchmarking MMLU:  31%|███       | 31/100 [00:08<00:15,  4.58it/s]\n",
      "Benchmarking MMLU:  32%|███▏      | 32/100 [00:08<00:14,  4.66it/s]\n",
      "Benchmarking MMLU:  33%|███▎      | 33/100 [00:08<00:14,  4.54it/s]\n",
      "Benchmarking MMLU:  34%|███▍      | 34/100 [00:08<00:14,  4.65it/s]\n",
      "Benchmarking MMLU:  35%|███▌      | 35/100 [00:09<00:13,  4.71it/s]\n",
      "Benchmarking MMLU:  36%|███▌      | 36/100 [00:09<00:13,  4.75it/s]\n",
      "Benchmarking MMLU:  37%|███▋      | 37/100 [00:09<00:13,  4.69it/s]\n",
      "Benchmarking MMLU:  38%|███▊      | 38/100 [00:09<00:13,  4.59it/s]\n",
      "Benchmarking MMLU:  39%|███▉      | 39/100 [00:09<00:13,  4.56it/s]\n",
      "Benchmarking MMLU:  40%|████      | 40/100 [00:10<00:13,  4.44it/s]\n",
      "Benchmarking MMLU:  41%|████      | 41/100 [00:10<00:13,  4.46it/s]\n",
      "Benchmarking MMLU:  42%|████▏     | 42/100 [00:10<00:12,  4.50it/s]\n",
      "Benchmarking MMLU:  43%|████▎     | 43/100 [00:10<00:12,  4.54it/s]\n",
      "Benchmarking MMLU:  44%|████▍     | 44/100 [00:11<00:12,  4.53it/s]\n",
      "Benchmarking MMLU:  45%|████▌     | 45/100 [00:11<00:11,  4.63it/s]\n",
      "Benchmarking MMLU:  46%|████▌     | 46/100 [00:11<00:12,  4.49it/s]\n",
      "Benchmarking MMLU:  47%|████▋     | 47/100 [00:11<00:11,  4.53it/s]\n",
      "Benchmarking MMLU:  48%|████▊     | 48/100 [00:11<00:11,  4.51it/s]\n",
      "Benchmarking MMLU:  49%|████▉     | 49/100 [00:12<00:11,  4.57it/s]\n",
      "Benchmarking MMLU:  50%|█████     | 50/100 [00:12<00:11,  4.38it/s]\n",
      "Benchmarking MMLU:  51%|█████     | 51/100 [00:12<00:11,  4.41it/s]\n",
      "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:12<00:10,  4.42it/s]\n",
      "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:13<00:10,  4.54it/s]\n",
      "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:13<00:10,  4.47it/s]\n",
      "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:13<00:10,  4.48it/s]\n",
      "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:13<00:09,  4.48it/s]\n",
      "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:13<00:09,  4.56it/s]\n",
      "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:14<00:09,  4.56it/s]\n",
      "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:14<00:09,  4.40it/s]\n",
      "Benchmarking MMLU:  60%|██████    | 60/100 [00:14<00:08,  4.46it/s]\n",
      "Benchmarking MMLU:  61%|██████    | 61/100 [00:14<00:09,  4.33it/s]\n",
      "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:15<00:08,  4.42it/s]\n",
      "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:15<00:08,  4.48it/s]\n",
      "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:15<00:08,  4.45it/s]\n",
      "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:15<00:07,  4.48it/s]\n",
      "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:15<00:07,  4.51it/s]\n",
      "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:16<00:07,  4.56it/s]\n",
      "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:16<00:06,  4.58it/s]\n",
      "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:16<00:07,  4.39it/s]\n",
      "Benchmarking MMLU:  70%|███████   | 70/100 [00:16<00:06,  4.51it/s]\n",
      "Benchmarking MMLU:  71%|███████   | 71/100 [00:17<00:06,  4.57it/s]\n",
      "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:17<00:06,  4.60it/s]\n",
      "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:17<00:05,  4.65it/s]\n",
      "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:17<00:05,  4.56it/s]\n",
      "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:17<00:05,  4.43it/s]\n",
      "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:18<00:05,  4.30it/s]\n",
      "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:18<00:05,  4.38it/s]\n",
      "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:18<00:05,  4.39it/s]\n",
      "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:18<00:04,  4.42it/s]\n",
      "Benchmarking MMLU:  80%|████████  | 80/100 [00:19<00:04,  4.36it/s]\n",
      "Benchmarking MMLU:  81%|████████  | 81/100 [00:19<00:04,  4.45it/s]\n",
      "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:19<00:04,  4.46it/s]\n",
      "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:19<00:03,  4.29it/s]\n",
      "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:19<00:03,  4.39it/s]\n",
      "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:20<00:03,  4.51it/s]\n",
      "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:20<00:03,  4.46it/s]\n",
      "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:20<00:03,  4.28it/s]\n",
      "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:20<00:02,  4.37it/s]\n",
      "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:21<00:02,  4.40it/s]\n",
      "Benchmarking MMLU:  90%|█████████ | 90/100 [00:21<00:02,  4.52it/s]\n",
      "Benchmarking MMLU:  91%|█████████ | 91/100 [00:21<00:02,  4.47it/s]\n",
      "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:21<00:01,  4.49it/s]\n",
      "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:22<00:01,  4.39it/s]\n",
      "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:22<00:01,  4.44it/s]\n",
      "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:22<00:01,  4.53it/s]\n",
      "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:22<00:00,  4.57it/s]\n",
      "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:22<00:00,  4.37it/s]\n",
      "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:23<00:00,  4.46it/s]\n",
      "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:23<00:00,  4.47it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:23<00:00,  4.42it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:23<00:00,  4.24it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mmlu \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --exit_layer 8 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.3700\n",
      "accuracy: 0.3700\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.3700000047683716, 'accuracy': 0.37}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.04906256675720215}, 'time_per_token': {'mean': 0.04906256675720215}, 'tokens_per_second': {'mean': 22.639218657016755}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:00<00:43,  2.29it/s]\n",
      "Benchmarking MMLU:   3%|▎         | 3/100 [00:00<00:15,  6.39it/s]\n",
      "Benchmarking MMLU:   5%|▌         | 5/100 [00:00<00:09,  9.78it/s]\n",
      "Benchmarking MMLU:   7%|▋         | 7/100 [00:00<00:07, 12.43it/s]\n",
      "Benchmarking MMLU:  10%|█         | 10/100 [00:00<00:05, 15.25it/s]\n",
      "Benchmarking MMLU:  13%|█▎        | 13/100 [00:01<00:04, 17.94it/s]\n",
      "Benchmarking MMLU:  16%|█▌        | 16/100 [00:01<00:04, 18.98it/s]\n",
      "Benchmarking MMLU:  19%|█▉        | 19/100 [00:01<00:03, 20.51it/s]\n",
      "Benchmarking MMLU:  22%|██▏       | 22/100 [00:01<00:03, 21.41it/s]\n",
      "Benchmarking MMLU:  25%|██▌       | 25/100 [00:01<00:03, 21.68it/s]\n",
      "Benchmarking MMLU:  28%|██▊       | 28/100 [00:01<00:03, 21.36it/s]\n",
      "Benchmarking MMLU:  31%|███       | 31/100 [00:01<00:03, 21.75it/s]\n",
      "Benchmarking MMLU:  34%|███▍      | 34/100 [00:01<00:02, 22.54it/s]\n",
      "Benchmarking MMLU:  37%|███▋      | 37/100 [00:02<00:02, 23.47it/s]\n",
      "Benchmarking MMLU:  40%|████      | 40/100 [00:02<00:02, 23.26it/s]\n",
      "Benchmarking MMLU:  43%|████▎     | 43/100 [00:02<00:02, 23.97it/s]\n",
      "Benchmarking MMLU:  46%|████▌     | 46/100 [00:02<00:02, 22.90it/s]\n",
      "Benchmarking MMLU:  49%|████▉     | 49/100 [00:02<00:02, 23.33it/s]\n",
      "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:02<00:02, 22.46it/s]\n",
      "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:02<00:02, 21.39it/s]\n",
      "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:03<00:02, 20.51it/s]\n",
      "Benchmarking MMLU:  61%|██████    | 61/100 [00:03<00:01, 20.52it/s]\n",
      "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:03<00:01, 21.68it/s]\n",
      "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:03<00:01, 19.61it/s]\n",
      "Benchmarking MMLU:  70%|███████   | 70/100 [00:03<00:01, 19.65it/s]\n",
      "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:03<00:01, 20.63it/s]\n",
      "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:03<00:01, 21.75it/s]\n",
      "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:04<00:00, 21.91it/s]\n",
      "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:04<00:00, 20.94it/s]\n",
      "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:04<00:00, 21.69it/s]\n",
      "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:04<00:00, 22.03it/s]\n",
      "Benchmarking MMLU:  91%|█████████ | 91/100 [00:04<00:00, 21.33it/s]\n",
      "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:04<00:00, 22.11it/s]\n",
      "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:04<00:00, 22.51it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:04<00:00, 23.06it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:04<00:00, 20.09it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mmlu \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.3700\n",
      "accuracy: 0.3700\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.3700000047683716, 'accuracy': 0.37}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.04725863218307495}, 'time_per_token': {'mean': 0.04725863218307495}, 'tokens_per_second': {'mean': 24.50369641661644}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:00<00:58,  1.71it/s]\n",
      "Benchmarking MMLU:   4%|▍         | 4/100 [00:00<00:14,  6.57it/s]\n",
      "Benchmarking MMLU:   7%|▋         | 7/100 [00:00<00:08, 10.99it/s]\n",
      "Benchmarking MMLU:   9%|▉         | 9/100 [00:00<00:07, 12.88it/s]\n",
      "Benchmarking MMLU:  11%|█         | 11/100 [00:01<00:06, 13.96it/s]\n",
      "Benchmarking MMLU:  14%|█▍        | 14/100 [00:01<00:05, 17.13it/s]\n",
      "Benchmarking MMLU:  17%|█▋        | 17/100 [00:01<00:04, 18.49it/s]\n",
      "Benchmarking MMLU:  20%|██        | 20/100 [00:01<00:04, 19.49it/s]\n",
      "Benchmarking MMLU:  23%|██▎       | 23/100 [00:01<00:03, 21.07it/s]\n",
      "Benchmarking MMLU:  26%|██▌       | 26/100 [00:01<00:03, 21.49it/s]\n",
      "Benchmarking MMLU:  29%|██▉       | 29/100 [00:01<00:03, 21.76it/s]\n",
      "Benchmarking MMLU:  32%|███▏      | 32/100 [00:01<00:03, 22.55it/s]\n",
      "Benchmarking MMLU:  35%|███▌      | 35/100 [00:02<00:02, 22.90it/s]\n",
      "Benchmarking MMLU:  38%|███▊      | 38/100 [00:02<00:02, 22.23it/s]\n",
      "Benchmarking MMLU:  41%|████      | 41/100 [00:02<00:02, 22.49it/s]\n",
      "Benchmarking MMLU:  44%|████▍     | 44/100 [00:02<00:02, 23.04it/s]\n",
      "Benchmarking MMLU:  47%|████▋     | 47/100 [00:02<00:02, 23.89it/s]\n",
      "Benchmarking MMLU:  50%|█████     | 50/100 [00:02<00:02, 24.93it/s]\n",
      "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:02<00:01, 24.94it/s]\n",
      "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:02<00:01, 25.62it/s]\n",
      "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:03<00:01, 25.56it/s]\n",
      "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:03<00:01, 25.35it/s]\n",
      "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:03<00:01, 25.31it/s]\n",
      "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:03<00:01, 24.64it/s]\n",
      "Benchmarking MMLU:  71%|███████   | 71/100 [00:03<00:01, 23.78it/s]\n",
      "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:03<00:01, 24.15it/s]\n",
      "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:03<00:00, 25.33it/s]\n",
      "Benchmarking MMLU:  80%|████████  | 80/100 [00:03<00:00, 23.71it/s]\n",
      "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:04<00:00, 23.36it/s]\n",
      "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:04<00:00, 23.52it/s]\n",
      "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:04<00:00, 23.39it/s]\n",
      "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:04<00:00, 22.91it/s]\n",
      "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:04<00:00, 23.49it/s]\n",
      "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:04<00:00, 24.35it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:04<00:00, 20.88it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mmlu \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --output_dir ./logs \\\n",
    "       --exit_layer -1 \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34286\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.322998046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39530\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.174072265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.366455078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5045\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.057373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.52197265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127075\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.354736328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.76904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.88134765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4951171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127075\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2247314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.18310546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46407\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66530\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60600\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.234130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89990234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.434326171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.036346435546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48099\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.90478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.92919921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.46826171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.76708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21430\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0699462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53709\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.78564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.33447265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60600\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.86865234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39990234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1871337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39530\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.76904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46407\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.740234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85858\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 41070\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.041778564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66530\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.64501953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.96875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127075\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.62255859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89501953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75491\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.416748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7880859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5361328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39530\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09381103515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.81689453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 72605\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.074462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62117\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.199951171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98421\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.486083984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.386962890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.089111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.60302734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9365234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.486083984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1490478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.063720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.91748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38734\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005664825439453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79159\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63762\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56641\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0096588134765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50906\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09344482421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49398\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9560546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56949\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.342529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12558\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12329\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.87744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12329\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 126402\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91444\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0304107666015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62117\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.66650390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85886\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2342529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 44710\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.82373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 44710\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4072265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52044\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.970703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42607\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.279296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.96435546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39404296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 51249\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.144775390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46407\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39599609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.85302734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42423\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2568359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77064\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2230224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.53466796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102674\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.14794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.62353515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2325439453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1143798828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1405029296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10498046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 107815\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07928466796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13811\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0197601318359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96123\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04876708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2401123046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68399\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.463134765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25224\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.14306640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.060760498046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.474609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 105093\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.59228515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89013671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34486\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.28955078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.62158203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9404296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.53515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.421142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0936279296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.56884765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1522216796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 112900\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1744384765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52622\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25224\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.93896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.44140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6923828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57014\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35619\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0296783447265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127075\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.235107421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.84130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66530\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0161590576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.289306640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47830\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.94970703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95431\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0675048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98421\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.30615234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.271728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52325\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.20751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.90673828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5045\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.75341796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.60693359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.74072265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52622\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.498779296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2178955078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39720\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04608154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127075\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2139892578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60600\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9541015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60600\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5771484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.97265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2418212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.053497314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46407\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.93896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.84033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36940\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.474853515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03472900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5045\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.68359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9580078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85858\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10107421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60053\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0123291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38889\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.386962890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.304443359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1807861328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.78955078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.51220703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7216796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50858\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6669921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.41796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0682373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1263427734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9423828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70934\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0985107421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68882\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.417236328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.79296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.814453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39720\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4856\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.294677734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60600\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13296\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.40087890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.45947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0396728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.413330078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79678\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.47314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29667\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64063\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2357177734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68509\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58748\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.12188720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.58837890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47830\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09429931640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68399\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.46875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09954833984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.23046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47830\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07647705078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.123046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14761\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2230224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39720\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.45068359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68882\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.80322265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68399\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1737060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47830\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0248565673828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46407\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.432373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.165771484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50858\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.60400390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.4000\n",
      "accuracy: 0.4000\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.4000000059604645, 'accuracy': 0.4}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.20467217445373534}, 'time_per_token': {'mean': 0.1884273688495159}, 'tokens_per_second': {'mean': 5.544164162874222}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:00<01:30,  1.09it/s]\n",
      "Benchmarking MMLU:   2%|▏         | 2/100 [00:01<00:48,  2.04it/s]\n",
      "Benchmarking MMLU:   3%|▎         | 3/100 [00:01<00:34,  2.85it/s]\n",
      "Benchmarking MMLU:   4%|▍         | 4/100 [00:01<00:27,  3.53it/s]\n",
      "Benchmarking MMLU:   5%|▌         | 5/100 [00:01<00:23,  4.00it/s]\n",
      "Benchmarking MMLU:   6%|▌         | 6/100 [00:01<00:22,  4.23it/s]\n",
      "Benchmarking MMLU:   7%|▋         | 7/100 [00:02<00:20,  4.52it/s]\n",
      "Benchmarking MMLU:   8%|▊         | 8/100 [00:02<00:19,  4.72it/s]\n",
      "Benchmarking MMLU:   9%|▉         | 9/100 [00:02<00:18,  4.80it/s]\n",
      "Benchmarking MMLU:  10%|█         | 10/100 [00:02<00:17,  5.02it/s]\n",
      "Benchmarking MMLU:  11%|█         | 11/100 [00:02<00:17,  5.10it/s]\n",
      "Benchmarking MMLU:  12%|█▏        | 12/100 [00:03<00:17,  5.07it/s]\n",
      "Benchmarking MMLU:  13%|█▎        | 13/100 [00:03<00:16,  5.23it/s]\n",
      "Benchmarking MMLU:  14%|█▍        | 14/100 [00:03<00:16,  5.24it/s]\n",
      "Benchmarking MMLU:  15%|█▌        | 15/100 [00:03<00:16,  5.29it/s]\n",
      "Benchmarking MMLU:  16%|█▌        | 16/100 [00:03<00:16,  5.20it/s]\n",
      "Benchmarking MMLU:  17%|█▋        | 17/100 [00:03<00:15,  5.24it/s]\n",
      "Benchmarking MMLU:  18%|█▊        | 18/100 [00:04<00:15,  5.20it/s]\n",
      "Benchmarking MMLU:  19%|█▉        | 19/100 [00:04<00:17,  4.74it/s]\n",
      "Benchmarking MMLU:  20%|██        | 20/100 [00:04<00:16,  4.83it/s]\n",
      "Benchmarking MMLU:  21%|██        | 21/100 [00:04<00:16,  4.91it/s]\n",
      "Benchmarking MMLU:  22%|██▏       | 22/100 [00:05<00:15,  4.88it/s]\n",
      "Benchmarking MMLU:  23%|██▎       | 23/100 [00:05<00:15,  5.11it/s]\n",
      "Benchmarking MMLU:  24%|██▍       | 24/100 [00:05<00:14,  5.14it/s]\n",
      "Benchmarking MMLU:  25%|██▌       | 25/100 [00:05<00:14,  5.27it/s]\n",
      "Benchmarking MMLU:  26%|██▌       | 26/100 [00:05<00:13,  5.34it/s]\n",
      "Benchmarking MMLU:  27%|██▋       | 27/100 [00:05<00:13,  5.45it/s]\n",
      "Benchmarking MMLU:  28%|██▊       | 28/100 [00:06<00:13,  5.40it/s]\n",
      "Benchmarking MMLU:  29%|██▉       | 29/100 [00:06<00:13,  5.37it/s]\n",
      "Benchmarking MMLU:  30%|███       | 30/100 [00:06<00:13,  5.22it/s]\n",
      "Benchmarking MMLU:  31%|███       | 31/100 [00:06<00:12,  5.40it/s]\n",
      "Benchmarking MMLU:  32%|███▏      | 32/100 [00:06<00:13,  5.12it/s]\n",
      "Benchmarking MMLU:  33%|███▎      | 33/100 [00:08<00:43,  1.54it/s]\n",
      "Benchmarking MMLU:  34%|███▍      | 34/100 [00:08<00:33,  1.96it/s]\n",
      "Benchmarking MMLU:  35%|███▌      | 35/100 [00:08<00:26,  2.42it/s]\n",
      "Benchmarking MMLU:  36%|███▌      | 36/100 [00:09<00:22,  2.84it/s]\n",
      "Benchmarking MMLU:  37%|███▋      | 37/100 [00:09<00:18,  3.34it/s]\n",
      "Benchmarking MMLU:  38%|███▊      | 38/100 [00:09<00:16,  3.65it/s]\n",
      "Benchmarking MMLU:  39%|███▉      | 39/100 [00:09<00:15,  3.99it/s]\n",
      "Benchmarking MMLU:  40%|████      | 40/100 [00:09<00:13,  4.30it/s]\n",
      "Benchmarking MMLU:  41%|████      | 41/100 [00:10<00:12,  4.72it/s]\n",
      "Benchmarking MMLU:  42%|████▏     | 42/100 [00:10<00:11,  4.92it/s]\n",
      "Benchmarking MMLU:  43%|████▎     | 43/100 [00:10<00:11,  5.07it/s]\n",
      "Benchmarking MMLU:  44%|████▍     | 44/100 [00:10<00:10,  5.25it/s]\n",
      "Benchmarking MMLU:  45%|████▌     | 45/100 [00:10<00:10,  5.22it/s]\n",
      "Benchmarking MMLU:  46%|████▌     | 46/100 [00:11<00:10,  5.35it/s]\n",
      "Benchmarking MMLU:  47%|████▋     | 47/100 [00:11<00:09,  5.52it/s]\n",
      "Benchmarking MMLU:  48%|████▊     | 48/100 [00:11<00:09,  5.56it/s]\n",
      "Benchmarking MMLU:  49%|████▉     | 49/100 [00:11<00:09,  5.54it/s]\n",
      "Benchmarking MMLU:  50%|█████     | 50/100 [00:11<00:08,  5.69it/s]\n",
      "Benchmarking MMLU:  51%|█████     | 51/100 [00:11<00:09,  5.35it/s]\n",
      "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:12<00:08,  5.47it/s]\n",
      "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:12<00:08,  5.49it/s]\n",
      "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:12<00:08,  5.61it/s]\n",
      "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:12<00:07,  5.79it/s]\n",
      "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:12<00:07,  5.56it/s]\n",
      "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:12<00:07,  5.60it/s]\n",
      "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:13<00:07,  5.74it/s]\n",
      "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:13<00:07,  5.84it/s]\n",
      "Benchmarking MMLU:  60%|██████    | 60/100 [00:13<00:06,  5.85it/s]\n",
      "Benchmarking MMLU:  61%|██████    | 61/100 [00:13<00:06,  5.90it/s]\n",
      "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:13<00:06,  5.95it/s]\n",
      "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:13<00:06,  5.97it/s]\n",
      "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:14<00:06,  5.94it/s]\n",
      "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:14<00:05,  5.96it/s]\n",
      "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:14<00:06,  5.59it/s]\n",
      "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:14<00:05,  5.65it/s]\n",
      "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:14<00:05,  5.70it/s]\n",
      "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:15<00:05,  5.79it/s]\n",
      "Benchmarking MMLU:  70%|███████   | 70/100 [00:15<00:05,  5.76it/s]\n",
      "Benchmarking MMLU:  71%|███████   | 71/100 [00:15<00:05,  5.72it/s]\n",
      "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:15<00:04,  5.81it/s]\n",
      "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:15<00:04,  5.73it/s]\n",
      "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:15<00:04,  5.82it/s]\n",
      "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:16<00:04,  5.57it/s]\n",
      "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:16<00:04,  5.70it/s]\n",
      "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:16<00:04,  5.37it/s]\n",
      "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:16<00:03,  5.56it/s]\n",
      "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:16<00:03,  5.47it/s]\n",
      "Benchmarking MMLU:  80%|████████  | 80/100 [00:16<00:03,  5.63it/s]\n",
      "Benchmarking MMLU:  81%|████████  | 81/100 [00:17<00:03,  5.77it/s]\n",
      "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:17<00:03,  5.75it/s]\n",
      "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:17<00:02,  5.73it/s]\n",
      "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:17<00:02,  5.84it/s]\n",
      "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:17<00:02,  5.80it/s]\n",
      "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:18<00:02,  5.67it/s]\n",
      "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:18<00:02,  5.65it/s]\n",
      "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:18<00:02,  5.74it/s]\n",
      "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:18<00:01,  5.79it/s]\n",
      "Benchmarking MMLU:  90%|█████████ | 90/100 [00:18<00:01,  5.77it/s]\n",
      "Benchmarking MMLU:  91%|█████████ | 91/100 [00:18<00:01,  5.81it/s]\n",
      "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:19<00:01,  5.74it/s]\n",
      "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:19<00:01,  5.61it/s]\n",
      "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:19<00:01,  5.52it/s]\n",
      "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:19<00:00,  5.51it/s]\n",
      "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:19<00:00,  5.46it/s]\n",
      "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:20<00:00,  5.37it/s]\n",
      "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:20<00:00,  5.51it/s]\n",
      "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:20<00:00,  5.58it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:20<00:00,  5.44it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:20<00:00,  4.87it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mmlu \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy self_speculative \\\n",
    "       --exit_layer 8 \\\n",
    "       --num_speculations 6 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Checking output ids: [423, 198]\n",
      "Checking output ids: [423, 198, 70869]\n",
      "Checking output ids: [423, 198, 70869, 25]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770, 2637]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770, 2637, 2052]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770, 2637, 2052, 315]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770, 2637, 2052, 315, 279]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770, 2637, 2052, 315, 279, 3485]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770, 2637, 2052, 315, 279, 3485, 75797]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770, 2637, 2052, 315, 279, 3485, 75797, 2493]\n",
      "Checking output ids: [423, 198, 70869, 25, 39553, 13, 374, 364, 67, 6, 602, 1770, 2637, 2052, 315, 279, 3485, 75797, 2493, 37794]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.3500\n",
      "accuracy: 0.3500\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.3499999940395355, 'accuracy': 0.35}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.05174910306930542}, 'time_per_token': {'mean': 0.04794729923829436}, 'tokens_per_second': {'mean': 23.259432015419005}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:00<00:44,  2.21it/s]\n",
      "Benchmarking MMLU:   4%|▍         | 4/100 [00:00<00:11,  8.17it/s]\n",
      "Benchmarking MMLU:   7%|▋         | 7/100 [00:00<00:07, 12.28it/s]\n",
      "Benchmarking MMLU:   9%|▉         | 9/100 [00:00<00:06, 13.28it/s]\n",
      "Benchmarking MMLU:  12%|█▏        | 12/100 [00:00<00:05, 16.00it/s]\n",
      "Benchmarking MMLU:  15%|█▌        | 15/100 [00:01<00:04, 17.89it/s]\n",
      "Benchmarking MMLU:  18%|█▊        | 18/100 [00:01<00:04, 18.72it/s]\n",
      "Benchmarking MMLU:  21%|██        | 21/100 [00:01<00:03, 20.51it/s]\n",
      "Benchmarking MMLU:  24%|██▍       | 24/100 [00:01<00:03, 21.00it/s]\n",
      "Benchmarking MMLU:  27%|██▋       | 27/100 [00:01<00:03, 22.14it/s]\n",
      "Benchmarking MMLU:  30%|███       | 30/100 [00:01<00:03, 22.57it/s]\n",
      "Benchmarking MMLU:  33%|███▎      | 33/100 [00:01<00:02, 23.23it/s]\n",
      "Benchmarking MMLU:  36%|███▌      | 36/100 [00:02<00:02, 23.30it/s]\n",
      "Benchmarking MMLU:  39%|███▉      | 39/100 [00:02<00:02, 21.84it/s]\n",
      "Benchmarking MMLU:  42%|████▏     | 42/100 [00:02<00:02, 22.75it/s]\n",
      "Benchmarking MMLU:  45%|████▌     | 45/100 [00:02<00:02, 22.06it/s]\n",
      "Benchmarking MMLU:  48%|████▊     | 48/100 [00:02<00:02, 22.40it/s]\n",
      "Benchmarking MMLU:  51%|█████     | 51/100 [00:02<00:02, 22.22it/s]\n",
      "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:02<00:02, 22.77it/s]\n",
      "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:02<00:01, 22.93it/s]\n",
      "Benchmarking MMLU:  60%|██████    | 60/100 [00:03<00:01, 23.91it/s]\n",
      "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:03<00:01, 24.17it/s]\n",
      "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:03<00:01, 24.09it/s]\n",
      "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:03<00:01, 24.19it/s]\n",
      "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:03<00:01, 23.59it/s]\n",
      "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:03<00:01, 23.31it/s]\n",
      "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:03<00:00, 23.43it/s]\n",
      "Benchmarking MMLU:  81%|████████  | 81/100 [00:03<00:00, 22.76it/s]\n",
      "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:04<00:00, 22.96it/s]\n",
      "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:04<00:00, 21.95it/s]\n",
      "Benchmarking MMLU:  90%|█████████ | 90/100 [00:04<00:00, 20.95it/s]\n",
      "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:04<00:00, 20.53it/s]\n",
      "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:04<00:00, 20.78it/s]\n",
      "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:05<00:00, 11.94it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:05<00:00, 19.02it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mmlu \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy layerdrop \\\n",
    "       --dropout_rate 0.2 \\\n",
    "       --layerdrop_seed 42 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "Layer 4/16: Halt prob: 0.1653, Accumulated: 0.1653, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0672, Accumulated: 0.2325, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0405, Accumulated: 0.2730, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0273, Accumulated: 0.3003, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0255, Accumulated: 0.3258, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0322, Accumulated: 0.3580, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0408, Accumulated: 0.3989, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1019, Accumulated: 0.5007, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1106, Accumulated: 0.6113, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1265, Accumulated: 0.7378, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1207, Accumulated: 0.8585, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0867, Accumulated: 0.9452, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0322, Accumulated: 0.9774, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0198, Accumulated: 0.0198, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0528, Accumulated: 0.0726, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0223, Accumulated: 0.0949, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0325, Accumulated: 0.1274, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0313, Accumulated: 0.1587, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0089, Accumulated: 0.1676, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0104, Accumulated: 0.1780, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0084, Accumulated: 0.1864, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0222, Accumulated: 0.2086, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7868, Accumulated: 0.9954, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1519, Accumulated: 0.1519, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0651, Accumulated: 0.2170, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0308, Accumulated: 0.2478, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0268, Accumulated: 0.2746, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0177, Accumulated: 0.2923, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0324, Accumulated: 0.3247, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0311, Accumulated: 0.3558, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0755, Accumulated: 0.4313, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1187, Accumulated: 0.5499, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1268, Accumulated: 0.6767, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1429, Accumulated: 0.8196, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1007, Accumulated: 0.9203, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0403, Accumulated: 0.9606, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0072, Accumulated: 0.0072, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0101, Accumulated: 0.0173, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0058, Accumulated: 0.0230, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0693, Accumulated: 0.0923, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0109, Accumulated: 0.1032, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0087, Accumulated: 0.1119, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0125, Accumulated: 0.1245, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0076, Accumulated: 0.1321, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0162, Accumulated: 0.1483, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7498, Accumulated: 0.8981, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1006, Accumulated: 0.9988, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1337, Accumulated: 0.1337, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0416, Accumulated: 0.1753, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0185, Accumulated: 0.1938, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0208, Accumulated: 0.2146, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0128, Accumulated: 0.2274, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0242, Accumulated: 0.2516, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0278, Accumulated: 0.2794, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0851, Accumulated: 0.3645, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1346, Accumulated: 0.4991, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1541, Accumulated: 0.6532, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1678, Accumulated: 0.8210, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1133, Accumulated: 0.9343, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0443, Accumulated: 0.9785, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0182, Accumulated: 0.0182, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0045, Accumulated: 0.0227, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0126, Accumulated: 0.0352, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1265, Accumulated: 0.1617, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0069, Accumulated: 0.1686, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0095, Accumulated: 0.1781, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0151, Accumulated: 0.1933, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.4636, Accumulated: 0.6569, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1134, Accumulated: 0.7703, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.2283, Accumulated: 0.9987, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1565, Accumulated: 0.1565, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0811, Accumulated: 0.2376, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0461, Accumulated: 0.2837, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0345, Accumulated: 0.3183, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0320, Accumulated: 0.3502, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0310, Accumulated: 0.3812, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0544, Accumulated: 0.4356, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1199, Accumulated: 0.5555, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1444, Accumulated: 0.7000, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1265, Accumulated: 0.8265, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0934, Accumulated: 0.9198, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0502, Accumulated: 0.9701, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0171, Accumulated: 0.9872, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0072, Accumulated: 0.0072, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0131, Accumulated: 0.0204, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0146, Accumulated: 0.0350, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0345, Accumulated: 0.0695, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0084, Accumulated: 0.0780, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0184, Accumulated: 0.0963, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0314, Accumulated: 0.1277, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0645, Accumulated: 0.1922, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0277, Accumulated: 0.2199, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7641, Accumulated: 0.9840, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0160, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0762, Accumulated: 0.0762, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0339, Accumulated: 0.1101, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0200, Accumulated: 0.1302, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0140, Accumulated: 0.1442, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0142, Accumulated: 0.1584, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0218, Accumulated: 0.1802, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0226, Accumulated: 0.2028, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0574, Accumulated: 0.2602, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0782, Accumulated: 0.3384, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1425, Accumulated: 0.4809, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.2242, Accumulated: 0.7051, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1989, Accumulated: 0.9039, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0681, Accumulated: 0.9721, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0065, Accumulated: 0.0065, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0096, Accumulated: 0.0161, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0063, Accumulated: 0.0224, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0663, Accumulated: 0.0887, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0140, Accumulated: 0.1026, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0297, Accumulated: 0.1324, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0062, Accumulated: 0.1386, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0802, Accumulated: 0.2188, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0589, Accumulated: 0.2777, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6994, Accumulated: 0.9771, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0229, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1404, Accumulated: 0.1404, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0673, Accumulated: 0.2077, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0449, Accumulated: 0.2526, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0444, Accumulated: 0.2970, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0355, Accumulated: 0.3325, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0482, Accumulated: 0.3807, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0571, Accumulated: 0.4378, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1136, Accumulated: 0.5515, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1638, Accumulated: 0.7153, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1328, Accumulated: 0.8481, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0848, Accumulated: 0.9329, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0435, Accumulated: 0.9763, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0139, Accumulated: 0.9902, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0070, Accumulated: 0.0070, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0143, Accumulated: 0.0213, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0175, Accumulated: 0.0388, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0134, Accumulated: 0.0522, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0084, Accumulated: 0.0606, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0285, Accumulated: 0.0892, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0117, Accumulated: 0.1008, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0424, Accumulated: 0.1432, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0545, Accumulated: 0.1977, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7902, Accumulated: 0.9879, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0121, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1948, Accumulated: 0.1948, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0663, Accumulated: 0.2612, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0495, Accumulated: 0.3106, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0342, Accumulated: 0.3448, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0290, Accumulated: 0.3738, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0256, Accumulated: 0.3994, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0308, Accumulated: 0.4302, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0568, Accumulated: 0.4870, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0890, Accumulated: 0.5760, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1227, Accumulated: 0.6987, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1257, Accumulated: 0.8244, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0914, Accumulated: 0.9158, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0472, Accumulated: 0.9630, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0058, Accumulated: 0.0058, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0110, Accumulated: 0.0168, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0118, Accumulated: 0.0286, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0959, Accumulated: 0.1244, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0122, Accumulated: 0.1366, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0060, Accumulated: 0.1426, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0226, Accumulated: 0.1652, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0089, Accumulated: 0.1741, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0087, Accumulated: 0.1828, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7916, Accumulated: 0.9745, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0255, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2245, Accumulated: 0.2245, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0962, Accumulated: 0.3207, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0614, Accumulated: 0.3820, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0445, Accumulated: 0.4265, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0417, Accumulated: 0.4682, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0499, Accumulated: 0.5181, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0581, Accumulated: 0.5763, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0774, Accumulated: 0.6536, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1067, Accumulated: 0.7604, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0962, Accumulated: 0.8566, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0714, Accumulated: 0.9280, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0434, Accumulated: 0.9715, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0145, Accumulated: 0.9859, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0096, Accumulated: 0.0096, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0120, Accumulated: 0.0216, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0066, Accumulated: 0.0282, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0183, Accumulated: 0.0465, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0062, Accumulated: 0.0528, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0184, Accumulated: 0.0711, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0115, Accumulated: 0.0827, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.4244, Accumulated: 0.5071, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1745, Accumulated: 0.6816, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.3175, Accumulated: 0.9991, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1635, Accumulated: 0.1635, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0620, Accumulated: 0.2254, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0433, Accumulated: 0.2687, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0463, Accumulated: 0.3150, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0349, Accumulated: 0.3500, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0441, Accumulated: 0.3940, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0510, Accumulated: 0.4451, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1040, Accumulated: 0.5491, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1712, Accumulated: 0.7203, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1262, Accumulated: 0.8465, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0822, Accumulated: 0.9286, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0463, Accumulated: 0.9750, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0147, Accumulated: 0.9897, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0068, Accumulated: 0.0068, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0190, Accumulated: 0.0258, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0084, Accumulated: 0.0342, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0082, Accumulated: 0.0423, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0048, Accumulated: 0.0471, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0280, Accumulated: 0.0751, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0162, Accumulated: 0.0913, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0247, Accumulated: 0.1160, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0296, Accumulated: 0.1457, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8460, Accumulated: 0.9917, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1560, Accumulated: 0.1560, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0762, Accumulated: 0.2322, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0417, Accumulated: 0.2740, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0258, Accumulated: 0.2998, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0183, Accumulated: 0.3181, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0327, Accumulated: 0.3507, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0306, Accumulated: 0.3813, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0695, Accumulated: 0.4508, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1120, Accumulated: 0.5627, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1271, Accumulated: 0.6899, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1362, Accumulated: 0.8261, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0988, Accumulated: 0.9248, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0378, Accumulated: 0.9627, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0144, Accumulated: 0.0144, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0086, Accumulated: 0.0229, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0076, Accumulated: 0.0306, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0163, Accumulated: 0.0469, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0048, Accumulated: 0.0517, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0164, Accumulated: 0.0680, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0053, Accumulated: 0.0733, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0078, Accumulated: 0.0811, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0317, Accumulated: 0.1128, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8296, Accumulated: 0.9424, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0573, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0762, Accumulated: 0.0762, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0436, Accumulated: 0.1198, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0203, Accumulated: 0.1400, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0179, Accumulated: 0.1580, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0157, Accumulated: 0.1736, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0262, Accumulated: 0.1998, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0294, Accumulated: 0.2292, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0671, Accumulated: 0.2964, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1347, Accumulated: 0.4310, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1518, Accumulated: 0.5829, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1880, Accumulated: 0.7709, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1491, Accumulated: 0.9200, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0520, Accumulated: 0.9720, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0089, Accumulated: 0.0089, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0130, Accumulated: 0.0219, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0084, Accumulated: 0.0303, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0425, Accumulated: 0.0728, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0158, Accumulated: 0.0885, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0136, Accumulated: 0.1022, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0107, Accumulated: 0.1129, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1755, Accumulated: 0.2884, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0710, Accumulated: 0.3594, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6372, Accumulated: 0.9966, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1526, Accumulated: 0.1526, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0694, Accumulated: 0.2220, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0364, Accumulated: 0.2584, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0289, Accumulated: 0.2873, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0194, Accumulated: 0.3067, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0314, Accumulated: 0.3381, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0342, Accumulated: 0.3723, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0782, Accumulated: 0.4505, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1163, Accumulated: 0.5667, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1276, Accumulated: 0.6943, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1363, Accumulated: 0.8306, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0976, Accumulated: 0.9282, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0365, Accumulated: 0.9647, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0070, Accumulated: 0.0070, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0090, Accumulated: 0.0160, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0051, Accumulated: 0.0211, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0709, Accumulated: 0.0920, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0084, Accumulated: 0.1004, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0084, Accumulated: 0.1088, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0078, Accumulated: 0.1166, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0089, Accumulated: 0.1255, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0182, Accumulated: 0.1437, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7267, Accumulated: 0.8704, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1278, Accumulated: 0.9982, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0686, Accumulated: 0.0686, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0285, Accumulated: 0.0971, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0219, Accumulated: 0.1190, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0208, Accumulated: 0.1398, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0159, Accumulated: 0.1557, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0261, Accumulated: 0.1817, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0478, Accumulated: 0.2296, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0712, Accumulated: 0.3008, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0871, Accumulated: 0.3878, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1560, Accumulated: 0.5439, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1849, Accumulated: 0.7287, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1670, Accumulated: 0.8958, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0667, Accumulated: 0.9624, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0225, Accumulated: 0.0225, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0122, Accumulated: 0.0347, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0091, Accumulated: 0.0437, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0081, Accumulated: 0.0518, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0065, Accumulated: 0.0584, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0191, Accumulated: 0.0774, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0172, Accumulated: 0.0946, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0703, Accumulated: 0.1649, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0723, Accumulated: 0.2372, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7494, Accumulated: 0.9866, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0133, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1974, Accumulated: 0.1974, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0799, Accumulated: 0.2773, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0481, Accumulated: 0.3254, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0465, Accumulated: 0.3719, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.4034, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0407, Accumulated: 0.4441, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0533, Accumulated: 0.4973, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1030, Accumulated: 0.6004, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1413, Accumulated: 0.7416, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1157, Accumulated: 0.8574, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0760, Accumulated: 0.9334, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0427, Accumulated: 0.9760, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0138, Accumulated: 0.9898, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0078, Accumulated: 0.0078, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0111, Accumulated: 0.0189, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0093, Accumulated: 0.0282, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0373, Accumulated: 0.0655, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0158, Accumulated: 0.0813, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0347, Accumulated: 0.1160, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0130, Accumulated: 0.1291, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0150, Accumulated: 0.1441, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0260, Accumulated: 0.1701, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8190, Accumulated: 0.9891, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0109, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1807, Accumulated: 0.1807, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0772, Accumulated: 0.2579, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0440, Accumulated: 0.3019, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0358, Accumulated: 0.3377, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0284, Accumulated: 0.3661, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0314, Accumulated: 0.3975, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0386, Accumulated: 0.4361, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0669, Accumulated: 0.5030, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1188, Accumulated: 0.6218, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1207, Accumulated: 0.7425, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1069, Accumulated: 0.8494, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0848, Accumulated: 0.9343, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0321, Accumulated: 0.9664, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0098, Accumulated: 0.0098, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0111, Accumulated: 0.0208, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0081, Accumulated: 0.0290, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0367, Accumulated: 0.0657, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0126, Accumulated: 0.0783, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0522, Accumulated: 0.1305, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0505, Accumulated: 0.1810, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0064, Accumulated: 0.1875, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0253, Accumulated: 0.2128, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7519, Accumulated: 0.9646, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0352, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0753, Accumulated: 0.0753, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0535, Accumulated: 0.1288, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0210, Accumulated: 0.1499, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0184, Accumulated: 0.1682, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0231, Accumulated: 0.1913, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0205, Accumulated: 0.2118, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0269, Accumulated: 0.2387, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0667, Accumulated: 0.3054, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1147, Accumulated: 0.4201, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1511, Accumulated: 0.5712, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1822, Accumulated: 0.7534, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1707, Accumulated: 0.9240, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0505, Accumulated: 0.9745, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0234, Accumulated: 0.0234, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0069, Accumulated: 0.0304, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0071, Accumulated: 0.0375, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0175, Accumulated: 0.0549, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0146, Accumulated: 0.0695, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0112, Accumulated: 0.0807, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0125, Accumulated: 0.0931, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1688, Accumulated: 0.2620, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1684, Accumulated: 0.4303, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5635, Accumulated: 0.9939, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1238, Accumulated: 0.1238, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0621, Accumulated: 0.1859, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0434, Accumulated: 0.2293, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0413, Accumulated: 0.2706, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0294, Accumulated: 0.3000, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0401, Accumulated: 0.3401, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0493, Accumulated: 0.3894, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1068, Accumulated: 0.4962, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1250, Accumulated: 0.6212, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1525, Accumulated: 0.7737, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1177, Accumulated: 0.8914, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0729, Accumulated: 0.9642, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0230, Accumulated: 0.9873, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0231, Accumulated: 0.0231, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0157, Accumulated: 0.0387, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0118, Accumulated: 0.0505, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0122, Accumulated: 0.0627, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0113, Accumulated: 0.0740, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0129, Accumulated: 0.0869, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0339, Accumulated: 0.1207, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0276, Accumulated: 0.1483, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1211, Accumulated: 0.2694, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7135, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0170, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1331, Accumulated: 0.1331, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0606, Accumulated: 0.1937, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0263, Accumulated: 0.2200, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0321, Accumulated: 0.2521, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0208, Accumulated: 0.2730, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0381, Accumulated: 0.3111, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0404, Accumulated: 0.3516, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0992, Accumulated: 0.4508, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1344, Accumulated: 0.5851, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1368, Accumulated: 0.7220, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1362, Accumulated: 0.8581, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0907, Accumulated: 0.9488, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0312, Accumulated: 0.9800, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0076, Accumulated: 0.0076, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0168, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0041, Accumulated: 0.0209, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0416, Accumulated: 0.0624, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0115, Accumulated: 0.0740, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0205, Accumulated: 0.0944, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0072, Accumulated: 0.1017, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.4970, Accumulated: 0.5986, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1468, Accumulated: 0.7454, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.2535, Accumulated: 0.9989, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0779, Accumulated: 0.0779, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0419, Accumulated: 0.1198, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0266, Accumulated: 0.1464, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0243, Accumulated: 0.1706, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0245, Accumulated: 0.1952, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0299, Accumulated: 0.2251, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0402, Accumulated: 0.2653, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0922, Accumulated: 0.3575, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1325, Accumulated: 0.4900, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1773, Accumulated: 0.6673, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1691, Accumulated: 0.8364, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1075, Accumulated: 0.9439, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0392, Accumulated: 0.9831, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0348, Accumulated: 0.0348, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0713, Accumulated: 0.1062, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0057, Accumulated: 0.1118, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0136, Accumulated: 0.1254, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0108, Accumulated: 0.1362, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0089, Accumulated: 0.1451, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0104, Accumulated: 0.1555, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.3544, Accumulated: 0.5099, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1553, Accumulated: 0.6652, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.3320, Accumulated: 0.9972, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0656, Accumulated: 0.0656, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0256, Accumulated: 0.0912, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0186, Accumulated: 0.1098, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0169, Accumulated: 0.1267, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0174, Accumulated: 0.1441, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0272, Accumulated: 0.1713, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0249, Accumulated: 0.1962, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0555, Accumulated: 0.2517, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0935, Accumulated: 0.3452, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1371, Accumulated: 0.4823, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1849, Accumulated: 0.6672, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1935, Accumulated: 0.8607, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0822, Accumulated: 0.9430, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0121, Accumulated: 0.0121, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0416, Accumulated: 0.0537, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0121, Accumulated: 0.0658, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0160, Accumulated: 0.0819, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0053, Accumulated: 0.0871, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0158, Accumulated: 0.1030, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0097, Accumulated: 0.1127, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0415, Accumulated: 0.1542, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0432, Accumulated: 0.1974, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7940, Accumulated: 0.9914, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1108, Accumulated: 0.1108, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0363, Accumulated: 0.1471, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0265, Accumulated: 0.1736, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0189, Accumulated: 0.1925, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0188, Accumulated: 0.2113, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0156, Accumulated: 0.2269, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0295, Accumulated: 0.2564, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0661, Accumulated: 0.3225, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0826, Accumulated: 0.4051, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1064, Accumulated: 0.5115, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1465, Accumulated: 0.6579, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1697, Accumulated: 0.8276, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0952, Accumulated: 0.9228, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0099, Accumulated: 0.0099, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0081, Accumulated: 0.0180, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0090, Accumulated: 0.0270, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1076, Accumulated: 0.1346, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0408, Accumulated: 0.1754, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0146, Accumulated: 0.1900, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0352, Accumulated: 0.2252, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0082, Accumulated: 0.2334, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0095, Accumulated: 0.2429, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7264, Accumulated: 0.9693, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0304, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2036, Accumulated: 0.2036, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0805, Accumulated: 0.2842, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0394, Accumulated: 0.3235, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0379, Accumulated: 0.3614, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0323, Accumulated: 0.3937, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0391, Accumulated: 0.4328, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0416, Accumulated: 0.4744, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0828, Accumulated: 0.5573, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0946, Accumulated: 0.6518, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1036, Accumulated: 0.7554, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1136, Accumulated: 0.8691, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0712, Accumulated: 0.9402, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0262, Accumulated: 0.9664, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0122, Accumulated: 0.0201, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0076, Accumulated: 0.0277, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0170, Accumulated: 0.0446, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0106, Accumulated: 0.0553, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0082, Accumulated: 0.0635, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0109, Accumulated: 0.0744, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.3729, Accumulated: 0.4473, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1327, Accumulated: 0.5799, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.4186, Accumulated: 0.9986, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1725, Accumulated: 0.1725, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0946, Accumulated: 0.2670, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0524, Accumulated: 0.3194, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0375, Accumulated: 0.3569, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0297, Accumulated: 0.3866, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0301, Accumulated: 0.4166, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0424, Accumulated: 0.4591, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0725, Accumulated: 0.5316, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1282, Accumulated: 0.6598, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1068, Accumulated: 0.7666, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1125, Accumulated: 0.8791, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0734, Accumulated: 0.9526, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0277, Accumulated: 0.9802, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0144, Accumulated: 0.0144, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0066, Accumulated: 0.0210, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0087, Accumulated: 0.0297, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0360, Accumulated: 0.0657, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0098, Accumulated: 0.0755, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0069, Accumulated: 0.0824, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0107, Accumulated: 0.0931, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0855, Accumulated: 0.1786, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0962, Accumulated: 0.2748, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7181, Accumulated: 0.9929, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1553, Accumulated: 0.1553, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0619, Accumulated: 0.2172, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0408, Accumulated: 0.2580, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0364, Accumulated: 0.2944, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0352, Accumulated: 0.3296, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0406, Accumulated: 0.3702, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0456, Accumulated: 0.4158, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0952, Accumulated: 0.5110, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0994, Accumulated: 0.6105, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1195, Accumulated: 0.7300, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1113, Accumulated: 0.8413, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0837, Accumulated: 0.9251, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0429, Accumulated: 0.9680, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0093, Accumulated: 0.0093, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0133, Accumulated: 0.0225, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0101, Accumulated: 0.0327, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0379, Accumulated: 0.0705, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0095, Accumulated: 0.0800, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0174, Accumulated: 0.0975, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0201, Accumulated: 0.1176, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0741, Accumulated: 0.1917, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0478, Accumulated: 0.2395, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7412, Accumulated: 0.9807, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0192, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1168, Accumulated: 0.1168, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0434, Accumulated: 0.1603, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0217, Accumulated: 0.1819, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0162, Accumulated: 0.1982, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0162, Accumulated: 0.2144, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0206, Accumulated: 0.2350, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0305, Accumulated: 0.2655, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0816, Accumulated: 0.3471, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1336, Accumulated: 0.4807, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1695, Accumulated: 0.6502, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1744, Accumulated: 0.8246, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1282, Accumulated: 0.9528, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0326, Accumulated: 0.9854, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0126, Accumulated: 0.0126, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0126, Accumulated: 0.0252, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0136, Accumulated: 0.0388, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0306, Accumulated: 0.0694, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0244, Accumulated: 0.0938, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0064, Accumulated: 0.1002, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0136, Accumulated: 0.1138, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0346, Accumulated: 0.1484, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0264, Accumulated: 0.1747, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8176, Accumulated: 0.9923, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2112, Accumulated: 0.2112, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0881, Accumulated: 0.2992, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0519, Accumulated: 0.3512, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0388, Accumulated: 0.3900, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.4215, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0347, Accumulated: 0.4562, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0434, Accumulated: 0.4997, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0838, Accumulated: 0.5835, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1152, Accumulated: 0.6987, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1056, Accumulated: 0.8043, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0861, Accumulated: 0.8905, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0553, Accumulated: 0.9458, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0250, Accumulated: 0.9708, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0337, Accumulated: 0.0337, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0812, Accumulated: 0.1149, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0103, Accumulated: 0.1252, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0161, Accumulated: 0.1412, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0086, Accumulated: 0.1498, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0112, Accumulated: 0.1610, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0051, Accumulated: 0.1661, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1921, Accumulated: 0.3582, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1518, Accumulated: 0.5100, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.4881, Accumulated: 0.9981, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1500, Accumulated: 0.1500, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0714, Accumulated: 0.2214, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0255, Accumulated: 0.2469, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0239, Accumulated: 0.2708, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0238, Accumulated: 0.2946, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0280, Accumulated: 0.3226, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0294, Accumulated: 0.3521, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0839, Accumulated: 0.4360, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1363, Accumulated: 0.5723, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1413, Accumulated: 0.7136, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1249, Accumulated: 0.8385, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0992, Accumulated: 0.9377, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0364, Accumulated: 0.9740, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0130, Accumulated: 0.0130, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0558, Accumulated: 0.0689, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0829, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0202, Accumulated: 0.1031, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0145, Accumulated: 0.1176, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0091, Accumulated: 0.1267, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0142, Accumulated: 0.1409, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.4807, Accumulated: 0.6216, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.2254, Accumulated: 0.8470, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1528, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1250, Accumulated: 0.1250, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0538, Accumulated: 0.1788, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0391, Accumulated: 0.2179, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0328, Accumulated: 0.2507, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0286, Accumulated: 0.2793, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0262, Accumulated: 0.3055, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0293, Accumulated: 0.3348, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0570, Accumulated: 0.3917, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1039, Accumulated: 0.4956, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1377, Accumulated: 0.6333, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1722, Accumulated: 0.8054, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1207, Accumulated: 0.9262, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0441, Accumulated: 0.9703, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0118, Accumulated: 0.0118, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0210, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0109, Accumulated: 0.0319, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0380, Accumulated: 0.0698, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0217, Accumulated: 0.0915, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0106, Accumulated: 0.1021, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0264, Accumulated: 0.1285, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0172, Accumulated: 0.1457, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0318, Accumulated: 0.1776, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7939, Accumulated: 0.9715, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0285, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1592, Accumulated: 0.1592, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0419, Accumulated: 0.2010, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0329, Accumulated: 0.2339, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0314, Accumulated: 0.2653, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0184, Accumulated: 0.2837, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0259, Accumulated: 0.3096, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0376, Accumulated: 0.3472, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0708, Accumulated: 0.4181, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1213, Accumulated: 0.5393, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1290, Accumulated: 0.6683, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1323, Accumulated: 0.8006, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1129, Accumulated: 0.9136, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0455, Accumulated: 0.9591, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0291, Accumulated: 0.0291, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0269, Accumulated: 0.0560, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0150, Accumulated: 0.0711, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0075, Accumulated: 0.0785, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0066, Accumulated: 0.0851, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0043, Accumulated: 0.0894, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0291, Accumulated: 0.1186, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1191, Accumulated: 0.2377, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1843, Accumulated: 0.4220, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5743, Accumulated: 0.9963, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0853, Accumulated: 0.0853, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0367, Accumulated: 0.1220, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0157, Accumulated: 0.1377, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0151, Accumulated: 0.1528, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0138, Accumulated: 0.1666, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0216, Accumulated: 0.1882, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0355, Accumulated: 0.2237, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1018, Accumulated: 0.3255, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1353, Accumulated: 0.4608, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1497, Accumulated: 0.6104, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1715, Accumulated: 0.7819, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1284, Accumulated: 0.9103, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0549, Accumulated: 0.9652, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0193, Accumulated: 0.0193, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0126, Accumulated: 0.0319, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0141, Accumulated: 0.0460, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0076, Accumulated: 0.0536, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0231, Accumulated: 0.0767, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0171, Accumulated: 0.0939, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0373, Accumulated: 0.1312, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.3404, Accumulated: 0.4716, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1673, Accumulated: 0.6389, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.3551, Accumulated: 0.9940, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2482, Accumulated: 0.2482, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1050, Accumulated: 0.3532, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0685, Accumulated: 0.4216, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0545, Accumulated: 0.4761, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0456, Accumulated: 0.5217, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0502, Accumulated: 0.5719, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0537, Accumulated: 0.6256, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0745, Accumulated: 0.7001, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0950, Accumulated: 0.7950, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0809, Accumulated: 0.8759, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0588, Accumulated: 0.9347, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0349, Accumulated: 0.9696, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0133, Accumulated: 0.9828, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0144, Accumulated: 0.0144, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0193, Accumulated: 0.0336, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0094, Accumulated: 0.0431, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0282, Accumulated: 0.0713, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0067, Accumulated: 0.0780, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0061, Accumulated: 0.0841, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0754, Accumulated: 0.1595, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0210, Accumulated: 0.1805, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0163, Accumulated: 0.1969, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7910, Accumulated: 0.9878, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0121, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0925, Accumulated: 0.0925, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0325, Accumulated: 0.1250, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0216, Accumulated: 0.1466, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0188, Accumulated: 0.1654, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0217, Accumulated: 0.1871, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0236, Accumulated: 0.2107, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0300, Accumulated: 0.2407, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0538, Accumulated: 0.2945, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1040, Accumulated: 0.3985, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1687, Accumulated: 0.5672, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1997, Accumulated: 0.7669, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1700, Accumulated: 0.9370, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0425, Accumulated: 0.9794, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0146, Accumulated: 0.0146, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0127, Accumulated: 0.0273, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0094, Accumulated: 0.0367, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0063, Accumulated: 0.0431, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0206, Accumulated: 0.0637, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0155, Accumulated: 0.0791, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0074, Accumulated: 0.0865, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0421, Accumulated: 0.1286, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0881, Accumulated: 0.2168, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7806, Accumulated: 0.9973, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1754, Accumulated: 0.1754, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0644, Accumulated: 0.2398, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0470, Accumulated: 0.2868, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0423, Accumulated: 0.3291, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0469, Accumulated: 0.3760, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0493, Accumulated: 0.4253, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0325, Accumulated: 0.4578, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0810, Accumulated: 0.5387, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1119, Accumulated: 0.6507, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1275, Accumulated: 0.7782, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1161, Accumulated: 0.8943, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0697, Accumulated: 0.9640, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0236, Accumulated: 0.9876, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0147, Accumulated: 0.0147, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0091, Accumulated: 0.0239, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0125, Accumulated: 0.0364, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0296, Accumulated: 0.0660, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0112, Accumulated: 0.0771, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0190, Accumulated: 0.0961, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0186, Accumulated: 0.1147, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1052, Accumulated: 0.2199, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0539, Accumulated: 0.2739, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7226, Accumulated: 0.9965, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0679, Accumulated: 0.0679, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0396, Accumulated: 0.1075, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0185, Accumulated: 0.1260, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0187, Accumulated: 0.1448, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0199, Accumulated: 0.1647, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0238, Accumulated: 0.1885, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0277, Accumulated: 0.2162, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0542, Accumulated: 0.2704, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0982, Accumulated: 0.3686, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1353, Accumulated: 0.5039, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1854, Accumulated: 0.6893, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1960, Accumulated: 0.8853, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0699, Accumulated: 0.9553, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0064, Accumulated: 0.0064, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0078, Accumulated: 0.0141, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0124, Accumulated: 0.0266, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0464, Accumulated: 0.0730, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0172, Accumulated: 0.0901, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0290, Accumulated: 0.1191, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0190, Accumulated: 0.1381, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1497, Accumulated: 0.2878, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1071, Accumulated: 0.3949, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6015, Accumulated: 0.9965, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2368, Accumulated: 0.2368, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0792, Accumulated: 0.3161, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0394, Accumulated: 0.3554, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0424, Accumulated: 0.3978, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0282, Accumulated: 0.4260, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0333, Accumulated: 0.4593, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0321, Accumulated: 0.4914, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0614, Accumulated: 0.5528, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0837, Accumulated: 0.6365, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1267, Accumulated: 0.7632, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1037, Accumulated: 0.8669, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0733, Accumulated: 0.9402, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0277, Accumulated: 0.9679, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0120, Accumulated: 0.0120, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0116, Accumulated: 0.0236, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0081, Accumulated: 0.0317, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0388, Accumulated: 0.0705, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0094, Accumulated: 0.0799, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0154, Accumulated: 0.0953, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0216, Accumulated: 0.1169, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0697, Accumulated: 0.1866, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0753, Accumulated: 0.2619, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7323, Accumulated: 0.9942, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0889, Accumulated: 0.0889, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0500, Accumulated: 0.1389, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0447, Accumulated: 0.1836, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0394, Accumulated: 0.2230, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0373, Accumulated: 0.2603, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0266, Accumulated: 0.2869, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0323, Accumulated: 0.3192, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0993, Accumulated: 0.4185, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1461, Accumulated: 0.5646, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1573, Accumulated: 0.7219, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1359, Accumulated: 0.8578, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0933, Accumulated: 0.9511, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0313, Accumulated: 0.9825, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0091, Accumulated: 0.0091, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0083, Accumulated: 0.0174, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0065, Accumulated: 0.0239, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0135, Accumulated: 0.0374, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0105, Accumulated: 0.0480, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.0619, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0055, Accumulated: 0.0673, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2921, Accumulated: 0.3595, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1722, Accumulated: 0.5316, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.4670, Accumulated: 0.9986, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1267, Accumulated: 0.1267, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0530, Accumulated: 0.1797, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0367, Accumulated: 0.2165, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0327, Accumulated: 0.2492, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0324, Accumulated: 0.2816, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0456, Accumulated: 0.3273, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0350, Accumulated: 0.3622, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0756, Accumulated: 0.4379, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1209, Accumulated: 0.5588, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1176, Accumulated: 0.6764, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1431, Accumulated: 0.8195, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1162, Accumulated: 0.9357, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0408, Accumulated: 0.9765, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0150, Accumulated: 0.0150, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0320, Accumulated: 0.0470, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0208, Accumulated: 0.0677, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0075, Accumulated: 0.0752, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0144, Accumulated: 0.0896, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0176, Accumulated: 0.1072, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0140, Accumulated: 0.1212, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2323, Accumulated: 0.3536, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1152, Accumulated: 0.4688, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5278, Accumulated: 0.9966, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2069, Accumulated: 0.2069, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0877, Accumulated: 0.2946, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0426, Accumulated: 0.3372, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0407, Accumulated: 0.3779, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0329, Accumulated: 0.4108, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0359, Accumulated: 0.4467, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0355, Accumulated: 0.4822, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0767, Accumulated: 0.5589, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1095, Accumulated: 0.6684, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1210, Accumulated: 0.7895, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0985, Accumulated: 0.8880, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0654, Accumulated: 0.9534, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0235, Accumulated: 0.9769, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0116, Accumulated: 0.0116, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0225, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0054, Accumulated: 0.0279, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0457, Accumulated: 0.0736, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.0827, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0098, Accumulated: 0.0924, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0229, Accumulated: 0.1153, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0308, Accumulated: 0.1462, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0129, Accumulated: 0.1590, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8323, Accumulated: 0.9914, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1210, Accumulated: 0.1210, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0467, Accumulated: 0.1677, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0241, Accumulated: 0.1918, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0325, Accumulated: 0.2243, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0259, Accumulated: 0.2502, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0280, Accumulated: 0.2782, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0378, Accumulated: 0.3160, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0992, Accumulated: 0.4152, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1135, Accumulated: 0.5287, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1292, Accumulated: 0.6579, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1307, Accumulated: 0.7886, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1353, Accumulated: 0.9239, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0499, Accumulated: 0.9738, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0232, Accumulated: 0.0232, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0191, Accumulated: 0.0423, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0174, Accumulated: 0.0597, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0094, Accumulated: 0.0691, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0193, Accumulated: 0.0884, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0113, Accumulated: 0.0997, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0076, Accumulated: 0.1073, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0295, Accumulated: 0.1368, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0518, Accumulated: 0.1886, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7979, Accumulated: 0.9865, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0134, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2246, Accumulated: 0.2246, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0841, Accumulated: 0.3087, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0550, Accumulated: 0.3637, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0284, Accumulated: 0.3920, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0231, Accumulated: 0.4151, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0254, Accumulated: 0.4405, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0268, Accumulated: 0.4673, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0784, Accumulated: 0.5456, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1225, Accumulated: 0.6681, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1243, Accumulated: 0.7924, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1041, Accumulated: 0.8965, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0630, Accumulated: 0.9595, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0234, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0205, Accumulated: 0.0205, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0129, Accumulated: 0.0334, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0111, Accumulated: 0.0445, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0362, Accumulated: 0.0807, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0049, Accumulated: 0.0856, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0109, Accumulated: 0.0966, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0229, Accumulated: 0.1194, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0227, Accumulated: 0.1421, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0146, Accumulated: 0.1567, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7552, Accumulated: 0.9119, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0875, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1545, Accumulated: 0.1545, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0560, Accumulated: 0.2105, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0380, Accumulated: 0.2485, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0367, Accumulated: 0.2852, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0290, Accumulated: 0.3142, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0370, Accumulated: 0.3512, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0429, Accumulated: 0.3941, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0987, Accumulated: 0.4928, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1410, Accumulated: 0.6338, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1300, Accumulated: 0.7638, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1119, Accumulated: 0.8757, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0733, Accumulated: 0.9490, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0302, Accumulated: 0.9792, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0116, Accumulated: 0.0116, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0097, Accumulated: 0.0213, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0056, Accumulated: 0.0269, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0311, Accumulated: 0.0580, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0070, Accumulated: 0.0650, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0155, Accumulated: 0.0805, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0081, Accumulated: 0.0886, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1470, Accumulated: 0.2355, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0638, Accumulated: 0.2994, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6876, Accumulated: 0.9870, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0130, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1636, Accumulated: 0.1636, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0773, Accumulated: 0.2409, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0437, Accumulated: 0.2846, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0366, Accumulated: 0.3212, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0365, Accumulated: 0.3576, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0446, Accumulated: 0.4022, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0629, Accumulated: 0.4651, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1068, Accumulated: 0.5719, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1288, Accumulated: 0.7006, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1126, Accumulated: 0.8133, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0827, Accumulated: 0.8960, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0572, Accumulated: 0.9532, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0240, Accumulated: 0.9773, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0220, Accumulated: 0.0220, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0095, Accumulated: 0.0315, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0072, Accumulated: 0.0387, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0660, Accumulated: 0.1046, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0107, Accumulated: 0.1153, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0276, Accumulated: 0.1429, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0081, Accumulated: 0.1510, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0591, Accumulated: 0.2101, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0303, Accumulated: 0.2404, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7499, Accumulated: 0.9904, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1714, Accumulated: 0.1714, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0622, Accumulated: 0.2336, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0564, Accumulated: 0.2900, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0538, Accumulated: 0.3438, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0429, Accumulated: 0.3867, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0400, Accumulated: 0.4267, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0420, Accumulated: 0.4687, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1007, Accumulated: 0.5694, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1243, Accumulated: 0.6936, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1019, Accumulated: 0.7955, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0893, Accumulated: 0.8848, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0659, Accumulated: 0.9507, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0272, Accumulated: 0.9779, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0110, Accumulated: 0.0110, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0240, Accumulated: 0.0350, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0128, Accumulated: 0.0478, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0103, Accumulated: 0.0580, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0098, Accumulated: 0.0679, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0137, Accumulated: 0.0816, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0074, Accumulated: 0.0891, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0537, Accumulated: 0.1427, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0997, Accumulated: 0.2425, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7490, Accumulated: 0.9915, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2015, Accumulated: 0.2015, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0631, Accumulated: 0.2646, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0288, Accumulated: 0.2934, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0232, Accumulated: 0.3166, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0178, Accumulated: 0.3344, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0263, Accumulated: 0.3607, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0330, Accumulated: 0.3937, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0797, Accumulated: 0.4734, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1115, Accumulated: 0.5849, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1301, Accumulated: 0.7150, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1245, Accumulated: 0.8395, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0912, Accumulated: 0.9307, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0372, Accumulated: 0.9679, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0198, Accumulated: 0.0198, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0077, Accumulated: 0.0275, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0185, Accumulated: 0.0460, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0190, Accumulated: 0.0650, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0070, Accumulated: 0.0720, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0103, Accumulated: 0.0822, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0106, Accumulated: 0.0929, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0500, Accumulated: 0.1428, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0805, Accumulated: 0.2233, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7596, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0170, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1013, Accumulated: 0.1013, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0480, Accumulated: 0.1493, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0426, Accumulated: 0.1920, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0363, Accumulated: 0.2283, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0379, Accumulated: 0.2661, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0412, Accumulated: 0.3073, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0366, Accumulated: 0.3439, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0806, Accumulated: 0.4245, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1371, Accumulated: 0.5616, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1570, Accumulated: 0.7186, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1486, Accumulated: 0.8673, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0955, Accumulated: 0.9628, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0245, Accumulated: 0.9873, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0153, Accumulated: 0.0153, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0124, Accumulated: 0.0276, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0066, Accumulated: 0.0342, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0434, Accumulated: 0.0777, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0042, Accumulated: 0.0819, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0075, Accumulated: 0.0894, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0124, Accumulated: 0.1018, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0084, Accumulated: 0.1102, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0165, Accumulated: 0.1267, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8490, Accumulated: 0.9757, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0243, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1733, Accumulated: 0.1733, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0583, Accumulated: 0.2316, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0400, Accumulated: 0.2716, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0417, Accumulated: 0.3133, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0328, Accumulated: 0.3461, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0311, Accumulated: 0.3771, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0324, Accumulated: 0.4095, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1044, Accumulated: 0.5139, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1444, Accumulated: 0.6583, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1269, Accumulated: 0.7852, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1238, Accumulated: 0.9090, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0591, Accumulated: 0.9681, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0187, Accumulated: 0.9868, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0135, Accumulated: 0.0135, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0311, Accumulated: 0.0446, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0065, Accumulated: 0.0512, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0072, Accumulated: 0.0584, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0120, Accumulated: 0.0704, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0132, Accumulated: 0.0837, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0352, Accumulated: 0.1188, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0596, Accumulated: 0.1784, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1108, Accumulated: 0.2892, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6993, Accumulated: 0.9885, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0114, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1810, Accumulated: 0.1810, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0725, Accumulated: 0.2536, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0344, Accumulated: 0.2879, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0220, Accumulated: 0.3100, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0140, Accumulated: 0.3240, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0213, Accumulated: 0.3453, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0396, Accumulated: 0.3849, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0823, Accumulated: 0.4672, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1298, Accumulated: 0.5969, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1473, Accumulated: 0.7443, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1427, Accumulated: 0.8870, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0819, Accumulated: 0.9689, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0232, Accumulated: 0.9921, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0138, Accumulated: 0.0138, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0153, Accumulated: 0.0291, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0062, Accumulated: 0.0353, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0516, Accumulated: 0.0870, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0056, Accumulated: 0.0925, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0147, Accumulated: 0.1072, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0315, Accumulated: 0.1387, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.3709, Accumulated: 0.5096, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1109, Accumulated: 0.6205, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.3775, Accumulated: 0.9980, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1190, Accumulated: 0.1190, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0375, Accumulated: 0.1565, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0301, Accumulated: 0.1866, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0246, Accumulated: 0.2111, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0171, Accumulated: 0.2283, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0320, Accumulated: 0.2602, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0269, Accumulated: 0.2871, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0489, Accumulated: 0.3361, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0772, Accumulated: 0.4133, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1181, Accumulated: 0.5314, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.2218, Accumulated: 0.7532, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1836, Accumulated: 0.9369, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0470, Accumulated: 0.9839, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0257, Accumulated: 0.0257, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0348, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0055, Accumulated: 0.0404, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0246, Accumulated: 0.0650, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0721, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0345, Accumulated: 0.1067, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0123, Accumulated: 0.1190, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0450, Accumulated: 0.1640, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0490, Accumulated: 0.2130, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7685, Accumulated: 0.9816, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0184, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1534, Accumulated: 0.1534, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0517, Accumulated: 0.2051, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0402, Accumulated: 0.2453, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0331, Accumulated: 0.2784, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0245, Accumulated: 0.3029, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0282, Accumulated: 0.3311, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0236, Accumulated: 0.3547, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0684, Accumulated: 0.4231, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1085, Accumulated: 0.5317, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1464, Accumulated: 0.6780, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1665, Accumulated: 0.8445, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1032, Accumulated: 0.9477, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0346, Accumulated: 0.9823, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0128, Accumulated: 0.0128, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0081, Accumulated: 0.0209, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0067, Accumulated: 0.0276, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0362, Accumulated: 0.0638, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0106, Accumulated: 0.0744, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0107, Accumulated: 0.0851, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0065, Accumulated: 0.0916, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1363, Accumulated: 0.2278, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0660, Accumulated: 0.2939, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6944, Accumulated: 0.9883, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0117, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1311, Accumulated: 0.1311, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0592, Accumulated: 0.1903, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0430, Accumulated: 0.2333, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0405, Accumulated: 0.2738, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0398, Accumulated: 0.3136, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0412, Accumulated: 0.3549, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0348, Accumulated: 0.3896, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0666, Accumulated: 0.4563, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1361, Accumulated: 0.5923, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1329, Accumulated: 0.7252, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1319, Accumulated: 0.8571, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0900, Accumulated: 0.9471, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0330, Accumulated: 0.9801, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0193, Accumulated: 0.0193, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0173, Accumulated: 0.0366, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0099, Accumulated: 0.0465, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0102, Accumulated: 0.0568, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0218, Accumulated: 0.0786, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0067, Accumulated: 0.0853, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0118, Accumulated: 0.0971, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1232, Accumulated: 0.2203, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1172, Accumulated: 0.3375, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6531, Accumulated: 0.9906, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2136, Accumulated: 0.2136, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0829, Accumulated: 0.2966, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0503, Accumulated: 0.3468, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0357, Accumulated: 0.3825, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0259, Accumulated: 0.4084, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0347, Accumulated: 0.4431, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0359, Accumulated: 0.4790, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0925, Accumulated: 0.5715, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1383, Accumulated: 0.7098, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1153, Accumulated: 0.8251, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0858, Accumulated: 0.9109, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0529, Accumulated: 0.9639, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0211, Accumulated: 0.9849, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0127, Accumulated: 0.0127, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0367, Accumulated: 0.0493, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0116, Accumulated: 0.0609, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0100, Accumulated: 0.0709, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0070, Accumulated: 0.0779, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0664, Accumulated: 0.1443, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0069, Accumulated: 0.1512, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0955, Accumulated: 0.2467, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1129, Accumulated: 0.3596, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6369, Accumulated: 0.9966, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2167, Accumulated: 0.2167, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0954, Accumulated: 0.3121, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0553, Accumulated: 0.3674, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0485, Accumulated: 0.4160, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0313, Accumulated: 0.4473, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0414, Accumulated: 0.4886, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0484, Accumulated: 0.5370, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0912, Accumulated: 0.6282, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1130, Accumulated: 0.7412, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0850, Accumulated: 0.8262, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0916, Accumulated: 0.9179, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0487, Accumulated: 0.9666, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0157, Accumulated: 0.9823, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0095, Accumulated: 0.0095, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0090, Accumulated: 0.0185, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0060, Accumulated: 0.0245, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0384, Accumulated: 0.0630, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0065, Accumulated: 0.0695, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0164, Accumulated: 0.0859, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0155, Accumulated: 0.1014, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1037, Accumulated: 0.2051, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0781, Accumulated: 0.2832, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7126, Accumulated: 0.9958, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1458, Accumulated: 0.1458, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0600, Accumulated: 0.2058, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0310, Accumulated: 0.2367, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0249, Accumulated: 0.2616, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0204, Accumulated: 0.2820, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0222, Accumulated: 0.3042, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0330, Accumulated: 0.3372, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0952, Accumulated: 0.4324, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1497, Accumulated: 0.5821, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1703, Accumulated: 0.7524, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1314, Accumulated: 0.8838, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0730, Accumulated: 0.9568, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0260, Accumulated: 0.9828, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0099, Accumulated: 0.0099, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0742, Accumulated: 0.0841, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0125, Accumulated: 0.0966, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0065, Accumulated: 0.1031, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0101, Accumulated: 0.1132, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0406, Accumulated: 0.1538, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0089, Accumulated: 0.1627, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0524, Accumulated: 0.2151, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0336, Accumulated: 0.2487, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7374, Accumulated: 0.9861, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0138, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1227, Accumulated: 0.1227, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0508, Accumulated: 0.1736, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0356, Accumulated: 0.2092, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0268, Accumulated: 0.2360, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0256, Accumulated: 0.2616, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0343, Accumulated: 0.2959, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0340, Accumulated: 0.3299, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0933, Accumulated: 0.4233, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1538, Accumulated: 0.5770, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1610, Accumulated: 0.7380, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1376, Accumulated: 0.8757, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0830, Accumulated: 0.9587, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0247, Accumulated: 0.9834, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0106, Accumulated: 0.0106, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0160, Accumulated: 0.0266, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0130, Accumulated: 0.0396, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0110, Accumulated: 0.0506, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0080, Accumulated: 0.0586, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0104, Accumulated: 0.0690, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0102, Accumulated: 0.0792, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2040, Accumulated: 0.2832, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1815, Accumulated: 0.4647, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5343, Accumulated: 0.9990, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2234, Accumulated: 0.2234, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0915, Accumulated: 0.3149, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0600, Accumulated: 0.3749, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0472, Accumulated: 0.4221, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0338, Accumulated: 0.4559, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0379, Accumulated: 0.4938, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0399, Accumulated: 0.5337, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0766, Accumulated: 0.6102, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1238, Accumulated: 0.7340, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1097, Accumulated: 0.8438, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0792, Accumulated: 0.9230, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0451, Accumulated: 0.9681, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0175, Accumulated: 0.9856, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0102, Accumulated: 0.0102, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0182, Accumulated: 0.0284, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0062, Accumulated: 0.0346, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0117, Accumulated: 0.0463, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0053, Accumulated: 0.0517, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0098, Accumulated: 0.0615, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0252, Accumulated: 0.0867, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0137, Accumulated: 0.1003, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0152, Accumulated: 0.1156, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8767, Accumulated: 0.9922, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2306, Accumulated: 0.2306, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0895, Accumulated: 0.3201, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0517, Accumulated: 0.3717, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0419, Accumulated: 0.4136, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0322, Accumulated: 0.4459, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0418, Accumulated: 0.4876, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0495, Accumulated: 0.5371, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1006, Accumulated: 0.6378, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1154, Accumulated: 0.7532, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0937, Accumulated: 0.8469, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0698, Accumulated: 0.9167, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0433, Accumulated: 0.9600, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0176, Accumulated: 0.9776, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0123, Accumulated: 0.0123, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0246, Accumulated: 0.0369, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0121, Accumulated: 0.0489, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0254, Accumulated: 0.0743, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0080, Accumulated: 0.0823, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0086, Accumulated: 0.0909, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.1146, Accumulated: 0.2055, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0196, Accumulated: 0.2251, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0056, Accumulated: 0.2307, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7562, Accumulated: 0.9869, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0131, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2487, Accumulated: 0.2487, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1063, Accumulated: 0.3550, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0781, Accumulated: 0.4330, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0470, Accumulated: 0.4800, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0459, Accumulated: 0.5259, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0515, Accumulated: 0.5774, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0447, Accumulated: 0.6222, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0743, Accumulated: 0.6965, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0816, Accumulated: 0.7781, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0669, Accumulated: 0.8449, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0751, Accumulated: 0.9200, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0546, Accumulated: 0.9746, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0160, Accumulated: 0.9906, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0152, Accumulated: 0.0152, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0072, Accumulated: 0.0224, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0138, Accumulated: 0.0361, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0688, Accumulated: 0.1049, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0117, Accumulated: 0.1166, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0100, Accumulated: 0.1266, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0094, Accumulated: 0.1360, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2567, Accumulated: 0.3927, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1205, Accumulated: 0.5132, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.4815, Accumulated: 0.9948, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1115, Accumulated: 0.1115, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0525, Accumulated: 0.1639, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0478, Accumulated: 0.2117, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0410, Accumulated: 0.2527, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0323, Accumulated: 0.2850, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0369, Accumulated: 0.3220, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0431, Accumulated: 0.3651, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0775, Accumulated: 0.4426, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1298, Accumulated: 0.5723, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1300, Accumulated: 0.7023, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1366, Accumulated: 0.8390, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0984, Accumulated: 0.9374, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0394, Accumulated: 0.9768, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0197, Accumulated: 0.0197, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0119, Accumulated: 0.0315, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0064, Accumulated: 0.0379, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0349, Accumulated: 0.0728, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0131, Accumulated: 0.0859, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0059, Accumulated: 0.0919, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0369, Accumulated: 0.1288, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0294, Accumulated: 0.1582, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0213, Accumulated: 0.1795, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7964, Accumulated: 0.9760, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0239, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2094, Accumulated: 0.2094, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0821, Accumulated: 0.2915, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0487, Accumulated: 0.3402, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0370, Accumulated: 0.3772, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0308, Accumulated: 0.4080, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0421, Accumulated: 0.4501, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0618, Accumulated: 0.5118, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0861, Accumulated: 0.5979, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1167, Accumulated: 0.7146, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1054, Accumulated: 0.8201, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0863, Accumulated: 0.9064, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0560, Accumulated: 0.9624, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0198, Accumulated: 0.9822, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0131, Accumulated: 0.0131, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0088, Accumulated: 0.0219, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0191, Accumulated: 0.0409, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0298, Accumulated: 0.0708, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0070, Accumulated: 0.0777, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0105, Accumulated: 0.0883, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0237, Accumulated: 0.1119, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0387, Accumulated: 0.1506, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0366, Accumulated: 0.1872, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8052, Accumulated: 0.9925, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1798, Accumulated: 0.1798, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0757, Accumulated: 0.2555, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0420, Accumulated: 0.2975, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0321, Accumulated: 0.3296, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0250, Accumulated: 0.3547, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0476, Accumulated: 0.4023, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0677, Accumulated: 0.4700, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1238, Accumulated: 0.5937, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1399, Accumulated: 0.7336, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1138, Accumulated: 0.8474, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0808, Accumulated: 0.9282, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0463, Accumulated: 0.9745, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0144, Accumulated: 0.9889, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0073, Accumulated: 0.0073, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0101, Accumulated: 0.0174, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0103, Accumulated: 0.0277, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0241, Accumulated: 0.0518, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0100, Accumulated: 0.0618, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0290, Accumulated: 0.0908, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0233, Accumulated: 0.1142, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1582, Accumulated: 0.2724, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1315, Accumulated: 0.4039, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5940, Accumulated: 0.9980, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2407, Accumulated: 0.2407, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0955, Accumulated: 0.3362, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0655, Accumulated: 0.4017, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0466, Accumulated: 0.4483, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0352, Accumulated: 0.4835, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0393, Accumulated: 0.5228, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0461, Accumulated: 0.5690, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0869, Accumulated: 0.6558, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1015, Accumulated: 0.7573, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0901, Accumulated: 0.8474, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0692, Accumulated: 0.9166, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0441, Accumulated: 0.9607, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0188, Accumulated: 0.9795, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0086, Accumulated: 0.0086, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0124, Accumulated: 0.0210, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0111, Accumulated: 0.0321, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0377, Accumulated: 0.0697, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0277, Accumulated: 0.0974, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0067, Accumulated: 0.1041, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0094, Accumulated: 0.1135, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0095, Accumulated: 0.1230, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0215, Accumulated: 0.1445, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8484, Accumulated: 0.9929, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1138, Accumulated: 0.1138, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0510, Accumulated: 0.1648, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0596, Accumulated: 0.2244, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0334, Accumulated: 0.2578, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0261, Accumulated: 0.2839, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0368, Accumulated: 0.3208, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0402, Accumulated: 0.3609, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0753, Accumulated: 0.4362, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1035, Accumulated: 0.5397, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1600, Accumulated: 0.6997, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1520, Accumulated: 0.8518, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0849, Accumulated: 0.9367, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0357, Accumulated: 0.9724, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0133, Accumulated: 0.0133, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0150, Accumulated: 0.0283, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0103, Accumulated: 0.0386, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0820, Accumulated: 0.1206, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0118, Accumulated: 0.1324, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0338, Accumulated: 0.1662, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0140, Accumulated: 0.1802, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0965, Accumulated: 0.2767, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0652, Accumulated: 0.3419, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6475, Accumulated: 0.9894, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0105, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1146, Accumulated: 0.1146, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0645, Accumulated: 0.1791, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0267, Accumulated: 0.2057, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0191, Accumulated: 0.2248, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0206, Accumulated: 0.2454, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0328, Accumulated: 0.2782, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0411, Accumulated: 0.3194, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0997, Accumulated: 0.4191, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1396, Accumulated: 0.5586, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0946, Accumulated: 0.6532, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1313, Accumulated: 0.7845, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1303, Accumulated: 0.9149, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0522, Accumulated: 0.9671, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0207, Accumulated: 0.0207, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0298, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0130, Accumulated: 0.0428, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1054, Accumulated: 0.1482, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0057, Accumulated: 0.1539, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0107, Accumulated: 0.1645, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0083, Accumulated: 0.1729, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0114, Accumulated: 0.1842, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0210, Accumulated: 0.2053, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7773, Accumulated: 0.9825, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0174, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1302, Accumulated: 0.1302, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0682, Accumulated: 0.1985, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0460, Accumulated: 0.2445, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0395, Accumulated: 0.2839, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0342, Accumulated: 0.3181, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0258, Accumulated: 0.3440, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0268, Accumulated: 0.3708, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0651, Accumulated: 0.4359, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0881, Accumulated: 0.5239, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1072, Accumulated: 0.6311, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1343, Accumulated: 0.7654, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1123, Accumulated: 0.8777, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0666, Accumulated: 0.9443, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0126, Accumulated: 0.0126, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0066, Accumulated: 0.0193, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0133, Accumulated: 0.0326, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0420, Accumulated: 0.0746, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0068, Accumulated: 0.0814, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0108, Accumulated: 0.0922, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0166, Accumulated: 0.1087, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0392, Accumulated: 0.1479, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0241, Accumulated: 0.1720, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7682, Accumulated: 0.9402, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0597, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1497, Accumulated: 0.1497, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0411, Accumulated: 0.1908, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0168, Accumulated: 0.2076, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0181, Accumulated: 0.2256, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0166, Accumulated: 0.2423, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0161, Accumulated: 0.2583, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0238, Accumulated: 0.2821, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0844, Accumulated: 0.3665, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1522, Accumulated: 0.5187, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1838, Accumulated: 0.7025, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1623, Accumulated: 0.8648, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0788, Accumulated: 0.9435, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0310, Accumulated: 0.9746, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0162, Accumulated: 0.0162, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0101, Accumulated: 0.0263, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0118, Accumulated: 0.0381, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0128, Accumulated: 0.0509, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0099, Accumulated: 0.0608, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0205, Accumulated: 0.0813, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0389, Accumulated: 0.1202, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.5662, Accumulated: 0.6864, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0867, Accumulated: 0.7731, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.2256, Accumulated: 0.9987, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0688, Accumulated: 0.0688, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0353, Accumulated: 0.1041, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0182, Accumulated: 0.1223, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0303, Accumulated: 0.1526, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0240, Accumulated: 0.1765, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0421, Accumulated: 0.2186, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0508, Accumulated: 0.2695, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0984, Accumulated: 0.3678, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1302, Accumulated: 0.4980, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1684, Accumulated: 0.6664, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1831, Accumulated: 0.8495, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1119, Accumulated: 0.9613, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0262, Accumulated: 0.9875, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0147, Accumulated: 0.0147, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0093, Accumulated: 0.0239, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0078, Accumulated: 0.0317, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0352, Accumulated: 0.0668, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0068, Accumulated: 0.0736, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0165, Accumulated: 0.0901, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0179, Accumulated: 0.1080, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0489, Accumulated: 0.1569, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0581, Accumulated: 0.2151, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7792, Accumulated: 0.9943, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1927, Accumulated: 0.1927, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0759, Accumulated: 0.2686, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0219, Accumulated: 0.2905, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0275, Accumulated: 0.3179, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0186, Accumulated: 0.3365, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0229, Accumulated: 0.3594, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0387, Accumulated: 0.3981, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0704, Accumulated: 0.4686, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1295, Accumulated: 0.5981, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1485, Accumulated: 0.7467, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1322, Accumulated: 0.8789, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0810, Accumulated: 0.9598, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0250, Accumulated: 0.9848, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0263, Accumulated: 0.0263, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0119, Accumulated: 0.0382, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0129, Accumulated: 0.0511, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0065, Accumulated: 0.0576, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0058, Accumulated: 0.0634, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0116, Accumulated: 0.0750, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0103, Accumulated: 0.0853, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0580, Accumulated: 0.1432, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1219, Accumulated: 0.2652, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7219, Accumulated: 0.9871, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0128, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1766, Accumulated: 0.1766, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0507, Accumulated: 0.2273, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0285, Accumulated: 0.2558, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0263, Accumulated: 0.2821, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0194, Accumulated: 0.3015, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0358, Accumulated: 0.3374, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0365, Accumulated: 0.3739, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0858, Accumulated: 0.4596, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1261, Accumulated: 0.5857, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1590, Accumulated: 0.7447, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1245, Accumulated: 0.8692, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0761, Accumulated: 0.9453, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0336, Accumulated: 0.9788, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0177, Accumulated: 0.0177, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0082, Accumulated: 0.0259, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0145, Accumulated: 0.0404, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0244, Accumulated: 0.0648, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0772, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0127, Accumulated: 0.0899, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0163, Accumulated: 0.1063, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1905, Accumulated: 0.2967, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1209, Accumulated: 0.4176, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5741, Accumulated: 0.9918, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1157, Accumulated: 0.1157, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0495, Accumulated: 0.1652, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0216, Accumulated: 0.1868, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0250, Accumulated: 0.2119, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0181, Accumulated: 0.2300, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0280, Accumulated: 0.2579, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0660, Accumulated: 0.3239, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0972, Accumulated: 0.4211, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1355, Accumulated: 0.5567, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1215, Accumulated: 0.6782, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1217, Accumulated: 0.7999, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1121, Accumulated: 0.9120, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0618, Accumulated: 0.9737, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0301, Accumulated: 0.0301, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0223, Accumulated: 0.0523, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0100, Accumulated: 0.0624, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0108, Accumulated: 0.0732, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0066, Accumulated: 0.0798, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0131, Accumulated: 0.0929, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0196, Accumulated: 0.1125, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1464, Accumulated: 0.2588, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1923, Accumulated: 0.4512, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5402, Accumulated: 0.9914, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2026, Accumulated: 0.2026, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0740, Accumulated: 0.2767, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0612, Accumulated: 0.3379, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0542, Accumulated: 0.3920, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0492, Accumulated: 0.4412, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0501, Accumulated: 0.4913, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0542, Accumulated: 0.5455, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0942, Accumulated: 0.6397, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1157, Accumulated: 0.7554, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0908, Accumulated: 0.8462, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0856, Accumulated: 0.9317, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0489, Accumulated: 0.9807, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0135, Accumulated: 0.9941, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0151, Accumulated: 0.0151, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0308, Accumulated: 0.0459, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0070, Accumulated: 0.0529, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0070, Accumulated: 0.0598, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.0689, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0131, Accumulated: 0.0821, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0100, Accumulated: 0.0921, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1634, Accumulated: 0.2554, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1305, Accumulated: 0.3860, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6018, Accumulated: 0.9877, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0123, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1466, Accumulated: 0.1466, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0719, Accumulated: 0.2185, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0323, Accumulated: 0.2508, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0380, Accumulated: 0.2888, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0258, Accumulated: 0.3145, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0293, Accumulated: 0.3438, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0399, Accumulated: 0.3838, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1294, Accumulated: 0.5132, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1338, Accumulated: 0.6470, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1179, Accumulated: 0.7649, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1142, Accumulated: 0.8791, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0686, Accumulated: 0.9478, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0310, Accumulated: 0.9788, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0288, Accumulated: 0.0288, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0130, Accumulated: 0.0418, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0054, Accumulated: 0.0472, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0111, Accumulated: 0.0583, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0101, Accumulated: 0.0684, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0145, Accumulated: 0.0829, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0145, Accumulated: 0.0974, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.3451, Accumulated: 0.4425, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.2564, Accumulated: 0.6989, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.2967, Accumulated: 0.9956, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1440, Accumulated: 0.1440, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0581, Accumulated: 0.2022, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0256, Accumulated: 0.2278, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0278, Accumulated: 0.2556, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0324, Accumulated: 0.2880, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0330, Accumulated: 0.3210, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0358, Accumulated: 0.3568, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1105, Accumulated: 0.4674, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1246, Accumulated: 0.5920, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1380, Accumulated: 0.7299, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1424, Accumulated: 0.8723, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0896, Accumulated: 0.9620, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0257, Accumulated: 0.9876, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0143, Accumulated: 0.0143, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0079, Accumulated: 0.0222, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0089, Accumulated: 0.0311, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0486, Accumulated: 0.0797, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0071, Accumulated: 0.0868, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0219, Accumulated: 0.1088, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0280, Accumulated: 0.1368, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0227, Accumulated: 0.1595, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0383, Accumulated: 0.1978, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7975, Accumulated: 0.9953, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0842, Accumulated: 0.0842, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0245, Accumulated: 0.1087, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0163, Accumulated: 0.1249, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0233, Accumulated: 0.1483, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0196, Accumulated: 0.1679, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0232, Accumulated: 0.1910, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0173, Accumulated: 0.2083, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0598, Accumulated: 0.2681, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1128, Accumulated: 0.3810, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1486, Accumulated: 0.5296, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1836, Accumulated: 0.7132, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1715, Accumulated: 0.8848, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0617, Accumulated: 0.9464, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0103, Accumulated: 0.0103, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0186, Accumulated: 0.0289, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0161, Accumulated: 0.0450, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0091, Accumulated: 0.0541, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0100, Accumulated: 0.0640, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0089, Accumulated: 0.0730, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0086, Accumulated: 0.0815, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0514, Accumulated: 0.1329, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0709, Accumulated: 0.2038, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7791, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0171, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1865, Accumulated: 0.1865, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0752, Accumulated: 0.2617, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0592, Accumulated: 0.3209, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0517, Accumulated: 0.3726, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0437, Accumulated: 0.4163, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0469, Accumulated: 0.4632, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0423, Accumulated: 0.5055, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0804, Accumulated: 0.5859, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0959, Accumulated: 0.6818, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0980, Accumulated: 0.7798, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0922, Accumulated: 0.8719, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0673, Accumulated: 0.9393, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0306, Accumulated: 0.9699, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0091, Accumulated: 0.0091, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0086, Accumulated: 0.0177, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0120, Accumulated: 0.0297, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1469, Accumulated: 0.1766, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0069, Accumulated: 0.1834, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0143, Accumulated: 0.1977, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0116, Accumulated: 0.2093, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0845, Accumulated: 0.2938, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0598, Accumulated: 0.3536, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6389, Accumulated: 0.9924, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1893, Accumulated: 0.1893, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0659, Accumulated: 0.2552, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0345, Accumulated: 0.2897, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0295, Accumulated: 0.3192, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0241, Accumulated: 0.3433, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0318, Accumulated: 0.3751, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0386, Accumulated: 0.4138, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0912, Accumulated: 0.5049, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1315, Accumulated: 0.6364, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1265, Accumulated: 0.7629, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1081, Accumulated: 0.8710, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0743, Accumulated: 0.9453, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0271, Accumulated: 0.9724, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0145, Accumulated: 0.0145, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0140, Accumulated: 0.0285, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0055, Accumulated: 0.0340, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0339, Accumulated: 0.0679, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0068, Accumulated: 0.0746, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0120, Accumulated: 0.0867, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0156, Accumulated: 0.1023, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0878, Accumulated: 0.1900, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0547, Accumulated: 0.2447, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7450, Accumulated: 0.9897, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0103, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1945, Accumulated: 0.1945, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0863, Accumulated: 0.2807, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0655, Accumulated: 0.3462, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0355, Accumulated: 0.3817, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0324, Accumulated: 0.4141, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0304, Accumulated: 0.4445, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0484, Accumulated: 0.4930, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0827, Accumulated: 0.5757, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1061, Accumulated: 0.6818, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1074, Accumulated: 0.7892, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0903, Accumulated: 0.8795, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0691, Accumulated: 0.9487, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0274, Accumulated: 0.9761, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0131, Accumulated: 0.0131, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0225, Accumulated: 0.0356, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0114, Accumulated: 0.0471, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0214, Accumulated: 0.0685, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0060, Accumulated: 0.0745, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0556, Accumulated: 0.1301, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0119, Accumulated: 0.1420, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0193, Accumulated: 0.1613, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0407, Accumulated: 0.2020, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7867, Accumulated: 0.9887, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0113, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2152, Accumulated: 0.2152, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0880, Accumulated: 0.3032, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0563, Accumulated: 0.3596, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0465, Accumulated: 0.4061, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0390, Accumulated: 0.4451, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0408, Accumulated: 0.4860, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0512, Accumulated: 0.5372, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0946, Accumulated: 0.6318, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1165, Accumulated: 0.7483, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0954, Accumulated: 0.8437, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0762, Accumulated: 0.9199, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0453, Accumulated: 0.9652, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0184, Accumulated: 0.9836, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0110, Accumulated: 0.0110, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0159, Accumulated: 0.0270, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0117, Accumulated: 0.0386, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0467, Accumulated: 0.0853, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0205, Accumulated: 0.1059, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0241, Accumulated: 0.1300, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0057, Accumulated: 0.1357, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2403, Accumulated: 0.3761, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1110, Accumulated: 0.4871, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5109, Accumulated: 0.9980, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0898, Accumulated: 0.0898, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0444, Accumulated: 0.1342, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0312, Accumulated: 0.1654, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0337, Accumulated: 0.1991, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0175, Accumulated: 0.2165, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0276, Accumulated: 0.2441, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0256, Accumulated: 0.2697, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0653, Accumulated: 0.3350, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1080, Accumulated: 0.4430, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1332, Accumulated: 0.5762, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1454, Accumulated: 0.7216, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1754, Accumulated: 0.8970, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0584, Accumulated: 0.9553, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0186, Accumulated: 0.0186, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0095, Accumulated: 0.0281, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0159, Accumulated: 0.0440, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0310, Accumulated: 0.0750, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0109, Accumulated: 0.0859, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0064, Accumulated: 0.0923, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0212, Accumulated: 0.1135, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2155, Accumulated: 0.3290, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1392, Accumulated: 0.4681, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5293, Accumulated: 0.9974, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1021, Accumulated: 0.1021, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0264, Accumulated: 0.1285, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0179, Accumulated: 0.1464, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0178, Accumulated: 0.1642, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0176, Accumulated: 0.1817, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0203, Accumulated: 0.2020, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0227, Accumulated: 0.2248, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0515, Accumulated: 0.2763, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1119, Accumulated: 0.3882, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1362, Accumulated: 0.5244, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.2062, Accumulated: 0.7306, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1534, Accumulated: 0.8840, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0715, Accumulated: 0.9555, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0144, Accumulated: 0.0144, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0091, Accumulated: 0.0234, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0067, Accumulated: 0.0302, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0382, Accumulated: 0.0684, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0041, Accumulated: 0.0724, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0163, Accumulated: 0.0887, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0122, Accumulated: 0.1009, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1216, Accumulated: 0.2225, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1255, Accumulated: 0.3480, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6488, Accumulated: 0.9968, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2113, Accumulated: 0.2113, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0589, Accumulated: 0.2702, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0243, Accumulated: 0.2945, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0227, Accumulated: 0.3171, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0177, Accumulated: 0.3348, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0244, Accumulated: 0.3592, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0323, Accumulated: 0.3915, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0914, Accumulated: 0.4829, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1343, Accumulated: 0.6172, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1187, Accumulated: 0.7359, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1262, Accumulated: 0.8621, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0773, Accumulated: 0.9394, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0294, Accumulated: 0.9688, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0226, Accumulated: 0.0226, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0678, Accumulated: 0.0904, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0095, Accumulated: 0.0999, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0158, Accumulated: 0.1158, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0109, Accumulated: 0.1267, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0062, Accumulated: 0.1329, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0111, Accumulated: 0.1440, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.4806, Accumulated: 0.6247, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1559, Accumulated: 0.7805, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.2186, Accumulated: 0.9991, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2074, Accumulated: 0.2074, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0881, Accumulated: 0.2955, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0516, Accumulated: 0.3471, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0354, Accumulated: 0.3825, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0252, Accumulated: 0.4077, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0318, Accumulated: 0.4395, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0336, Accumulated: 0.4731, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0624, Accumulated: 0.5355, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0906, Accumulated: 0.6261, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1020, Accumulated: 0.7281, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1109, Accumulated: 0.8389, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0926, Accumulated: 0.9315, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0389, Accumulated: 0.9704, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0146, Accumulated: 0.0146, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0080, Accumulated: 0.0227, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0117, Accumulated: 0.0343, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1158, Accumulated: 0.1501, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0146, Accumulated: 0.1647, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0074, Accumulated: 0.1721, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0109, Accumulated: 0.1830, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2870, Accumulated: 0.4700, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1282, Accumulated: 0.5982, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.3998, Accumulated: 0.9980, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1995, Accumulated: 0.1995, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1102, Accumulated: 0.3097, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0818, Accumulated: 0.3915, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0711, Accumulated: 0.4625, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0552, Accumulated: 0.5178, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0643, Accumulated: 0.5821, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0517, Accumulated: 0.6337, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0952, Accumulated: 0.7290, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0866, Accumulated: 0.8156, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0764, Accumulated: 0.8920, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0608, Accumulated: 0.9528, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0312, Accumulated: 0.9840, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0094, Accumulated: 0.9934, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0131, Accumulated: 0.0131, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0419, Accumulated: 0.0551, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0114, Accumulated: 0.0665, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0062, Accumulated: 0.0727, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0799, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0101, Accumulated: 0.0900, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0173, Accumulated: 0.1073, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0575, Accumulated: 0.1649, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1324, Accumulated: 0.2973, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6989, Accumulated: 0.9962, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0688, Accumulated: 0.0688, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0213, Accumulated: 0.0901, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0167, Accumulated: 0.1068, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0195, Accumulated: 0.1263, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0165, Accumulated: 0.1428, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0285, Accumulated: 0.1713, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0220, Accumulated: 0.1933, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0689, Accumulated: 0.2622, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1604, Accumulated: 0.4226, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1755, Accumulated: 0.5981, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1891, Accumulated: 0.7872, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1293, Accumulated: 0.9164, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0579, Accumulated: 0.9743, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0262, Accumulated: 0.0262, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0145, Accumulated: 0.0406, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0105, Accumulated: 0.0511, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0068, Accumulated: 0.0579, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0120, Accumulated: 0.0699, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0086, Accumulated: 0.0786, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0826, Accumulated: 0.1612, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0936, Accumulated: 0.2548, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1050, Accumulated: 0.3598, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6293, Accumulated: 0.9891, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0109, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1903, Accumulated: 0.1903, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0562, Accumulated: 0.2465, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0517, Accumulated: 0.2982, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0278, Accumulated: 0.3260, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0181, Accumulated: 0.3441, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0224, Accumulated: 0.3665, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0244, Accumulated: 0.3909, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0687, Accumulated: 0.4597, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1173, Accumulated: 0.5770, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1244, Accumulated: 0.7015, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1363, Accumulated: 0.8378, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0968, Accumulated: 0.9346, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0377, Accumulated: 0.9723, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0216, Accumulated: 0.0216, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0153, Accumulated: 0.0370, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0122, Accumulated: 0.0492, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0104, Accumulated: 0.0596, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0407, Accumulated: 0.1003, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0146, Accumulated: 0.1150, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0230, Accumulated: 0.1380, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0395, Accumulated: 0.1775, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0488, Accumulated: 0.2263, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7454, Accumulated: 0.9717, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0278, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1996, Accumulated: 0.1996, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0915, Accumulated: 0.2911, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0455, Accumulated: 0.3366, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0311, Accumulated: 0.3677, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0200, Accumulated: 0.3877, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0341, Accumulated: 0.4219, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0355, Accumulated: 0.4573, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0697, Accumulated: 0.5270, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1077, Accumulated: 0.6347, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1108, Accumulated: 0.7455, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1143, Accumulated: 0.8598, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0767, Accumulated: 0.9365, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0319, Accumulated: 0.9684, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0067, Accumulated: 0.0067, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0078, Accumulated: 0.0145, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0056, Accumulated: 0.0200, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0715, Accumulated: 0.0916, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0110, Accumulated: 0.1026, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0085, Accumulated: 0.1110, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0119, Accumulated: 0.1230, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0076, Accumulated: 0.1306, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0132, Accumulated: 0.1438, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7421, Accumulated: 0.8859, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1123, Accumulated: 0.9982, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1842, Accumulated: 0.1842, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0711, Accumulated: 0.2553, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0445, Accumulated: 0.2998, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0331, Accumulated: 0.3329, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0297, Accumulated: 0.3626, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0364, Accumulated: 0.3990, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0522, Accumulated: 0.4513, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0963, Accumulated: 0.5476, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1260, Accumulated: 0.6736, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1235, Accumulated: 0.7971, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0928, Accumulated: 0.8899, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0695, Accumulated: 0.9594, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0235, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0063, Accumulated: 0.0063, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0074, Accumulated: 0.0137, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0065, Accumulated: 0.0202, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0227, Accumulated: 0.0428, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.0520, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0272, Accumulated: 0.0792, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0202, Accumulated: 0.0994, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1353, Accumulated: 0.2347, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0833, Accumulated: 0.3181, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6786, Accumulated: 0.9967, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1730, Accumulated: 0.1730, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0680, Accumulated: 0.2410, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0229, Accumulated: 0.2639, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0311, Accumulated: 0.2950, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0248, Accumulated: 0.3198, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0218, Accumulated: 0.3416, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0308, Accumulated: 0.3724, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1135, Accumulated: 0.4859, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1397, Accumulated: 0.6256, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1359, Accumulated: 0.7615, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1230, Accumulated: 0.8845, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0753, Accumulated: 0.9598, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0231, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0137, Accumulated: 0.0137, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0228, Accumulated: 0.0365, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0086, Accumulated: 0.0451, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0134, Accumulated: 0.0585, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0132, Accumulated: 0.0717, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0097, Accumulated: 0.0815, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0211, Accumulated: 0.1026, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.7033, Accumulated: 0.8059, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1063, Accumulated: 0.9121, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0871, Accumulated: 0.9993, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1863, Accumulated: 0.1863, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0645, Accumulated: 0.2507, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0353, Accumulated: 0.2861, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0248, Accumulated: 0.3109, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0214, Accumulated: 0.3323, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0345, Accumulated: 0.3668, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0405, Accumulated: 0.4074, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1137, Accumulated: 0.5211, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1456, Accumulated: 0.6667, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1263, Accumulated: 0.7930, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1112, Accumulated: 0.9042, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0479, Accumulated: 0.9521, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0218, Accumulated: 0.9739, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0086, Accumulated: 0.0086, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0077, Accumulated: 0.0163, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0164, Accumulated: 0.0327, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0509, Accumulated: 0.0836, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0076, Accumulated: 0.0911, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0108, Accumulated: 0.1019, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0121, Accumulated: 0.1141, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0525, Accumulated: 0.1666, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0458, Accumulated: 0.2123, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7827, Accumulated: 0.9950, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1298, Accumulated: 0.1298, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0460, Accumulated: 0.1758, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0322, Accumulated: 0.2080, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0251, Accumulated: 0.2331, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0236, Accumulated: 0.2566, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0275, Accumulated: 0.2841, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0255, Accumulated: 0.3097, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0747, Accumulated: 0.3844, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1209, Accumulated: 0.5053, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1547, Accumulated: 0.6600, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1387, Accumulated: 0.7987, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1312, Accumulated: 0.9299, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0409, Accumulated: 0.9708, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0118, Accumulated: 0.0118, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0112, Accumulated: 0.0230, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0082, Accumulated: 0.0312, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0544, Accumulated: 0.0856, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0042, Accumulated: 0.0898, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.1036, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0493, Accumulated: 0.1530, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1592, Accumulated: 0.3122, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0778, Accumulated: 0.3900, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6067, Accumulated: 0.9967, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1858, Accumulated: 0.1858, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0653, Accumulated: 0.2511, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0371, Accumulated: 0.2882, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0314, Accumulated: 0.3196, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0229, Accumulated: 0.3425, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0265, Accumulated: 0.3690, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0296, Accumulated: 0.3987, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0992, Accumulated: 0.4979, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1115, Accumulated: 0.6094, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1131, Accumulated: 0.7225, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1033, Accumulated: 0.8257, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0958, Accumulated: 0.9216, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0403, Accumulated: 0.9619, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0139, Accumulated: 0.0139, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0408, Accumulated: 0.0547, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0154, Accumulated: 0.0701, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0078, Accumulated: 0.0779, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0310, Accumulated: 0.1089, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0131, Accumulated: 0.1221, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0093, Accumulated: 0.1313, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1022, Accumulated: 0.2335, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0831, Accumulated: 0.3167, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6763, Accumulated: 0.9930, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1564, Accumulated: 0.1564, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0638, Accumulated: 0.2202, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0337, Accumulated: 0.2539, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0268, Accumulated: 0.2806, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0197, Accumulated: 0.3003, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0418, Accumulated: 0.3421, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0309, Accumulated: 0.3729, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0818, Accumulated: 0.4548, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1266, Accumulated: 0.5814, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1308, Accumulated: 0.7122, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1330, Accumulated: 0.8452, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0885, Accumulated: 0.9337, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0330, Accumulated: 0.9668, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0192, Accumulated: 0.0192, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0230, Accumulated: 0.0421, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0132, Accumulated: 0.0554, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0047, Accumulated: 0.0601, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0090, Accumulated: 0.0690, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0170, Accumulated: 0.0861, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0116, Accumulated: 0.0977, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0145, Accumulated: 0.1122, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0191, Accumulated: 0.1313, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8195, Accumulated: 0.9508, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0488, Accumulated: 0.9996, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1570, Accumulated: 0.1570, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0720, Accumulated: 0.2290, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0369, Accumulated: 0.2659, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0290, Accumulated: 0.2949, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0248, Accumulated: 0.3197, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0369, Accumulated: 0.3566, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0474, Accumulated: 0.4040, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1061, Accumulated: 0.5101, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1436, Accumulated: 0.6537, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1304, Accumulated: 0.7841, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1065, Accumulated: 0.8906, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0590, Accumulated: 0.9496, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0253, Accumulated: 0.9748, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0202, Accumulated: 0.0202, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0059, Accumulated: 0.0260, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0221, Accumulated: 0.0481, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0243, Accumulated: 0.0725, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0115, Accumulated: 0.0839, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0252, Accumulated: 0.1091, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0139, Accumulated: 0.1230, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1451, Accumulated: 0.2681, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0867, Accumulated: 0.3548, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6307, Accumulated: 0.9855, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0144, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1554, Accumulated: 0.1554, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0438, Accumulated: 0.1992, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0174, Accumulated: 0.2166, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0170, Accumulated: 0.2335, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0214, Accumulated: 0.2550, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0239, Accumulated: 0.2789, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0294, Accumulated: 0.3083, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0725, Accumulated: 0.3809, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0930, Accumulated: 0.4739, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1528, Accumulated: 0.6267, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1762, Accumulated: 0.8030, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1255, Accumulated: 0.9285, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0462, Accumulated: 0.9748, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0117, Accumulated: 0.0117, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0080, Accumulated: 0.0197, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0052, Accumulated: 0.0249, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0397, Accumulated: 0.0646, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0718, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0430, Accumulated: 0.1148, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0244, Accumulated: 0.1392, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0522, Accumulated: 0.1914, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0373, Accumulated: 0.2287, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7630, Accumulated: 0.9917, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2158, Accumulated: 0.2158, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0616, Accumulated: 0.2774, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0374, Accumulated: 0.3148, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0205, Accumulated: 0.3352, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0161, Accumulated: 0.3513, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0335, Accumulated: 0.3848, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0464, Accumulated: 0.4313, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0747, Accumulated: 0.5060, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1033, Accumulated: 0.6093, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1136, Accumulated: 0.7229, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1175, Accumulated: 0.8404, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0920, Accumulated: 0.9324, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0351, Accumulated: 0.9674, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0153, Accumulated: 0.0153, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0394, Accumulated: 0.0546, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0526, Accumulated: 0.1073, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0089, Accumulated: 0.1161, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0084, Accumulated: 0.1245, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0127, Accumulated: 0.1373, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0278, Accumulated: 0.1650, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1597, Accumulated: 0.3247, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.2351, Accumulated: 0.5598, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.4344, Accumulated: 0.9942, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0995, Accumulated: 0.0995, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0216, Accumulated: 0.1211, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0138, Accumulated: 0.1350, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0212, Accumulated: 0.1561, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0163, Accumulated: 0.1725, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0186, Accumulated: 0.1911, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0362, Accumulated: 0.2273, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1124, Accumulated: 0.3398, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1352, Accumulated: 0.4749, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1622, Accumulated: 0.6371, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1572, Accumulated: 0.7943, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1202, Accumulated: 0.9145, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0538, Accumulated: 0.9683, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0162, Accumulated: 0.0162, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0096, Accumulated: 0.0258, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0093, Accumulated: 0.0351, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0337, Accumulated: 0.0688, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0048, Accumulated: 0.0735, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0069, Accumulated: 0.0804, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0128, Accumulated: 0.0933, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0634, Accumulated: 0.1567, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0552, Accumulated: 0.2119, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7785, Accumulated: 0.9904, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2053, Accumulated: 0.2053, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0756, Accumulated: 0.2809, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0462, Accumulated: 0.3271, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0316, Accumulated: 0.3587, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0240, Accumulated: 0.3827, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0347, Accumulated: 0.4174, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0373, Accumulated: 0.4547, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0848, Accumulated: 0.5395, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1211, Accumulated: 0.6606, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1248, Accumulated: 0.7854, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1051, Accumulated: 0.8904, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0624, Accumulated: 0.9528, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0238, Accumulated: 0.9766, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0152, Accumulated: 0.0152, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0148, Accumulated: 0.0301, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0167, Accumulated: 0.0468, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0192, Accumulated: 0.0659, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0076, Accumulated: 0.0735, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0222, Accumulated: 0.0957, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0446, Accumulated: 0.1403, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0697, Accumulated: 0.2100, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0761, Accumulated: 0.2861, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7062, Accumulated: 0.9923, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1801, Accumulated: 0.1801, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0544, Accumulated: 0.2345, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0309, Accumulated: 0.2654, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0352, Accumulated: 0.3005, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0310, Accumulated: 0.3316, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0298, Accumulated: 0.3614, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0348, Accumulated: 0.3961, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0695, Accumulated: 0.4656, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1190, Accumulated: 0.5846, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1168, Accumulated: 0.7014, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1271, Accumulated: 0.8285, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1002, Accumulated: 0.9286, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0337, Accumulated: 0.9624, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0096, Accumulated: 0.0096, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0155, Accumulated: 0.0251, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0068, Accumulated: 0.0319, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0516, Accumulated: 0.0835, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0958, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0133, Accumulated: 0.1091, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0094, Accumulated: 0.1186, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1461, Accumulated: 0.2647, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1178, Accumulated: 0.3824, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6157, Accumulated: 0.9982, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.0991, Accumulated: 0.0991, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0399, Accumulated: 0.1390, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0325, Accumulated: 0.1715, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0267, Accumulated: 0.1982, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0267, Accumulated: 0.2249, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0329, Accumulated: 0.2578, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0375, Accumulated: 0.2953, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0666, Accumulated: 0.3618, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1105, Accumulated: 0.4724, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1432, Accumulated: 0.6156, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1692, Accumulated: 0.7848, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1290, Accumulated: 0.9138, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0516, Accumulated: 0.9654, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0096, Accumulated: 0.0096, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0095, Accumulated: 0.0191, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0064, Accumulated: 0.0255, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0481, Accumulated: 0.0736, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0069, Accumulated: 0.0805, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0112, Accumulated: 0.0918, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0206, Accumulated: 0.1123, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0259, Accumulated: 0.1383, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0362, Accumulated: 0.1744, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8167, Accumulated: 0.9911, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1942, Accumulated: 0.1942, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0654, Accumulated: 0.2596, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0474, Accumulated: 0.3070, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0308, Accumulated: 0.3378, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0230, Accumulated: 0.3608, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0381, Accumulated: 0.3989, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0392, Accumulated: 0.4380, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0637, Accumulated: 0.5017, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0954, Accumulated: 0.5972, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1323, Accumulated: 0.7294, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1330, Accumulated: 0.8624, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0868, Accumulated: 0.9492, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0278, Accumulated: 0.9770, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0130, Accumulated: 0.0130, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0093, Accumulated: 0.0223, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0115, Accumulated: 0.0337, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0706, Accumulated: 0.1043, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0142, Accumulated: 0.1185, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0312, Accumulated: 0.1498, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0181, Accumulated: 0.1678, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0982, Accumulated: 0.2661, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1007, Accumulated: 0.3668, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6240, Accumulated: 0.9907, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1586, Accumulated: 0.1586, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0644, Accumulated: 0.2229, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0310, Accumulated: 0.2539, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0251, Accumulated: 0.2790, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0209, Accumulated: 0.2999, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0238, Accumulated: 0.3237, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0421, Accumulated: 0.3658, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1097, Accumulated: 0.4755, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1475, Accumulated: 0.6230, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1319, Accumulated: 0.7549, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1286, Accumulated: 0.8836, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0693, Accumulated: 0.9528, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0281, Accumulated: 0.9809, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0195, Accumulated: 0.0195, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0288, Accumulated: 0.0483, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0127, Accumulated: 0.0610, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0109, Accumulated: 0.0718, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0075, Accumulated: 0.0794, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0301, Accumulated: 0.1095, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0142, Accumulated: 0.1236, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0284, Accumulated: 0.1520, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0708, Accumulated: 0.2228, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5931, Accumulated: 0.8160, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1827, Accumulated: 0.9987, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.3400\n",
      "accuracy: 0.3400\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.3400000035762787, 'accuracy': 0.34}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.12368115186691284}, 'time_per_token': {'mean': 0.12368115186691284}, 'tokens_per_second': {'mean': 8.490512878894807}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:00<00:42,  2.31it/s]\n",
      "Benchmarking MMLU:   2%|▏         | 2/100 [00:00<00:24,  3.97it/s]\n",
      "Benchmarking MMLU:   3%|▎         | 3/100 [00:00<00:18,  5.30it/s]\n",
      "Benchmarking MMLU:   4%|▍         | 4/100 [00:00<00:17,  5.52it/s]\n",
      "Benchmarking MMLU:   5%|▌         | 5/100 [00:00<00:14,  6.38it/s]\n",
      "Benchmarking MMLU:   6%|▌         | 6/100 [00:01<00:17,  5.39it/s]\n",
      "Benchmarking MMLU:   7%|▋         | 7/100 [00:01<00:15,  6.12it/s]\n",
      "Benchmarking MMLU:   8%|▊         | 8/100 [00:01<00:13,  6.68it/s]\n",
      "Benchmarking MMLU:   9%|▉         | 9/100 [00:01<00:15,  5.96it/s]\n",
      "Benchmarking MMLU:  10%|█         | 10/100 [00:01<00:13,  6.44it/s]\n",
      "Benchmarking MMLU:  11%|█         | 11/100 [00:01<00:12,  7.06it/s]\n",
      "Benchmarking MMLU:  12%|█▏        | 12/100 [00:01<00:11,  7.42it/s]\n",
      "Benchmarking MMLU:  13%|█▎        | 13/100 [00:02<00:10,  7.93it/s]\n",
      "Benchmarking MMLU:  14%|█▍        | 14/100 [00:02<00:12,  6.79it/s]\n",
      "Benchmarking MMLU:  15%|█▌        | 15/100 [00:02<00:12,  7.02it/s]\n",
      "Benchmarking MMLU:  16%|█▌        | 16/100 [00:02<00:11,  7.60it/s]\n",
      "Benchmarking MMLU:  17%|█▋        | 17/100 [00:02<00:10,  8.02it/s]\n",
      "Benchmarking MMLU:  18%|█▊        | 18/100 [00:02<00:09,  8.29it/s]\n",
      "Benchmarking MMLU:  19%|█▉        | 19/100 [00:02<00:09,  8.33it/s]\n",
      "Benchmarking MMLU:  20%|██        | 20/100 [00:02<00:09,  8.41it/s]\n",
      "Benchmarking MMLU:  21%|██        | 21/100 [00:03<00:09,  8.64it/s]\n",
      "Benchmarking MMLU:  22%|██▏       | 22/100 [00:03<00:08,  8.75it/s]\n",
      "Benchmarking MMLU:  23%|██▎       | 23/100 [00:03<00:08,  8.96it/s]\n",
      "Benchmarking MMLU:  24%|██▍       | 24/100 [00:03<00:08,  8.97it/s]\n",
      "Benchmarking MMLU:  25%|██▌       | 25/100 [00:03<00:08,  9.15it/s]\n",
      "Benchmarking MMLU:  26%|██▌       | 26/100 [00:03<00:10,  7.26it/s]\n",
      "Benchmarking MMLU:  27%|██▋       | 27/100 [00:03<00:09,  7.66it/s]\n",
      "Benchmarking MMLU:  28%|██▊       | 28/100 [00:03<00:09,  7.97it/s]\n",
      "Benchmarking MMLU:  29%|██▉       | 29/100 [00:04<00:08,  8.17it/s]\n",
      "Benchmarking MMLU:  30%|███       | 30/100 [00:04<00:08,  8.44it/s]\n",
      "Benchmarking MMLU:  31%|███       | 31/100 [00:04<00:09,  7.62it/s]\n",
      "Benchmarking MMLU:  32%|███▏      | 32/100 [00:04<00:08,  8.03it/s]\n",
      "Benchmarking MMLU:  33%|███▎      | 33/100 [00:04<00:07,  8.53it/s]\n",
      "Benchmarking MMLU:  34%|███▍      | 34/100 [00:04<00:07,  8.79it/s]\n",
      "Benchmarking MMLU:  35%|███▌      | 35/100 [00:04<00:07,  8.90it/s]\n",
      "Benchmarking MMLU:  36%|███▌      | 36/100 [00:04<00:07,  8.83it/s]\n",
      "Benchmarking MMLU:  37%|███▋      | 37/100 [00:05<00:07,  8.71it/s]\n",
      "Benchmarking MMLU:  38%|███▊      | 38/100 [00:05<00:07,  8.61it/s]\n",
      "Benchmarking MMLU:  39%|███▉      | 39/100 [00:05<00:07,  8.67it/s]\n",
      "Benchmarking MMLU:  41%|████      | 41/100 [00:05<00:06,  8.96it/s]\n",
      "Benchmarking MMLU:  42%|████▏     | 42/100 [00:05<00:06,  8.50it/s]\n",
      "Benchmarking MMLU:  43%|████▎     | 43/100 [00:05<00:06,  8.64it/s]\n",
      "Benchmarking MMLU:  44%|████▍     | 44/100 [00:05<00:06,  8.74it/s]\n",
      "Benchmarking MMLU:  45%|████▌     | 45/100 [00:05<00:06,  8.72it/s]\n",
      "Benchmarking MMLU:  46%|████▌     | 46/100 [00:06<00:06,  8.92it/s]\n",
      "Benchmarking MMLU:  47%|████▋     | 47/100 [00:06<00:05,  8.96it/s]\n",
      "Benchmarking MMLU:  48%|████▊     | 48/100 [00:06<00:05,  9.02it/s]\n",
      "Benchmarking MMLU:  49%|████▉     | 49/100 [00:06<00:05,  8.82it/s]\n",
      "Benchmarking MMLU:  50%|█████     | 50/100 [00:06<00:05,  9.02it/s]\n",
      "Benchmarking MMLU:  51%|█████     | 51/100 [00:06<00:06,  8.14it/s]\n",
      "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:06<00:05,  8.42it/s]\n",
      "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:06<00:05,  8.08it/s]\n",
      "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:06<00:05,  8.23it/s]\n",
      "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:07<00:06,  6.93it/s]\n",
      "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:07<00:06,  6.62it/s]\n",
      "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:07<00:05,  7.18it/s]\n",
      "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:07<00:05,  7.63it/s]\n",
      "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:07<00:05,  7.94it/s]\n",
      "Benchmarking MMLU:  60%|██████    | 60/100 [00:07<00:04,  8.03it/s]\n",
      "Benchmarking MMLU:  61%|██████    | 61/100 [00:07<00:05,  7.33it/s]\n",
      "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:08<00:04,  7.83it/s]\n",
      "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:08<00:04,  8.33it/s]\n",
      "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:08<00:04,  8.46it/s]\n",
      "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:08<00:04,  8.49it/s]\n",
      "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:08<00:03,  8.78it/s]\n",
      "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:08<00:03,  8.87it/s]\n",
      "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:08<00:03,  8.82it/s]\n",
      "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:08<00:03,  8.98it/s]\n",
      "Benchmarking MMLU:  70%|███████   | 70/100 [00:08<00:03,  8.97it/s]\n",
      "Benchmarking MMLU:  71%|███████   | 71/100 [00:09<00:03,  8.89it/s]\n",
      "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:09<00:03,  8.85it/s]\n",
      "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:09<00:03,  8.82it/s]\n",
      "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:09<00:03,  8.66it/s]\n",
      "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:09<00:02,  8.62it/s]\n",
      "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:09<00:02,  8.73it/s]\n",
      "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:09<00:02,  7.99it/s]\n",
      "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:09<00:02,  8.35it/s]\n",
      "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:10<00:02,  8.53it/s]\n",
      "Benchmarking MMLU:  80%|████████  | 80/100 [00:10<00:02,  8.77it/s]\n",
      "Benchmarking MMLU:  81%|████████  | 81/100 [00:10<00:02,  9.03it/s]\n",
      "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:10<00:02,  8.92it/s]\n",
      "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:10<00:01,  8.66it/s]\n",
      "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:10<00:01,  8.85it/s]\n",
      "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:10<00:01,  8.81it/s]\n",
      "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:10<00:01,  7.22it/s]\n",
      "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:11<00:01,  7.52it/s]\n",
      "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:11<00:01,  7.87it/s]\n",
      "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:11<00:01,  8.14it/s]\n",
      "Benchmarking MMLU:  90%|█████████ | 90/100 [00:11<00:01,  8.39it/s]\n",
      "Benchmarking MMLU:  91%|█████████ | 91/100 [00:11<00:01,  8.43it/s]\n",
      "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:11<00:00,  8.58it/s]\n",
      "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:11<00:00,  8.73it/s]\n",
      "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:11<00:00,  8.95it/s]\n",
      "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:11<00:00,  9.09it/s]\n",
      "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:12<00:00,  9.20it/s]\n",
      "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:12<00:00,  9.05it/s]\n",
      "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:12<00:00,  8.98it/s]\n",
      "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:12<00:00,  9.26it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:12<00:00,  9.25it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:12<00:00,  8.03it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mmlu \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy depth_adaptive_sequence \\\n",
    "       --halting_threshold 0.99 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RACE-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: race_m\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on RACE_M with 100 samples...\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (RACE_M) ---\n",
      "exact_match: 0.0100\n",
      "accuracy: 0.0100\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.009999999776482582, 'accuracy': 0.01}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.24458784341812134}, 'time_per_token': {'mean': 0.012229392202571035}, 'tokens_per_second': {'mean': 82.71523124694824}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking RACE_M:   1%|          | 1/100 [00:00<00:56,  1.75it/s]\n",
      "Benchmarking RACE_M:   2%|▏         | 2/100 [00:00<00:37,  2.62it/s]\n",
      "Benchmarking RACE_M:   3%|▎         | 3/100 [00:01<00:30,  3.20it/s]\n",
      "Benchmarking RACE_M:   4%|▍         | 4/100 [00:01<00:27,  3.51it/s]\n",
      "Benchmarking RACE_M:   5%|▌         | 5/100 [00:01<00:25,  3.73it/s]\n",
      "Benchmarking RACE_M:   6%|▌         | 6/100 [00:01<00:23,  3.95it/s]\n",
      "Benchmarking RACE_M:   7%|▋         | 7/100 [00:01<00:22,  4.14it/s]\n",
      "Benchmarking RACE_M:   8%|▊         | 8/100 [00:02<00:21,  4.20it/s]\n",
      "Benchmarking RACE_M:   9%|▉         | 9/100 [00:02<00:21,  4.17it/s]\n",
      "Benchmarking RACE_M:  10%|█         | 10/100 [00:02<00:21,  4.28it/s]\n",
      "Benchmarking RACE_M:  11%|█         | 11/100 [00:02<00:20,  4.33it/s]\n",
      "Benchmarking RACE_M:  12%|█▏        | 12/100 [00:03<00:20,  4.39it/s]\n",
      "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:03<00:20,  4.34it/s]\n",
      "Benchmarking RACE_M:  14%|█▍        | 14/100 [00:03<00:20,  4.30it/s]\n",
      "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:03<00:19,  4.36it/s]\n",
      "Benchmarking RACE_M:  16%|█▌        | 16/100 [00:04<00:19,  4.24it/s]\n",
      "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:04<00:19,  4.33it/s]\n",
      "Benchmarking RACE_M:  18%|█▊        | 18/100 [00:04<00:19,  4.31it/s]\n",
      "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:04<00:18,  4.34it/s]\n",
      "Benchmarking RACE_M:  20%|██        | 20/100 [00:04<00:18,  4.36it/s]\n",
      "Benchmarking RACE_M:  21%|██        | 21/100 [00:05<00:18,  4.34it/s]\n",
      "Benchmarking RACE_M:  22%|██▏       | 22/100 [00:05<00:17,  4.39it/s]\n",
      "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:05<00:17,  4.41it/s]\n",
      "Benchmarking RACE_M:  24%|██▍       | 24/100 [00:05<00:17,  4.40it/s]\n",
      "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:06<00:17,  4.37it/s]\n",
      "Benchmarking RACE_M:  26%|██▌       | 26/100 [00:06<00:17,  4.20it/s]\n",
      "Benchmarking RACE_M:  27%|██▋       | 27/100 [00:06<00:17,  4.13it/s]\n",
      "Benchmarking RACE_M:  28%|██▊       | 28/100 [00:06<00:17,  4.17it/s]\n",
      "Benchmarking RACE_M:  29%|██▉       | 29/100 [00:07<00:17,  4.10it/s]\n",
      "Benchmarking RACE_M:  30%|███       | 30/100 [00:07<00:17,  3.95it/s]\n",
      "Benchmarking RACE_M:  31%|███       | 31/100 [00:07<00:17,  3.89it/s]\n",
      "Benchmarking RACE_M:  32%|███▏      | 32/100 [00:07<00:17,  3.89it/s]\n",
      "Benchmarking RACE_M:  33%|███▎      | 33/100 [00:08<00:17,  3.77it/s]\n",
      "Benchmarking RACE_M:  34%|███▍      | 34/100 [00:08<00:17,  3.82it/s]\n",
      "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:08<00:17,  3.78it/s]\n",
      "Benchmarking RACE_M:  36%|███▌      | 36/100 [00:08<00:16,  3.86it/s]\n",
      "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:09<00:16,  3.92it/s]\n",
      "Benchmarking RACE_M:  38%|███▊      | 38/100 [00:09<00:15,  3.97it/s]\n",
      "Benchmarking RACE_M:  39%|███▉      | 39/100 [00:09<00:15,  4.00it/s]\n",
      "Benchmarking RACE_M:  40%|████      | 40/100 [00:09<00:14,  4.03it/s]\n",
      "Benchmarking RACE_M:  41%|████      | 41/100 [00:10<00:14,  4.07it/s]\n",
      "Benchmarking RACE_M:  42%|████▏     | 42/100 [00:10<00:14,  3.97it/s]\n",
      "Benchmarking RACE_M:  43%|████▎     | 43/100 [00:10<00:14,  4.01it/s]\n",
      "Benchmarking RACE_M:  44%|████▍     | 44/100 [00:10<00:14,  3.93it/s]\n",
      "Benchmarking RACE_M:  45%|████▌     | 45/100 [00:11<00:14,  3.76it/s]\n",
      "Benchmarking RACE_M:  46%|████▌     | 46/100 [00:11<00:14,  3.82it/s]\n",
      "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:11<00:13,  3.84it/s]\n",
      "Benchmarking RACE_M:  48%|████▊     | 48/100 [00:12<00:13,  3.90it/s]\n",
      "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:12<00:12,  3.97it/s]\n",
      "Benchmarking RACE_M:  50%|█████     | 50/100 [00:12<00:12,  4.05it/s]\n",
      "Benchmarking RACE_M:  51%|█████     | 51/100 [00:12<00:12,  4.04it/s]\n",
      "Benchmarking RACE_M:  52%|█████▏    | 52/100 [00:12<00:11,  4.14it/s]\n",
      "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:13<00:11,  4.14it/s]\n",
      "Benchmarking RACE_M:  54%|█████▍    | 54/100 [00:13<00:11,  4.15it/s]\n",
      "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:13<00:10,  4.22it/s]\n",
      "Benchmarking RACE_M:  56%|█████▌    | 56/100 [00:13<00:10,  4.18it/s]\n",
      "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:14<00:10,  4.24it/s]\n",
      "Benchmarking RACE_M:  58%|█████▊    | 58/100 [00:14<00:09,  4.22it/s]\n",
      "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:14<00:09,  4.19it/s]\n",
      "Benchmarking RACE_M:  60%|██████    | 60/100 [00:14<00:09,  4.05it/s]\n",
      "Benchmarking RACE_M:  61%|██████    | 61/100 [00:15<00:09,  4.15it/s]\n",
      "Benchmarking RACE_M:  62%|██████▏   | 62/100 [00:15<00:09,  4.19it/s]\n",
      "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:15<00:08,  4.18it/s]\n",
      "Benchmarking RACE_M:  64%|██████▍   | 64/100 [00:15<00:08,  4.11it/s]\n",
      "Benchmarking RACE_M:  65%|██████▌   | 65/100 [00:16<00:08,  4.04it/s]\n",
      "Benchmarking RACE_M:  66%|██████▌   | 66/100 [00:16<00:08,  4.13it/s]\n",
      "Benchmarking RACE_M:  67%|██████▋   | 67/100 [00:16<00:08,  4.11it/s]\n",
      "Benchmarking RACE_M:  68%|██████▊   | 68/100 [00:16<00:07,  4.03it/s]\n",
      "Benchmarking RACE_M:  69%|██████▉   | 69/100 [00:17<00:07,  4.00it/s]\n",
      "Benchmarking RACE_M:  70%|███████   | 70/100 [00:17<00:07,  4.05it/s]\n",
      "Benchmarking RACE_M:  71%|███████   | 71/100 [00:17<00:07,  4.02it/s]\n",
      "Benchmarking RACE_M:  72%|███████▏  | 72/100 [00:17<00:06,  4.15it/s]\n",
      "Benchmarking RACE_M:  73%|███████▎  | 73/100 [00:18<00:06,  4.10it/s]\n",
      "Benchmarking RACE_M:  74%|███████▍  | 74/100 [00:18<00:06,  4.15it/s]\n",
      "Benchmarking RACE_M:  75%|███████▌  | 75/100 [00:18<00:05,  4.21it/s]\n",
      "Benchmarking RACE_M:  76%|███████▌  | 76/100 [00:18<00:05,  4.14it/s]\n",
      "Benchmarking RACE_M:  77%|███████▋  | 77/100 [00:19<00:05,  4.11it/s]\n",
      "Benchmarking RACE_M:  78%|███████▊  | 78/100 [00:19<00:05,  4.20it/s]\n",
      "Benchmarking RACE_M:  79%|███████▉  | 79/100 [00:19<00:05,  4.03it/s]\n",
      "Benchmarking RACE_M:  80%|████████  | 80/100 [00:19<00:05,  4.00it/s]\n",
      "Benchmarking RACE_M:  81%|████████  | 81/100 [00:20<00:04,  4.01it/s]\n",
      "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:20<00:04,  4.02it/s]\n",
      "Benchmarking RACE_M:  83%|████████▎ | 83/100 [00:20<00:04,  4.03it/s]\n",
      "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:20<00:03,  4.02it/s]\n",
      "Benchmarking RACE_M:  85%|████████▌ | 85/100 [00:20<00:03,  4.08it/s]\n",
      "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:21<00:03,  4.14it/s]\n",
      "Benchmarking RACE_M:  87%|████████▋ | 87/100 [00:21<00:03,  4.08it/s]\n",
      "Benchmarking RACE_M:  88%|████████▊ | 88/100 [00:21<00:02,  4.11it/s]\n",
      "Benchmarking RACE_M:  89%|████████▉ | 89/100 [00:21<00:02,  4.12it/s]\n",
      "Benchmarking RACE_M:  90%|█████████ | 90/100 [00:22<00:02,  4.06it/s]\n",
      "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:22<00:02,  4.15it/s]\n",
      "Benchmarking RACE_M:  92%|█████████▏| 92/100 [00:22<00:01,  4.08it/s]\n",
      "Benchmarking RACE_M:  93%|█████████▎| 93/100 [00:22<00:01,  4.13it/s]\n",
      "Benchmarking RACE_M:  94%|█████████▍| 94/100 [00:23<00:01,  4.17it/s]\n",
      "Benchmarking RACE_M:  95%|█████████▌| 95/100 [00:23<00:01,  4.15it/s]\n",
      "Benchmarking RACE_M:  96%|█████████▌| 96/100 [00:23<00:00,  4.04it/s]\n",
      "Benchmarking RACE_M:  97%|█████████▋| 97/100 [00:23<00:00,  3.97it/s]\n",
      "Benchmarking RACE_M:  98%|█████████▊| 98/100 [00:24<00:00,  4.16it/s]\n",
      "Benchmarking RACE_M:  99%|█████████▉| 99/100 [00:24<00:00,  4.21it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:24<00:00,  4.34it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:24<00:00,  4.07it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: race_m\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on RACE_M with 100 samples...\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (RACE_M) ---\n",
      "exact_match: 0.5500\n",
      "accuracy: 0.5500\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.550000011920929, 'accuracy': 0.55}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.06174783229827881}, 'time_per_token': {'mean': 0.06174783229827881}, 'tokens_per_second': {'mean': 17.54588997602463}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking RACE_M:   1%|          | 1/100 [00:00<00:38,  2.56it/s]\n",
      "Benchmarking RACE_M:   3%|▎         | 3/100 [00:00<00:14,  6.55it/s]\n",
      "Benchmarking RACE_M:   5%|▌         | 5/100 [00:00<00:09,  9.68it/s]\n",
      "Benchmarking RACE_M:   7%|▋         | 7/100 [00:00<00:07, 11.78it/s]\n",
      "Benchmarking RACE_M:   9%|▉         | 9/100 [00:00<00:07, 12.90it/s]\n",
      "Benchmarking RACE_M:  11%|█         | 11/100 [00:01<00:06, 13.53it/s]\n",
      "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:01<00:05, 14.64it/s]\n",
      "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:01<00:05, 14.89it/s]\n",
      "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:01<00:05, 15.67it/s]\n",
      "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:01<00:05, 15.53it/s]\n",
      "Benchmarking RACE_M:  21%|██        | 21/100 [00:01<00:05, 15.60it/s]\n",
      "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:01<00:04, 16.17it/s]\n",
      "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:01<00:04, 16.77it/s]\n",
      "Benchmarking RACE_M:  27%|██▋       | 27/100 [00:01<00:04, 16.48it/s]\n",
      "Benchmarking RACE_M:  29%|██▉       | 29/100 [00:02<00:04, 16.79it/s]\n",
      "Benchmarking RACE_M:  31%|███       | 31/100 [00:02<00:04, 17.13it/s]\n",
      "Benchmarking RACE_M:  33%|███▎      | 33/100 [00:02<00:04, 16.44it/s]\n",
      "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:02<00:03, 17.21it/s]\n",
      "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:02<00:03, 17.86it/s]\n",
      "Benchmarking RACE_M:  40%|████      | 40/100 [00:02<00:03, 17.95it/s]\n",
      "Benchmarking RACE_M:  42%|████▏     | 42/100 [00:02<00:03, 16.40it/s]\n",
      "Benchmarking RACE_M:  44%|████▍     | 44/100 [00:02<00:03, 16.70it/s]\n",
      "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:03<00:03, 17.46it/s]\n",
      "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:03<00:02, 17.44it/s]\n",
      "Benchmarking RACE_M:  51%|█████     | 51/100 [00:03<00:02, 18.02it/s]\n",
      "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:03<00:02, 17.72it/s]\n",
      "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:03<00:02, 17.85it/s]\n",
      "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:03<00:02, 17.33it/s]\n",
      "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:03<00:02, 17.47it/s]\n",
      "Benchmarking RACE_M:  61%|██████    | 61/100 [00:03<00:02, 16.54it/s]\n",
      "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:04<00:02, 16.87it/s]\n",
      "Benchmarking RACE_M:  65%|██████▌   | 65/100 [00:04<00:02, 16.34it/s]\n",
      "Benchmarking RACE_M:  67%|██████▋   | 67/100 [00:04<00:01, 16.62it/s]\n",
      "Benchmarking RACE_M:  69%|██████▉   | 69/100 [00:04<00:01, 17.10it/s]\n",
      "Benchmarking RACE_M:  72%|███████▏  | 72/100 [00:04<00:01, 17.90it/s]\n",
      "Benchmarking RACE_M:  74%|███████▍  | 74/100 [00:04<00:01, 17.14it/s]\n",
      "Benchmarking RACE_M:  76%|███████▌  | 76/100 [00:04<00:01, 15.83it/s]\n",
      "Benchmarking RACE_M:  78%|███████▊  | 78/100 [00:04<00:01, 15.98it/s]\n",
      "Benchmarking RACE_M:  80%|████████  | 80/100 [00:05<00:01, 16.69it/s]\n",
      "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:05<00:01, 16.37it/s]\n",
      "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:05<00:00, 17.22it/s]\n",
      "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:05<00:00, 17.67it/s]\n",
      "Benchmarking RACE_M:  88%|████████▊ | 88/100 [00:05<00:00, 16.85it/s]\n",
      "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:05<00:00, 18.05it/s]\n",
      "Benchmarking RACE_M:  93%|█████████▎| 93/100 [00:05<00:00, 17.43it/s]\n",
      "Benchmarking RACE_M:  95%|█████████▌| 95/100 [00:05<00:00, 17.84it/s]\n",
      "Benchmarking RACE_M:  97%|█████████▋| 97/100 [00:06<00:00, 16.90it/s]\n",
      "Benchmarking RACE_M:  99%|█████████▉| 99/100 [00:06<00:00, 16.20it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:06<00:00, 15.88it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: race_m\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on RACE_M with 100 samples...\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.148193359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67932\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0087738037109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3653\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.59765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9072265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.439208984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.040252685546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.83447265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.153076171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.70458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.250732421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2337646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7099609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 119714\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4912109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.90478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34486\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28206\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.31591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95937\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2178955078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39990234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39530\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.344970703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.93798828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.58984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9619140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89697265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73933\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1221923828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0673828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0782470703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15144\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.040924072265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89501953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.26708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.74462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1605224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.49951171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67324\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9013671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.185791015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.84765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.29443359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.058746337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.90966796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.71728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10443115234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.68896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.689453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.385009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07623291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.740234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7177734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.93798828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67324\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6767578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.58837890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.84033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.943359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.466796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27457\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.97509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101520\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4775390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99575\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 126057\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.48876953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29816\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71435\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1107177734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106563\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.48388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45940\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27712\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.496337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 33440\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.44580078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14957\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61965\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.90185546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30086\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1749267578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104471\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.19677734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 579\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71435\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.814453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68209\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.061981201171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.57763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89013671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8974609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.880859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13296\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1356201171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5987\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10736083984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.79296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45140\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.488037109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34286\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1246337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.262939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.58154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89013671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.278076171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6416015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.82666015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.055328369140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03839111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2437744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.92529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.92529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45999\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5361328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0240325927734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.90478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34486\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.73095703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.166748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8777\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.21826171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7392578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.81298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.147216796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47978\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.024169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07989501953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57014\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.37060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.73876953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.59423828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7041015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27119\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.048004150390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.32080078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6279296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.469482421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2078857421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0858154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19625\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06671142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2132568359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 395\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0308990478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67324\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0745849609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3653\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02374267578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71070\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.416748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.363037109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.626953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67324\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2705078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6927\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.154541015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03826904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5595703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 97171\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.039306640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1466064453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15271\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.83642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.345947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5045\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.51513671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.080810546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.307373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2666015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9306640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47830\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0184783935546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.88720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0936279296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53645\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98421\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.052459716796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.146484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.90966796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.19921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7490234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1488037109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.71875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.441162109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.30078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.241455078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.37939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1444091796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.517578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63726\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0259552001953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06451416015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9150390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 90486\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.15087890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.30322265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.30810546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.92236328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2337646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9345\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07867431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.211669921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.249267578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106984\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1624755859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52622\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05670166015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.278076171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (RACE_M) ---\n",
      "exact_match: 0.5500\n",
      "accuracy: 0.5500\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.550000011920929, 'accuracy': 0.55}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.23030508041381836}, 'time_per_token': {'mean': 0.21454630479216574}, 'tokens_per_second': {'mean': 4.7786476051807405}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking RACE_M:   1%|          | 1/100 [00:00<00:56,  1.75it/s]\n",
      "Benchmarking RACE_M:   2%|▏         | 2/100 [00:00<00:36,  2.71it/s]\n",
      "Benchmarking RACE_M:   3%|▎         | 3/100 [00:01<00:29,  3.31it/s]\n",
      "Benchmarking RACE_M:   4%|▍         | 4/100 [00:01<00:26,  3.66it/s]\n",
      "Benchmarking RACE_M:   5%|▌         | 5/100 [00:01<00:24,  3.84it/s]\n",
      "Benchmarking RACE_M:   6%|▌         | 6/100 [00:01<00:23,  4.08it/s]\n",
      "Benchmarking RACE_M:   7%|▋         | 7/100 [00:01<00:21,  4.33it/s]\n",
      "Benchmarking RACE_M:   8%|▊         | 8/100 [00:02<00:21,  4.22it/s]\n",
      "Benchmarking RACE_M:   9%|▉         | 9/100 [00:02<00:20,  4.37it/s]\n",
      "Benchmarking RACE_M:  10%|█         | 10/100 [00:02<00:20,  4.46it/s]\n",
      "Benchmarking RACE_M:  11%|█         | 11/100 [00:02<00:19,  4.56it/s]\n",
      "Benchmarking RACE_M:  12%|█▏        | 12/100 [00:03<00:19,  4.60it/s]\n",
      "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:03<00:19,  4.43it/s]\n",
      "Benchmarking RACE_M:  14%|█▍        | 14/100 [00:03<00:18,  4.55it/s]\n",
      "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:03<00:18,  4.62it/s]\n",
      "Benchmarking RACE_M:  16%|█▌        | 16/100 [00:03<00:17,  4.71it/s]\n",
      "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:04<00:17,  4.83it/s]\n",
      "Benchmarking RACE_M:  18%|█▊        | 18/100 [00:04<00:16,  4.92it/s]\n",
      "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:04<00:17,  4.76it/s]\n",
      "Benchmarking RACE_M:  20%|██        | 20/100 [00:04<00:17,  4.50it/s]\n",
      "Benchmarking RACE_M:  21%|██        | 21/100 [00:04<00:17,  4.49it/s]\n",
      "Benchmarking RACE_M:  22%|██▏       | 22/100 [00:05<00:17,  4.58it/s]\n",
      "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:05<00:16,  4.63it/s]\n",
      "Benchmarking RACE_M:  24%|██▍       | 24/100 [00:05<00:16,  4.75it/s]\n",
      "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:05<00:15,  4.80it/s]\n",
      "Benchmarking RACE_M:  26%|██▌       | 26/100 [00:06<00:16,  4.43it/s]\n",
      "Benchmarking RACE_M:  27%|██▋       | 27/100 [00:06<00:16,  4.39it/s]\n",
      "Benchmarking RACE_M:  28%|██▊       | 28/100 [00:06<00:15,  4.60it/s]\n",
      "Benchmarking RACE_M:  29%|██▉       | 29/100 [00:06<00:14,  4.80it/s]\n",
      "Benchmarking RACE_M:  30%|███       | 30/100 [00:06<00:14,  4.89it/s]\n",
      "Benchmarking RACE_M:  31%|███       | 31/100 [00:07<00:14,  4.91it/s]\n",
      "Benchmarking RACE_M:  32%|███▏      | 32/100 [00:07<00:13,  5.06it/s]\n",
      "Benchmarking RACE_M:  33%|███▎      | 33/100 [00:07<00:13,  5.06it/s]\n",
      "Benchmarking RACE_M:  34%|███▍      | 34/100 [00:07<00:12,  5.11it/s]\n",
      "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:07<00:12,  5.03it/s]\n",
      "Benchmarking RACE_M:  36%|███▌      | 36/100 [00:08<00:12,  5.00it/s]\n",
      "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:08<00:12,  4.91it/s]\n",
      "Benchmarking RACE_M:  38%|███▊      | 38/100 [00:08<00:12,  4.84it/s]\n",
      "Benchmarking RACE_M:  39%|███▉      | 39/100 [00:10<00:39,  1.56it/s]\n",
      "Benchmarking RACE_M:  40%|████      | 40/100 [00:10<00:30,  1.94it/s]\n",
      "Benchmarking RACE_M:  41%|████      | 41/100 [00:10<00:25,  2.35it/s]\n",
      "Benchmarking RACE_M:  42%|████▏     | 42/100 [00:10<00:21,  2.73it/s]\n",
      "Benchmarking RACE_M:  43%|████▎     | 43/100 [00:10<00:18,  3.12it/s]\n",
      "Benchmarking RACE_M:  44%|████▍     | 44/100 [00:11<00:15,  3.55it/s]\n",
      "Benchmarking RACE_M:  45%|████▌     | 45/100 [00:11<00:14,  3.81it/s]\n",
      "Benchmarking RACE_M:  46%|████▌     | 46/100 [00:11<00:13,  4.06it/s]\n",
      "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:11<00:12,  4.12it/s]\n",
      "Benchmarking RACE_M:  48%|████▊     | 48/100 [00:12<00:12,  4.25it/s]\n",
      "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:12<00:11,  4.44it/s]\n",
      "Benchmarking RACE_M:  50%|█████     | 50/100 [00:12<00:11,  4.40it/s]\n",
      "Benchmarking RACE_M:  51%|█████     | 51/100 [00:12<00:10,  4.53it/s]\n",
      "Benchmarking RACE_M:  52%|█████▏    | 52/100 [00:12<00:10,  4.56it/s]\n",
      "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:13<00:10,  4.59it/s]\n",
      "Benchmarking RACE_M:  54%|█████▍    | 54/100 [00:13<00:09,  4.64it/s]\n",
      "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:13<00:09,  4.59it/s]\n",
      "Benchmarking RACE_M:  56%|█████▌    | 56/100 [00:13<00:09,  4.48it/s]\n",
      "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:14<00:09,  4.32it/s]\n",
      "Benchmarking RACE_M:  58%|█████▊    | 58/100 [00:14<00:09,  4.53it/s]\n",
      "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:14<00:08,  4.65it/s]\n",
      "Benchmarking RACE_M:  60%|██████    | 60/100 [00:14<00:08,  4.61it/s]\n",
      "Benchmarking RACE_M:  61%|██████    | 61/100 [00:14<00:08,  4.63it/s]\n",
      "Benchmarking RACE_M:  62%|██████▏   | 62/100 [00:15<00:08,  4.70it/s]\n",
      "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:15<00:07,  4.64it/s]\n",
      "Benchmarking RACE_M:  64%|██████▍   | 64/100 [00:15<00:07,  4.62it/s]\n",
      "Benchmarking RACE_M:  65%|██████▌   | 65/100 [00:15<00:07,  4.72it/s]\n",
      "Benchmarking RACE_M:  66%|██████▌   | 66/100 [00:15<00:07,  4.68it/s]\n",
      "Benchmarking RACE_M:  67%|██████▋   | 67/100 [00:16<00:07,  4.67it/s]\n",
      "Benchmarking RACE_M:  68%|██████▊   | 68/100 [00:16<00:06,  4.58it/s]\n",
      "Benchmarking RACE_M:  69%|██████▉   | 69/100 [00:16<00:06,  4.57it/s]\n",
      "Benchmarking RACE_M:  70%|███████   | 70/100 [00:16<00:06,  4.50it/s]\n",
      "Benchmarking RACE_M:  71%|███████   | 71/100 [00:17<00:06,  4.61it/s]\n",
      "Benchmarking RACE_M:  72%|███████▏  | 72/100 [00:17<00:06,  4.54it/s]\n",
      "Benchmarking RACE_M:  73%|███████▎  | 73/100 [00:17<00:05,  4.65it/s]\n",
      "Benchmarking RACE_M:  74%|███████▍  | 74/100 [00:17<00:05,  4.64it/s]\n",
      "Benchmarking RACE_M:  75%|███████▌  | 75/100 [00:17<00:05,  4.60it/s]\n",
      "Benchmarking RACE_M:  76%|███████▌  | 76/100 [00:18<00:05,  4.72it/s]\n",
      "Benchmarking RACE_M:  77%|███████▋  | 77/100 [00:18<00:04,  4.65it/s]\n",
      "Benchmarking RACE_M:  78%|███████▊  | 78/100 [00:18<00:04,  4.61it/s]\n",
      "Benchmarking RACE_M:  79%|███████▉  | 79/100 [00:18<00:04,  4.55it/s]\n",
      "Benchmarking RACE_M:  80%|████████  | 80/100 [00:18<00:04,  4.67it/s]\n",
      "Benchmarking RACE_M:  81%|████████  | 81/100 [00:19<00:04,  4.73it/s]\n",
      "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:19<00:03,  4.90it/s]\n",
      "Benchmarking RACE_M:  83%|████████▎ | 83/100 [00:19<00:03,  4.79it/s]\n",
      "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:19<00:03,  4.89it/s]\n",
      "Benchmarking RACE_M:  85%|████████▌ | 85/100 [00:20<00:03,  4.86it/s]\n",
      "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:20<00:02,  4.80it/s]\n",
      "Benchmarking RACE_M:  87%|████████▋ | 87/100 [00:20<00:02,  4.83it/s]\n",
      "Benchmarking RACE_M:  88%|████████▊ | 88/100 [00:20<00:02,  4.66it/s]\n",
      "Benchmarking RACE_M:  89%|████████▉ | 89/100 [00:20<00:02,  4.65it/s]\n",
      "Benchmarking RACE_M:  90%|█████████ | 90/100 [00:21<00:02,  4.54it/s]\n",
      "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:21<00:01,  4.63it/s]\n",
      "Benchmarking RACE_M:  92%|█████████▏| 92/100 [00:21<00:01,  4.68it/s]\n",
      "Benchmarking RACE_M:  93%|█████████▎| 93/100 [00:21<00:01,  4.66it/s]\n",
      "Benchmarking RACE_M:  94%|█████████▍| 94/100 [00:21<00:01,  4.68it/s]\n",
      "Benchmarking RACE_M:  95%|█████████▌| 95/100 [00:22<00:01,  4.73it/s]\n",
      "Benchmarking RACE_M:  96%|█████████▌| 96/100 [00:22<00:00,  4.89it/s]\n",
      "Benchmarking RACE_M:  97%|█████████▋| 97/100 [00:22<00:00,  4.93it/s]\n",
      "Benchmarking RACE_M:  98%|█████████▊| 98/100 [00:22<00:00,  5.04it/s]\n",
      "Benchmarking RACE_M:  99%|█████████▉| 99/100 [00:22<00:00,  4.98it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:23<00:00,  4.74it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:23<00:00,  4.32it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: race_m\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on RACE_M with 100 samples...\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [423]\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [426]\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [362]\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Checking output ids: [356]\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (RACE_M) ---\n",
      "exact_match: 0.4800\n",
      "accuracy: 0.4800\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.47999998927116394, 'accuracy': 0.48}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.06551705360412598}, 'time_per_token': {'mean': 0.06551705360412598}, 'tokens_per_second': {'mean': 16.49040322303772}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking RACE_M:   1%|          | 1/100 [00:00<00:39,  2.50it/s]\n",
      "Benchmarking RACE_M:   3%|▎         | 3/100 [00:00<00:14,  6.56it/s]\n",
      "Benchmarking RACE_M:   5%|▌         | 5/100 [00:00<00:10,  9.03it/s]\n",
      "Benchmarking RACE_M:   7%|▋         | 7/100 [00:00<00:08, 10.53it/s]\n",
      "Benchmarking RACE_M:   9%|▉         | 9/100 [00:00<00:07, 12.73it/s]\n",
      "Benchmarking RACE_M:  11%|█         | 11/100 [00:01<00:06, 14.08it/s]\n",
      "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:01<00:06, 13.79it/s]\n",
      "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:01<00:06, 14.01it/s]\n",
      "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:01<00:06, 13.63it/s]\n",
      "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:01<00:05, 14.39it/s]\n",
      "Benchmarking RACE_M:  21%|██        | 21/100 [00:01<00:05, 14.73it/s]\n",
      "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:01<00:05, 14.81it/s]\n",
      "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:02<00:05, 14.76it/s]\n",
      "Benchmarking RACE_M:  27%|██▋       | 27/100 [00:02<00:05, 14.44it/s]\n",
      "Benchmarking RACE_M:  30%|███       | 30/100 [00:02<00:04, 15.94it/s]\n",
      "Benchmarking RACE_M:  32%|███▏      | 32/100 [00:02<00:04, 15.56it/s]\n",
      "Benchmarking RACE_M:  34%|███▍      | 34/100 [00:02<00:04, 15.99it/s]\n",
      "Benchmarking RACE_M:  36%|███▌      | 36/100 [00:02<00:03, 16.15it/s]\n",
      "Benchmarking RACE_M:  39%|███▉      | 39/100 [00:02<00:03, 16.80it/s]\n",
      "Benchmarking RACE_M:  41%|████      | 41/100 [00:02<00:03, 16.97it/s]\n",
      "Benchmarking RACE_M:  43%|████▎     | 43/100 [00:03<00:03, 15.52it/s]\n",
      "Benchmarking RACE_M:  45%|████▌     | 45/100 [00:03<00:03, 16.04it/s]\n",
      "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:03<00:03, 16.95it/s]\n",
      "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:03<00:02, 17.22it/s]\n",
      "Benchmarking RACE_M:  51%|█████     | 51/100 [00:03<00:03, 15.96it/s]\n",
      "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:03<00:02, 15.73it/s]\n",
      "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:03<00:02, 15.45it/s]\n",
      "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:04<00:02, 14.35it/s]\n",
      "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:04<00:02, 14.55it/s]\n",
      "Benchmarking RACE_M:  61%|██████    | 61/100 [00:04<00:02, 14.68it/s]\n",
      "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:04<00:02, 14.79it/s]\n",
      "Benchmarking RACE_M:  66%|██████▌   | 66/100 [00:04<00:02, 16.54it/s]\n",
      "Benchmarking RACE_M:  68%|██████▊   | 68/100 [00:04<00:01, 16.74it/s]\n",
      "Benchmarking RACE_M:  70%|███████   | 70/100 [00:04<00:01, 17.36it/s]\n",
      "Benchmarking RACE_M:  72%|███████▏  | 72/100 [00:04<00:01, 16.53it/s]\n",
      "Benchmarking RACE_M:  74%|███████▍  | 74/100 [00:05<00:01, 17.11it/s]\n",
      "Benchmarking RACE_M:  76%|███████▌  | 76/100 [00:05<00:01, 16.84it/s]\n",
      "Benchmarking RACE_M:  78%|███████▊  | 78/100 [00:05<00:01, 16.81it/s]\n",
      "Benchmarking RACE_M:  80%|████████  | 80/100 [00:05<00:01, 16.40it/s]\n",
      "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:05<00:01, 15.96it/s]\n",
      "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:05<00:01, 15.38it/s]\n",
      "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:05<00:00, 14.71it/s]\n",
      "Benchmarking RACE_M:  88%|████████▊ | 88/100 [00:05<00:00, 15.48it/s]\n",
      "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:06<00:00, 16.84it/s]\n",
      "Benchmarking RACE_M:  93%|█████████▎| 93/100 [00:06<00:00, 17.00it/s]\n",
      "Benchmarking RACE_M:  95%|█████████▌| 95/100 [00:06<00:00, 16.36it/s]\n",
      "Benchmarking RACE_M:  97%|█████████▋| 97/100 [00:06<00:00, 16.30it/s]\n",
      "Benchmarking RACE_M:  99%|█████████▉| 99/100 [00:06<00:00, 15.99it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:06<00:00, 14.98it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: race_m\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on RACE_M with 100 samples...\n",
      "Layer 4/16: Halt prob: 0.1422, Accumulated: 0.1422, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0641, Accumulated: 0.2063, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0429, Accumulated: 0.2492, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0375, Accumulated: 0.2867, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0354, Accumulated: 0.3221, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0383, Accumulated: 0.3604, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0434, Accumulated: 0.4038, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0968, Accumulated: 0.5006, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1314, Accumulated: 0.6320, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1430, Accumulated: 0.7750, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1132, Accumulated: 0.8883, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0637, Accumulated: 0.9520, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0220, Accumulated: 0.9740, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0097, Accumulated: 0.0097, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0098, Accumulated: 0.0195, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0233, Accumulated: 0.0428, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0519, Accumulated: 0.0947, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0061, Accumulated: 0.1008, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0090, Accumulated: 0.1097, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0058, Accumulated: 0.1156, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0102, Accumulated: 0.1258, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0173, Accumulated: 0.1431, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8460, Accumulated: 0.9891, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0108, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2190, Accumulated: 0.2190, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0821, Accumulated: 0.3011, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0520, Accumulated: 0.3532, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0400, Accumulated: 0.3932, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0311, Accumulated: 0.4243, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0381, Accumulated: 0.4623, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0486, Accumulated: 0.5109, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1179, Accumulated: 0.6289, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1340, Accumulated: 0.7629, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1006, Accumulated: 0.8634, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0702, Accumulated: 0.9336, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0397, Accumulated: 0.9733, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0138, Accumulated: 0.9872, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0088, Accumulated: 0.0088, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0097, Accumulated: 0.0185, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0102, Accumulated: 0.0287, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0261, Accumulated: 0.0547, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0242, Accumulated: 0.0789, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0136, Accumulated: 0.0925, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0445, Accumulated: 0.1370, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0150, Accumulated: 0.1520, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0210, Accumulated: 0.1730, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.3384, Accumulated: 0.5114, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.4535, Accumulated: 0.9649, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0345, Accumulated: 0.9995, Threshold: 0.9900\n",
      "Early exit at layer 15/16\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1688, Accumulated: 0.1688, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0740, Accumulated: 0.2428, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0555, Accumulated: 0.2984, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0380, Accumulated: 0.3364, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0333, Accumulated: 0.3697, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0482, Accumulated: 0.4179, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0521, Accumulated: 0.4700, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1206, Accumulated: 0.5906, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1610, Accumulated: 0.7516, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1124, Accumulated: 0.8640, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0711, Accumulated: 0.9350, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0421, Accumulated: 0.9772, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0127, Accumulated: 0.9898, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0227, Accumulated: 0.0227, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0248, Accumulated: 0.0475, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0286, Accumulated: 0.0761, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0205, Accumulated: 0.0966, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0202, Accumulated: 0.1168, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0140, Accumulated: 0.1308, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0114, Accumulated: 0.1422, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0333, Accumulated: 0.1754, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0555, Accumulated: 0.2310, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7555, Accumulated: 0.9865, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0134, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2058, Accumulated: 0.2058, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0930, Accumulated: 0.2988, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0579, Accumulated: 0.3566, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0489, Accumulated: 0.4055, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0398, Accumulated: 0.4453, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0458, Accumulated: 0.4911, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0471, Accumulated: 0.5382, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0943, Accumulated: 0.6324, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1319, Accumulated: 0.7643, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1013, Accumulated: 0.8657, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0669, Accumulated: 0.9325, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0368, Accumulated: 0.9693, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0139, Accumulated: 0.9831, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0072, Accumulated: 0.0072, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0141, Accumulated: 0.0214, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0314, Accumulated: 0.0527, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0345, Accumulated: 0.0872, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0090, Accumulated: 0.0962, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0113, Accumulated: 0.1075, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0103, Accumulated: 0.1178, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0160, Accumulated: 0.1338, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0489, Accumulated: 0.1827, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7706, Accumulated: 0.9533, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0459, Accumulated: 0.9992, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2235, Accumulated: 0.2235, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0900, Accumulated: 0.3136, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0581, Accumulated: 0.3716, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0408, Accumulated: 0.4124, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0400, Accumulated: 0.4525, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0424, Accumulated: 0.4948, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0490, Accumulated: 0.5438, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0949, Accumulated: 0.6387, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1218, Accumulated: 0.7605, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0971, Accumulated: 0.8576, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0774, Accumulated: 0.9351, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0383, Accumulated: 0.9734, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0130, Accumulated: 0.9863, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0076, Accumulated: 0.0076, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0390, Accumulated: 0.0466, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0117, Accumulated: 0.0583, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0751, Accumulated: 0.1334, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0087, Accumulated: 0.1421, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0532, Accumulated: 0.1954, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0215, Accumulated: 0.2169, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0090, Accumulated: 0.2259, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0109, Accumulated: 0.2369, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6733, Accumulated: 0.9102, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0830, Accumulated: 0.9932, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1548, Accumulated: 0.1548, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0671, Accumulated: 0.2219, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0479, Accumulated: 0.2698, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0414, Accumulated: 0.3112, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0309, Accumulated: 0.3421, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0376, Accumulated: 0.3797, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0458, Accumulated: 0.4255, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0990, Accumulated: 0.5244, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1486, Accumulated: 0.6730, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1270, Accumulated: 0.8000, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0949, Accumulated: 0.8949, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0587, Accumulated: 0.9536, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0199, Accumulated: 0.9735, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0113, Accumulated: 0.0113, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0114, Accumulated: 0.0226, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0116, Accumulated: 0.0342, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0181, Accumulated: 0.0523, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0083, Accumulated: 0.0605, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0075, Accumulated: 0.0680, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0108, Accumulated: 0.0788, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0363, Accumulated: 0.1152, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0366, Accumulated: 0.1518, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8143, Accumulated: 0.9660, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0338, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1904, Accumulated: 0.1904, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0896, Accumulated: 0.2801, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0572, Accumulated: 0.3373, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0417, Accumulated: 0.3790, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0350, Accumulated: 0.4140, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0430, Accumulated: 0.4570, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0519, Accumulated: 0.5090, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0913, Accumulated: 0.6003, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1207, Accumulated: 0.7210, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1004, Accumulated: 0.8214, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0790, Accumulated: 0.9004, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0567, Accumulated: 0.9571, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0182, Accumulated: 0.9753, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0089, Accumulated: 0.0089, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0119, Accumulated: 0.0208, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0087, Accumulated: 0.0295, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0169, Accumulated: 0.0464, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0205, Accumulated: 0.0669, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0606, Accumulated: 0.1275, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0172, Accumulated: 0.1447, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0565, Accumulated: 0.2013, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0293, Accumulated: 0.2306, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7626, Accumulated: 0.9932, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1632, Accumulated: 0.1632, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0591, Accumulated: 0.2224, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0477, Accumulated: 0.2701, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0346, Accumulated: 0.3047, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0334, Accumulated: 0.3381, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0390, Accumulated: 0.3770, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0461, Accumulated: 0.4231, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1141, Accumulated: 0.5372, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1551, Accumulated: 0.6923, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1186, Accumulated: 0.8109, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0839, Accumulated: 0.8948, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0575, Accumulated: 0.9523, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0226, Accumulated: 0.9750, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0098, Accumulated: 0.0098, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0053, Accumulated: 0.0152, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0128, Accumulated: 0.0280, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0211, Accumulated: 0.0490, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.0583, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0172, Accumulated: 0.0754, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0087, Accumulated: 0.0841, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2359, Accumulated: 0.3200, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1578, Accumulated: 0.4778, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5212, Accumulated: 0.9990, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1973, Accumulated: 0.1973, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0863, Accumulated: 0.2836, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0517, Accumulated: 0.3353, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0422, Accumulated: 0.3774, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0308, Accumulated: 0.4082, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0381, Accumulated: 0.4464, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0658, Accumulated: 0.5122, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1162, Accumulated: 0.6284, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1125, Accumulated: 0.7409, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0984, Accumulated: 0.8393, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0707, Accumulated: 0.9100, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0483, Accumulated: 0.9583, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0206, Accumulated: 0.9789, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0089, Accumulated: 0.0089, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0152, Accumulated: 0.0241, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0105, Accumulated: 0.0347, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0204, Accumulated: 0.0551, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0676, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0136, Accumulated: 0.0812, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0072, Accumulated: 0.0884, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0117, Accumulated: 0.1001, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0162, Accumulated: 0.1163, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8630, Accumulated: 0.9793, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0206, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1884, Accumulated: 0.1884, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0754, Accumulated: 0.2638, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0491, Accumulated: 0.3128, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0382, Accumulated: 0.3510, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0317, Accumulated: 0.3827, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0388, Accumulated: 0.4215, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0447, Accumulated: 0.4662, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0860, Accumulated: 0.5522, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1565, Accumulated: 0.7088, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1178, Accumulated: 0.8266, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0881, Accumulated: 0.9147, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0518, Accumulated: 0.9664, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0159, Accumulated: 0.9823, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0080, Accumulated: 0.0080, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0107, Accumulated: 0.0188, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0105, Accumulated: 0.0293, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0261, Accumulated: 0.0554, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0084, Accumulated: 0.0638, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0344, Accumulated: 0.0982, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0225, Accumulated: 0.1207, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1015, Accumulated: 0.2222, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0421, Accumulated: 0.2643, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7242, Accumulated: 0.9885, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0114, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2147, Accumulated: 0.2147, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0994, Accumulated: 0.3141, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0679, Accumulated: 0.3820, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0488, Accumulated: 0.4308, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0423, Accumulated: 0.4730, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0462, Accumulated: 0.5192, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0488, Accumulated: 0.5680, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0817, Accumulated: 0.6497, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1035, Accumulated: 0.7532, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0856, Accumulated: 0.8388, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0711, Accumulated: 0.9099, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0447, Accumulated: 0.9546, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0169, Accumulated: 0.9715, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0088, Accumulated: 0.0088, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0080, Accumulated: 0.0168, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0072, Accumulated: 0.0240, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0742, Accumulated: 0.0982, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0056, Accumulated: 0.1038, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0239, Accumulated: 0.1277, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0127, Accumulated: 0.1404, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0363, Accumulated: 0.1768, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0223, Accumulated: 0.1991, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7556, Accumulated: 0.9546, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0451, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2480, Accumulated: 0.2480, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1144, Accumulated: 0.3624, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0681, Accumulated: 0.4305, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0505, Accumulated: 0.4810, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0387, Accumulated: 0.5197, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0442, Accumulated: 0.5639, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0480, Accumulated: 0.6120, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0934, Accumulated: 0.7054, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1136, Accumulated: 0.8190, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0809, Accumulated: 0.8999, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0526, Accumulated: 0.9525, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0262, Accumulated: 0.9787, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0090, Accumulated: 0.9877, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0135, Accumulated: 0.0214, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0154, Accumulated: 0.0369, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0349, Accumulated: 0.0718, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0152, Accumulated: 0.0870, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0237, Accumulated: 0.1107, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0678, Accumulated: 0.1786, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0127, Accumulated: 0.1913, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0148, Accumulated: 0.2061, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7645, Accumulated: 0.9705, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0291, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2008, Accumulated: 0.2008, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0778, Accumulated: 0.2786, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0501, Accumulated: 0.3286, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0390, Accumulated: 0.3676, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0308, Accumulated: 0.3984, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0384, Accumulated: 0.4368, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0444, Accumulated: 0.4812, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0951, Accumulated: 0.5763, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1360, Accumulated: 0.7123, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1138, Accumulated: 0.8261, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0883, Accumulated: 0.9144, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0481, Accumulated: 0.9625, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0177, Accumulated: 0.9801, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0139, Accumulated: 0.0139, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0347, Accumulated: 0.0486, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0149, Accumulated: 0.0636, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0191, Accumulated: 0.0827, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0899, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0081, Accumulated: 0.0980, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0112, Accumulated: 0.1092, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0191, Accumulated: 0.1282, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0323, Accumulated: 0.1605, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8112, Accumulated: 0.9717, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0280, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1980, Accumulated: 0.1980, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0808, Accumulated: 0.2788, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0511, Accumulated: 0.3299, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0436, Accumulated: 0.3735, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0326, Accumulated: 0.4061, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0428, Accumulated: 0.4489, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0470, Accumulated: 0.4959, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0843, Accumulated: 0.5802, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1180, Accumulated: 0.6982, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1040, Accumulated: 0.8022, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0863, Accumulated: 0.8886, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0628, Accumulated: 0.9514, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0227, Accumulated: 0.9741, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0080, Accumulated: 0.0080, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0107, Accumulated: 0.0187, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0089, Accumulated: 0.0276, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0502, Accumulated: 0.0778, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0228, Accumulated: 0.1006, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0487, Accumulated: 0.1493, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0157, Accumulated: 0.1650, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0639, Accumulated: 0.2289, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0463, Accumulated: 0.2752, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7110, Accumulated: 0.9862, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0138, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2094, Accumulated: 0.2094, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0912, Accumulated: 0.3005, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0536, Accumulated: 0.3541, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0440, Accumulated: 0.3981, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0351, Accumulated: 0.4332, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0456, Accumulated: 0.4788, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0474, Accumulated: 0.5262, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0887, Accumulated: 0.6148, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1319, Accumulated: 0.7468, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1045, Accumulated: 0.8512, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0726, Accumulated: 0.9239, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0434, Accumulated: 0.9673, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0145, Accumulated: 0.9818, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0084, Accumulated: 0.0084, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0079, Accumulated: 0.0163, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0202, Accumulated: 0.0365, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0288, Accumulated: 0.0653, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0248, Accumulated: 0.0901, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0228, Accumulated: 0.1129, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0104, Accumulated: 0.1233, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1218, Accumulated: 0.2451, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.2177, Accumulated: 0.4628, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5351, Accumulated: 0.9979, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1980, Accumulated: 0.1980, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0784, Accumulated: 0.2764, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0525, Accumulated: 0.3289, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0397, Accumulated: 0.3686, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0321, Accumulated: 0.4007, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0397, Accumulated: 0.4404, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0454, Accumulated: 0.4858, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0980, Accumulated: 0.5838, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1384, Accumulated: 0.7222, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1127, Accumulated: 0.8349, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0825, Accumulated: 0.9174, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0463, Accumulated: 0.9637, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0173, Accumulated: 0.9810, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0149, Accumulated: 0.0149, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0097, Accumulated: 0.0245, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0100, Accumulated: 0.0345, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0225, Accumulated: 0.0570, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0131, Accumulated: 0.0700, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0240, Accumulated: 0.0940, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0100, Accumulated: 0.1040, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0541, Accumulated: 0.1581, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0624, Accumulated: 0.2206, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7593, Accumulated: 0.9798, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0201, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1827, Accumulated: 0.1827, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0845, Accumulated: 0.2672, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0510, Accumulated: 0.3182, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0315, Accumulated: 0.3498, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0290, Accumulated: 0.3788, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0367, Accumulated: 0.4155, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0553, Accumulated: 0.4708, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1026, Accumulated: 0.5734, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1484, Accumulated: 0.7218, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1151, Accumulated: 0.8369, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0850, Accumulated: 0.9219, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0471, Accumulated: 0.9690, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0145, Accumulated: 0.9834, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0078, Accumulated: 0.0078, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0094, Accumulated: 0.0172, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0147, Accumulated: 0.0319, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0660, Accumulated: 0.0979, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0117, Accumulated: 0.1096, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0146, Accumulated: 0.1242, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0073, Accumulated: 0.1315, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0172, Accumulated: 0.1487, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0185, Accumulated: 0.1671, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7755, Accumulated: 0.9427, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0569, Accumulated: 0.9996, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2112, Accumulated: 0.2112, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0919, Accumulated: 0.3031, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0720, Accumulated: 0.3751, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0493, Accumulated: 0.4244, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0465, Accumulated: 0.4709, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0510, Accumulated: 0.5219, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0598, Accumulated: 0.5817, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0917, Accumulated: 0.6733, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1083, Accumulated: 0.7816, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0884, Accumulated: 0.8700, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0664, Accumulated: 0.9365, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0350, Accumulated: 0.9715, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0117, Accumulated: 0.9832, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0065, Accumulated: 0.0065, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0106, Accumulated: 0.0170, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0075, Accumulated: 0.0245, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0583, Accumulated: 0.0828, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0114, Accumulated: 0.0942, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0351, Accumulated: 0.1293, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0158, Accumulated: 0.1451, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0224, Accumulated: 0.1675, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0130, Accumulated: 0.1805, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7686, Accumulated: 0.9492, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0497, Accumulated: 0.9989, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1711, Accumulated: 0.1711, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0757, Accumulated: 0.2469, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0430, Accumulated: 0.2899, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0386, Accumulated: 0.3285, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0334, Accumulated: 0.3619, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0392, Accumulated: 0.4011, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0485, Accumulated: 0.4496, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0980, Accumulated: 0.5475, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1456, Accumulated: 0.6931, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1309, Accumulated: 0.8240, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0924, Accumulated: 0.9164, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0510, Accumulated: 0.9674, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0183, Accumulated: 0.9856, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0082, Accumulated: 0.0082, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0087, Accumulated: 0.0168, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0181, Accumulated: 0.0350, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0246, Accumulated: 0.0596, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0131, Accumulated: 0.0727, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0112, Accumulated: 0.0839, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0051, Accumulated: 0.0890, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0440, Accumulated: 0.1330, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0397, Accumulated: 0.1726, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7995, Accumulated: 0.9721, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0277, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1829, Accumulated: 0.1829, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0706, Accumulated: 0.2534, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0426, Accumulated: 0.2960, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0370, Accumulated: 0.3330, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0308, Accumulated: 0.3638, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0370, Accumulated: 0.4008, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0434, Accumulated: 0.4442, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1016, Accumulated: 0.5458, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1291, Accumulated: 0.6749, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1210, Accumulated: 0.7958, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0990, Accumulated: 0.8948, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0585, Accumulated: 0.9534, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0211, Accumulated: 0.9745, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0072, Accumulated: 0.0072, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0177, Accumulated: 0.0249, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0106, Accumulated: 0.0355, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1891, Accumulated: 0.2246, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0274, Accumulated: 0.2520, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0235, Accumulated: 0.2755, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0297, Accumulated: 0.3052, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0268, Accumulated: 0.3320, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0133, Accumulated: 0.3453, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6490, Accumulated: 0.9942, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1517, Accumulated: 0.1517, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0679, Accumulated: 0.2196, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0466, Accumulated: 0.2662, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0338, Accumulated: 0.3000, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0278, Accumulated: 0.3278, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0429, Accumulated: 0.3707, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0584, Accumulated: 0.4290, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1370, Accumulated: 0.5660, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1245, Accumulated: 0.6905, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1120, Accumulated: 0.8025, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0982, Accumulated: 0.9007, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0571, Accumulated: 0.9578, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0186, Accumulated: 0.9764, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0449, Accumulated: 0.0449, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0334, Accumulated: 0.0783, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0096, Accumulated: 0.0879, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0248, Accumulated: 0.1127, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0110, Accumulated: 0.1238, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0212, Accumulated: 0.1450, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0187, Accumulated: 0.1636, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0059, Accumulated: 0.1695, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0103, Accumulated: 0.1798, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7994, Accumulated: 0.9792, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0206, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2417, Accumulated: 0.2417, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1072, Accumulated: 0.3489, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0692, Accumulated: 0.4181, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0496, Accumulated: 0.4677, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0370, Accumulated: 0.5047, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0425, Accumulated: 0.5472, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0492, Accumulated: 0.5965, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1084, Accumulated: 0.7048, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1181, Accumulated: 0.8229, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0832, Accumulated: 0.9062, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0527, Accumulated: 0.9589, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0232, Accumulated: 0.9821, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0084, Accumulated: 0.9904, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0110, Accumulated: 0.0110, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0126, Accumulated: 0.0236, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0112, Accumulated: 0.0348, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0655, Accumulated: 0.1003, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0117, Accumulated: 0.1120, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0151, Accumulated: 0.1270, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0115, Accumulated: 0.1386, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0148, Accumulated: 0.1534, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0390, Accumulated: 0.1924, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8001, Accumulated: 0.9925, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1843, Accumulated: 0.1843, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0694, Accumulated: 0.2538, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0441, Accumulated: 0.2979, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0355, Accumulated: 0.3335, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0343, Accumulated: 0.3677, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0426, Accumulated: 0.4103, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0420, Accumulated: 0.4522, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1161, Accumulated: 0.5683, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1556, Accumulated: 0.7239, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1269, Accumulated: 0.8507, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0850, Accumulated: 0.9357, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0409, Accumulated: 0.9766, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0125, Accumulated: 0.9891, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0120, Accumulated: 0.0120, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0140, Accumulated: 0.0261, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0110, Accumulated: 0.0370, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0223, Accumulated: 0.0593, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.0685, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0269, Accumulated: 0.0954, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0158, Accumulated: 0.1112, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0166, Accumulated: 0.1278, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0117, Accumulated: 0.1394, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7530, Accumulated: 0.8924, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1055, Accumulated: 0.9980, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1638, Accumulated: 0.1638, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0734, Accumulated: 0.2372, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0463, Accumulated: 0.2835, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0388, Accumulated: 0.3223, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0312, Accumulated: 0.3535, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0364, Accumulated: 0.3898, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0587, Accumulated: 0.4485, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1078, Accumulated: 0.5564, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1413, Accumulated: 0.6977, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1182, Accumulated: 0.8159, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0870, Accumulated: 0.9029, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0554, Accumulated: 0.9582, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0201, Accumulated: 0.9783, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0111, Accumulated: 0.0111, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0079, Accumulated: 0.0189, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0109, Accumulated: 0.0298, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0328, Accumulated: 0.0627, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0089, Accumulated: 0.0715, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0307, Accumulated: 0.1022, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0180, Accumulated: 0.1202, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0379, Accumulated: 0.1581, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0463, Accumulated: 0.2044, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7723, Accumulated: 0.9767, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0231, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2216, Accumulated: 0.2216, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0871, Accumulated: 0.3086, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0413, Accumulated: 0.3499, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0327, Accumulated: 0.3827, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0255, Accumulated: 0.4081, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0351, Accumulated: 0.4432, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0443, Accumulated: 0.4875, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0992, Accumulated: 0.5866, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1339, Accumulated: 0.7206, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1041, Accumulated: 0.8247, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0779, Accumulated: 0.9025, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0500, Accumulated: 0.9525, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0195, Accumulated: 0.9720, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0084, Accumulated: 0.0084, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0090, Accumulated: 0.0174, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0244, Accumulated: 0.0418, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1145, Accumulated: 0.1563, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0098, Accumulated: 0.1661, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0065, Accumulated: 0.1726, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0080, Accumulated: 0.1806, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0223, Accumulated: 0.2029, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0144, Accumulated: 0.2173, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7674, Accumulated: 0.9847, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0152, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1918, Accumulated: 0.1918, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0860, Accumulated: 0.2778, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0502, Accumulated: 0.3280, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0385, Accumulated: 0.3665, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0341, Accumulated: 0.4006, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0378, Accumulated: 0.4384, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0550, Accumulated: 0.4935, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1125, Accumulated: 0.6060, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1470, Accumulated: 0.7529, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1078, Accumulated: 0.8608, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0704, Accumulated: 0.9312, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0385, Accumulated: 0.9697, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0143, Accumulated: 0.9840, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0056, Accumulated: 0.0056, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0195, Accumulated: 0.0251, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0080, Accumulated: 0.0331, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0840, Accumulated: 0.1172, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0392, Accumulated: 0.1564, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0177, Accumulated: 0.1740, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0305, Accumulated: 0.2045, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0121, Accumulated: 0.2166, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0088, Accumulated: 0.2254, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6721, Accumulated: 0.8975, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0949, Accumulated: 0.9924, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1663, Accumulated: 0.1663, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0700, Accumulated: 0.2362, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0450, Accumulated: 0.2812, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0307, Accumulated: 0.3119, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0258, Accumulated: 0.3378, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0322, Accumulated: 0.3700, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0450, Accumulated: 0.4150, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1073, Accumulated: 0.5223, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1513, Accumulated: 0.6735, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1254, Accumulated: 0.7990, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0948, Accumulated: 0.8938, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0596, Accumulated: 0.9534, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0235, Accumulated: 0.9769, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0204, Accumulated: 0.0204, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1008, Accumulated: 0.1212, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0153, Accumulated: 0.1365, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0115, Accumulated: 0.1481, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0403, Accumulated: 0.1884, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0091, Accumulated: 0.1974, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0183, Accumulated: 0.2158, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0320, Accumulated: 0.2477, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0580, Accumulated: 0.3058, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6875, Accumulated: 0.9932, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1406, Accumulated: 0.1406, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0652, Accumulated: 0.2058, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0503, Accumulated: 0.2561, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0364, Accumulated: 0.2925, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0268, Accumulated: 0.3193, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0370, Accumulated: 0.3563, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0484, Accumulated: 0.4047, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1482, Accumulated: 0.5529, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1633, Accumulated: 0.7162, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1313, Accumulated: 0.8475, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0827, Accumulated: 0.9302, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0419, Accumulated: 0.9721, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0139, Accumulated: 0.9860, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0091, Accumulated: 0.0091, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0134, Accumulated: 0.0225, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0098, Accumulated: 0.0323, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0269, Accumulated: 0.0592, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0063, Accumulated: 0.0655, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0161, Accumulated: 0.0816, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0157, Accumulated: 0.0973, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0340, Accumulated: 0.1313, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0366, Accumulated: 0.1679, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8175, Accumulated: 0.9854, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0146, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1725, Accumulated: 0.1725, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0714, Accumulated: 0.2439, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0519, Accumulated: 0.2958, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0434, Accumulated: 0.3392, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0373, Accumulated: 0.3765, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0374, Accumulated: 0.4139, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0360, Accumulated: 0.4499, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0694, Accumulated: 0.5194, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1214, Accumulated: 0.6408, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1113, Accumulated: 0.7521, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0964, Accumulated: 0.8485, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0804, Accumulated: 0.9289, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0314, Accumulated: 0.9603, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0168, Accumulated: 0.0168, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0289, Accumulated: 0.0457, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0151, Accumulated: 0.0608, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0169, Accumulated: 0.0778, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0045, Accumulated: 0.0822, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0144, Accumulated: 0.0967, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0094, Accumulated: 0.1060, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1307, Accumulated: 0.2368, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.2376, Accumulated: 0.4743, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5233, Accumulated: 0.9977, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1921, Accumulated: 0.1921, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0850, Accumulated: 0.2771, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0508, Accumulated: 0.3279, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0384, Accumulated: 0.3663, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0329, Accumulated: 0.3992, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0438, Accumulated: 0.4430, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0423, Accumulated: 0.4853, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0649, Accumulated: 0.5502, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1065, Accumulated: 0.6567, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0964, Accumulated: 0.7531, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1116, Accumulated: 0.8647, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0753, Accumulated: 0.9400, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0288, Accumulated: 0.9689, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0083, Accumulated: 0.0083, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0137, Accumulated: 0.0220, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0120, Accumulated: 0.0340, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.3747, Accumulated: 0.4088, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0372, Accumulated: 0.4459, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0050, Accumulated: 0.4510, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0125, Accumulated: 0.4635, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0076, Accumulated: 0.4711, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0063, Accumulated: 0.4775, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.4779, Accumulated: 0.9553, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0436, Accumulated: 0.9989, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1763, Accumulated: 0.1763, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0869, Accumulated: 0.2632, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0554, Accumulated: 0.3186, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0356, Accumulated: 0.3541, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0332, Accumulated: 0.3874, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0348, Accumulated: 0.4221, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0504, Accumulated: 0.4725, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1045, Accumulated: 0.5770, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1471, Accumulated: 0.7241, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1139, Accumulated: 0.8380, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0800, Accumulated: 0.9180, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0447, Accumulated: 0.9626, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0155, Accumulated: 0.9782, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0162, Accumulated: 0.0162, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0245, Accumulated: 0.0407, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0185, Accumulated: 0.0593, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0106, Accumulated: 0.0699, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0236, Accumulated: 0.0935, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0104, Accumulated: 0.1039, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0121, Accumulated: 0.1160, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0303, Accumulated: 0.1463, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0102, Accumulated: 0.1565, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7372, Accumulated: 0.8937, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1004, Accumulated: 0.9942, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2180, Accumulated: 0.2180, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0862, Accumulated: 0.3043, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0607, Accumulated: 0.3650, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0486, Accumulated: 0.4136, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0373, Accumulated: 0.4508, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0504, Accumulated: 0.5013, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0459, Accumulated: 0.5471, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0856, Accumulated: 0.6328, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1297, Accumulated: 0.7625, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0940, Accumulated: 0.8565, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0708, Accumulated: 0.9273, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0378, Accumulated: 0.9651, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0144, Accumulated: 0.9795, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0087, Accumulated: 0.0087, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0072, Accumulated: 0.0159, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0180, Accumulated: 0.0339, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0536, Accumulated: 0.0875, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0134, Accumulated: 0.1009, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0128, Accumulated: 0.1136, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0202, Accumulated: 0.1338, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0372, Accumulated: 0.1711, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0133, Accumulated: 0.1844, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7826, Accumulated: 0.9669, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0328, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1698, Accumulated: 0.1698, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0566, Accumulated: 0.2264, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0428, Accumulated: 0.2692, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0405, Accumulated: 0.3097, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0267, Accumulated: 0.3364, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0347, Accumulated: 0.3710, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0377, Accumulated: 0.4087, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0909, Accumulated: 0.4996, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1217, Accumulated: 0.6213, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1187, Accumulated: 0.7400, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1177, Accumulated: 0.8578, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0755, Accumulated: 0.9333, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0273, Accumulated: 0.9605, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0075, Accumulated: 0.0075, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0114, Accumulated: 0.0188, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0131, Accumulated: 0.0320, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1937, Accumulated: 0.2256, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0249, Accumulated: 0.2506, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0050, Accumulated: 0.2556, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0062, Accumulated: 0.2618, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0449, Accumulated: 0.3067, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0096, Accumulated: 0.3163, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6747, Accumulated: 0.9910, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1639, Accumulated: 0.1639, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0929, Accumulated: 0.2568, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0637, Accumulated: 0.3205, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0435, Accumulated: 0.3640, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0342, Accumulated: 0.3983, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0398, Accumulated: 0.4381, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0495, Accumulated: 0.4875, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1077, Accumulated: 0.5953, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1278, Accumulated: 0.7230, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1044, Accumulated: 0.8274, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0857, Accumulated: 0.9132, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0514, Accumulated: 0.9646, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0174, Accumulated: 0.9820, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0098, Accumulated: 0.0098, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0093, Accumulated: 0.0191, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0104, Accumulated: 0.0295, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0794, Accumulated: 0.1089, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0068, Accumulated: 0.1157, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0117, Accumulated: 0.1274, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0069, Accumulated: 0.1343, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0131, Accumulated: 0.1474, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0192, Accumulated: 0.1666, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8257, Accumulated: 0.9923, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2366, Accumulated: 0.2366, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0906, Accumulated: 0.3272, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0565, Accumulated: 0.3836, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0436, Accumulated: 0.4272, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0373, Accumulated: 0.4645, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0423, Accumulated: 0.5068, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0482, Accumulated: 0.5550, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1057, Accumulated: 0.6607, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1279, Accumulated: 0.7886, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0954, Accumulated: 0.8840, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0624, Accumulated: 0.9464, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0321, Accumulated: 0.9784, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0108, Accumulated: 0.9892, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0145, Accumulated: 0.0145, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0133, Accumulated: 0.0278, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0082, Accumulated: 0.0359, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0688, Accumulated: 0.1047, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0080, Accumulated: 0.1127, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0320, Accumulated: 0.1446, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0206, Accumulated: 0.1652, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0155, Accumulated: 0.1807, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0412, Accumulated: 0.2219, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7736, Accumulated: 0.9954, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2212, Accumulated: 0.2212, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0947, Accumulated: 0.3159, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0510, Accumulated: 0.3669, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0423, Accumulated: 0.4093, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0343, Accumulated: 0.4436, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0414, Accumulated: 0.4850, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0467, Accumulated: 0.5317, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0960, Accumulated: 0.6277, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1115, Accumulated: 0.7392, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0989, Accumulated: 0.8381, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0785, Accumulated: 0.9166, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0451, Accumulated: 0.9617, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0156, Accumulated: 0.9773, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0205, Accumulated: 0.0205, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0618, Accumulated: 0.0823, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0223, Accumulated: 0.1045, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0275, Accumulated: 0.1320, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0142, Accumulated: 0.1462, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0114, Accumulated: 0.1576, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0125, Accumulated: 0.1701, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0741, Accumulated: 0.2442, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0556, Accumulated: 0.2998, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6933, Accumulated: 0.9932, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1965, Accumulated: 0.1965, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0856, Accumulated: 0.2821, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0546, Accumulated: 0.3367, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0434, Accumulated: 0.3801, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0345, Accumulated: 0.4146, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0426, Accumulated: 0.4572, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0554, Accumulated: 0.5126, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0912, Accumulated: 0.6037, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1293, Accumulated: 0.7330, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1047, Accumulated: 0.8377, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0804, Accumulated: 0.9180, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0446, Accumulated: 0.9627, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0171, Accumulated: 0.9797, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0091, Accumulated: 0.0091, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0287, Accumulated: 0.0378, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0190, Accumulated: 0.0568, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1185, Accumulated: 0.1753, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.1844, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0659, Accumulated: 0.2502, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0074, Accumulated: 0.2576, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0075, Accumulated: 0.2651, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0041, Accumulated: 0.2692, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6584, Accumulated: 0.9276, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0716, Accumulated: 0.9991, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1954, Accumulated: 0.1954, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0888, Accumulated: 0.2842, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0536, Accumulated: 0.3378, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0405, Accumulated: 0.3783, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0346, Accumulated: 0.4128, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0387, Accumulated: 0.4516, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0463, Accumulated: 0.4978, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0834, Accumulated: 0.5812, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1357, Accumulated: 0.7169, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1089, Accumulated: 0.8258, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0801, Accumulated: 0.9059, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0515, Accumulated: 0.9575, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0176, Accumulated: 0.9750, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0100, Accumulated: 0.0100, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0105, Accumulated: 0.0204, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0102, Accumulated: 0.0306, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0606, Accumulated: 0.0912, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0121, Accumulated: 0.1034, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0181, Accumulated: 0.1215, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0113, Accumulated: 0.1328, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0689, Accumulated: 0.2017, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0836, Accumulated: 0.2853, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7105, Accumulated: 0.9958, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1989, Accumulated: 0.1989, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0934, Accumulated: 0.2923, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0598, Accumulated: 0.3521, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0419, Accumulated: 0.3940, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0377, Accumulated: 0.4317, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0433, Accumulated: 0.4750, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0546, Accumulated: 0.5296, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1050, Accumulated: 0.6346, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1253, Accumulated: 0.7599, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1020, Accumulated: 0.8620, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0757, Accumulated: 0.9377, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0379, Accumulated: 0.9756, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0113, Accumulated: 0.9869, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0094, Accumulated: 0.0094, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0305, Accumulated: 0.0399, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0176, Accumulated: 0.0575, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0289, Accumulated: 0.0863, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0116, Accumulated: 0.0979, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0137, Accumulated: 0.1116, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0234, Accumulated: 0.1350, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0265, Accumulated: 0.1615, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0420, Accumulated: 0.2034, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7860, Accumulated: 0.9895, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0103, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1750, Accumulated: 0.1750, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0819, Accumulated: 0.2569, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0525, Accumulated: 0.3094, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0364, Accumulated: 0.3458, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0283, Accumulated: 0.3741, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0350, Accumulated: 0.4091, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0455, Accumulated: 0.4545, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1301, Accumulated: 0.5846, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1598, Accumulated: 0.7445, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1057, Accumulated: 0.8501, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0720, Accumulated: 0.9221, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0421, Accumulated: 0.9642, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0148, Accumulated: 0.9790, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0140, Accumulated: 0.0140, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0136, Accumulated: 0.0277, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0113, Accumulated: 0.0390, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0215, Accumulated: 0.0605, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0083, Accumulated: 0.0687, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0398, Accumulated: 0.1085, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0158, Accumulated: 0.1244, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0134, Accumulated: 0.1378, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0260, Accumulated: 0.1638, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8244, Accumulated: 0.9882, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0118, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2037, Accumulated: 0.2037, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0893, Accumulated: 0.2930, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0508, Accumulated: 0.3438, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0386, Accumulated: 0.3825, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0328, Accumulated: 0.4152, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0455, Accumulated: 0.4607, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0592, Accumulated: 0.5199, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1123, Accumulated: 0.6322, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1351, Accumulated: 0.7673, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1043, Accumulated: 0.8716, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0646, Accumulated: 0.9363, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0367, Accumulated: 0.9729, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0126, Accumulated: 0.9855, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0066, Accumulated: 0.0066, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0209, Accumulated: 0.0275, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0105, Accumulated: 0.0380, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0508, Accumulated: 0.0888, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0111, Accumulated: 0.0999, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0224, Accumulated: 0.1224, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0849, Accumulated: 0.2073, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0176, Accumulated: 0.2249, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0211, Accumulated: 0.2459, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6786, Accumulated: 0.9245, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0679, Accumulated: 0.9924, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1986, Accumulated: 0.1986, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0914, Accumulated: 0.2900, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0548, Accumulated: 0.3448, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0451, Accumulated: 0.3899, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0371, Accumulated: 0.4270, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0399, Accumulated: 0.4669, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0422, Accumulated: 0.5091, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0931, Accumulated: 0.6022, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1351, Accumulated: 0.7373, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1111, Accumulated: 0.8484, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0777, Accumulated: 0.9261, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0379, Accumulated: 0.9640, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0144, Accumulated: 0.9784, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0112, Accumulated: 0.0112, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0120, Accumulated: 0.0232, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0130, Accumulated: 0.0362, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0308, Accumulated: 0.0670, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0794, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0063, Accumulated: 0.0857, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0127, Accumulated: 0.0984, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0496, Accumulated: 0.1480, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0096, Accumulated: 0.1576, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8021, Accumulated: 0.9597, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0399, Accumulated: 0.9996, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1085, Accumulated: 0.1085, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0528, Accumulated: 0.1613, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0313, Accumulated: 0.1926, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0276, Accumulated: 0.2202, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0190, Accumulated: 0.2392, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0244, Accumulated: 0.2636, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0308, Accumulated: 0.2944, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0928, Accumulated: 0.3872, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1384, Accumulated: 0.5256, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1237, Accumulated: 0.6493, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1337, Accumulated: 0.7829, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.1121, Accumulated: 0.8951, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0442, Accumulated: 0.9393, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0076, Accumulated: 0.0076, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0145, Accumulated: 0.0221, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0161, Accumulated: 0.0382, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.2080, Accumulated: 0.2463, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0249, Accumulated: 0.2712, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0084, Accumulated: 0.2796, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0072, Accumulated: 0.2867, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0068, Accumulated: 0.2935, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0055, Accumulated: 0.2990, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5648, Accumulated: 0.8638, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1322, Accumulated: 0.9959, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1437, Accumulated: 0.1437, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0724, Accumulated: 0.2161, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0501, Accumulated: 0.2662, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0344, Accumulated: 0.3006, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0307, Accumulated: 0.3313, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0344, Accumulated: 0.3657, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0523, Accumulated: 0.4180, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1169, Accumulated: 0.5348, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1552, Accumulated: 0.6901, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1263, Accumulated: 0.8164, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0902, Accumulated: 0.9066, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0526, Accumulated: 0.9592, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0189, Accumulated: 0.9781, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0219, Accumulated: 0.0219, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0206, Accumulated: 0.0425, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0153, Accumulated: 0.0577, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0125, Accumulated: 0.0702, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0079, Accumulated: 0.0781, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0136, Accumulated: 0.0917, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0194, Accumulated: 0.1111, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1878, Accumulated: 0.2989, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.2658, Accumulated: 0.5648, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.4278, Accumulated: 0.9926, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1779, Accumulated: 0.1779, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0745, Accumulated: 0.2523, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0502, Accumulated: 0.3025, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0400, Accumulated: 0.3425, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0296, Accumulated: 0.3721, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0382, Accumulated: 0.4102, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0479, Accumulated: 0.4582, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1042, Accumulated: 0.5624, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1375, Accumulated: 0.6999, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1154, Accumulated: 0.8153, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0866, Accumulated: 0.9019, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0540, Accumulated: 0.9559, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0201, Accumulated: 0.9761, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0054, Accumulated: 0.0054, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0163, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0066, Accumulated: 0.0229, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0843, Accumulated: 0.1072, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0432, Accumulated: 0.1504, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0105, Accumulated: 0.1610, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0135, Accumulated: 0.1744, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0408, Accumulated: 0.2152, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0727, Accumulated: 0.2879, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6575, Accumulated: 0.9454, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0540, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1448, Accumulated: 0.1448, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0668, Accumulated: 0.2116, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0480, Accumulated: 0.2595, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0411, Accumulated: 0.3007, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0318, Accumulated: 0.3324, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0387, Accumulated: 0.3711, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0436, Accumulated: 0.4147, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0943, Accumulated: 0.5090, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1410, Accumulated: 0.6500, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1271, Accumulated: 0.7771, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1054, Accumulated: 0.8824, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0670, Accumulated: 0.9494, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0226, Accumulated: 0.9720, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0342, Accumulated: 0.0342, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0358, Accumulated: 0.0700, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0118, Accumulated: 0.0818, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0091, Accumulated: 0.0909, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0108, Accumulated: 0.1016, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0144, Accumulated: 0.1160, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0095, Accumulated: 0.1254, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0506, Accumulated: 0.1760, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0984, Accumulated: 0.2744, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7015, Accumulated: 0.9759, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0241, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1622, Accumulated: 0.1622, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0759, Accumulated: 0.2382, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0503, Accumulated: 0.2884, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0443, Accumulated: 0.3328, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0327, Accumulated: 0.3655, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0436, Accumulated: 0.4090, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0434, Accumulated: 0.4524, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0910, Accumulated: 0.5434, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1280, Accumulated: 0.6714, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1143, Accumulated: 0.7857, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0932, Accumulated: 0.8789, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0654, Accumulated: 0.9444, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0255, Accumulated: 0.9699, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0187, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0159, Accumulated: 0.0346, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0161, Accumulated: 0.0507, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0065, Accumulated: 0.0572, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0300, Accumulated: 0.0872, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0077, Accumulated: 0.0949, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0252, Accumulated: 0.1202, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0083, Accumulated: 0.1285, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8388, Accumulated: 0.9672, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0325, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1735, Accumulated: 0.1735, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0923, Accumulated: 0.2658, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0520, Accumulated: 0.3178, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0360, Accumulated: 0.3538, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0306, Accumulated: 0.3844, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0411, Accumulated: 0.4256, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0558, Accumulated: 0.4814, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1091, Accumulated: 0.5905, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1367, Accumulated: 0.7272, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1121, Accumulated: 0.8393, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0824, Accumulated: 0.9217, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0420, Accumulated: 0.9636, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0159, Accumulated: 0.9795, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0117, Accumulated: 0.0117, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0262, Accumulated: 0.0379, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0145, Accumulated: 0.0524, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0279, Accumulated: 0.0803, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0116, Accumulated: 0.0919, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0085, Accumulated: 0.1004, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0245, Accumulated: 0.1249, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0252, Accumulated: 0.1501, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0290, Accumulated: 0.1791, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8008, Accumulated: 0.9800, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0199, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1678, Accumulated: 0.1678, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0738, Accumulated: 0.2416, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0462, Accumulated: 0.2879, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0401, Accumulated: 0.3280, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0308, Accumulated: 0.3588, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0360, Accumulated: 0.3948, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0579, Accumulated: 0.4527, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1063, Accumulated: 0.5590, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1391, Accumulated: 0.6981, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1175, Accumulated: 0.8156, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0864, Accumulated: 0.9019, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0566, Accumulated: 0.9585, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0203, Accumulated: 0.9789, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0059, Accumulated: 0.0059, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0127, Accumulated: 0.0186, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0089, Accumulated: 0.0275, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0762, Accumulated: 0.1037, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0070, Accumulated: 0.1107, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0121, Accumulated: 0.1228, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0116, Accumulated: 0.1344, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0414, Accumulated: 0.1758, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0218, Accumulated: 0.1976, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7436, Accumulated: 0.9412, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0572, Accumulated: 0.9985, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1962, Accumulated: 0.1962, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0789, Accumulated: 0.2751, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0506, Accumulated: 0.3257, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0426, Accumulated: 0.3682, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0319, Accumulated: 0.4002, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0413, Accumulated: 0.4414, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0435, Accumulated: 0.4850, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0975, Accumulated: 0.5825, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1424, Accumulated: 0.7249, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1214, Accumulated: 0.8463, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0816, Accumulated: 0.9280, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0420, Accumulated: 0.9699, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0141, Accumulated: 0.9840, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0099, Accumulated: 0.0099, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0071, Accumulated: 0.0170, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0096, Accumulated: 0.0265, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0523, Accumulated: 0.0788, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0078, Accumulated: 0.0866, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0304, Accumulated: 0.1170, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0161, Accumulated: 0.1331, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0753, Accumulated: 0.2084, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0359, Accumulated: 0.2443, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7458, Accumulated: 0.9900, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2451, Accumulated: 0.2451, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1035, Accumulated: 0.3486, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0609, Accumulated: 0.4095, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0445, Accumulated: 0.4540, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0373, Accumulated: 0.4913, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0480, Accumulated: 0.5393, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0549, Accumulated: 0.5942, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0948, Accumulated: 0.6890, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1195, Accumulated: 0.8085, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0901, Accumulated: 0.8986, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0586, Accumulated: 0.9572, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0261, Accumulated: 0.9833, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0082, Accumulated: 0.9915, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0110, Accumulated: 0.0110, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0112, Accumulated: 0.0222, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0063, Accumulated: 0.0285, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.2243, Accumulated: 0.2527, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0083, Accumulated: 0.2611, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0156, Accumulated: 0.2767, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0241, Accumulated: 0.3008, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0173, Accumulated: 0.3180, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0193, Accumulated: 0.3373, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6442, Accumulated: 0.9816, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0182, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2133, Accumulated: 0.2133, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0859, Accumulated: 0.2992, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0510, Accumulated: 0.3502, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0399, Accumulated: 0.3901, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0324, Accumulated: 0.4224, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0410, Accumulated: 0.4635, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0452, Accumulated: 0.5087, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0860, Accumulated: 0.5947, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1234, Accumulated: 0.7181, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1117, Accumulated: 0.8298, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0812, Accumulated: 0.9109, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0468, Accumulated: 0.9577, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0188, Accumulated: 0.9765, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0120, Accumulated: 0.0120, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0301, Accumulated: 0.0421, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0231, Accumulated: 0.0652, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0090, Accumulated: 0.0742, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0310, Accumulated: 0.1053, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0134, Accumulated: 0.1186, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0319, Accumulated: 0.1506, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1035, Accumulated: 0.2541, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1135, Accumulated: 0.3676, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6198, Accumulated: 0.9873, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0126, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2296, Accumulated: 0.2296, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0953, Accumulated: 0.3249, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0656, Accumulated: 0.3906, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0449, Accumulated: 0.4354, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0446, Accumulated: 0.4800, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0536, Accumulated: 0.5337, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0651, Accumulated: 0.5988, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0987, Accumulated: 0.6975, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1006, Accumulated: 0.7981, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0759, Accumulated: 0.8740, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0588, Accumulated: 0.9328, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0344, Accumulated: 0.9673, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0151, Accumulated: 0.9823, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0098, Accumulated: 0.0098, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0120, Accumulated: 0.0218, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0126, Accumulated: 0.0344, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0324, Accumulated: 0.0668, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0193, Accumulated: 0.0862, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0291, Accumulated: 0.1152, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0148, Accumulated: 0.1300, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0192, Accumulated: 0.1493, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0122, Accumulated: 0.1614, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8218, Accumulated: 0.9832, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0167, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2025, Accumulated: 0.2025, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0876, Accumulated: 0.2901, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0506, Accumulated: 0.3407, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0427, Accumulated: 0.3834, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0305, Accumulated: 0.4139, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0350, Accumulated: 0.4489, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0430, Accumulated: 0.4919, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0930, Accumulated: 0.5849, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1343, Accumulated: 0.7192, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1118, Accumulated: 0.8310, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0876, Accumulated: 0.9185, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0470, Accumulated: 0.9655, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0162, Accumulated: 0.9818, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0126, Accumulated: 0.0126, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0188, Accumulated: 0.0314, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0101, Accumulated: 0.0415, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0469, Accumulated: 0.0884, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0113, Accumulated: 0.0996, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0091, Accumulated: 0.1087, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0087, Accumulated: 0.1174, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0157, Accumulated: 0.1330, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0183, Accumulated: 0.1513, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8019, Accumulated: 0.9532, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0462, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2169, Accumulated: 0.2169, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0903, Accumulated: 0.3073, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0574, Accumulated: 0.3647, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0430, Accumulated: 0.4077, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0352, Accumulated: 0.4429, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0430, Accumulated: 0.4859, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0584, Accumulated: 0.5443, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1033, Accumulated: 0.6476, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1241, Accumulated: 0.7717, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0924, Accumulated: 0.8641, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0651, Accumulated: 0.9292, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0376, Accumulated: 0.9668, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0145, Accumulated: 0.9813, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0189, Accumulated: 0.0189, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0087, Accumulated: 0.0275, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0120, Accumulated: 0.0396, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0320, Accumulated: 0.0715, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0096, Accumulated: 0.0811, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0267, Accumulated: 0.1079, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0097, Accumulated: 0.1175, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1181, Accumulated: 0.2356, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1450, Accumulated: 0.3806, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6058, Accumulated: 0.9864, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0135, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1754, Accumulated: 0.1754, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0815, Accumulated: 0.2569, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0509, Accumulated: 0.3079, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0427, Accumulated: 0.3506, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0381, Accumulated: 0.3887, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0448, Accumulated: 0.4336, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0636, Accumulated: 0.4972, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1074, Accumulated: 0.6046, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1292, Accumulated: 0.7338, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1138, Accumulated: 0.8475, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0774, Accumulated: 0.9249, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0447, Accumulated: 0.9697, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0143, Accumulated: 0.9840, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0095, Accumulated: 0.0095, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0157, Accumulated: 0.0252, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0086, Accumulated: 0.0338, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0305, Accumulated: 0.0643, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0096, Accumulated: 0.0740, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0089, Accumulated: 0.0829, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0084, Accumulated: 0.0913, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0429, Accumulated: 0.1342, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0506, Accumulated: 0.1849, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8100, Accumulated: 0.9948, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1702, Accumulated: 0.1702, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0677, Accumulated: 0.2379, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0383, Accumulated: 0.2761, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0262, Accumulated: 0.3024, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0274, Accumulated: 0.3297, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0293, Accumulated: 0.3590, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0444, Accumulated: 0.4035, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1181, Accumulated: 0.5216, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1793, Accumulated: 0.7009, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1374, Accumulated: 0.8382, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0904, Accumulated: 0.9286, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0466, Accumulated: 0.9752, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0147, Accumulated: 0.9899, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0118, Accumulated: 0.0118, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0444, Accumulated: 0.0561, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0068, Accumulated: 0.0629, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0151, Accumulated: 0.0780, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0075, Accumulated: 0.0855, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0085, Accumulated: 0.0941, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0069, Accumulated: 0.1009, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0297, Accumulated: 0.1306, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0191, Accumulated: 0.1497, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8304, Accumulated: 0.9801, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0198, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1725, Accumulated: 0.1725, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0688, Accumulated: 0.2413, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0414, Accumulated: 0.2827, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0337, Accumulated: 0.3163, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0239, Accumulated: 0.3402, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0287, Accumulated: 0.3690, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0484, Accumulated: 0.4173, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1028, Accumulated: 0.5202, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1483, Accumulated: 0.6685, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1239, Accumulated: 0.7924, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1033, Accumulated: 0.8957, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0605, Accumulated: 0.9563, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0208, Accumulated: 0.9770, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0083, Accumulated: 0.0083, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0190, Accumulated: 0.0273, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0125, Accumulated: 0.0398, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0195, Accumulated: 0.0594, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0047, Accumulated: 0.0641, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0107, Accumulated: 0.0748, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0071, Accumulated: 0.0819, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0203, Accumulated: 0.1022, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0230, Accumulated: 0.1252, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8543, Accumulated: 0.9795, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0204, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1835, Accumulated: 0.1835, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0822, Accumulated: 0.2657, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0568, Accumulated: 0.3224, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0395, Accumulated: 0.3620, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0368, Accumulated: 0.3988, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0386, Accumulated: 0.4374, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0485, Accumulated: 0.4859, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0970, Accumulated: 0.5829, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1323, Accumulated: 0.7152, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1078, Accumulated: 0.8230, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0837, Accumulated: 0.9068, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0580, Accumulated: 0.9648, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0187, Accumulated: 0.9835, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0056, Accumulated: 0.0056, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0155, Accumulated: 0.0212, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0168, Accumulated: 0.0380, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.3248, Accumulated: 0.3628, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0221, Accumulated: 0.3849, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0107, Accumulated: 0.3957, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0105, Accumulated: 0.4062, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0059, Accumulated: 0.4120, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0053, Accumulated: 0.4173, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5417, Accumulated: 0.9590, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0405, Accumulated: 0.9995, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2311, Accumulated: 0.2311, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1025, Accumulated: 0.3336, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0550, Accumulated: 0.3885, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0455, Accumulated: 0.4341, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0362, Accumulated: 0.4703, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0448, Accumulated: 0.5150, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0596, Accumulated: 0.5746, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0990, Accumulated: 0.6736, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1212, Accumulated: 0.7948, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0954, Accumulated: 0.8902, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0563, Accumulated: 0.9465, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0292, Accumulated: 0.9757, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0109, Accumulated: 0.9866, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0105, Accumulated: 0.0105, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0059, Accumulated: 0.0164, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0136, Accumulated: 0.0300, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0292, Accumulated: 0.0592, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0121, Accumulated: 0.0714, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0499, Accumulated: 0.1213, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0138, Accumulated: 0.1351, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0149, Accumulated: 0.1500, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0167, Accumulated: 0.1667, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7918, Accumulated: 0.9585, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0409, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1808, Accumulated: 0.1808, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0693, Accumulated: 0.2501, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0429, Accumulated: 0.2930, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0359, Accumulated: 0.3290, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0289, Accumulated: 0.3578, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0378, Accumulated: 0.3957, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0429, Accumulated: 0.4386, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1037, Accumulated: 0.5423, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1490, Accumulated: 0.6913, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1266, Accumulated: 0.8179, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0846, Accumulated: 0.9025, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0563, Accumulated: 0.9588, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0204, Accumulated: 0.9792, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0408, Accumulated: 0.0408, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0472, Accumulated: 0.0880, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0088, Accumulated: 0.0969, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0470, Accumulated: 0.1439, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0098, Accumulated: 0.1537, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0174, Accumulated: 0.1711, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0105, Accumulated: 0.1817, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0641, Accumulated: 0.2458, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0522, Accumulated: 0.2981, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6803, Accumulated: 0.9784, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0215, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2115, Accumulated: 0.2115, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0843, Accumulated: 0.2959, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0575, Accumulated: 0.3534, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0459, Accumulated: 0.3993, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0388, Accumulated: 0.4381, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0427, Accumulated: 0.4808, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0510, Accumulated: 0.5318, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1070, Accumulated: 0.6388, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1333, Accumulated: 0.7721, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1027, Accumulated: 0.8748, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0714, Accumulated: 0.9462, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0326, Accumulated: 0.9788, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0100, Accumulated: 0.9888, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0108, Accumulated: 0.0108, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0302, Accumulated: 0.0410, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0249, Accumulated: 0.0659, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0160, Accumulated: 0.0819, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0213, Accumulated: 0.1033, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0168, Accumulated: 0.1201, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0402, Accumulated: 0.1603, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0317, Accumulated: 0.1920, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1012, Accumulated: 0.2932, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6968, Accumulated: 0.9900, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0098, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2185, Accumulated: 0.2185, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0842, Accumulated: 0.3027, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0547, Accumulated: 0.3574, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0428, Accumulated: 0.4003, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0343, Accumulated: 0.4346, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0412, Accumulated: 0.4758, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0479, Accumulated: 0.5237, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0920, Accumulated: 0.6156, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1327, Accumulated: 0.7483, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1031, Accumulated: 0.8514, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0736, Accumulated: 0.9250, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0409, Accumulated: 0.9659, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0171, Accumulated: 0.9830, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0068, Accumulated: 0.0068, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0152, Accumulated: 0.0220, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0073, Accumulated: 0.0293, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1121, Accumulated: 0.1414, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0308, Accumulated: 0.1722, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0164, Accumulated: 0.1886, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0487, Accumulated: 0.2373, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0053, Accumulated: 0.2426, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0115, Accumulated: 0.2541, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7182, Accumulated: 0.9723, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0256, Accumulated: 0.9980, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2566, Accumulated: 0.2566, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1221, Accumulated: 0.3786, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0724, Accumulated: 0.4511, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0540, Accumulated: 0.5051, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0398, Accumulated: 0.5448, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0457, Accumulated: 0.5906, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0487, Accumulated: 0.6392, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0908, Accumulated: 0.7301, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1047, Accumulated: 0.8347, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0736, Accumulated: 0.9083, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0483, Accumulated: 0.9566, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0243, Accumulated: 0.9809, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0081, Accumulated: 0.9889, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0103, Accumulated: 0.0103, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0080, Accumulated: 0.0183, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0084, Accumulated: 0.0267, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0610, Accumulated: 0.0876, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.0968, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0352, Accumulated: 0.1320, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0200, Accumulated: 0.1520, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0399, Accumulated: 0.1919, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0715, Accumulated: 0.2633, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7147, Accumulated: 0.9781, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0217, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1802, Accumulated: 0.1802, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0849, Accumulated: 0.2650, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0541, Accumulated: 0.3192, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0456, Accumulated: 0.3648, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0390, Accumulated: 0.4038, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0437, Accumulated: 0.4475, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0545, Accumulated: 0.5019, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1166, Accumulated: 0.6186, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1437, Accumulated: 0.7622, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1135, Accumulated: 0.8757, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0663, Accumulated: 0.9420, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0332, Accumulated: 0.9753, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0111, Accumulated: 0.9864, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0103, Accumulated: 0.0103, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0163, Accumulated: 0.0266, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0179, Accumulated: 0.0445, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1056, Accumulated: 0.1501, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0081, Accumulated: 0.1582, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0169, Accumulated: 0.1750, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0116, Accumulated: 0.1866, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1213, Accumulated: 0.3079, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0763, Accumulated: 0.3843, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6082, Accumulated: 0.9925, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1548, Accumulated: 0.1548, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0656, Accumulated: 0.2204, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0436, Accumulated: 0.2640, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0354, Accumulated: 0.2994, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0316, Accumulated: 0.3310, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0362, Accumulated: 0.3673, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0438, Accumulated: 0.4110, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1130, Accumulated: 0.5240, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1563, Accumulated: 0.6803, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1272, Accumulated: 0.8075, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0915, Accumulated: 0.8991, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0572, Accumulated: 0.9563, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0202, Accumulated: 0.9765, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0070, Accumulated: 0.0070, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0178, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0318, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0495, Accumulated: 0.0813, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0201, Accumulated: 0.1014, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0113, Accumulated: 0.1127, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0299, Accumulated: 0.1425, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0139, Accumulated: 0.1565, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0314, Accumulated: 0.1879, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7951, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0169, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1674, Accumulated: 0.1674, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1020, Accumulated: 0.2694, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0691, Accumulated: 0.3385, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0526, Accumulated: 0.3910, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0393, Accumulated: 0.4303, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0430, Accumulated: 0.4733, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0444, Accumulated: 0.5178, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1041, Accumulated: 0.6219, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1249, Accumulated: 0.7468, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1107, Accumulated: 0.8574, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0777, Accumulated: 0.9351, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0408, Accumulated: 0.9759, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0116, Accumulated: 0.9875, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0151, Accumulated: 0.0151, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0074, Accumulated: 0.0225, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0057, Accumulated: 0.0282, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0420, Accumulated: 0.0702, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0064, Accumulated: 0.0766, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0465, Accumulated: 0.1231, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0127, Accumulated: 0.1357, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0677, Accumulated: 0.2035, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0892, Accumulated: 0.2926, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6991, Accumulated: 0.9917, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2384, Accumulated: 0.2384, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1051, Accumulated: 0.3435, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0699, Accumulated: 0.4134, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0557, Accumulated: 0.4691, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0402, Accumulated: 0.5093, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0426, Accumulated: 0.5519, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0430, Accumulated: 0.5949, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0656, Accumulated: 0.6605, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0932, Accumulated: 0.7538, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0767, Accumulated: 0.8305, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0837, Accumulated: 0.9141, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0484, Accumulated: 0.9626, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0159, Accumulated: 0.9784, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0078, Accumulated: 0.0078, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0352, Accumulated: 0.0429, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0101, Accumulated: 0.0530, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1394, Accumulated: 0.1925, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0171, Accumulated: 0.2095, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0153, Accumulated: 0.2248, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0056, Accumulated: 0.2305, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0118, Accumulated: 0.2423, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0144, Accumulated: 0.2567, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6849, Accumulated: 0.9416, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0579, Accumulated: 0.9995, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2094, Accumulated: 0.2094, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0778, Accumulated: 0.2872, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0513, Accumulated: 0.3384, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0418, Accumulated: 0.3802, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0286, Accumulated: 0.4088, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0378, Accumulated: 0.4466, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0425, Accumulated: 0.4891, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0908, Accumulated: 0.5799, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1244, Accumulated: 0.7043, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1115, Accumulated: 0.8158, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0879, Accumulated: 0.9037, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0512, Accumulated: 0.9549, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0203, Accumulated: 0.9752, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0128, Accumulated: 0.0128, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0141, Accumulated: 0.0269, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0144, Accumulated: 0.0413, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0678, Accumulated: 0.1090, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0190, Accumulated: 0.1281, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0057, Accumulated: 0.1338, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0162, Accumulated: 0.1500, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0097, Accumulated: 0.1597, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0099, Accumulated: 0.1696, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7294, Accumulated: 0.8990, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0985, Accumulated: 0.9975, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1809, Accumulated: 0.1809, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0698, Accumulated: 0.2507, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0403, Accumulated: 0.2910, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0322, Accumulated: 0.3232, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0264, Accumulated: 0.3496, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0367, Accumulated: 0.3863, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0405, Accumulated: 0.4267, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1020, Accumulated: 0.5288, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1438, Accumulated: 0.6726, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1263, Accumulated: 0.7989, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0876, Accumulated: 0.8865, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0606, Accumulated: 0.9471, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0240, Accumulated: 0.9712, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0095, Accumulated: 0.0095, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0197, Accumulated: 0.0292, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0266, Accumulated: 0.0558, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0244, Accumulated: 0.0802, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0111, Accumulated: 0.0913, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0151, Accumulated: 0.1064, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0097, Accumulated: 0.1160, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0342, Accumulated: 0.1502, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0307, Accumulated: 0.1809, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7935, Accumulated: 0.9744, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0255, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2335, Accumulated: 0.2335, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0997, Accumulated: 0.3333, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0518, Accumulated: 0.3850, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0381, Accumulated: 0.4231, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0269, Accumulated: 0.4501, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0367, Accumulated: 0.4867, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0441, Accumulated: 0.5309, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0836, Accumulated: 0.6144, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1264, Accumulated: 0.7408, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1034, Accumulated: 0.8442, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0772, Accumulated: 0.9215, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0437, Accumulated: 0.9651, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0144, Accumulated: 0.9795, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0070, Accumulated: 0.0070, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0193, Accumulated: 0.0264, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0443, Accumulated: 0.0707, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1458, Accumulated: 0.2165, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0205, Accumulated: 0.2369, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0132, Accumulated: 0.2501, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0084, Accumulated: 0.2585, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0050, Accumulated: 0.2634, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0052, Accumulated: 0.2687, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5274, Accumulated: 0.7961, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1869, Accumulated: 0.9830, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0162, Accumulated: 0.9992, Threshold: 0.9900\n",
      "Early exit at layer 15/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2234, Accumulated: 0.2234, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0932, Accumulated: 0.3166, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0509, Accumulated: 0.3675, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0371, Accumulated: 0.4046, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0339, Accumulated: 0.4386, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0390, Accumulated: 0.4775, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0451, Accumulated: 0.5227, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1050, Accumulated: 0.6277, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1258, Accumulated: 0.7535, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1014, Accumulated: 0.8548, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0714, Accumulated: 0.9262, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0412, Accumulated: 0.9674, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0155, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0062, Accumulated: 0.0062, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0132, Accumulated: 0.0194, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0088, Accumulated: 0.0283, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1431, Accumulated: 0.1713, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0189, Accumulated: 0.1903, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0123, Accumulated: 0.2025, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0077, Accumulated: 0.2102, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0943, Accumulated: 0.3045, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0925, Accumulated: 0.3970, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5998, Accumulated: 0.9968, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2576, Accumulated: 0.2576, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1040, Accumulated: 0.3616, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0620, Accumulated: 0.4236, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0503, Accumulated: 0.4738, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0383, Accumulated: 0.5121, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0407, Accumulated: 0.5528, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0470, Accumulated: 0.5998, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0939, Accumulated: 0.6937, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1110, Accumulated: 0.8047, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0820, Accumulated: 0.8867, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0553, Accumulated: 0.9420, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0319, Accumulated: 0.9739, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0124, Accumulated: 0.9863, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0102, Accumulated: 0.0102, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0166, Accumulated: 0.0268, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0163, Accumulated: 0.0431, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.2710, Accumulated: 0.3141, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0497, Accumulated: 0.3638, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0066, Accumulated: 0.3704, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0055, Accumulated: 0.3759, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0192, Accumulated: 0.3951, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0170, Accumulated: 0.4120, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5099, Accumulated: 0.9219, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0751, Accumulated: 0.9970, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2363, Accumulated: 0.2363, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0904, Accumulated: 0.3267, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0548, Accumulated: 0.3815, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0426, Accumulated: 0.4241, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0371, Accumulated: 0.4612, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0418, Accumulated: 0.5030, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0471, Accumulated: 0.5501, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1023, Accumulated: 0.6524, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1275, Accumulated: 0.7800, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0981, Accumulated: 0.8781, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0653, Accumulated: 0.9433, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0347, Accumulated: 0.9780, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0109, Accumulated: 0.9889, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0069, Accumulated: 0.0069, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0219, Accumulated: 0.0288, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0106, Accumulated: 0.0394, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0484, Accumulated: 0.0878, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0129, Accumulated: 0.1007, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0122, Accumulated: 0.1129, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0068, Accumulated: 0.1196, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0139, Accumulated: 0.1335, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0104, Accumulated: 0.1439, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8352, Accumulated: 0.9791, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0208, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2211, Accumulated: 0.2211, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0879, Accumulated: 0.3090, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0504, Accumulated: 0.3594, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0416, Accumulated: 0.4010, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0277, Accumulated: 0.4287, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0385, Accumulated: 0.4672, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0527, Accumulated: 0.5200, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0991, Accumulated: 0.6190, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1334, Accumulated: 0.7524, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1104, Accumulated: 0.8628, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0682, Accumulated: 0.9310, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0385, Accumulated: 0.9695, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0136, Accumulated: 0.9831, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0219, Accumulated: 0.0219, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0267, Accumulated: 0.0486, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0217, Accumulated: 0.0703, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0137, Accumulated: 0.0840, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0055, Accumulated: 0.0895, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0082, Accumulated: 0.0977, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0108, Accumulated: 0.1085, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2523, Accumulated: 0.3608, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1192, Accumulated: 0.4799, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5041, Accumulated: 0.9840, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0158, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1477, Accumulated: 0.1477, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0775, Accumulated: 0.2252, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0553, Accumulated: 0.2805, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0462, Accumulated: 0.3267, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0414, Accumulated: 0.3681, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0429, Accumulated: 0.4110, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0558, Accumulated: 0.4668, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0773, Accumulated: 0.5441, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1150, Accumulated: 0.6591, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1045, Accumulated: 0.7635, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1044, Accumulated: 0.8679, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0757, Accumulated: 0.9436, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0270, Accumulated: 0.9707, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0075, Accumulated: 0.0075, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0193, Accumulated: 0.0267, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0118, Accumulated: 0.0385, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0646, Accumulated: 0.1031, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0067, Accumulated: 0.1099, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0198, Accumulated: 0.1297, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0072, Accumulated: 0.1369, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0327, Accumulated: 0.1696, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0480, Accumulated: 0.2176, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7763, Accumulated: 0.9939, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1862, Accumulated: 0.1862, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0824, Accumulated: 0.2686, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0516, Accumulated: 0.3201, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0394, Accumulated: 0.3596, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0337, Accumulated: 0.3933, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0429, Accumulated: 0.4362, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0411, Accumulated: 0.4772, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0678, Accumulated: 0.5450, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1065, Accumulated: 0.6515, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0990, Accumulated: 0.7504, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1112, Accumulated: 0.8616, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0796, Accumulated: 0.9412, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0294, Accumulated: 0.9706, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0086, Accumulated: 0.0086, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0082, Accumulated: 0.0168, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0081, Accumulated: 0.0249, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.3126, Accumulated: 0.3375, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0143, Accumulated: 0.3518, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0065, Accumulated: 0.3583, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0045, Accumulated: 0.3627, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0081, Accumulated: 0.3708, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0143, Accumulated: 0.3852, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5605, Accumulated: 0.9457, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0535, Accumulated: 0.9992, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1537, Accumulated: 0.1537, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0830, Accumulated: 0.2366, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0592, Accumulated: 0.2959, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0473, Accumulated: 0.3432, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0313, Accumulated: 0.3745, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0443, Accumulated: 0.4188, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0494, Accumulated: 0.4681, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1232, Accumulated: 0.5914, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1399, Accumulated: 0.7312, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1204, Accumulated: 0.8516, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0771, Accumulated: 0.9288, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0435, Accumulated: 0.9723, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0146, Accumulated: 0.9869, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0102, Accumulated: 0.0102, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0218, Accumulated: 0.0320, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0096, Accumulated: 0.0416, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0655, Accumulated: 0.1071, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0169, Accumulated: 0.1240, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0111, Accumulated: 0.1351, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0073, Accumulated: 0.1424, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0120, Accumulated: 0.1543, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0149, Accumulated: 0.1692, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7716, Accumulated: 0.9408, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0581, Accumulated: 0.9989, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1948, Accumulated: 0.1948, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0847, Accumulated: 0.2795, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0493, Accumulated: 0.3288, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0382, Accumulated: 0.3670, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0268, Accumulated: 0.3938, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0336, Accumulated: 0.4275, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0392, Accumulated: 0.4667, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0898, Accumulated: 0.5565, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1348, Accumulated: 0.6913, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1234, Accumulated: 0.8147, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0940, Accumulated: 0.9087, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0562, Accumulated: 0.9649, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0173, Accumulated: 0.9822, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0071, Accumulated: 0.0150, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0162, Accumulated: 0.0312, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0269, Accumulated: 0.0581, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0066, Accumulated: 0.0647, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0085, Accumulated: 0.0732, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0060, Accumulated: 0.0792, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0286, Accumulated: 0.1077, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0646, Accumulated: 0.1724, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8082, Accumulated: 0.9806, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0192, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1949, Accumulated: 0.1949, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0821, Accumulated: 0.2771, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0511, Accumulated: 0.3282, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0385, Accumulated: 0.3666, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0276, Accumulated: 0.3942, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0349, Accumulated: 0.4291, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0424, Accumulated: 0.4715, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0864, Accumulated: 0.5580, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1158, Accumulated: 0.6738, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1031, Accumulated: 0.7768, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0995, Accumulated: 0.8763, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0774, Accumulated: 0.9537, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0249, Accumulated: 0.9787, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0071, Accumulated: 0.0071, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0096, Accumulated: 0.0167, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0102, Accumulated: 0.0269, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.3297, Accumulated: 0.3567, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0116, Accumulated: 0.3682, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0083, Accumulated: 0.3765, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0127, Accumulated: 0.3892, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0117, Accumulated: 0.4009, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0161, Accumulated: 0.4171, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5562, Accumulated: 0.9732, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0265, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1981, Accumulated: 0.1981, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0902, Accumulated: 0.2883, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0511, Accumulated: 0.3394, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0429, Accumulated: 0.3823, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0346, Accumulated: 0.4169, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0413, Accumulated: 0.4582, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0501, Accumulated: 0.5083, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0996, Accumulated: 0.6080, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1297, Accumulated: 0.7377, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1050, Accumulated: 0.8427, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0763, Accumulated: 0.9190, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0436, Accumulated: 0.9627, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0165, Accumulated: 0.9791, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0066, Accumulated: 0.0066, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0127, Accumulated: 0.0193, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0062, Accumulated: 0.0255, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0435, Accumulated: 0.0690, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0073, Accumulated: 0.0763, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0180, Accumulated: 0.0943, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0121, Accumulated: 0.1064, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0079, Accumulated: 0.1143, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0113, Accumulated: 0.1257, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8423, Accumulated: 0.9680, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0316, Accumulated: 0.9995, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2068, Accumulated: 0.2068, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0910, Accumulated: 0.2978, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0646, Accumulated: 0.3624, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0402, Accumulated: 0.4026, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0324, Accumulated: 0.4350, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0326, Accumulated: 0.4676, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0474, Accumulated: 0.5150, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0963, Accumulated: 0.6113, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1309, Accumulated: 0.7422, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1034, Accumulated: 0.8455, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0761, Accumulated: 0.9216, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0429, Accumulated: 0.9645, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0150, Accumulated: 0.9795, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0080, Accumulated: 0.0080, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0341, Accumulated: 0.0421, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0100, Accumulated: 0.0521, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0662, Accumulated: 0.1184, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0150, Accumulated: 0.1334, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0205, Accumulated: 0.1539, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0162, Accumulated: 0.1701, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0069, Accumulated: 0.1770, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0185, Accumulated: 0.1955, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7857, Accumulated: 0.9811, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0187, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2266, Accumulated: 0.2266, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0964, Accumulated: 0.3230, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0611, Accumulated: 0.3841, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0511, Accumulated: 0.4351, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0371, Accumulated: 0.4722, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0516, Accumulated: 0.5238, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0576, Accumulated: 0.5815, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0948, Accumulated: 0.6763, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1002, Accumulated: 0.7765, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0846, Accumulated: 0.8611, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0676, Accumulated: 0.9287, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0399, Accumulated: 0.9686, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0141, Accumulated: 0.9827, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0193, Accumulated: 0.0193, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0396, Accumulated: 0.0589, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0084, Accumulated: 0.0674, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0138, Accumulated: 0.0812, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0100, Accumulated: 0.0912, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0161, Accumulated: 0.1073, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0087, Accumulated: 0.1159, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1006, Accumulated: 0.2166, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0987, Accumulated: 0.3153, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6807, Accumulated: 0.9960, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1719, Accumulated: 0.1719, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0742, Accumulated: 0.2461, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0432, Accumulated: 0.2893, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0302, Accumulated: 0.3195, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0280, Accumulated: 0.3475, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0357, Accumulated: 0.3831, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0501, Accumulated: 0.4332, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1090, Accumulated: 0.5422, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1576, Accumulated: 0.6998, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1284, Accumulated: 0.8282, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0919, Accumulated: 0.9201, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0483, Accumulated: 0.9685, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0171, Accumulated: 0.9856, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0066, Accumulated: 0.0066, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0148, Accumulated: 0.0214, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0089, Accumulated: 0.0302, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1056, Accumulated: 0.1358, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0261, Accumulated: 0.1619, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0069, Accumulated: 0.1688, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0288, Accumulated: 0.1976, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0060, Accumulated: 0.2036, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0136, Accumulated: 0.2172, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7205, Accumulated: 0.9377, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0608, Accumulated: 0.9985, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1570, Accumulated: 0.1570, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0626, Accumulated: 0.2196, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0532, Accumulated: 0.2727, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0336, Accumulated: 0.3063, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0290, Accumulated: 0.3353, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0292, Accumulated: 0.3645, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0439, Accumulated: 0.4085, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1081, Accumulated: 0.5166, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1748, Accumulated: 0.6914, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1353, Accumulated: 0.8266, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0952, Accumulated: 0.9218, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0504, Accumulated: 0.9722, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0143, Accumulated: 0.9865, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0061, Accumulated: 0.0061, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0149, Accumulated: 0.0210, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0350, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.2672, Accumulated: 0.3022, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0114, Accumulated: 0.3136, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0100, Accumulated: 0.3235, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0091, Accumulated: 0.3327, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0104, Accumulated: 0.3431, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0196, Accumulated: 0.3626, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6265, Accumulated: 0.9891, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0108, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2228, Accumulated: 0.2228, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0819, Accumulated: 0.3047, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0508, Accumulated: 0.3555, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0447, Accumulated: 0.4001, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0367, Accumulated: 0.4368, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0404, Accumulated: 0.4772, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0484, Accumulated: 0.5256, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0789, Accumulated: 0.6045, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1140, Accumulated: 0.7186, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1025, Accumulated: 0.8211, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0820, Accumulated: 0.9031, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0516, Accumulated: 0.9547, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0190, Accumulated: 0.9738, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0195, Accumulated: 0.0195, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0275, Accumulated: 0.0470, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0180, Accumulated: 0.0651, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0110, Accumulated: 0.0761, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0103, Accumulated: 0.0864, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0142, Accumulated: 0.1005, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0114, Accumulated: 0.1119, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0179, Accumulated: 0.1299, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0104, Accumulated: 0.1402, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8249, Accumulated: 0.9652, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0346, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1689, Accumulated: 0.1689, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0747, Accumulated: 0.2437, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0497, Accumulated: 0.2934, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0342, Accumulated: 0.3276, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0287, Accumulated: 0.3564, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0418, Accumulated: 0.3982, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0575, Accumulated: 0.4557, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1332, Accumulated: 0.5888, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1174, Accumulated: 0.7063, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1080, Accumulated: 0.8143, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0896, Accumulated: 0.9039, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0535, Accumulated: 0.9574, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0182, Accumulated: 0.9756, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0086, Accumulated: 0.0086, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0125, Accumulated: 0.0211, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0122, Accumulated: 0.0333, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.2747, Accumulated: 0.3081, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0183, Accumulated: 0.3263, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0099, Accumulated: 0.3362, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0090, Accumulated: 0.3453, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0331, Accumulated: 0.3784, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0395, Accumulated: 0.4178, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5731, Accumulated: 0.9909, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2074, Accumulated: 0.2074, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1035, Accumulated: 0.3109, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0581, Accumulated: 0.3690, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0379, Accumulated: 0.4069, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0339, Accumulated: 0.4408, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0390, Accumulated: 0.4799, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0404, Accumulated: 0.5202, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0853, Accumulated: 0.6056, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1289, Accumulated: 0.7345, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1123, Accumulated: 0.8468, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0894, Accumulated: 0.9362, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0395, Accumulated: 0.9757, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0118, Accumulated: 0.9875, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0104, Accumulated: 0.0104, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0124, Accumulated: 0.0228, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0105, Accumulated: 0.0333, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0254, Accumulated: 0.0587, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0100, Accumulated: 0.0686, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0158, Accumulated: 0.0845, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0078, Accumulated: 0.0922, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0119, Accumulated: 0.1042, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0077, Accumulated: 0.1119, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7355, Accumulated: 0.8474, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1474, Accumulated: 0.9948, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1975, Accumulated: 0.1975, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0784, Accumulated: 0.2759, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0556, Accumulated: 0.3315, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0469, Accumulated: 0.3784, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0383, Accumulated: 0.4167, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0431, Accumulated: 0.4599, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0445, Accumulated: 0.5044, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1033, Accumulated: 0.6077, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1395, Accumulated: 0.7471, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1066, Accumulated: 0.8537, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0797, Accumulated: 0.9334, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0421, Accumulated: 0.9755, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0123, Accumulated: 0.9878, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0173, Accumulated: 0.0173, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0084, Accumulated: 0.0258, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0116, Accumulated: 0.0374, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0721, Accumulated: 0.1095, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0150, Accumulated: 0.1244, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0062, Accumulated: 0.1306, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0128, Accumulated: 0.1434, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0171, Accumulated: 0.1605, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0183, Accumulated: 0.1788, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6712, Accumulated: 0.8500, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1432, Accumulated: 0.9933, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2283, Accumulated: 0.2283, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0991, Accumulated: 0.3274, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0613, Accumulated: 0.3886, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0463, Accumulated: 0.4349, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0414, Accumulated: 0.4763, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0418, Accumulated: 0.5181, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0531, Accumulated: 0.5712, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0979, Accumulated: 0.6691, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1263, Accumulated: 0.7954, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0913, Accumulated: 0.8866, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0597, Accumulated: 0.9464, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0296, Accumulated: 0.9760, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0111, Accumulated: 0.9871, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0077, Accumulated: 0.0077, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0085, Accumulated: 0.0162, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0078, Accumulated: 0.0240, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0171, Accumulated: 0.0411, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0123, Accumulated: 0.0534, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0100, Accumulated: 0.0634, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0106, Accumulated: 0.0740, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0258, Accumulated: 0.0998, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0212, Accumulated: 0.1211, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8429, Accumulated: 0.9639, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0358, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2354, Accumulated: 0.2354, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0987, Accumulated: 0.3340, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0543, Accumulated: 0.3884, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0370, Accumulated: 0.4253, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0296, Accumulated: 0.4549, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0327, Accumulated: 0.4876, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0400, Accumulated: 0.5276, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0845, Accumulated: 0.6121, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1457, Accumulated: 0.7577, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1119, Accumulated: 0.8696, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0727, Accumulated: 0.9423, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0335, Accumulated: 0.9759, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0118, Accumulated: 0.9877, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0214, Accumulated: 0.0214, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0485, Accumulated: 0.0700, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0160, Accumulated: 0.0860, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0203, Accumulated: 0.1063, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0082, Accumulated: 0.1145, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0101, Accumulated: 0.1247, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0154, Accumulated: 0.1401, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0564, Accumulated: 0.1965, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0067, Accumulated: 0.2032, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6879, Accumulated: 0.8911, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1064, Accumulated: 0.9974, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2002, Accumulated: 0.2002, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0853, Accumulated: 0.2855, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0572, Accumulated: 0.3427, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0426, Accumulated: 0.3852, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0414, Accumulated: 0.4266, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0503, Accumulated: 0.4768, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0571, Accumulated: 0.5339, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0973, Accumulated: 0.6313, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1397, Accumulated: 0.7710, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1034, Accumulated: 0.8744, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0709, Accumulated: 0.9454, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0328, Accumulated: 0.9782, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0099, Accumulated: 0.9881, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0071, Accumulated: 0.0071, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0088, Accumulated: 0.0159, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0098, Accumulated: 0.0258, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0559, Accumulated: 0.0817, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0080, Accumulated: 0.0897, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0226, Accumulated: 0.1122, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0100, Accumulated: 0.1222, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0832, Accumulated: 0.2054, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1465, Accumulated: 0.3519, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6465, Accumulated: 0.9984, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2062, Accumulated: 0.2062, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0821, Accumulated: 0.2883, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0532, Accumulated: 0.3414, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0433, Accumulated: 0.3848, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0296, Accumulated: 0.4143, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0386, Accumulated: 0.4529, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0426, Accumulated: 0.4956, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0895, Accumulated: 0.5851, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1180, Accumulated: 0.7031, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1090, Accumulated: 0.8121, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0888, Accumulated: 0.9010, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0530, Accumulated: 0.9540, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0204, Accumulated: 0.9744, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0177, Accumulated: 0.0177, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0106, Accumulated: 0.0283, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0074, Accumulated: 0.0357, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0772, Accumulated: 0.1129, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.1220, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0329, Accumulated: 0.1549, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0208, Accumulated: 0.1757, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0056, Accumulated: 0.1813, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0086, Accumulated: 0.1899, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7591, Accumulated: 0.9490, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0501, Accumulated: 0.9991, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1855, Accumulated: 0.1855, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0787, Accumulated: 0.2642, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0447, Accumulated: 0.3089, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0375, Accumulated: 0.3464, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0325, Accumulated: 0.3790, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0389, Accumulated: 0.4178, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0498, Accumulated: 0.4676, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0991, Accumulated: 0.5667, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1569, Accumulated: 0.7236, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1151, Accumulated: 0.8387, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0828, Accumulated: 0.9216, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0459, Accumulated: 0.9674, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0159, Accumulated: 0.9833, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0107, Accumulated: 0.0107, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0087, Accumulated: 0.0194, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0122, Accumulated: 0.0316, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0310, Accumulated: 0.0626, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0143, Accumulated: 0.0769, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0138, Accumulated: 0.0906, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0342, Accumulated: 0.1248, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0759, Accumulated: 0.2007, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0547, Accumulated: 0.2554, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7275, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0170, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1863, Accumulated: 0.1863, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0784, Accumulated: 0.2647, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0514, Accumulated: 0.3160, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0393, Accumulated: 0.3553, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0310, Accumulated: 0.3863, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0445, Accumulated: 0.4308, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0503, Accumulated: 0.4811, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0976, Accumulated: 0.5787, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1317, Accumulated: 0.7104, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1128, Accumulated: 0.8231, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0846, Accumulated: 0.9078, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0516, Accumulated: 0.9593, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0184, Accumulated: 0.9778, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0300, Accumulated: 0.0378, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0138, Accumulated: 0.0516, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0593, Accumulated: 0.1109, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0126, Accumulated: 0.1234, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0114, Accumulated: 0.1348, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0090, Accumulated: 0.1438, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0202, Accumulated: 0.1640, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0610, Accumulated: 0.2251, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7693, Accumulated: 0.9943, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1689, Accumulated: 0.1689, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0693, Accumulated: 0.2383, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0532, Accumulated: 0.2915, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0379, Accumulated: 0.3293, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0261, Accumulated: 0.3555, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0384, Accumulated: 0.3938, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0400, Accumulated: 0.4339, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1041, Accumulated: 0.5379, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1393, Accumulated: 0.6773, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1313, Accumulated: 0.8085, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0871, Accumulated: 0.8957, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0567, Accumulated: 0.9523, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0210, Accumulated: 0.9733, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0314, Accumulated: 0.0314, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0293, Accumulated: 0.0607, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0115, Accumulated: 0.0722, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0116, Accumulated: 0.0838, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0159, Accumulated: 0.0997, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0207, Accumulated: 0.1204, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0291, Accumulated: 0.1495, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0272, Accumulated: 0.1768, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0585, Accumulated: 0.2353, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7274, Accumulated: 0.9627, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0364, Accumulated: 0.9991, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1876, Accumulated: 0.1876, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0808, Accumulated: 0.2684, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0493, Accumulated: 0.3177, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0416, Accumulated: 0.3593, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0320, Accumulated: 0.3913, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0345, Accumulated: 0.4258, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0477, Accumulated: 0.4735, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1061, Accumulated: 0.5796, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1670, Accumulated: 0.7466, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1208, Accumulated: 0.8674, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0784, Accumulated: 0.9457, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0354, Accumulated: 0.9811, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0100, Accumulated: 0.9911, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0077, Accumulated: 0.0077, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0196, Accumulated: 0.0273, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0110, Accumulated: 0.0384, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0566, Accumulated: 0.0949, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0271, Accumulated: 0.1220, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0156, Accumulated: 0.1376, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0544, Accumulated: 0.1920, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0161, Accumulated: 0.2081, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0109, Accumulated: 0.2190, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7638, Accumulated: 0.9828, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0170, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2117, Accumulated: 0.2117, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0810, Accumulated: 0.2926, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0574, Accumulated: 0.3500, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0398, Accumulated: 0.3898, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.4213, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0384, Accumulated: 0.4598, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0553, Accumulated: 0.5150, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0953, Accumulated: 0.6104, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1134, Accumulated: 0.7237, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1017, Accumulated: 0.8255, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0842, Accumulated: 0.9097, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0452, Accumulated: 0.9548, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0175, Accumulated: 0.9723, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0104, Accumulated: 0.0104, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0062, Accumulated: 0.0165, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0112, Accumulated: 0.0278, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0601, Accumulated: 0.0879, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0160, Accumulated: 0.1039, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0118, Accumulated: 0.1157, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0256, Accumulated: 0.1413, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0143, Accumulated: 0.1556, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0389, Accumulated: 0.1945, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7960, Accumulated: 0.9906, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.2163, Accumulated: 0.2163, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0900, Accumulated: 0.3063, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0575, Accumulated: 0.3637, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0450, Accumulated: 0.4088, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0371, Accumulated: 0.4458, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0422, Accumulated: 0.4881, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0479, Accumulated: 0.5360, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1013, Accumulated: 0.6373, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1250, Accumulated: 0.7624, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0999, Accumulated: 0.8623, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0680, Accumulated: 0.9302, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0367, Accumulated: 0.9669, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0146, Accumulated: 0.9815, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0093, Accumulated: 0.0093, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0085, Accumulated: 0.0178, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0223, Accumulated: 0.0401, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0319, Accumulated: 0.0720, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0130, Accumulated: 0.0850, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0121, Accumulated: 0.0972, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0220, Accumulated: 0.1191, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0636, Accumulated: 0.1827, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1218, Accumulated: 0.3045, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6887, Accumulated: 0.9932, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Layer 4/16: Halt prob: 0.1846, Accumulated: 0.1846, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0760, Accumulated: 0.2606, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0432, Accumulated: 0.3039, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0350, Accumulated: 0.3389, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0309, Accumulated: 0.3698, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0384, Accumulated: 0.4081, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0467, Accumulated: 0.4548, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1004, Accumulated: 0.5552, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1398, Accumulated: 0.6949, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1145, Accumulated: 0.8094, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0904, Accumulated: 0.8998, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0562, Accumulated: 0.9560, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0204, Accumulated: 0.9764, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0103, Accumulated: 0.0103, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0110, Accumulated: 0.0213, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0186, Accumulated: 0.0399, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0260, Accumulated: 0.0659, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0158, Accumulated: 0.0817, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0143, Accumulated: 0.0960, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0164, Accumulated: 0.1125, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0289, Accumulated: 0.1414, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0206, Accumulated: 0.1620, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7934, Accumulated: 0.9554, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0444, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (RACE_M) ---\n",
      "exact_match: 0.5300\n",
      "accuracy: 0.5300\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.5299999713897705, 'accuracy': 0.53}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.1993955421447754}, 'time_per_token': {'mean': 0.1993955421447754}, 'tokens_per_second': {'mean': 5.2693106961250304}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking RACE_M:   1%|          | 1/100 [00:00<00:45,  2.16it/s]\n",
      "Benchmarking RACE_M:   2%|▏         | 2/100 [00:00<00:32,  3.03it/s]\n",
      "Benchmarking RACE_M:   3%|▎         | 3/100 [00:00<00:26,  3.67it/s]\n",
      "Benchmarking RACE_M:   4%|▍         | 4/100 [00:01<00:21,  4.55it/s]\n",
      "Benchmarking RACE_M:   5%|▌         | 5/100 [00:01<00:19,  4.96it/s]\n",
      "Benchmarking RACE_M:   6%|▌         | 6/100 [00:01<00:20,  4.60it/s]\n",
      "Benchmarking RACE_M:   7%|▋         | 7/100 [00:01<00:19,  4.71it/s]\n",
      "Benchmarking RACE_M:   8%|▊         | 8/100 [00:01<00:17,  5.15it/s]\n",
      "Benchmarking RACE_M:   9%|▉         | 9/100 [00:02<00:19,  4.72it/s]\n",
      "Benchmarking RACE_M:  10%|█         | 10/100 [00:02<00:18,  4.80it/s]\n",
      "Benchmarking RACE_M:  11%|█         | 11/100 [00:02<00:17,  5.18it/s]\n",
      "Benchmarking RACE_M:  12%|█▏        | 12/100 [00:02<00:17,  5.07it/s]\n",
      "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:02<00:16,  5.12it/s]\n",
      "Benchmarking RACE_M:  14%|█▍        | 14/100 [00:03<00:16,  5.10it/s]\n",
      "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:03<00:16,  5.08it/s]\n",
      "Benchmarking RACE_M:  16%|█▌        | 16/100 [00:03<00:16,  5.07it/s]\n",
      "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:03<00:15,  5.39it/s]\n",
      "Benchmarking RACE_M:  18%|█▊        | 18/100 [00:03<00:14,  5.66it/s]\n",
      "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:03<00:14,  5.42it/s]\n",
      "Benchmarking RACE_M:  20%|██        | 20/100 [00:04<00:16,  4.97it/s]\n",
      "Benchmarking RACE_M:  21%|██        | 21/100 [00:04<00:14,  5.31it/s]\n",
      "Benchmarking RACE_M:  22%|██▏       | 22/100 [00:04<00:16,  4.79it/s]\n",
      "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:04<00:16,  4.74it/s]\n",
      "Benchmarking RACE_M:  24%|██▍       | 24/100 [00:05<00:15,  4.80it/s]\n",
      "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:05<00:14,  5.10it/s]\n",
      "Benchmarking RACE_M:  26%|██▌       | 26/100 [00:05<00:15,  4.88it/s]\n",
      "Benchmarking RACE_M:  27%|██▋       | 27/100 [00:05<00:15,  4.59it/s]\n",
      "Benchmarking RACE_M:  28%|██▊       | 28/100 [00:05<00:14,  5.14it/s]\n",
      "Benchmarking RACE_M:  29%|██▉       | 29/100 [00:05<00:12,  5.68it/s]\n",
      "Benchmarking RACE_M:  30%|███       | 30/100 [00:06<00:11,  6.14it/s]\n",
      "Benchmarking RACE_M:  31%|███       | 31/100 [00:06<00:11,  6.12it/s]\n",
      "Benchmarking RACE_M:  32%|███▏      | 32/100 [00:06<00:11,  5.76it/s]\n",
      "Benchmarking RACE_M:  33%|███▎      | 33/100 [00:06<00:10,  6.46it/s]\n",
      "Benchmarking RACE_M:  34%|███▍      | 34/100 [00:06<00:09,  6.65it/s]\n",
      "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:06<00:10,  5.99it/s]\n",
      "Benchmarking RACE_M:  36%|███▌      | 36/100 [00:07<00:10,  5.99it/s]\n",
      "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:07<00:11,  5.37it/s]\n",
      "Benchmarking RACE_M:  38%|███▊      | 38/100 [00:07<00:11,  5.43it/s]\n",
      "Benchmarking RACE_M:  39%|███▉      | 39/100 [00:07<00:11,  5.19it/s]\n",
      "Benchmarking RACE_M:  40%|████      | 40/100 [00:07<00:11,  5.10it/s]\n",
      "Benchmarking RACE_M:  41%|████      | 41/100 [00:08<00:11,  4.95it/s]\n",
      "Benchmarking RACE_M:  42%|████▏     | 42/100 [00:08<00:10,  5.47it/s]\n",
      "Benchmarking RACE_M:  43%|████▎     | 43/100 [00:08<00:09,  5.98it/s]\n",
      "Benchmarking RACE_M:  44%|████▍     | 44/100 [00:08<00:09,  5.65it/s]\n",
      "Benchmarking RACE_M:  45%|████▌     | 45/100 [00:08<00:10,  5.37it/s]\n",
      "Benchmarking RACE_M:  46%|████▌     | 46/100 [00:08<00:10,  4.98it/s]\n",
      "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:09<00:10,  4.94it/s]\n",
      "Benchmarking RACE_M:  48%|████▊     | 48/100 [00:09<00:11,  4.70it/s]\n",
      "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:09<00:10,  4.70it/s]\n",
      "Benchmarking RACE_M:  50%|█████     | 50/100 [00:09<00:11,  4.48it/s]\n",
      "Benchmarking RACE_M:  51%|█████     | 51/100 [00:10<00:11,  4.40it/s]\n",
      "Benchmarking RACE_M:  52%|█████▏    | 52/100 [00:10<00:10,  4.50it/s]\n",
      "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:10<00:10,  4.30it/s]\n",
      "Benchmarking RACE_M:  54%|█████▍    | 54/100 [00:10<00:10,  4.25it/s]\n",
      "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:11<00:10,  4.13it/s]\n",
      "Benchmarking RACE_M:  56%|█████▌    | 56/100 [00:11<00:10,  4.34it/s]\n",
      "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:11<00:10,  4.17it/s]\n",
      "Benchmarking RACE_M:  58%|█████▊    | 58/100 [00:11<00:09,  4.60it/s]\n",
      "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:11<00:09,  4.52it/s]\n",
      "Benchmarking RACE_M:  60%|██████    | 60/100 [00:12<00:09,  4.36it/s]\n",
      "Benchmarking RACE_M:  61%|██████    | 61/100 [00:12<00:08,  4.44it/s]\n",
      "Benchmarking RACE_M:  62%|██████▏   | 62/100 [00:12<00:07,  4.80it/s]\n",
      "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:12<00:07,  4.71it/s]\n",
      "Benchmarking RACE_M:  64%|██████▍   | 64/100 [00:13<00:07,  4.67it/s]\n",
      "Benchmarking RACE_M:  65%|██████▌   | 65/100 [00:13<00:07,  4.69it/s]\n",
      "Benchmarking RACE_M:  66%|██████▌   | 66/100 [00:13<00:07,  4.75it/s]\n",
      "Benchmarking RACE_M:  67%|██████▋   | 67/100 [00:13<00:06,  5.28it/s]\n",
      "Benchmarking RACE_M:  68%|██████▊   | 68/100 [00:13<00:05,  5.71it/s]\n",
      "Benchmarking RACE_M:  69%|██████▉   | 69/100 [00:13<00:06,  5.07it/s]\n",
      "Benchmarking RACE_M:  70%|███████   | 70/100 [00:14<00:05,  5.24it/s]\n",
      "Benchmarking RACE_M:  71%|███████   | 71/100 [00:14<00:05,  5.12it/s]\n",
      "Benchmarking RACE_M:  72%|███████▏  | 72/100 [00:14<00:05,  5.01it/s]\n",
      "Benchmarking RACE_M:  73%|███████▎  | 73/100 [00:14<00:05,  4.88it/s]\n",
      "Benchmarking RACE_M:  74%|███████▍  | 74/100 [00:15<00:05,  4.63it/s]\n",
      "Benchmarking RACE_M:  75%|███████▌  | 75/100 [00:15<00:05,  4.49it/s]\n",
      "Benchmarking RACE_M:  76%|███████▌  | 76/100 [00:15<00:04,  5.08it/s]\n",
      "Benchmarking RACE_M:  77%|███████▋  | 77/100 [00:15<00:04,  5.69it/s]\n",
      "Benchmarking RACE_M:  78%|███████▊  | 78/100 [00:15<00:03,  5.74it/s]\n",
      "Benchmarking RACE_M:  79%|███████▉  | 79/100 [00:15<00:03,  5.48it/s]\n",
      "Benchmarking RACE_M:  80%|████████  | 80/100 [00:16<00:03,  5.61it/s]\n",
      "Benchmarking RACE_M:  81%|████████  | 81/100 [00:16<00:03,  5.17it/s]\n",
      "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:16<00:03,  5.05it/s]\n",
      "Benchmarking RACE_M:  83%|████████▎ | 83/100 [00:16<00:03,  5.04it/s]\n",
      "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:16<00:03,  4.94it/s]\n",
      "Benchmarking RACE_M:  85%|████████▌ | 85/100 [00:17<00:02,  5.42it/s]\n",
      "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:17<00:02,  5.64it/s]\n",
      "Benchmarking RACE_M:  87%|████████▋ | 87/100 [00:17<00:02,  6.02it/s]\n",
      "Benchmarking RACE_M:  88%|████████▊ | 88/100 [00:17<00:01,  6.04it/s]\n",
      "Benchmarking RACE_M:  89%|████████▉ | 89/100 [00:17<00:01,  5.87it/s]\n",
      "Benchmarking RACE_M:  90%|█████████ | 90/100 [00:17<00:01,  5.43it/s]\n",
      "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:18<00:02,  4.44it/s]\n",
      "Benchmarking RACE_M:  92%|█████████▏| 92/100 [00:18<00:01,  4.44it/s]\n",
      "Benchmarking RACE_M:  93%|█████████▎| 93/100 [00:18<00:01,  4.47it/s]\n",
      "Benchmarking RACE_M:  94%|█████████▍| 94/100 [00:18<00:01,  4.59it/s]\n",
      "Benchmarking RACE_M:  95%|█████████▌| 95/100 [00:19<00:01,  4.67it/s]\n",
      "Benchmarking RACE_M:  96%|█████████▌| 96/100 [00:19<00:00,  4.78it/s]\n",
      "Benchmarking RACE_M:  97%|█████████▋| 97/100 [00:19<00:00,  5.07it/s]\n",
      "Benchmarking RACE_M:  98%|█████████▊| 98/100 [00:19<00:00,  5.38it/s]\n",
      "Benchmarking RACE_M:  99%|█████████▉| 99/100 [00:19<00:00,  5.15it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:20<00:00,  5.04it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:20<00:00,  4.99it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_m \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --exit_layer 8 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_m \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_m \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy self_speculative \\\n",
    "       --exit_layer 8 \\\n",
    "       --num_speculations 6 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_m \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy layerdrop \\\n",
    "       --dropout_rate 0.2 \\\n",
    "       --layerdrop_seed 42 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_m \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy depth_adaptive_sequence \\\n",
    "       --halting_threshold 0.99 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RACE-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_h \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --exit_layer 8 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard benchmark for dataset: race_h\n",
      "[Prompt]:\n",
      "Article: Jack had gone to the university to study history, but he kept playing all the time and at the end of his first year, his history professor failed him in his exams. He was so poor at his subject that he would have to leave the university. However, his father made up his mind that he would go to see the professor to ask him to let Jack go on his studies the next year.\n",
      "\"He's a good boy,\" said the father, \"and if you let him pass this time, I'm sure he'll improve a lot next year and pass the exam at the end of it really well.\"\n",
      "\"No, no, that's quite impossible.\" said the professor at once, \"Do you know, last month I asked him when Napoleon  had died, and he didn't know!\"\n",
      "\"Please, sir, give him another chance.\" said Jack's father. \"You see, I'm afraid we don't take any newspapers in our house, so none of us even know that Napoleon was ill.\"\n",
      "\n",
      "Question: Jack didn't know when Napoleon had died because  _  .\n",
      "A. he didn't do well in his history\n",
      "B. he didn't take any newspaper\n",
      "C. he didn't know Napoleon\n",
      "D. he didn't know Napoleon was ill\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Mr. and Mrs. Green lived in a big city. One summer they went to the country for their holiday. They enjoyed it very much because it was a quiet, clean place.\n",
      "One day they went for a walk early in the morning and met an old man. He lived on a farm, and he was sitting in the warm sun in front of his house. Mr. Green asked him, \"Do you like to live in this quiet place?\"\n",
      "The old man said, \"Yes, I do.\"\n",
      "Mr. Green then asked, \"What are the good things about it?\"\n",
      "The old man answered, \"Well, the people here know each other. They often come and visit me, and I often go and visit them. And there are also many children here.\" Mr. Green said, \"That's interesting, and what are the bad things?\"\n",
      "The old man thought for a moment and then said, \"Well, the same things, really.\"\n",
      "\n",
      "Question: Mr. and Mrs. Green enjoyed the country because   _  .\n",
      "A. there were many children\n",
      "B. there was an old man\n",
      "C. it was far from the city\n",
      "D. it was quiet and clean\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Paper is one of the most important products ever invented by man.\n",
      "The invention of paper meant that more people could be educated because more books could be printed. Paper provided an important way to communicate with knowledge.\n",
      "Paper was first made in China about 2000 years ago. In Egypt and the West, paper was not very commonly used before the year 1400. Paper was not made in southern Europe until about the year 1100. After that, the forestry country of Canada, Sweden, Norway, Finland, and the United States became the most important in paper-making. Today Finland makes the best paper in the world. And it has the biggest paper industry in the world.\n",
      "When we think of paper, we think of newspapers, books, letters, envelopes, and writing paper. So paper plays an important role in our lives.\n",
      "Paper is very good for keeping you warm, Houses are often insulated with paper. You have perhaps seen homeless men sleep on a large number of newspapers. They are insulating themselves from the cold. In Finland, in winter it is sometimes 40 degrees below zero. The farmers wear paper boots in the snow. _\n",
      "\n",
      "Question: What's the meaning of the sentence \"  _  \"?\n",
      "A. Books are warmer.\n",
      "B. Newspapers are warmer.\n",
      "C. Houses are the warmest.\n",
      "D. Paper is the warmest.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: October is getting closer and it also means that the year of 2014 is coming to an end. \"Hooray! It's a holiday!\" While you are thinking of putting textbooks aside and playing video games, let's take a look at what children in other continents usually do during their holidays.\n",
      "Children in America don't have much homework to do. They keep themselves busy by playing camp games. A parent says, \"My daughter Shirley usually attends different camps. We don't ask her to spend plenty of time on maths problems or spelling tests.\"\n",
      "Children in Australia take partin activities on over twenty different themes  . They learn painting, dancing, singing, history, culture and so on. Parents can _ their kids to enjoy the learning process and to build a closer relationship with them.\n",
      "These are what African kids do: build a boat, have a camel race, make a drum and make a rag   football. Don't you think it is interesting that kids in other places have no idea how to make a drum, but kids in Africa do?\n",
      "Plan your holiday well and try what you want to try. Make a good plan and you will have a lot of fun.\n",
      "\n",
      "Question: Where does Shirley come from?\n",
      "A. Asia.\n",
      "B. America.\n",
      "C. Australia.\n",
      "D. Africa.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "\n",
      "Answer: B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: A Chinese couple forced their 4- year- old son to run naked  during a snowstorm with the temperature dipping to -13degC in New York, where they were enjoying a holiday.\n",
      "The boy's father calls himself \"Eagle Dad\". He says he follows the parenting style of eagles, which are known to push their babies off cliffs so that they learn to fly by themselves.\n",
      "Different people have different ideas about it. Some people think it is proper to do like \"Eagle Dad\". The 4- year- old boy, Duoduo, was weak since he was born, so his father tried to help him train to keep strong. But others disagree, they think we should concentrate more on the best ways to teach children in these fast changing times.\n",
      "Different families use different methods to teach children, but all of them should be allowed by the law. Parents should pay full attention to children's physical and metal conditions, and make sure the ways can help their children think and act positively.\n",
      "As long as parents know this, they can use different methods to educate children. Every child has different character. Some children grow up to be success under the guidance of (......)\"eagle dads\" or \"tiger moms\". Others are also successful growing up under more considerate elders.\n",
      "\n",
      "Question: Which of the following is WRONG?\n",
      "A. The event happened in America.\n",
      "B. Duoduo was only four years old.\n",
      "C. The writer didn't agree \"eagle dad's\" educating method.\n",
      "D. Different children have different characters.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Do you know why different animals or pests have their special colours? Colours in them seem to be mainly used to protect themselves.\n",
      "Some birds like eating locusts , but birds cannot easily catch them. Why? It is because locusts change their colurs with the changes of the colours of crops .When crops are green, locusts look green .But as the harvest time comes, locusts change into the same brown colour as crops have .Some other pests whose colours are different from plants are easily found and eaten by others .So they have to hide themselves for lives and appear only at night.\n",
      "If you study the animals' life, you'll find the main use of colours is to protect themselves .Bears, lions and other animals move quietly through forests .They cannot be easily seen by hunters because their colours are much like the trees.\n",
      "Colours are useful not only on the land , but also in the sea .A kind of fish in the sea can give out a kind of black liquid when the fish face danger. The liquid spreads over quickly, so they cannot be found by their enemies and can quickly swim away. That is why they can live safely though they are not strong at all.\n",
      "\n",
      "Question: From the passage, we can know that  _  .\n",
      "A. locusts are big animals\n",
      "B. locusts are easily found by birds\n",
      "C. locusts are dangerous to their enemies\n",
      "D. locusts can change their colours to protect themselves\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Zhao Tao, a student from No.2 Middle School, has just come back from Shanghai. This morning, he told us something about his pleasant trip .When he talked about the Shanghai World Expo, he was so excited and so proud that he kept telling about it for several hours. The Shanghai World Expo held by China has been on for more than one month .It started on May 1st, and will end on October 31st, 2010. Its main idea is \"Better City, Better Life.\" About 242 countries and organizations are attending this expo. Many new products can be seen here, such as we can see the snow in the South Korea Corporate Pavilion  every day during this hot summer though it seldom snows in Shanghai. And we can see, hear, touch and smell the 4-D films at the Oil Pavilion. How wonderful all these new products are!\n",
      "China Pavilion is in the center of the expo garden. It is very beautiful. It represents the development of China from ancient time to now. It's a pride of our China!\n",
      "Thousands of people from all over the world are coming to the expo every day. And many volunteers are working for them. All the tourists are very pleased and they say that the Shanghai World Expo is the greatest one in the world so far.\n",
      "However, Zhao said, \"The expo garden is now so crowded. If you want to visit it, you'd better go there during the summer vacation.\"\n",
      "\n",
      "Question: Which of the following is NOT talked about in this passage?\n",
      "A. Zhao Tao is a middle school student.\n",
      "B. China's new products are excellent.\n",
      "C. The volunteers are working very hard.\n",
      "D. The expo garden is now very crowded.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: It is very important for children to get to school safely and on time every day. Luckily, there is a new program called Free Home to School Transport . It gives children free rides to school. But to enjoy the free trip. Children have to qualify .\n",
      "Children can take free home to school transport if they:\n",
      "*are between 5 and 16 years old\n",
      "*are going to the nearest school\n",
      "*live far away from school\n",
      "No matter how far away children live from school, they Can take the free transport if they have walking problems or there is no safe road for them. A safe road usually has crossings, lights and should be clean.\n",
      "Also, there are still free home to school _ for children in poor families and children with special educational needs, you can find out more on the Internet and see if your children are qualified.\n",
      "\n",
      "Question: Which of the following is TRUE?\n",
      "A. Seventeen-year-old students can take free rides to school.\n",
      "B. If Tom has some problem with his leg, he can enjoy the program.\n",
      "C. Poor students can not have free transport to school.\n",
      "D. A safe road should be near the school and have lights.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: The city of Yangzhou came into being at the Spring and Autumn Period ( about 500 AC ).\n",
      "As the key transportation link at joint place of the Great Canal ( Beijing-Hangzhou) and Changjiang (Yangtze River), Yangzhou has been from the Sui Dynasty (600 AD.) an economically rich city, and then reached its top in the Tang Dynasty. At that time Yangzhou was a famous port and one of few biggest cities in East Asia.\n",
      "With the improvement of the local economy and easy transportation way, there happened in the history a special local culture, which has an important place in Chinese culture. Many famous men of letters, poets, artists, scholars , statesmen, scientists and national heroes in the history were born in, lived in or had connection with Yangzhou. Li Bai, one of the greatest Chinese poets visited and stayed in Yangzhou several times in his life and one of his famous poems about Yangzhou has been so popular that Chinese of all ages can sing it and has become a symbol of Yangzhou . Zheng Banqiao, a famous Chinese painting painter in the Qing Dynasty heading a group called \"Eight Eccentrics\", had strongly influenced Chinese paintings. Wang Zhong and Yuan Yuan and some other scholars formed school of Yangzhou Scholars and achieved great success in the study of classic Chinese and writing. Zhu Ziqing, one of most famous modern Chinese writers and scholars, had always been proud of himself as a native of Yangzhou and thanked the city for being nourished  by its rich culture. Quite a few other names you may come across frequently in the study of Chinese culture and history have connection with Yangzhou . Yangzhou was so attractive and important that many Chinese emperors in history had come specially to visit or check the city. Emperor Suiyang, who ordered to cut the Great Canal so that he could come more easily and quickly, died on his last trip to the city and buried  here. Emperor Qianlong had come all the way from the north and visited the city nine times.\n",
      "\n",
      "Question: Who influenced Chinese paintings a lot according to this passage?\n",
      "A. Zheng Banqiao\n",
      "B. Zhu Ziqing\n",
      "C. Wang Zhong\n",
      "D. Li Bai\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: David eats well every day. For breakfast, he has bread, eggs and milk. At school, he has vegetables and rice for lunch. After lunch, he eats an apple. In the evening, he has chicken and fruit salad at home. David _ milk, but Mom says it is healthy. So he drinks it every day. After eight in the evening, he doesn't have food. Every day, David does some sports to be healthy. He plays tennis in the morning and plays basketball after school.\n",
      ",.\n",
      "\n",
      "Question: David doesn't eat food after   _   in the evening.\n",
      "A. 7\n",
      "B. 8\n",
      "C. 9\n",
      "D. 10\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: The city of Yangzhou came into being at the Spring and Autumn Period ( about 500 AC ).\n",
      "As the key transportation link at joint place of the Great Canal ( Beijing-Hangzhou) and Changjiang (Yangtze River), Yangzhou has been from the Sui Dynasty (600 AD.) an economically rich city, and then reached its top in the Tang Dynasty. At that time Yangzhou was a famous port and one of few biggest cities in East Asia.\n",
      "With the improvement of the local economy and easy transportation way, there happened in the history a special local culture, which has an important place in Chinese culture. Many famous men of letters, poets, artists, scholars , statesmen, scientists and national heroes in the history were born in, lived in or had connection with Yangzhou. Li Bai, one of the greatest Chinese poets visited and stayed in Yangzhou several times in his life and one of his famous poems about Yangzhou has been so popular that Chinese of all ages can sing it and has become a symbol of Yangzhou . Zheng Banqiao, a famous Chinese painting painter in the Qing Dynasty heading a group called \"Eight Eccentrics\", had strongly influenced Chinese paintings. Wang Zhong and Yuan Yuan and some other scholars formed school of Yangzhou Scholars and achieved great success in the study of classic Chinese and writing. Zhu Ziqing, one of most famous modern Chinese writers and scholars, had always been proud of himself as a native of Yangzhou and thanked the city for being nourished  by its rich culture. Quite a few other names you may come across frequently in the study of Chinese culture and history have connection with Yangzhou . Yangzhou was so attractive and important that many Chinese emperors in history had come specially to visit or check the city. Emperor Suiyang, who ordered to cut the Great Canal so that he could come more easily and quickly, died on his last trip to the city and buried  here. Emperor Qianlong had come all the way from the north and visited the city nine times.\n",
      "\n",
      "Question: We can infer the poem mentioned in this passage by Li Bai is   _  .\n",
      "A. <<>>\n",
      "B. <<>>\n",
      "C. <<>>\n",
      "D. <<>>\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: My friend Tom is a schoolboy. Everyone likes him very much because he is kind. He likes to help people. He is a smart boy and he can play many musical instruments . After school, when he is with his friends, he often plays musical instruments for them. On weekends, he is free and he always goes to the old people's home. He plays the violin and the guitar to make them happy. He thinks it's interesting and fun.\n",
      "Today is February 28th. It's Tom's birthday. He has a big and interesting party at home. Many friends come to his party. Tom's mother cooks a lot of food for them. Everyone gives a beautiful gift to him. Sally gives him an English dictionary because Tom also likes English. Bob gives Tom a guitar because he likes playing the guitar very much. At the party, Tom plays the guitar and he also plays the piano. We sing many songs and play some interesting games. We have a good time today.\n",
      "\n",
      "Question: _   gives Tom an English dictionary.\n",
      "A. His mother\n",
      "B. His father\n",
      "C. Sally\n",
      "D. Bob\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: My name is Dan and I have two brothers, Bob and Ray .We like hamburgers for lunch.\n",
      "Bob and I like French fries , but Ray doesn't . I don't like eggs for breakfast, but Bob and Ray\n",
      "Do. I like fruit for breakfast .We really like chicken and salad for dinner.\n",
      "\n",
      "Question: _   like hamburgers .\n",
      "A. Dan and Bob\n",
      "B. Bob and Ray\n",
      "C. Dan , Bob and Ray\n",
      "D. Dan and Ray\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: There was a new maths teacher and some new students in the school. One of the new students named Karl was very _ . The other students tried to explain   numbers to him, but he didn't understand.\n",
      "Before Karl arrived, maths was the most boring lesson of all. Now it was great fun. The children would listen to Karl and correct his mistakes. They all wanted to be the first to find his mistakes, and then tried to think up the best ways to explain them.\n",
      "But little Lewis was sure that Karl felt sad and wanted to talk with him. So, one day, he decided to walk after Karl after school. Lewis was sure he would see him crying. On the way home, Karl walked a few minutes to a park, and there he waited for someone to meet him...\n",
      "It was the new teacher!\n",
      "They went off, hand in hand. Lewis could hear them talking about maths. And that stupid Karl knew everything about it, and even much more than anyone else in the class!\n",
      "\n",
      "Question: Little Lewis didn't find that  _  .\n",
      "A. Karl walked a few minutes to a park\n",
      "B. Karl waited for someone to meet him\n",
      "C. Karl and the teacher went off together\n",
      "D. Karl knew nothing about maths\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
      "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
      "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
      "\n",
      "Question: The writer thinks that Victory is   _  .\n",
      "A. very poor\n",
      "B. very funny\n",
      "C. very kind\n",
      "D. very lucky\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: We know health and happiness are important in everyone's life. Here are some ways to make them easy.\n",
      "Eat a balanced diet . Eat a lot of fruit and vegetables, some grains  and a little meat.\n",
      "Exercise twice or three times a week.\n",
      "Get enough sleep. It is best to get eight hours' sleep a day.\n",
      "Keep yourself busy. This is good because _ stops you from having bad habits. To keep yourself busy, you can walk around the house, spend time with your pets, do a sport, or do a hobby you enjoy.\n",
      "Go out and make friends. Spend time and have fun with them. Talk with them, but you must be sure not to talk about anything bad. You should stay with the people who are healthy and happy themselves.\n",
      "\n",
      "Question: How often should you exercise if you want to get health and happiness?\n",
      "A. Every day .\n",
      "B. Twice a day\n",
      "C. Twice or three times a week .\n",
      "D. Three times a month.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "\n",
      "Explanation: Exercise twice or three times a week.\n",
      "\n",
      "Question: How often should you eat if you want to get health and happiness?\n",
      "A. Every day.\n",
      "B. Twice a day\n",
      "C. Twice or three times a week.\n",
      "D. Three times a month.\n",
      "Answer: A\n",
      "\n",
      "Explanation: Eat a balanced diet. Eat a lot of fruit and vegetables, some grains and a little meat.\n",
      "\n",
      "Question: How often should you sleep if you want to get health and happiness?\n",
      "A. Every day.\n",
      "B. Twice a day\n",
      "C. Twice or three times a week.\n",
      "D. Three times a month.\n",
      "Answer: A\n",
      "\n",
      "Explanation: Sleep eight hours a day. It is best to get eight hours' sleep a day.\n",
      "\n",
      "Question: How often should you keep yourself busy if you want to get health and happiness?\n",
      "A. Every day.\n",
      "B. Twice a day\n",
      "C. Twice or three times a week.\n",
      "D. Three times a month.\n",
      "Answer: A\n",
      "\n",
      "Explanation: Keep yourself busy. This is good because it stops you from having bad habits. To keep yourself busy, you can walk around the house, spend time with your pets, do a sport, or do a hobby you enjoy.\n",
      "\n",
      "Question: How often should you go out and make friends if you want to get health and happiness?\n",
      "A. Every day.\n",
      "B. Twice a day\n",
      "C. Twice or three times a week.\n",
      "D. Three times a month.\n",
      "Answer: A\n",
      "\n",
      "Explanation: Go out and make friends. Spend time and have fun with them. Talk with them, but you must be sure not to talk about anything bad. You should stay with the people who are healthy and happy themselves.\n",
      "Extracted prediction: A, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: We are all learning English, but how can we learn English well? A student can know a lot about English, but maybe  he can't speak English. If you want to know how to   swim, you must get into the river. And if you want to be a football player, you must play football.\n",
      "So, you see. You can learn English only by  using it. You must listen to your teacher in class. You must read your lessons every day. You must speak English to your classmates and also you must write something sometimes. Then one day, you may find your English very good.\n",
      "\n",
      "Question: The story of learning swimming and playing football tells us  _\n",
      "A. we learn English by using it\n",
      "B. swimming needs water\n",
      "C. playing football is easy\n",
      "D. learning English is difficult\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "\n",
      "Question: The story of learning swimming and playing football tells us  _\n",
      "A. we learn English by using it\n",
      "B. swimming needs water\n",
      "C. playing football is easy\n",
      "D. learning English is difficult\n",
      "\n",
      "Answer: D\n",
      "\n",
      "Question: The story of learning swimming and playing football tells us  _\n",
      "A. we learn English by using it\n",
      "B. swimming needs water\n",
      "C. playing football is easy\n",
      "D. learning English is difficult\n",
      "\n",
      "Answer: A\n",
      "Extracted prediction: D, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: This year, \"Wild China\" is famous, it shows us the beautiful scenes .But in fact, the environment around  us is getting worse and worse .In some places,we can't see fish swimming in the river or trees on the mountains. Many animals are facing the danger of living .At the same time, man is killing animals just for getting their skin and meat. In our country, the number of wild animals is becoming smaller and smaller. Some of them are even dying out .\n",
      "It's time to protect  our environment .But what can we do? How to protect _ ? For example,we can go to school on foot or by bike . we can use shopping baskets not plastic  bags when we go shopping,and we can use both sides of the paper to write . Also , we should plant more trees to protect the animals' living.\n",
      "In a word,if everyone does more to our environment ,our life will be better. \"There is only one earth\",I hope everyone will protect our environment well.\n",
      "\n",
      "Question: What about our environment around us in fact?\n",
      "A. better\n",
      "B. worse\n",
      "C. faster\n",
      "D. smaller\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Do You Want To Be A Musician?\n",
      "Do you want to be a musician? Come to our club, and you'll be very happy in the club. We have _ about the piano, the drums, the bamboo flute,the trumpet, the guitar and the violin for just $20 each.You can also learn to sing , to dance for $25 each. If you like art, you can be satisfied , too. It's just for $30 each!\n",
      "\n",
      "Question: If you want to learn about guitar and singing, you should pay  _  .\n",
      "A. $45\n",
      "B. $20\n",
      "C. $30\n",
      "D. $25\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: One day my wife and I went shopping at  the shop. We took the car as we had a lot of things to buy because my brother and his family were going to spend the weekend with us. We stopped the car in front of the shop. An hour later we came back to the car with a lot of things. Then the trouble started. We could not open the car door.\n",
      "\"Oh, dear,\" said my wife, \"What are you going to do?\"\n",
      "\"Let's ask that policeman,\" I said. The policeman was very kind and glad to help us. A few minutes later he got the door open. Just at that moment an angry man came up and shouted, \"What are you doing with my car?\"\n",
      "We looked at the number of the car and our faces turned very red.\n",
      "\n",
      "Question: The husband and the wife went shopping   _  .\n",
      "A. by bus\n",
      "B. in their car\n",
      "C. by bike\n",
      "D. on foot\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Do you know the phrase \"Weibo Addicts\"  ? Do you write a Weibo? If you don't, you are \"out\"!\n",
      "Weibo means microblog. People may spend much time writing a blog, but it takes a little time to write a microblog. Why? Because every message on a microblog is less than 140 words.\n",
      "Microblog started in the USA. It came to China in 2009 and it grows very fast. In 2011, the number of Chinese micro-bloggers grew to 300 million. People write microblogs for many reasons. For many microblog users, it is a great way of learning the freshest news, talking with friends and sharing different kinds of information, including news, everyday life, pictures, music, videos and so on.\n",
      "It is easy and fast to send a message on a microblog. However, this can also bring problems and even panic  . For example, when the big earthquake and tsunami   hit Japan in March, 2011, messages like \"Salt can help people fight radiation  \" were hot on microblogs. Then a crazy buying of salt followed. Later people knew it was just a rumor  .\n",
      "In a word, microblog plays a new part in the life of Chinese people.\n",
      "\n",
      "Question: What does Para. 2 mainly talk about?\n",
      "A. How to use Weibo.\n",
      "B. Why Weibo is so popular.\n",
      "C. Who is using Weibo.\n",
      "D. What Weibo is.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "\n",
      "Question: What does Para. 3 mainly talk about?\n",
      "A. How to use Weibo.\n",
      "B. Why Weibo is so popular.\n",
      "C. Who is using Weibo.\n",
      "D. What Weibo is.\n",
      "Answer: C\n",
      "Extracted prediction: D, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: At the age of sixteen, I went on my first volunteer program in West Virginia to repair or build homes for poor families. When we arrived, we discovered that the family we were going to help was living in a trailer that was in poor condition, no bigger than two parking spaces. A group of people had been working on it for two weeks, but every time they finished one problem, another appeared.\n",
      "We soon decided that the only way was to build a new house. It was something unusual because normally our goal was to repair old homes. The family was pleased with their new house that was 20 by 30 feet with three bedrooms, a bath and a kitchen.\n",
      "On Tuesday of that week, I asked the family's three boys, Josh, Eric and Ryan, \"What do you want for your new room?\" Kids in the families we had helped usually wanted toys or posters, so we were surprised when Josh, the oldest boy said, \"We just want beds.\" The boys had never slept in a bed. That night we had a meeting and decided that beds would be the perfect gift. On Thursday night, a few adults in our group drove to the nearest city and bought beds and new bedding.\n",
      "On Friday when we saw the truck coming, we told the family about the surprise. They were very excited.\n",
      "That afternoon, while we were setting up the beds, Eric ran into the house to watch us with wide eyes. As Maggie, a member of our group, put one of the pillows on the bed, Eric asked, \"What is that?\"\n",
      "\"A pillow,\" she replied.\n",
      "\"What do you do with it?\" Eric went on asking.\n",
      "\"When you go to sleep, you put your head on it,\" Maggie answered softly. Tears came to our eyes as she handed Eric the pillow.\n",
      "\"Oh . . . that's soft,\" he said, holding it tightly.\n",
      "Now, when my sister or I start to ask for something that seems very urgent , my dad always asks, \"Do you have a pillow?\" We know exactly what he means.\n",
      "\n",
      "Question: What can we learn from the story?\n",
      "A. The family needed two parking spaces.\n",
      "B. The boys of the family wanted toys and posters.\n",
      "C. The family were excited about the beds and bedding.\n",
      "D. The writer's group made some furniture for the family.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Dear John, Thank you very much for your letter. I am glad that you enjoyed your holiday with me. We enjoyed having you and your sister here. We hope that you will both be able to come again next year. Perhaps you'll be able to stay longer next time you come. A week is not really long enough, is it? If your school has a five-week holiday next year, perhaps  you'll be able to stay with us for two or three weeks.\n",
      "We have been back at school three weeks now. It feels like three months! I expect  that you are both working very hard now that you are in Grade One. I shall have to work hard next year when I am in Grade One. Tom and Ann won't be in Grade One until 2011.\n",
      "They went for a picnic yesterday but I didn't go with them because I cut my foot and I couldn't walk very well. They went to an island and enjoyed themselves. Do you still remember the island? That's where all five of us spent the last day of our holiday.\n",
      "Tom, Ann and I send our best wishes to Betty and you. We hope to see you soon.\n",
      "Yours sincerely,\n",
      "Michael\n",
      "\n",
      "Question: _  in Grade One now.\n",
      "A. John and his sister are both\n",
      "B. John is\n",
      "C. John's sister is\n",
      "D. Michael is\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: In the days when an ice cream sundae cost much less, a 10-year-old boy entered a hotel coffee shop and sat at a table. A waitress (woman assistant) put a glass of water in front of him. \"How much is an ice cream sundae?\" \"Fifty cents\", replied the waitress. The little boy pulled his hand out of his pocket and studied a number of coins in it. \"How much is a dish of _ ice cream?\" he asked. Some people were now waiting for a table and the waitress was a bit worried. \"Thirty-five cents,\" she said rudely(not politely). The little boy again counted the coins. \"I'll have the plain ice cream,\" he said. The waitress brought the ice cream, put the bill on the table and walked away. The boy finished the ice cream, paid the bill at the counter and went out. When the waitress came back, she began cleaning the table and then she couldn't believe what she had seen. There, placed nearly beside the empty dish, were two five-cent coins and five one-cent coins---her tip .\n",
      "\n",
      "Question: Why did the little boy have only a dish of a plain ice cream?\n",
      "A. The plain ice cream cost him much less.\n",
      "B. He enjoyed the cheaper ice cream better.\n",
      "C. The coins were not enough for an ice cream sundae.\n",
      "D. He wanted to save some coins to tip the waitress.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: To make sure that you enjoy your visit to the Harper Hot Springs and that you are safe during your visit, please take time to read the following:\n",
      "Do not put your head under the hot water because it may be bad for your eyes.\n",
      "Do not run around because the floors may be _ \n",
      "Do not leave your children alone.\n",
      "Do not leave your things about. Just ask one of our workers to look after your things.\n",
      "Do not eat or drink anything in the area because we want to keep the area clean .There is a place for you to eat and soft drinks when you need to have a rest.\n",
      "Do not bring anything made of glass into the area, because it maybe easily to broken when you fall.\n",
      "Do not bring any hard drinks into the area.\n",
      "Do not smoke in the area.\n",
      "Do not stay in the sunlight for too long.\n",
      "We hope that you will enjoy your visit here\n",
      ",. . (10)\n",
      "\n",
      "Question: The notice is Written for  _  .\n",
      "A. visitors\n",
      "B. children\n",
      "C. workers\n",
      "D. managers\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: After my husband died, my world crashed around me. My six children were 10, nine, eight, six, three and 18 months, and I was overwhelmed with the responsibilities of earning a living, caring for the children and simply _ .\n",
      "I was fortunate to find a wonderful housekeeper to care for the children during the week, but from Friday nights to Monday mornings, the children and I were alone, and frankly I was uneasy. Every unusual noise or any late-night phone call filled me with fear. I felt incredibly alone.\n",
      "One Friday evening I came home from work to find a big beautiful German shepherd  on our doorstep. It was obvious he wanted to make the house his home. The children took an instant liking to \"German\" and begged me to let him in. I agreed to let him sleep in the basement until the next day. That night I slept peacefully for the first time in many weeks.\n",
      "The following morning we made phone calls and checked lost-and-found ads for German's owner, but with no results. Saturday night he was still with us.\n",
      "On Sunday I had planned to take the children on a picnic. Since I thought it best to leave German behind in case his owner came by, we drove off without him. When we stopped to get gas at a local station, we were amazed to see German racing to the gas station after us. He stayed again Sunday night.\n",
      "Monday morning I let him out for a run while the children got ready for school. He didn't come back. We thought we'd never see him again. On Friday evening, German was back again. We took him in, and again he stayed until Monday morning, when our housekeeper arrived. It went like this for almost 10 months. We looked forward to his coming each Monday morning he left home.\n",
      "Each week, between German's visits, I grew a little braver, but every weekend I enjoyed his company. Then one Monday morning we patted his head and let him out for what turned out to be the last time. He never came back.\n",
      "\n",
      "Question: Which is the best title for the passage?\n",
      "A. A homeless dog\n",
      "B. A friend's strength\n",
      "C. How to keep a dog\n",
      "D. Keep up when in trouble\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Several years ago,a television reporter was talking to three of the most important people in America. One was a very rich banker,another owned one of the largest companies in the world,and the third owned many buildings in the center of New York.\n",
      "The reporter was talking to them about being important. \"How do we know if someone is really important?\" the reporter asked the banker.\n",
      "The banker thought for a few moments and then said, \"I think anybody who is invited to the White House to meet the President of the United States is really important. \"\n",
      "The reporter then turned to the owner of the very large company. \"Do you agree with that?\" she asked.\n",
      "The man shook his head, \"No. I think the President invites a lot of people to the White House. You'd only be important if while you were visiting the President, there was a telephone call from the president of another country,and the President of the US said he was too busy to answer it. \"\n",
      "The reporter turned to the third man. \"Do you think so?\"\n",
      "\"No, I don't,\" he said. \"I don't think that makes the visitor important. That makes the President important. \"\n",
      "\"Then what would make the visitor important?\" the reporter and the other two men asked.\n",
      "\"Oh, I think if the visitor to the White House was talking to the President and the phone rang, and the President picked up the receiver, listened and then said, 'It's for you. ' \"\n",
      "\n",
      "Question: The following is true EXCEPT  _  .\n",
      "A. The banker thought any visitor to the White House was really important.\n",
      "B. The owner of the very large company thought the visitor would be important if while he was visiting the President, the President would not answer any telephone call\n",
      "C. The owner of many buildings thoughtthe visitor was really important if he was talking to the President and the President received a telephone call for the visitor.\n",
      "D. the reporter knew the way to find out who was the most important.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: My name is Peter.I am 12.I have one brother and one sister.My brother is 15 and my sister is 9.I have a friend.He is an English boy.His name is Tanaka.He is in my class.I have a dog, too.Its name is Billy.Billy is 2.I like sports.I play basketball, soccer and volleyball after class .I have one pencil case, two English books and three Chinese books.\n",
      "\n",
      "Question: Peter and Tanaka are   _  .\n",
      "A. brothers\n",
      "B. sisters\n",
      "C. friends\n",
      "D. Chinese\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Hearing what I said, my dad laughed kindly. I continued, \"I owe your thanks, and I hope you realize how much you did for me as my dad.\"\n",
      "I could almost hear him smiling one the other end. I knew he was touched and felt a little shy. His voice sounded shaky.\n",
      "\"Well, we got you educated,\" he said, laughing generously.\n",
      "\"You did more than that,\" I said, \"You did well.\"\n",
      "\"You like your house now, and your life?\" he asked quietly.\n",
      "\"Yeah, Dad, I'm happy. You don't have to worry--things are going great for us.\"\n",
      "I told him I loved him and he told me he loved me and I hung up the phone. As I got ready for bed, I thought about what an amazing conversation we had.\n",
      "Ten hours later, my mother called, waking me up. I could hardly understand what she was trying to say.\n",
      "\"Your father's dead!\" she cried. \"I found him lying on the dinning room floor.\"\n",
      "Suddenly I was standing straight up beside my bed, holding the phone and sobbing .\n",
      "I was a thousand miles away. All I could think about was how many hours, minutes and seconds it would take me to jump on a plane and get there. I thought about my mother sitting there alone with my father, and I couldn't move fast enough.\n",
      "The flight was long and painful. I had planned on going home to see my dad and mom in another month, and I cried aloud, thinking I was too late. Then I suddenly realized the incredible miracle of it all: I hadn't been late at all. Actually, everything had been right on time.\n",
      "\n",
      "Question: When did Dad die?\n",
      "A. Soon after he made the telephone call.\n",
      "B. The next morning.\n",
      "C. Before the writer hung up the phone.\n",
      "D. Ten hours later after the telephone call.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: One day a farmer went out for a walk with his daughter. The farmer put on a pair of wrong shoes-one with a thick sole  and the other with a thin one. So as he began to walk, he felt very uncomfortable. When he was just out of the house, he turned to his daughter and said, \"Why should one of my legs be longer than the other today?\"\n",
      "The daughter looked at his father's legs carefully as he was walking, and then laughed, \"Oh, no, Daddy, your legs are all right. You have put on the wrong shoes.\"\n",
      "The farmer was very happy to hear that and said to himself, \"What a clever daughter I have got!\" Then he asked his daughter to go back and get the other pair of shoes for him.\n",
      "The farmer had only two pairs of shoes.\n",
      "When the daughter ran back to the house, she found that the other pair was also a pair of wrong shoes.\n",
      "She had to return to his father with nothing in her hands and said out of breath, \"It's no use changing them, Daddy! The shoes at home were not a pair, either!\"\n",
      "\n",
      "Question: When the farmer went out for a walk with his daughter, he put on a pair of   _   shoes.\n",
      "A. wrong\n",
      "B. comfortable\n",
      "C. old\n",
      "D. new\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: My mother used to say things just to make me mad. Like most teenagers, I thought I knew everything. And what I didn't know, I didn't want to be told. For example, if I said I was going to a movie, my mother would roll her eyes. On my way out, she'd shout, \" _ You don't want to learn that the hard way!\" I didn't know what that meant. I thought she just wanted me to stay at home.\n",
      "Many years later I had three teenagers of my own. They thought they knew everything. I would say the same things to them like my mom. That's when I first saw it. My mother wasn't trying to help me.\n",
      "Why do we always have to learn things \"the hard way\"? Why can't we just accept our elders' wisdom? It's a good lesson for anyone. Clearly, I still haven't learned it.\n",
      "Yesterday, I stepped out of the shower when I heard my cell phone ringing in the kitchen. Grabbing a towel, I ran through the house. I grabbed the phone and hit my left foot against the table. The X-ray showed that I'd broken two toes.\n",
      "We all need to slow ourselves down once in a while, before something bad does it for us. My mother was right about a lot of things. I wish I could have told her.\n",
      "\n",
      "Question: What can we learn from the passage?\n",
      "A. Mothers know everything in their lives.\n",
      "B. Listening to elders' suggestions can help us.\n",
      "C. The writer's mother had three children.\n",
      "D. Achieving a goal helps you build self-confidence.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Dear Dr Jackson,\n",
      "My parents are never happy with me. They are always criticizing my clothes, my hair and the music I listen to. They hate my friends' looks and they keep complaining when I go with them. I'm not allowed to stay out as late as my friends do, so I can't have any fun. My parents only seem to care about my school grades. Although I love them, sometimes I feel we live in different worlds. If they love me, can't they understand me? How can I make them understand me?\n",
      "Angel\n",
      "Dear Angel,\n",
      "Your problem is common to both teenagers and parents. Don't worry, because all this is natural. You see, your parents have grown up at a different time and they have different experiences. So, they think some things are strange, but you find the same things are all right. For example, the music you like may sound like noise to them. Your parents love you, so they feel they must stop you from doing whatever they find strange. On the other hand, you don't want to be different from other teenagers, so you feel that your parents\n",
      "you.\n",
      "I think you should talk about this problem with your parents. Try to explain to them what you want and make them know they can believe you. And then they'll find you are a responsible person and they will give you more freedom.\n",
      "Jackson\n",
      "\n",
      "Question: Why has Angel written to Dr Jackson?\n",
      "A. Because her parents make her happy.\n",
      "B. Because her parents can't understand her.\n",
      "C. Because her friends don't like her.\n",
      "D. Because she is not good enough at school.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Picture Show\n",
      "There are 12,000 pictures on show here. You can see the whole Chinese history!\n",
      "Place: City Museum\n",
      "Price: ~30\n",
      "Time: 9:00 a.m.-5:00 p.m. Monday-Friday\n",
      "Films at the Museum\n",
      "There are two European films on Saturday afternoon at the Museum Theatre. See Broken Window at 2:30. The Workers is at 4:45. For more information, call 84987898.\n",
      "International Picnic\n",
      "Are you tired of eating the same food every day? Come to Central Park on Saturday and enjoy food from all over the world. Delicious and not expensive. Noon to 5:00 p.m.\n",
      "Do You Want to Hear \"The Zoo\"?\n",
      "\"The Zoo\", a popular rock group from Australia, Will give their first US concert  this Saturday night, at 8 at Rose Hall, City College.\n",
      "The Music Shop's Sale\n",
      "Sale on every record and tape in the shop, Pop, Rock, Jazz, Disco, Folk. Sale starts on Tuesday and ends on Thursday.\n",
      "\n",
      "Question: If Lucy would like to buy some cheap records, she cannot go to the Music Shop on   _  .\n",
      "A. Tuesday\n",
      "B. Wednesday\n",
      "C. Thursday\n",
      "D. Saturday\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Take a class at Dulangkou School, and you'll see lots of things different from other schools, You can see the desks are not in rows and students sit in groups. They put their desks together so they're facing each other. How can they see the blackboard? There are three blackboards on the three walls of the classroom!\n",
      "The school calls the new way of learning \"Tuantuanzuo\", meaning sitting in groups. Wei Liying, a Junior 3 teacher, said it was to give students more chances to communicate.\n",
      "Each group has five or six students, according to Wei, and they play different roles .There is a team leader who takes care of the whole group. There is a \"study leader\"who makes sure that everyone finishes their homework. And there is a discipline leader who makes sure that nobody chats in class.\n",
      "Wang Lin is a team leader. The 15-year-old said that having to deal with so many things was tiring.\n",
      "\"I just looked after my own business before,\"said Wang. \"But now I have to think about my five group members.\"\n",
      "But Wang has got used to it and can see the benefits now.\n",
      "\"I used to speak too little. But being a team leader means you have to talk a lot. You could even call me an excellent speaker today.\"\n",
      "Zhang Qi, 16, was weak in English. She used to get about 70 in English tests. But in a recent test, Zhang got a grade of more than 80.\n",
      "\"I rarely  asked others when I had problems with my English tests. But now I can ask the team leader or study leader. They are really helpful.\"\n",
      "\n",
      "Question: A discipline leader is supposed to  _  .\n",
      "A. take care of the whole group\n",
      "B. make sure that everybody finishes homework\n",
      "C. make sure that nobody chats in class\n",
      "D. collect all the homework and hand it in to teachers\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Tommy hated school and was always looking for excuses  not to go.If he sneezed, he asked his mother to write a note saying he had a cold.If he had a headache, he asked his mother to take him to the doctor during school hours.\n",
      "He spent more time at home than he did at school.On the days that he did go to school, he looked for excuses to come home early.One morning he came home when the lessons were only half finished.His father was surprised.\n",
      "\"You've come home early,\" he said. \"Is the school closed today?\"\n",
      "\"No, Dad, \" Tommy said - \"It's open. I came home early.\n",
      "\"How did you do that?\" his father asked him. \"What did you say to the teacher?\"\n",
      "\"I told her that I had a new baby brother and that I had to come home and help you . \"\n",
      "\"But your mother has had twins,\" his father said, \"a boy and a girl. You've got a baby brother and a baby sister.\"\n",
      "\"Yes, I know, Dad, \" Tommy said. \"I'm saving up my baby sister for next week \"\n",
      "\n",
      "Question: Tommy tried to find excuses for not going to school because  _  .\n",
      "A. he didn't like it.\n",
      "B. it gave him a headache\n",
      "C. it made him sneeze\n",
      "D. it made him happy\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: The seahorse is a very strange fish. Do you know what its head looks like? It looks like a horse. Of course it is not as big as a horse. You can pick it up with one hand. It swims with its head up and tail down.\n",
      "This strange looking fish often remains still. It will hang on to a bit of weed  with its tail. Then when a small fish swims by, the seahorse will suddenly jump and eat it up.\n",
      "Mother seahorse lays eggs .These eggs are kept in Father's pouch .When the eggs hatch, the babies pop out of the pouch into the sea.\n",
      "\n",
      "Question: The seahorse is   _  .\n",
      "A. a small horse\n",
      "B. a fish\n",
      "C. an egg\n",
      "D. a sea\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: A boy and his father were walking in the mountains. Suddenly the boy fell,hurt himself,and cried,\"AAAhhhhhhhhh!!!\" To his surprise,he heard the voice repeating ,somewhere in the mountain,\"AAAhhhhhhhh!!!\" Then the boy shouted,\"Who are you?\" He received the answer,\"Who are you?\"He got angry at the answer,so he shouted,  \"Foolish!\"He received the answer,\"Foolish!\"\n",
      "He looked at his father and asked,\"What'sgoing on?\"The father smiled and said,\"My son,listen,\"And then he shouted to the mountain,\"Ilove you!\"The voice answed,\"Ilove you!\" Again the man cried,\"You are the best!\" The voice answed,\"You are the best!\"\n",
      "The boy was surprised,but did not understand. Then the father explained ,\"People call this 'ECSO',but really this is Life.It gives you back everything you say or do. Our life is just a reflection of what we have done. If you  want more love in the world,have more love in your heart. If you want to be successful,work hard. This can be used in everything in life. Life will give you back everything you have given to it.\n",
      "\n",
      "Question: From this story ,we know  _  .\n",
      "A. the didn't like others' voice at all\n",
      "B. the father had his own way to teach his son.\n",
      "C. It is not polite to repeat others' voice\n",
      "D. The boy and his father were rather tired\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Tom is a schoolboy. He is only seven years old, but he is very busy on weekdays. One Saturday he decided to relax himself, so he went to the cinema.\n",
      "It was the first time for him to do that. He bought a ticket and then went in. But after two or three minutes he came out, bought a second ticket and went in again. After a few minutes he came out again and bought a third ticket. Two or three minutes later he came out and asked for another ticket. Then the girl in the ticket office asked him,\"Why did you buy so many tickets? How many friends did you meet?\"Tom answered, \"No, I have no friends here. But a big boy always stops me at the door and tears  my ticket.\"\n",
      "\n",
      "Question: Tom wanted to buy  _  when the girl asked him why.\n",
      "A. a second ticket\n",
      "B. a third ticket\n",
      "C. a fourth ticket\n",
      "D. a fifth ticket\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: A young British man called Luke Cameron has done a good deed  every day for more than a year and he says it has completely changed his life.\n",
      "Luke made a decision at the beginning of 2014.He started by doing one small good thing every single day from January 1st, 2014.For example, he greeted the waiter at a cafe on New Year's Day and he bought food and drink for some homeless people the next day.\n",
      "He set up a website where he could write down all his good deeds, like helping the neighbor take out the rubbish or spending a few hours in helping a disabled lady pick out a dress for a party.\n",
      "\"I've never thought of any return from helping others.Actually, it has given me happiness and I have become more thankful and grateful for the things I have now.\" Luke said.He has decided to continue doing good deeds in 2015.\n",
      "Luke won the competition for the job of National Philanthropy  Manager because of his kind deeds.He will travel all over the UK and help 45 different charities in 2015.\n",
      "\"I used to work as a part-time worker in a shop.Now I become the National Philanthropy Manager.\" Luke said, \"I think I've helped myself by helping others.\"\n",
      "\n",
      "Question: Which of the following is NOT a good deed for Luke?\n",
      "A. Walking the dog for his neighbor.\n",
      "B. Cleaning the house for his old neighbor.\n",
      "C. Spending his own money buying food for people in need.\n",
      "D. Selling things to customers when he worked in the shop.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Music education hasn't changed much since the 1970s. Students are still taught to read notation so they can recite compositions that they would never listen to on their MP3 players or play with friends. Playing music enriches life. The question is: Why do schools teach music in a way that _ so many young people rather than catch their imagination? Can we do a better job of using the power of music to get kids excited about school?\n",
      "The experience of an organization called Little Kids Rock suggests the answer is yes -- if we change the way music is taught. Little Kids Rock has helped music programs in over a thousand public schools and served 150,000 children. The organization has given 30,000 free instruments out, mainly guitars, and trained 1,500 teachers to run music classes in which students quickly experience the joys of playing their favorite songs, performing in bands , and writing their own music.\n",
      "The key to Little Kids Rock is that it teaches children to play music the way many musicians learn to play it -- not by notation, but by listening, imitation and meaningful experimentation. \"The knowledge you need to get started playing rock music is very limited,\" explains Dave Wish, the founder of Little Kids Rock. \"In high school, my friend Paul taught me a couple of chords and my life was changed forever. On the first day of class, Little Kids Rock teachers place guitars in the hands of their students and get them practicing chords that will enable them to play thousands of songs. The kids decide what songs they want to learn and the class is off and running. Their progress is surprising. Within a year, eight and nine-year-olds are playing musical instruments, and giving concerts, even performing their own songs.\n",
      "One of the biggest advantages that music offers is the ability to encourage students who are otherwise bored by school. \"I've had students start coming back to school because of this program,\" said Adkison Thomas, who heads up music for the Dallas Independent School District. He added, \"One of the best things is that the teachers discover a new side of their students. They see kids become successful who weren't before.\"\n",
      "\n",
      "Question: Little Kids Rock is successful because   _  .\n",
      "A. it encourages kids to experience music\n",
      "B. it helps kids learn from great musicians\n",
      "C. it allows kids to decide how to learn music\n",
      "D. it offers musical programs all over the country\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: A traveler came out of the airport. There were a lot of taxis. He asked every taxi driver about his name. Then he took the third one. It cost 5 dollars from the airport to the hotel. \"How much does it cost for the whole day?\" The man asked. \"100 dollars,\" said the taxi driver. This was very dear  , but the man said it was OK.\n",
      "The taxi driver took the man everywhere. He showed him all the parks and museums in the city. In the evening they went back to the hotel. The traveler gave the taxi driver 100 dollars and said, \"What about tomorrow?\" The taxi driver looked at the man and said, \"Tomorrow is another 100 dollars.\" And the man said, \"That's OK! See you tomorrow.\" The taxi driver was very pleased.\n",
      "The next day the taxi driver took the traveler everywhere again. They visited all the parks and museums again. And in the evening they went back to the hotel. The man gave the taxi driver 100 dollars again and said, \"I'm going home tomorrow.\" The driver was sorry because he liked the traveler and 100 dollars a day was a lot of money. \"So you are going home. Where do you come from?\" He asked. \"I come from New York.\" \"New York,\" the taxi driver said, \"I have a sister in New York. Her name is Susan. Do you know her?\" \"Of course I know her. She gave me 200 dollars for you!\"\n",
      "\n",
      "Question: Why did the traveler take the third taxi?  Because   _   .\n",
      "A. the other taxi driver asked more money\n",
      "B. the third driver was a kind-hearted  man\n",
      "C. he didn't want to spend his own money on the coming visit\n",
      "D. the other driver didn't like him\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Kitesurfing as a water sport began in the 1980s, but didn't get popular until the end of last century. It is also known as kiteboarding, and in some European countries as flysurfing. Kitesurfing works through wind power  by using a large kite to pull a rider on the water at high speed.\n",
      "At first, kitesurfing was a difficult and dangerous sport. Now it is becoming easier and safer because of the safer kite design. For an able and strong person, kitesurfing can be a very fun, extremely exciting sport, just like skating on the water with a feeling of flying. It has become more and more popular.\n",
      "Compared with other water sports, kitesurfing is easier to learn. A beginner can understand how to operate the kite with 5--10 hours of training. And anybody aged from 13 to 65 can learn. It is not expensive to get the equipment for kitesurfing, which costs $1,000 to 82,500. Training lessons _ from $200 to $500 for two or three hours. With the development of its equipment progress, kitesurfing is becoming even safer. After some training, you can enjoy its excitement and challenging feeling.\n",
      "With the rising popularity of kitesurfing, most major seaside cities have kitesurfing clubs. In China, Xiamen is the only place that has the kitesurfing club, which provides professional kitesurfing training and equipments.\n",
      "\n",
      "Question: The most important reason for the popularity of kitesurfing is that   _  .\n",
      "A. its price is getting lower and lower\n",
      "B. more and more people are enjoying its excitement\n",
      "C. its equipment progress makes it easier and safer\n",
      "D. all people can learn and take part in it\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Do you kow that animals have love for each other and their children just like us humans? Let me tell you some moving stories of great animal parents.\n",
      "Several years ago a heavy rain hit a town and made the river go up. When the rain stopped, people found that a dog swam to an island in the river twice a day for two weeks. Why did she do so? Her four children were there. The mother swam there every day to feed her babies. This true story moved many people.\n",
      "Another story is about chimpanzees . A scientist named Jane Goodall spent 4 years living with chimpanzees in Africa. She found that chimpanzees also cared for those that were hurt or got lost. \"It is not only humans who have duties, animals also do,\" she said.\n",
      "Two birds in Chengdu also showed their parental  love. Their baby was hurt and fell on the street in the center of the city. Cars were driving past but the brave parents rushed down to the road and took the little bird away with their claws .\n",
      "\n",
      "Question: After the heavy rain, the mother dog swam to the island   _  .\n",
      "A. to look for food\n",
      "B. to feed her babies\n",
      "C. to move some people\n",
      "D. to carry things to her owner\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: You can be proud of yourselves, even if you can only make one or two of these green changes. The goal here is to limit CO2and other greenhouse gases, which are closely connected to the big problem of global-warming  .\n",
      "WAY 1: Bring your own cup to Starbucks. You'll get a 10-cent discount, and it's one less paper cup to end up in a dustbin. The store won't create more waste when they throw away a cup.\n",
      "WAY 2: Turn off your computer. If you don't do that, your PC is still using energy. Turning off a monitor   for 40 hours a week may only save $ 5 a month, but it reduces CO\n",
      "by 750 pounds.\n",
      "WAY 3: Reuse plastic bags. Instead of throwing away 100 billion plastic bags a year, try and get a second, third, or tenth use out of them. Better yet, next time you shop, try a reusable bag. Oil that is used for making just 14 plastic bags would run your car for one mile.\n",
      "WAY 4: Use recycled paper in the bathroom. Most of the toilet paper we use is made from trees found in forests. If every family replaced one roll of toilet paper with a recycled one, 424,000 trees would still be standing.\n",
      "WAY 5: Plant a tree. Adding green to your garden is beautiful and earth-pleasing. Just one tree will help make cleaner air and save the environment from 5, 000 pounds of hot CO\n",
      "each year.\n",
      "\n",
      "Question: What are the uses of planting a tree?\n",
      "A. To make your garden beautiful\n",
      "B. To help make cleaner air\n",
      "C. To save environment\n",
      "D. All of above\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "\n",
      "Question: What is the difference between a tree and a plant?\n",
      "A. A tree is a large plant\n",
      "B. A tree is a plant that grows in the forest\n",
      "C. A tree is a plant that grows in the forest and has leaves\n",
      "D. A tree is a plant that grows in the forest and has leaves and has roots\n",
      "Answer: B\n",
      "\n",
      "Question: What is the difference between a tree and a shrub?\n",
      "A. A tree is a large plant\n",
      "B. A tree is a plant that grows in the forest\n",
      "C. A tree is a plant that grows in the forest and has leaves\n",
      "D. A tree is a plant that grows in the forest and has leaves and has roots\n",
      "Answer: C\n",
      "\n",
      "Question: What is the difference between a tree and a bush?\n",
      "A. A tree is a large plant\n",
      "B. A tree is a plant that grows in the forest\n",
      "C. A tree is a plant that grows in the forest and has leaves\n",
      "D. A tree is a plant that grows in the forest and has leaves and has roots\n",
      "Answer: B\n",
      "\n",
      "Question: What is the difference between a tree and a palm tree?\n",
      "A. A tree is a large plant\n",
      "B. A tree is a plant that grows in the forest\n",
      "C. A tree is a plant that grows in the forest and has leaves\n",
      "D. A tree is a plant that grows in the forest and has leaves and has roots\n",
      "Answer: B\n",
      "\n",
      "Question: What is the difference between a tree and a shrub?\n",
      "A. A tree is a large plant\n",
      "B. A tree is a plant that grows in the forest\n",
      "C. A tree is a plant that grows in the forest and has leaves\n",
      "D. A tree is a plant that grows in the forest and has leaves and has roots\n",
      "Answer: B\n",
      "\n",
      "Question: What is the difference between a tree and a bush?\n",
      "A. A tree is a large plant\n",
      "B. A tree is a plant that grows in the forest\n",
      "C. A tree is a plant that grows in the forest and has leaves\n",
      "D. A tree is a plant that grows in the forest and has leaves and has roots\n",
      "Answer: B\n",
      "\n",
      "Question: What is the difference between a tree and a palm tree?\n",
      "A. A tree is a large plant\n",
      "B. A tree is a plant that grows in the forest\n",
      "C. A tree is a plant that grows in the forest and has leaves\n",
      "D. A tree is a plant that grows in the\n",
      "Extracted prediction: C, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: The best day of the week for shoppers is Saturday. In America, women do most of the shopping, while the young also enjoy shopping with their friends. Men don't enjoy taking time in the store. There are many places to shop. A mall is a group of many shops where you can buy clothes, _ and everything of the house. Shopping malls provide parking of the cars which is very important to the shopper. Usually the mall is under one roof, so each people doesn't get cold or wet from rain, wind, or snow. Mothers can buy clothes for family members. For the children, shoes, socks, dresses, coats, and sweaters are bought in August for the new school year. For the kitchen the mother might buy cooking pots, drinking glasses, and the television set. The bedroom furniture has beds, mirrors and so on. Finally, there are pictures in most rooms.\n",
      "To buy all these things at the mall takes many trips but mothers enjoy this kind of shopping.\n",
      "\n",
      "Question: What is a shopping mall?\n",
      "A. It's a group of many shops where you can buy everything you need.\n",
      "B. A department store where you can buy everything you need.\n",
      "C. A supermarket where you can buy vegetables, fruits and so on.\n",
      "D. You can park your car there\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: It was the golden season. I could see the yellow leaves dancing in the cool wind. I felt lonely and life is uninteresting. But one day, the sound of a violin came into my ears. I was so surprised that I ran out to see where it was from. A young girl, standing in the wind, was lost in playing her violin.\n",
      "I had never seen her before. The music was so wonderful that I forgot who I was.\n",
      "Leaves were still falling. Every day she played the violin in the same place and I was the only listener. It seemed that I no longer felt lonely and life became interesting. We didn't know each other, but I thought we were already good friends.\n",
      "One day, when I was listening, the sound suddenly stopped. The girl came over to me.\n",
      "\"You must like violin.\" she said.\n",
      "\"Yes. And you play very well. Why did you stop?\" I asked.\n",
      "Suddenly, a sad expression appeared on her face and I could feel something unusual.\n",
      "\"I came here to see my grandmother, but now I must leave. I once played very badly. It is your listening every day that has _ me.\" she said.\n",
      "\"In fact, it is your music that has given me those meaningful days.\" I answered. \"Let us be friends.\"\n",
      "The girl smiled and I smiled.\n",
      "I never heard her play again in my life. Only thick leaves were left behind. But I will always remember the girl. She is like a dream; so short, so bright that it makes life beautiful.\n",
      "There are many kinds of friends. Some are always with you, but don't understand you. Some say only a few words to you, but are close to you. I shall always think of those golden days and the girl with the violin. She will always bring back the friendship between us. I know she will always be my best friend.\n",
      "\n",
      "Question: What's the best title for the passage?\n",
      "A. A Musical Girl\n",
      "B. Wonderful Music\n",
      "C. A Special Friend in a Special Autumn\n",
      "D. How to Be Friends\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
      "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
      "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
      "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
      "\n",
      "Question: How long did the press conference last?\n",
      "A. We don't know.\n",
      "B. 1 hour.\n",
      "C. Half an hour.\n",
      "D. 10 minutes\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Tomorrow is August fourth. It is Peter's grandfather's birthday. It is his 73rd  birthday. Peter and his two sisters, Sally and Tina buy some things for their grandfather this afternoon. Sally buys a nice birthday card. And she writes \"Happy birthday\" on it. Tina buys a blue shirt from a clothes store. It is $29. Peter buys some fruit and a set of books. They are $39 .The name of the books is Harry Potter. His grandfather likes reading a lot. Peter hopes he will like the books.\n",
      "\n",
      "Question: How old is Peter's grandfather?\n",
      "A. 70 years old\n",
      "B. 73 years old\n",
      "C. 74 years old\n",
      "D. 75 years old\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
      "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
      "\n",
      "Question: Tony is from  _  .\n",
      "A. England\n",
      "B. America\n",
      "C. English\n",
      "D. American\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: What does it feel like to break a bone  ? It's different for everyone, but the pain is often sharp  . If the break is small, however, the person may not feel much pain at all. If you think that you or someone else has broken a bone, the most important things to do are to stay calm, make the hurt person comfortable, and call the doctor. Do not move the injured body part since movement could make it worse.\n",
      "To treat the break, the doctor will need to take an X-ray. This gives the doctor the information he or she needs to set   the bone: to put it back to its normal place. If the bone is large or it is broken in more than one place, the doctor may need to use metal pins   to set it. After the bone has been set, the next step is usually putting on a cast, the special, hard thing that will keep the bone in place for a month or two.\n",
      "Your bones are excellent at healing themselves. Broken bones will produce many new cells   and tiny blood vessels  . These cover both ends of the broken part, and close up the break until the bone is as whole and strong as before.\n",
      "\n",
      "Question: Which of the following is the best title for the passage?\n",
      "A. How to Know if a Bone is Broken\n",
      "B. How Broken Bones Heal Themselves\n",
      "C. Common Causes   of Broken Bones\n",
      "D. What You Should Know about Broken Bones\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Have you ever complained why life is so tiring? Does the sky sometimes seem dark to you? Are your studies sometimes not successful? Well, friends, cheer up and smile all the time. If you see the world with your warm heart , you'll find that the whole world smiles to you. While in school, sometimes you are tired of your lessons, but have you ever noticed the happy smile on your teacher's face when you did a good job?\n",
      "One day it is fine. Just before you want to go out, it suddenly starts to rain . Maybe you would feel very sad and start complaining about the weather. But dear friends, why don't you sit down and listen to the free concert that the nature offers you? And with the timely rain , crops in the fields will grow better and better and farmers will have a good harvest.\n",
      "Although everyone wants to succeed in what he tries to do, sometimes failure can't be avoided . I think failure is not terrible, and the terrible thing is that we are afraid of it and give up hope .\n",
      "When we face failure , we must be confident in ourselves, draw a useful lesson from it and try our best to finish what we have to do. As a popular saying goes , \" Failure is the mother of success .\"\n",
      "Attitude decides everything . With an optimistic  attitude life is easy and pleasant . Let's smile to whatever we meet and the whole world will smile to us .\n",
      "\n",
      "Question: The best title of this passage is  _  .\n",
      "A. Smile and the World Smiles to You\n",
      "B. Complaining about life\n",
      "C. Failure is the Mother of Success\n",
      "D. It is Very Hard to Success\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Dear Mr. Expert,\n",
      "I grew up in an abusive  home. I always promised myself that I'd get out as soon as possible. Now, at age 20, I have a good job and a nice house of my own, and I'm really proud.\n",
      "Here's the problem: some of my friends who still live with their parents spend the weekends with me. But now they make mine theirs. They bring boy friends over, talk on the phone, etc.\n",
      "I enjoy having my friends here sometimes - it makes the place feel comfortable and warm, but this is my home, not a party house, what shall I do?\n",
      "Joan\n",
      "Dear Joan,\n",
      "If your family didn't pay attention to your needs when you were a child, you probably have trouble letting others know your needs now.\n",
      "And if you've gathered your friends around you to rebuild a happy family, you may fear that saying no will bring back the kind of _ that you grew up in. You need to understand that in true friendship it's okay to put your own needs first from time to time.\n",
      "Be clear about the message you want to send. For example, \"I really love you, but I also need some personal space. So please call before you come over.\"\n",
      "Edward\n",
      "\n",
      "Question: We can infer  from the first letter that  _  .\n",
      "A. Joan considers her friends more important than her personal space\n",
      "B. Joan's friends visit her more often than she can accept\n",
      "C. Joan doesn't like the parties at all\n",
      "D. Joan dislikes the boyfriends that her friends bring over\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Why do we come to school? Most of us may say we come to school to study. But to study needs a right way, or you either waste the time or the money. The following are the ways for studying.\n",
      "The best time for reading is morning. In the morning the air is fresh and the mind is clear. For that reason we can get good results.\n",
      "In studying we must have patience . If we have not known a text well, we must read it again. We should not read the next one until we have learned the first one well.\n",
      "When we are studying, we must put our hearts into the books, or we can get nothing from the books while we are reading.\n",
      "We must always ask \"whys\". If it is not well understood, write it down and ask our teachers or our parents, brothers or friends. In any possible way, we must know it completely and what we have learned can be used well and made better.\n",
      "Though there are many ways for studying, yet what I have said above will be enough if we can keep them in heart and do so.\n",
      "\n",
      "Question: It's better for us to read in the morning because   _  .\n",
      "A. we have no other work to do\n",
      "B. we can get good results\n",
      "C. we have slept for some hours\n",
      "D. we may learn the next text\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Music is an important part in our life. We may feel boring without music. Today when you go to stores, stations, restaurants and other places, do you notice music playing at any of these places? The answer must be \"Yes\". And you might even hear music in an office or on a farm.\n",
      "I like many kinds of music. Classical music is great. Rock music is fast. Light music is relaxing. But I like folk music best. It sounds very beautiful. It can bring me into the dream land. It can make me relax and forget all the problems. It makes me learn better and helps me to be more active. It is true that I learn better when I am relaxed.\n",
      "Music can also influence  people's behavior . Classical music makes people feel rich . When a restaurant plays classical music, people spend more money on food and drinks. When the restaurant plays modern music, people spend less money. Without music, people spend evenless. Restaurants can make more money in this way.\n",
      "\n",
      "Question: Western classical music is often regarded as   _  .\n",
      "A. a sign of being slow\n",
      "B. something about behavior\n",
      "C. a sign of being rich\n",
      "D. something with new kinds\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: As prices and building costs keep rising, \"the do-it-yourself\"(DIY)trend  in the US continues to grow.\n",
      "\"We needed furniture for our living room,\" says John Kose, \"and we didn't have enough money to buy it.\" So we decided to try making a few tables and chairs. John got married six months ago, and like many young people these days, they are struggling  to make a home when the cost of living is very high. The Koses took a 2-week course for $ 280 at a night school. Now they build all their furniture and make repairs around the house.\n",
      "Jim Hatfield has three boys and his wife died. He has a full-time job at home as well as in a shoe-making factory. Last month, he received a car repair bill for $420. \"I was very upset about it. Now I've finished a car repair course. I should be able to fix the car myself. \"\n",
      "John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: Jim Hatfield decided to become a do-it-yourself when   _   .\n",
      "A. he had to raise the children all by himself\n",
      "B. he could not possibly do two jobs\n",
      "C. the car repair class was not helpful\n",
      "D. his car repairs cost too much\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Tom is a little boy ,and he is only seven years old. One day he went to the cinema. It is the first time for him to do that. He bought a ticket and then went in. But after two or three minutes he came out, bought a second ticket and went in again. After a few minutes he came out again and bought a third ticket. Two or three minutes later he came out and asked for another ticket. Then the girl in the ticket office asked him,\"Why do you buy so many tickets? How many friends do you meet?\"Tom answered,\" No, I have no friend here. But a big boy always stops me at the door and tears my ticket to pieces.\"\n",
      "\n",
      "Question: From the story we know  _  .\n",
      "A. the little boy had a lot of money\n",
      "B. the little boy knew nothing about the cinema\n",
      "C. The big boy wasn't friendly to Tom\n",
      "D. the girl wanted to get more money\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Mike was ten years old and he went to the Ashland School. He was very good at football, so he was chosen  by the school team. He always played very well in the matches, and he scored a lot of goals  . One day Mike said to his parents, \"we will play football with the Gum Tree School .Will you come and cheer us on?\" And they agreed to come.\n",
      "The match was in the park. The Gum Tree School team wore green shirts and blue shorts  , and Mike's team wore white shirts and red shorts. In the first two minutes of the match, Mike ran with the ball and kicked it into the goal. All the Ashland School boys and their families were very excited about it.\n",
      "After that, Mike scored two goals before half time. Then in the second half of the match he almost scored another goal, but he kicked the ball with his foot lightly , and the goalkeeper caught it easily and threw it out.\n",
      "After the match, Mike's father said to him, \"You missed a good chance   to score another goal, Mike. Why did you kick it lightly?\"\n",
      "\"Because there were tears   in the goalkeeper's eyes,\" Mike answered.\n",
      "\n",
      "Question: How many goals did Mike score in the match? .\n",
      "A. Two\n",
      "B. Four\n",
      "C. Three\n",
      "D. Five\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Are you always unwilling to do housework and cleaning for no reason? Well, you will be happy today. Today is No Housework Day. It's time to forget about housework and be relaxed.\n",
      "No Housework Day is always on April 7th. It is your chance to do anything, except housework. Better still, have someone else do housework for a day. Housework is a daily and endless job and most people think it's boring to do housework. I have many friends and their wish is to stay away from housework. In fact, their wish can never come true.\n",
      "Do you know how to celebrate No Housework Day? Well , there are two different ways.\n",
      "If you usually do the housework around the house, forget it on this day. Instead, kick back and enjoy the day. Relax and do anything, except housework.\n",
      "If you never do housework, you can do it for your family. It gives your parents a break from the housework. And, you just might get a chance to know how much housework your parents need to do every day.\n",
      "\n",
      "Question: The writer has many friends and their wish is   _  .\n",
      "A. not to do any housework any more\n",
      "B. to ask others to do their housework\n",
      "C. to celebrate No Housework Day\n",
      "D. to ask all the family members to do housework\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: When he was a teenager, Hunter Adam was very unhappy and he spent many years in a special hospital for people with mental health problems.\n",
      "When he left the hospital, Adam decided to become a doctor, so he went to a medical school in Virginia, USA. But when he was there, he did things in a different way. For example, he didn't like the doctor's white coats, so he wore shirts with flowers on them when he visited his patients and he tried to make them laugh. The doctors at the medical school didn't like Adams because he was too different.\n",
      "But Adams believed that people in hospital need more than medicine. He saw unhappy and lonely people, and he tried to help them as patients, but as people too. He spent a lot of time with children in the hospital and often dressed up like a clown to make the children laugh\n",
      "When he finished medical school and become a doctor, Adams opened his own hospital, called \"the Gusundheit Institute\",together with some other doctors. They wanted it to be a place with a different way of working with sick people.\n",
      "Hunter Adams became famous during the 1980s, and in 1988, Universal Pictures made a film about his life. It was very successful. In the film, Robin Williams played Adams. Williams said,:\"hunter is a really warm person, who believes that patients need a doctor who is a friend. I enjoyed playing him.\"\n",
      "\n",
      "Question: Why did the doctors at the medical school dislike Adams?\n",
      "A. because he was a warm person\n",
      "B. because he had mental health problem\n",
      "C. because he was a clown\n",
      "D. because he wasn't the same as others\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: It's reported that a company called MicroCHIPS has developed a wirelessly controlled device . The device is put under the skin and can supply a drug directly into the patient's body. People give the name \"microchips\" to it.\n",
      "Microchips bring good news to patients with long-term( ) illnesses, for example, Osteoporosis( ). People with Osteoporosis have to get daily injections( ) of medicine. One type of treatment requires injections for two years. Many patients stop taking the medicine because of the pain and stress of the infections. However, microchips can deal with it. Doctors will program the device before putting it under the skin, and the device has the ability to release  a dose   at a given time, every single day. One microchip can hold a full year's worth of medicine.\n",
      "Microchips may one day free (...... )people from having to remember to take their medicine, or get injections. The device may also be useful in treating other long-term diseases, including heart disease, cancer and even AIDS.\n",
      "\n",
      "Question: What is the passage mainly about?\n",
      "A. It introduces the company MicroCHIPS.\n",
      "B. It introduces a new wirelessly controlled device called \" microchips\".\n",
      "C. It introduces some common long-tern diseases.\n",
      "D. It's about how the device called\"microchips\"works.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: John gets up early from Monday to Saturday, because he must go to school before 7:30 on weekdays  and go to Drawing Club at 8:00 on Saturday mornings. He usually goes to the bookshop on Saturday afternoon, and after dinner he watches TV until  midnight .\n",
      "He doesn't get up early on Sundays. John's parents both work on Sundays. John always watches TV after he gets up. Then he usually goes to KFC to have a hamburger and some juice for lunch. After that, he goes back home and starts to play computer games until his parents come back. He does his homework after dinner. He usually has lots of weekend homework, so he must spend three hours on it. He usually goes to bed at about 11:00 p.m. on Sundays. He often complains  he has too much homework to do.\n",
      ",.\n",
      "\n",
      "Question: When does John do his weekend homework?\n",
      "A. On Sunday evening.\n",
      "B. On Sunday morning.\n",
      "C. On Saturday evening.\n",
      "D. On Sunday afternoon.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: On Children's Day a young woman from America goes to Beihai Park with her little daughter. There are too many people in the park. The woman can't find her daughter, So she goes to the policeman for  help. She tells the policeman her daughter is only six years old. She has two big eyes and a round face. Her hair is golden yellow. And she is in a short blue dress. At last the policeman helps her find her daughter. She thanks him very much.\n",
      "\n",
      "Question: Her daughter is only   _  .\n",
      "A. five\n",
      "B. six\n",
      "C. seven\n",
      "D. four\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: How much do you know about Albert Einstein?\n",
      "Albert Einstein, born on March 14, 1579 in Germany, was a great scientist in the world. He was strange because he hated haircuts and new clothes. He believed in peace. All his life, he hated war. However, his most famous idea, E=mc2, helped create the world's most dangerous weapon . Many people think he was the smartest person in the world. But Einstein said that _ \n",
      "What did he like?\n",
      "Einstein liked learning sailing . He sailed in small boats all his life. He once joked, \"Sailing is the sport that takes the least energy!\"\n",
      "When Einstein was a child, his mother made him take violin lessons. At first, he didn't like the violin. But then he learned to love music and became a good violinist. Later, he said, \"Love is the best teacher.\"\n",
      "Why is the sky blue?\n",
      "In 1910, Einstein asked a question which many children often ask, \"Why is the sky blue?\" After his careful research, he answered the question like this: \"It's because light is made up of many colors including blue. When light travels to Earth, gas particles spread the blue light all over the sky.\" His answer is true in physics.\n",
      "\n",
      "Question: Einstein offered a  _   explanation for the question why the sky is blue.\n",
      "A. magic\n",
      "B. scientific\n",
      "C. careful\n",
      "D. Natural\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
      "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
      "\n",
      "Question: There are   _   classrooms in Betty's school?\n",
      "A. 12\n",
      "B. 14\n",
      "C. 24\n",
      "D. 34\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Long long ago, there were three tortoises .  They were friends.\n",
      "One of them was a large tortoise, one was a medium-sized tortoise and the third was a small tortoise.\n",
      "One day they went into a restaurant and ordered some cakes. While(......) they were waiting for the cakes, they remembered that they didn't bring any money.\n",
      "\"Hey, we forgot to bring money to pay for our cakes,\" the big tortoise said.\n",
      "\"The little tortoise can go home and get it,\" the medium-sized tortoise said. \"He's the youngest, so he should be the one to go.\"\n",
      "The little tortoise wasn't very happy, but he knew he shouldn't argue with his elders, so he said, \"All right, I'll go. But you must promise  not to eat my cake while I'm away.\"\n",
      "The large tortoise and the medium-sized tortoise agreed, and the little tortoise left for home to get some money.\n",
      "A few days later, the big tortoise said to the medium-sized tortoise, \"Let's eat the little tortoise's cake. I'm hungry again.\"\n",
      "\"So am I,\" the medium-sized tortoise said, and reached for the cake.\n",
      "As she did so, the little tortoise shouted from near the door of the restaurant, \"If you touch  my cake, I won't go and get the money!\"\n",
      ", .\n",
      "\n",
      "Question: The three tortoises found they didn't take money with them   _   .\n",
      "A. when they were ordering the cake\n",
      "B. after they ate up the cake\n",
      "C. before they went into the restaurant\n",
      "D. after they ordered the cake\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Hello! My name is Kitty. I want to talk about my home town today.\n",
      "My home town is small but pretty. It's about two hours away from London by train. In the centre of the town there is a small lake. There are lots of trees and flowers around the lake. My parents often walk around the lake at the weekend. The air in my home town is very fresh   and clean.\n",
      "There are two schools in my home town, one primary school and one secondary school. I study in the secondary school and my younger sister studies in the primary school. I often ride my bike to school.\n",
      "I usually go to the youth centre to learn drawing with my sister on Friday afternoons. I like going shopping at the weekend. There are two big shopping malls there.[:Zxxk.Com]\n",
      "\n",
      "Question: There is  _  in the centre of the town.\n",
      "A. a primary school\n",
      "B. a secondary school\n",
      "C. a small lake\n",
      "D. a shopping mall\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: A story is told about a soldier who was finally coming home after having fought in Vietnam. He called his parents from San Francisco.\n",
      "\"Mom and Dad, I'm coming home, but I have a friend I'd like to bring with me.\"\n",
      "\"Sure,\" they replied, \"we'd love to meet him.\"\n",
      "\"There is something you should know,\" the son continued, \" he was hurt badly in the fighting. He lost an arm and a leg. He has nowhere else to go, and I want him to live with us.\"\n",
      "\"I'm sorry to hear that, son. Maybe we can help him find somewhere to live.\"\n",
      "\"No, Mom and Dad, I want him to live with us.\"\n",
      "\"Son,\" said the father, \"you don't know what you're asking. Someone like the young man would be a terrible burden for us. We have our own lives to live, and we can't let something like this stay with our lives. I think you should just come home and forget about this guy. He'll find a way to live on his own.\"\n",
      "At that point, the son hung up the phone. A few days later, however, they received a call from the San Francisco police. Their son had died after falling down from a building. The police believed it was suicide .\n",
      "The parents flew to San Francisco. To their surprise, they found their son had only one arm and one leg.\n",
      "The parents in this story are like many of us. We find it easy to love those who are good-looking or fun, but we don't like people who make us feel uncomfortable. We would rather stay away from people who aren't as healthy, beautiful, or smart as we are.\n",
      "\n",
      "Question: Who lost an arm and a leg in the fighting\n",
      "A. The soldier himself.\n",
      "B. The soldier's friend.\n",
      "C. The soldier's brother.\n",
      "D. The soldier's father.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Picture Show\n",
      "There are 12,000 pictures on show here. You can see the whole Chinese history!\n",
      "Place: City Museum\n",
      "Price: ~30\n",
      "Time: 9:00 a.m.-5:00 p.m. Monday-Friday\n",
      "Films at the Museum\n",
      "There are two European films on Saturday afternoon at the Museum Theatre. See Broken Window at 2:30. The Workers is at 4:45. For more information, call 84987898.\n",
      "International Picnic\n",
      "Are you tired of eating the same food every day? Come to Central Park on Saturday and enjoy food from all over the world. Delicious and not expensive. Noon to 5:00 p.m.\n",
      "Do You Want to Hear \"The Zoo\"?\n",
      "\"The Zoo\", a popular rock group from Australia, Will give their first US concert  this Saturday night, at 8 at Rose Hall, City College.\n",
      "The Music Shop's Sale\n",
      "Sale on every record and tape in the shop, Pop, Rock, Jazz, Disco, Folk. Sale starts on Tuesday and ends on Thursday.\n",
      "\n",
      "Question: Which of the followings is True according to the ads?\n",
      "A. People can see the whole European history in the City Museum.\n",
      "B. People can call 84987898 to find more information about food and music.\n",
      "C. People can eat different kinds of food in Central Park.\n",
      "D. People can go to the zoo this Saturday night.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: We know exercise is important in our life. Everyone needs to do exercise. Doctors say doing sports is good for us. Sports can make our body healthy.\n",
      "It's very useful  for children, too. It can make children clever. This means they will do well in study and schoolwork.\n",
      "There are easy ways to exercise. You can walk, run, or only jump. When you do exercise, you need to know what you are doing. Don't do sports too much at a time. Try all kinds of sports and look for one, two or even three sports you like. You can also exercise at the gym . Exercise can be fun. It can make you happy. Friends can exercise together at a gym or they can do sports together at any place they like.\n",
      "\n",
      "Question: It is NOT true that   _  .\n",
      "A. everyone needs to do sports\n",
      "B. doing a lot of sports at a time makes you very healthy\n",
      "C. we should try all kinds of sports\n",
      "D. people can do exercise at the gym or at home\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Jeff Keith has only one leg. When he was 12 years old, Jeff had cancer. Doctors had to cut off most of his right leg. Everyday Jeff puts on an _ leg. The leg is plastic. With the plastic leg Jeff can ski, ride a bicycle, swim, and play soccer. He can also run.\n",
      "In the photo, Jeff is running with some young men. They have plastic legs, too. They are wearing special T-shirts. The T-shirts say, \"Run, Jeff, Run. Jeff Keith Run Across America.\"\n",
      "When he was 22 years old, Jeff Keith ran across the United State, from the East Coast to the West Coast. He started running in Boston. Seven months later, he stopped running in Los Angeles. He ran 3,200 miles, that's about 16 miles each day. Jeff wore out 36 pairs of running shoes and five plastic legs.\n",
      "Jeff stopped in cities on the way to Los Angeles. In every city people gave Jeff money. The money was not for Jeff. It was for American Cancer Society. The American Cancer Society used the money to learn about cancer.\n",
      "On the way to Los Angeles Jeff talked to people about cancer. He also talked about being disabled. Jeff is disabled, but he can do many things: he skis, swims, plays soccer, and runs. He finished college and is studying to be a lawyer. Jeff says, \"People can do anything they want to do. I want people to know that. I am not only for disabled people. I ran for everyone!\"\n",
      ",.\n",
      "\n",
      "Question: This passage tells us a story about a   _   young man.\n",
      "A. disabled\n",
      "B. healthy\n",
      "C. blind\n",
      "D. sad\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: As prices and building costs keep rising, \"the do-it-yourself\"(DIY)trend  in the US continues to grow.\n",
      "\"We needed furniture for our living room,\" says John Kose, \"and we didn't have enough money to buy it.\" So we decided to try making a few tables and chairs. John got married six months ago, and like many young people these days, they are struggling  to make a home when the cost of living is very high. The Koses took a 2-week course for $ 280 at a night school. Now they build all their furniture and make repairs around the house.\n",
      "Jim Hatfield has three boys and his wife died. He has a full-time job at home as well as in a shoe-making factory. Last month, he received a car repair bill for $420. \"I was very upset about it. Now I've finished a car repair course. I should be able to fix the car myself. \"\n",
      "John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: How can people learn DIY?\n",
      "A. Go to classes.\n",
      "B. Read books.\n",
      "C. Go to classes and read books.\n",
      "D. The passage doesn't tell us.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Come and see the India elephants and the new tigers from America. The bears are waiting to meet you, and the monkeys from China are waiting to throw  things to you. The lovely dogs from Australia are waiting to laugh at you. The giraffes from Brazil are waiting to look down on you.\n",
      "Tickets                             Open time\n",
      "Grown-up: $2.00             9:00a.m--4:00p.m\n",
      "Children :over 12 $1.00               Except Friday\n",
      "Under12 Free                   10:00a.m--3:00p.m\n",
      "Keep the zoo clean!\n",
      "Don't touch  , give good food or go near the animals!\n",
      "\n",
      "Question: Which of the following is the visiting time?\n",
      "A. 8:30am Monday\n",
      "B. 9:30am Friday\n",
      "C. 3:00pm Sunday\n",
      "D. 5:00pm Tuesday\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: One day, I happened to meet an Englishman in the street and soon we began to talk. As I was talking about how I was studying English, the foreigner seemed to be very surprised, gently shaking his head and saying \"You don't say!\"\n",
      "I was confused, and I thought, \"Perhaps this is not a right thing to talk about.\" Then I said to him, \"Well, shall we talk about the Great Wall? Have you ever visited it?\"\n",
      "\"Certainly! Everyone back home will laugh at me if I leave here without seeing it. The Great Wall is wonderful! \" \"Yes, it is one of the wonders in the world. And people of many countries have come to visit it.\" As I went on telling him more about it, he stopped me again, \"You don't say!\"\n",
      "I couldn't help asking, \"Why couldn't I talk about it?\"\n",
      "\"Well, I didn't stop you talking about it,\" he answered, greatly surprised.\n",
      "\"Didn't you say 'You don't say!'?\" I asked again.\n",
      "Hearing this, the foreigner laughed loudly. He began to explain, \"'You don't say!' means 'Really'. Perhaps you know little about English idioms .\"\n",
      "Wow! How foolish I was! Since then I have been careful with English idioms.\n",
      "\n",
      "Question: What does the writer learn from his own experience? He should   _  .\n",
      "A. improve his spoken English\n",
      "B. speak with foreigners in a polite way\n",
      "C. pay attention to English idioms\n",
      "D. be brave enough talking with foreigners\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Tom was a farmer. He worked on the farm all day,but sometimes he went to the town market to sell fruit and vegetables. One day, a terrible sound attracted his attention in the town market. He saw a young bull for sale. The bull was white and yellow. It was looking at Tom in fear. Tom walked up and touched its head gently. Just at that time they both seemed to have known each other for a long time. How amazing!Tom bought it at once and called it Amba.\n",
      "From then on , Tom and Amba got on well with each other. But some friends told him that it was dangerous to have such a close relationship with an animal.\n",
      "One afternoon , Tom was walking through the forest with Amba. Suddenly , Amba stopped walking and kept pushing Tom with its head. Tom was very surprised and looked around. There was a big snake in front of him. It was beautiful but poisonous. Quickly Amba stepped on the snake's tail with its foot and at the same time Tom picked up a stick and hit the snake's head heavily. Soon the snake . died.\n",
      "Tom was very grateful for Amba's help. When people heard this, they were shocked at the bull's expression of love for Tom. But for Tom, Amba was not a bull but a member of his family.\n",
      "\n",
      "Question: Which of the following statements is NOT true?\n",
      "A. Tom went to the town market to sell fruit and vegetables.\n",
      "B. Tom's friends thought animals were safe.\n",
      "C. Tom hit the snake's head heavily with a stick.\n",
      "D. For Tom, Amba was a member of his family.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Mr. Jackson lives in a small town. He is a kind and funny man. And he is friendly to everyone. He likes talking with others very much. But he is always absent-minded  .\n",
      "One day, Mr Jackson went to visit a friend. His friend works on a farm and lives not far from the market and often goes to the market to sell things.\n",
      "They had dinner together and then talked and talked. Mr Jackson was very excited to meet his friend. He told his friend a lot of things. Midnight came, and then one o'clock, two o'clock and still Mr Jackson kept on talking. But by this time his friend was feeling very tired and kept on looking at the clock on the wall. He didn't want to be impolite, but at last he said, \"My dear friend, I don't want to put you out, but you see, it's too late now. I have to go to the market at six o'clock, and I must go to bed now.\"\n",
      "\"Oh, my God!\" said Mr Jackson in surprise, \"I thought you were at my house.\"\n",
      "\n",
      "Question: Mr Jackson likes   _   a lot.\n",
      "A. selling things\n",
      "B. talking with others\n",
      "C. playing soccer\n",
      "D. watching TV\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: If you see a group of people dancing and singing on the street or in the railway station, you don't need to feel surprised. They are flash mobbers  . Who are they? Are they mobs ? Don't feel afraid hearing their name. In fact, like a mob, they are a large group of people, but they have a good purpose. They usually get together in a place, do some simple actions, and then quickly disappear.\n",
      "Flash mob is now becoming more and more popular. People use it to do many things. For example, in 2009, Michael Jackson's fans took part in a flash mob to remember him. Hundreds of his fans organized through Internet and got together outside the railway station in Liverpool. They were singing and dancing Michael's famous song \"Beat It\" together. And in another example, some people took part in a flash mob to tell more people not to use negative words  .\n",
      "Flash mobs give different people a chance to come together to create a good memory.\n",
      "\n",
      "Question: In 2009, hundreds of people took part in a flash mob in Liverpool railway station to   _\n",
      "A. to show themselves\n",
      "B. to remember Michael Jackson\n",
      "C. tell people not to use negative words\n",
      "D. to make a film\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Mr. Jackson lives in a small town. He is a kind and funny man. And he is friendly to everyone. He likes talking with others very much. But he is always absent-minded  .\n",
      "One day, Mr Jackson went to visit a friend. His friend works on a farm and lives not far from the market and often goes to the market to sell things.\n",
      "They had dinner together and then talked and talked. Mr Jackson was very excited to meet his friend. He told his friend a lot of things. Midnight came, and then one o'clock, two o'clock and still Mr Jackson kept on talking. But by this time his friend was feeling very tired and kept on looking at the clock on the wall. He didn't want to be impolite, but at last he said, \"My dear friend, I don't want to put you out, but you see, it's too late now. I have to go to the market at six o'clock, and I must go to bed now.\"\n",
      "\"Oh, my God!\" said Mr Jackson in surprise, \"I thought you were at my house.\"\n",
      "\n",
      "Question: Mr Jackson's friend went to bed   _   that day.\n",
      "A. at midnight\n",
      "B. at one o'clock\n",
      "C. at two o'clock\n",
      "D. after two o'clock\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
      "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
      "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
      "She understood that she hadn't worn the hair clip to school at all.\n",
      "\n",
      "Question: We can learn from this passage that  _\n",
      "A. A friend is easier lost than found.\n",
      "B. Make your enemy your friend.\n",
      "C. A friend in need is a friend indeed.\n",
      "D. The most important is how we think about ourselves.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Tom is a little boy ,and he is only seven years old. One day he went to the cinema. It is the first time for him to do that. He bought a ticket and then went in. But after two or three minutes he came out, bought a second ticket and went in again. After a few minutes he came out again and bought a third ticket. Two or three minutes later he came out and asked for another ticket. Then the girl in the ticket office asked him,\"Why do you buy so many tickets? How many friends do you meet?\"Tom answered,\" No, I have no friend here. But a big boy always stops me at the door and tears my ticket to pieces.\"\n",
      "\n",
      "Question: The big boy  was  _   at the cinema.\n",
      "A. a bookseller\n",
      "B. a policeman\n",
      "C. a shopkeeper\n",
      "D. a worker\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Happiness is for everyone. You don't need to care about those who have beautiful houses with large  gardens and swimming pools or those who have nice cars and lots of money and so on. Why? .Because  those who have big house may often feel lonely and those who have cars may want to walk on the country roads at their free time.\n",
      "In fact, happiness is always around you if you put your heart into it. When you are in trouble at school, your friends will help you; when you study hard at your lessons, your parents are always taking good care of your life and your health; when you get success, your friends will say congratulations to you; when you  do something good to others, you will feel happy, too.All these are your happiness. If you notice them, you can see that happiness is always around you.\n",
      "Happiness is not the same as money.It is a feeling of your heart. When you are poor, you can also say you are very happy, because you have something else that can't be bought with money. When you meet with difficulties, you can say loudly you are very happy, because you have bad luck. As the saying goes, life is like a _ door. When it closes, it also opens.  If you take every chance you get,  you  can be a happy and lucky person.\n",
      "\n",
      "Question: Which is TRUE according to the passage?\n",
      "A. When you get success, your friends will be very proud of you.\n",
      "B. You can get help from others when you are in trouble.\n",
      "C. You can still be a happy person even if you have little money.\n",
      "D. All of the above.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Be honest. That's all you have to do on Honesty Day. It would be great if we were all honest every day of the year. It's good that there is a day to encourage honesty. M. Hirsh Goldberg started Honesty Day. He chose the last day of April because the first day is April Fool's Day, which celebrate lies. On Honesty Day, anyone may ask you any question and you should give a true and honest answer. That means that you have knowledge of Honesty Day.\n",
      "M. Hirsh Goldberg wrote a book on telling lies. He said in his book that almost all person lie about 200 times a day. In our daily life, a typical life for a man is \"I did not drink that much\" and for a woman is \"Nothing is wrong, I'm fine.\" It is found that nurses are the most honest people, while sales people and politicians are the biggest liars.\n",
      "Every Honesty Day, M. Hirsh Goldberg hands out prizes to honest people.\n",
      "\n",
      "Question: According to the passage,   _  are the most honest people.\n",
      "A. nurses\n",
      "B. sales people\n",
      "C. politicians\n",
      "D. all men\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Lucy:I like sports. I have ten tennis balls, seven basketballs, four volleyballs and five soccer balls. I play tennis with my friends every day.\n",
      "Mary:I have five baseballs, five volleyballs, two soccer balls. I like ping-pong. It's easy for me. I often play ping-pong with my classmates. I also have three ping-pong bats and some ping-pong balls.\n",
      "Alice:I don't have any balls. I  love sports, but I don't play them. I only watch them on TV.\n",
      "\n",
      "Question: Lucy and Mary have  _  volleyballs.\n",
      "A. four\n",
      "B. five\n",
      "C. eight\n",
      "D. nine\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Do you know \"World Reading Day\"? It is on April 23rd. It is the eighteenth \"World Reading Day\". As we know books are very important for us.\n",
      "In Germany, more than 70% of people like reading: They often read. They read in their homes. They read in libraries. They read in parks. They even read in hospitals. Parents often read books for kids.\n",
      "It is easy to buy books in Germany. There are many bookshops in Germany. They are in big cities and small town. A bookshop can sell many books every day. Germans also like to buy books on the Internet. More and more people buy books on the Internet.\n",
      "In Germany, people often have reading parties. They are happy at the parties.\n",
      "Do you love reading? Hope you enjoy it!\n",
      "\n",
      "Question: April 23rd is  _  .\n",
      "A. World Reading Day.\n",
      "B. China Reading Day\n",
      "C. Germany Reading Day.\n",
      "D. Germans Buy Books Day\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: British food is very different from Chinese food. For example, they eat a lot of potatoes.They like to eat them every day.They eat a lot of bread with butter for breakfast and usually for one other meal. Butter is made from milk.They do not eat much rice.For their dinner they like meat or fish with potatoes and one or two other vegetables.They cook all this together.After dinner they always have something sweet.They do not have dumplings.They drink a lot of tea.They are the biggest tea drinkers in the world.They like Chinese tea, but they usually drink strong black tea from India.\n",
      "\n",
      "Question: What do they eat when they have bread?\n",
      "A. Dessert\n",
      "B. Vegetables.\n",
      "C. Juice.\n",
      "D. Butter.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Mo, the first Nobel winner in literature born and living in China, said he had trouble with the sudden publicity, which put a lot of pressure on him.\n",
      "\"I only hope to return to my writing desk as soon as possible, and I would also like to do well in society anonymously. \" Mo said. He was bothered by a large number of requests asking him to offer help that took advantage of his fame. \" I was upset the first several days after the prize announcement, but then I realized the prize is just like a mirror that reflects various attitudes about my winning, and more, reflects the real me,\" Mo said. \"I still consider myself an ordinary citizen who writes. And presenting quality works is my duty and best way of giving back to society. I'm no superstar,\" he emphasized  several times.\n",
      "Mo believes Chinese literature has achieved much in the past thirty years, and the driving force behind that is not the prize. Writers' creations should not be driven by awards, or criticism, or readers' expectations. Mo said he misunderstood the standards of the academy's selection before he visited Stockholm  to receive the prize in December.\n",
      "\"I thought they were judging the authors' personality or political features, then I learned the sole standard of their selection is literature itself, which is also deeply based in the Swedish people's long-established practice of reading a large number of books,\" Mo said.\n",
      "During the forum, established Chinese and Australian writers discussed subjects as diverse as tradition and modernity, the local and the universe and cultural inclusiveness. And they will also read works to each other and the readers. The writers communication will further promote  Chinese writers to a global audience.\n",
      "Australian Ambassador  to China Frances Adamson agreed. \"It's a milestone  of literary exchanges between the two countries, who are longtime friends,\" Adamson said.\n",
      "\n",
      "Question: Which of the following statements is TRUE?\n",
      "A. Mo didn't hope to return to my writing desk\n",
      "B. Mo was always upset after the prize .\n",
      "C. The driving force behind writers is the prize\n",
      "D. Mo's success will promote Chinese writers.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Having friends, and finding new friendships is an important developmental task for preteens and teens. While they have learned to play well with others during their childhood, developing independent friendships is a different thing. Preteens and teens will be allowed to use their own resources to decide whether to be someone's friend or not, instead of being taught by their parents. Parents must give their teenagers some freedom in choosing who they want to hang out with.\n",
      "You can help your teens to choose their friends, although it's your teenagers who make the final decision. You can use teachable moments to talk about what makes a good friend. Here are some points to remember when you talk about friendships with your teenagers:\n",
      "1) You are allowed to have many friends;\n",
      "2) Honesty is important in a friendship;\n",
      "3) Friends sometimes hurt each other, but they can say sorry and forgive ;\n",
      "4) Friends can influence each other, sometimes they will help you but sometimes they will hurt you, too.\n",
      "5) Who you choose to be your friend is important, so choose wisely;\n",
      "6) It takes many learned skills to make and keep a friendship, and it also takes many skills to end a friendship;\n",
      "7) It is okay and even helpful to make friends with the opposite gender ;\n",
      "8) It takes time to make a good friend, but it is worth the effort;\n",
      "9) Spending time together will help you get to know your friends well and you will feel comfortable sharing feelings;\n",
      "10) A good friendship will make you feel good about yourself.\n",
      "\n",
      "Question: Which point is about how to end a friendship?\n",
      "A. Point 3.\n",
      "B. Point 4.\n",
      "C. Point 5.\n",
      "D. Point 6.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: In America, there is a traditional story called a \"tall tale\". A tall tale is a story about a person who is larger than life. The descriptions in the story are exaggerated  , which makes the story funny. People who had lived in undeveloped areas in America first told tall tales. After a hard day's work, they would get together to tell each other funny stories. One character from these stories was Paul Bunyan, a hero who cut down trees in North America. Tradition says he cleared forests from the northeastern United States to the Pacific Ocean.\n",
      "It is said that Paul Bunyan was born in the northeastern American state of Maine. His mother and father were shocked when they first saw the boy. When the boy was only a few weeks old, he weighed more than forty-five kilograms. As a child, Paul was always hungry. His parents needed ten cows to supply  milk for his meals. Before long, he ate fifty eggs and ten containers of potatoes every day. Young Paul grew so big that his parents did not know what to do with him. Once, Paul rolled over  so much in his sleep that he caused an earthquake. This angered people in the town where his parents lived. So the government told his mother and father they would have to move him somewhere else. Paul's parents had to take him into the woods where he grew up.\n",
      "\n",
      "Question: Paul's parents took him back to the woods because they  _  .\n",
      "A. wanted Paul to learn swimming\n",
      "B. was afraid that Paul would cause another earthquake\n",
      "C. was afraid that an earthquake would hurt Paul\n",
      "D. hoped that they wouldn't make Paul angry\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Mr Smith goes to the town   to see his son, Tom. Tom is studying music in a school there. He tells his father he does well and his father is very happy. That evening Mr Smith buys two tickets for a concert  . They get there early after dinner. They're sitting in the hall   and listening to them playing. The music is beautiful and Mr Smith enioys it very much. But he finds  his son doesn't like it at all. Mr Smith wants to know something about Tom. So he asks, \"Do you know the music?\" \"Yeah,\" answers Tom. \" And what's the musician playing now?\" Mr Smith asks. Tom doesn't know how to answer it. He thinks hard and then says, \"... the piano.\"\n",
      "\n",
      "Question: Which of the following is right ?\n",
      "A. Mr Smith lives in town.\n",
      "B. Tom knows much about the music.\n",
      "C. Mr Smith likes the music.\n",
      "D. Tom likes the music.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: I am Steve. I was born and grew up in South Wales. My favorite place to play was out on the hills where my imagination had plenty of space to expand  .\n",
      "My family moved out of Wales when I was thirteen. I went to a new school. One of my subjects was French. Because I had never learned any French, my teacher told me to sit in the corner and write anything I was interested in. That's the time I started writing, just for myself, and I've been writing ever since.\n",
      "I have always loved BIG IDEAS, and so I enjoy writing fantastic stories. And I also write horror   I think they are like the old fairytales   ,and can teach you important things.\n",
      "I am in my forties on the outside, twelve on the inside. I like rock music, Indian and Chinese food, and I enjoy drinking. I live in a small village with my wife Mary, ducks, cats, goats, hens and lots of rabbits. If you'd like to find out more about me and hope to buy any books, go to\n",
      "\n",
      "Question: From the passage, we can learn that the writer    _   .\n",
      "A. lives in a big city with his son\n",
      "B. likes eating Japanese and Indian food\n",
      "C. lives in the countryside with his wife\n",
      "D. introduces a nice book to us\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Picture Show\n",
      "There are 12,000 pictures on show here. You can see the whole Chinese history!\n",
      "Place: City Museum\n",
      "Price: ~30\n",
      "Time: 9:00 a.m.-5:00 p.m. Monday-Friday\n",
      "Films at the Museum\n",
      "There are two European films on Saturday afternoon at the Museum Theatre. See Broken Window at 2:30. The Workers is at 4:45. For more information, call 84987898.\n",
      "International Picnic\n",
      "Are you tired of eating the same food every day? Come to Central Park on Saturday and enjoy food from all over the world. Delicious and not expensive. Noon to 5:00 p.m.\n",
      "Do You Want to Hear \"The Zoo\"?\n",
      "\"The Zoo\", a popular rock group from Australia, Will give their first US concert  this Saturday night, at 8 at Rose Hall, City College.\n",
      "The Music Shop's Sale\n",
      "Sale on every record and tape in the shop, Pop, Rock, Jazz, Disco, Folk. Sale starts on Tuesday and ends on Thursday.\n",
      "\n",
      "Question: According to the ads , what can you do on Saturday afternoon if you have time?\n",
      "A. I can enjoy the delicious food in Central Park.\n",
      "B. I can see two films and buy some tapes.\n",
      "C. I can go to the City College to watch animals.\n",
      "D. I can see a picture show and listen to music.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Do You Want To Be A Musician?\n",
      "Do you want to be a musician? Come to our club, and you'll be very happy in the club. We have _ about the piano, the drums, the bamboo flute,the trumpet, the guitar and the violin for just $20 each.You can also learn to sing , to dance for $25 each. If you like art, you can be satisfied , too. It's just for $30 each!\n",
      "\n",
      "Question: We can't learn about  _  in the club.\n",
      "A. drums\n",
      "B. Bamboo flute\n",
      "C. guitar\n",
      "D. chess\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Do you help with chores at home? These are what some people say about it.\n",
      "Manuel, 19:   \"I only like to do the laundry. My mom does the other chores. When she isn't at home, I can cook an easy dinner myself, but please don't ask me whether I'm a good cook or not. \"\n",
      "Vivian, 38:  \"I do everything because I live by myself now. I think I can do everything because I watched and helped my mom cook our family meals all the time when I was young. At first I was told to help my mom, but later I began to like cooking. Now I can cook many kinds of dishes. \"\n",
      "Arthur, 67:  \"I do many things around the house because everyday is like Sunday for me now. I have to do something to keep busy. I help with gardening and cleaning the most. I enjoy doing these things. Cooking and laundry are my wife's chores. \"\n",
      "\n",
      "Question: Who did Vivian learn cooking from?\n",
      "A. Arthur.\n",
      "B. Her friend.\n",
      "C. Her mom.\n",
      "D. Her teacher.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
      "\n",
      "Question: Some people walk to go to work because   _  .\n",
      "A. they don't have any cars.\n",
      "B. they live near their workplaces.\n",
      "C. they live far from their workplaces.\n",
      "D. they like walking.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: We are all learning English, but how can we learn English well? A student can know a lot about English, but maybe  he can't speak English. If you want to know how to   swim, you must get into the river. And if you want to be a football player, you must play football.\n",
      "So, you see. You can learn English only by  using it. You must listen to your teacher in class. You must read your lessons every day. You must speak English to your classmates and also you must write something sometimes. Then one day, you may find your English very good.\n",
      "\n",
      "Question: If you want to be a football player, you should  _\n",
      "A. buy a good football\n",
      "B. play football\n",
      "C. watch others play football\n",
      "D. put your football away\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Dear Boris,\n",
      "Thanks for your nice letter.\n",
      "After I had spent a week with my English family, I slowly began to understand their English a little better. It's very different from what I learned at school! Students in my group are from different cities of Britain and their dialects   are different too! Some of their accents   are quite strong and they also have their own words and expressions.\n",
      "But it's not the language that's different and surprising. Before I came to England I had thought that fish and chips were eaten every day. That's quite wrong! I get rather mad now when I hear all the foolish words about typical   English food.\n",
      "I had expected to see \"London fog\". Do you remember our texts about it? We had no idea that most of this 'thick fog' disappeared many years ago when people stopped using coal in their homes. But the idea to speak about the weather was very helpful. The weather in London is really changeable.\n",
      "On the other hand habits are different. People tell me what is typically British here in London is not always typical in Wales or Scotland. Local habits and traditions are not the same as what we knew.\n",
      "But what is ordinary for all British is that they follow traditions. Probably Britain has more living signs of its past than many other countries. And people have always been proud of having ancient buildings in capitals, big cities and the countryside.\n",
      "I will tell you more about Britain in my other letters.\n",
      "Love from Britain,\n",
      "Peter\n",
      "\n",
      "Question: Which is NOT true according to the passage?\n",
      "A. What he's seen is quite different from what he'd learned\n",
      "B. British people like to follow traditions.\n",
      "C. Peter had learned about Britain before.\n",
      "D. Peter doesn't like his life in Britain.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Detective Wolf and Miss Fox\n",
      "Detective Wolf has waited in the doorway all the morning. He is going to meet Miss Fox. She bought a bag of diamonds from Africa. A few hours ago, someone told the police that a group of thieves would try to steal the diamonds, so the police asked Detective Wolf to make sure Miss Fox and her diamonds would be safe.\n",
      "Miss Fox arrived in the airport. Detective Wolf quickly helped her get into the police car and took her to the hotel. While they were talking, Detective Wolf noticed that Miss Fox was left-handed. Half and hour later, they got to the room, two policemen checked it over and made sure there wasn't anyone else in it. Miss Fox said she was tired and wanted to have a shower. She asked Detective Wolf and the policemen to keep the diamonds for her. Half an hour later, Miss Fox didn't get out. Detective Wolf felt a little strange. Just then he got a call from the airport-a woman was found in the toilet on the plane. She said she was Miss Fox and reported the criminal was left-handed. Detective Wolf rushed to the bathroom but saw nobody in it. He opened the bag immediately and found there were only stones in it.(<<>> )\n",
      "\n",
      "Question: Who was the criminal?\n",
      "A. Miss Wolf.\n",
      "B. A left-handed woman.\n",
      "C. One of the policemen.\n",
      "D. Detective Wolf.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: When you were very young, you liked to play with your friends. Did you find that playtime was always more fun when everyone shared the toys? Everyone got a turn. No one was left out.\n",
      "That's a life lesson that changes as you get older. As you grow up, you begin to understand that others have less than you do - in China and in the world. And that those of us who \"have\" things should help those who \" have less\" than we do. The idea of sharing _ \n",
      "At your age, you can \"share\" with people in need in three ways.\n",
      "1. You can give them a part of your money. Many adults do that regularly.\n",
      "2. You can share items you no longer use, such as clothing and toys. You can pass them onto others who cannot buy them.\n",
      "3. You can help people by giving your time and your energy.\n",
      "The last one is also called volunteering. Volunteering is about giving your time to take part in activities that will help others. Every year, many thousands of volunteers in the world give the most valuable gift of all. They give their time. They give their talent. They give of themselves. And they are enjoying it. Volunteering isn't just about work. It's about fun too.\n",
      ",.\n",
      "\n",
      "Question: What does volunteering mean according to the passage?\n",
      "A. Give people money.\n",
      "B. Share items one no longer uses.\n",
      "C. Help people by giving one's time and energy.\n",
      "D. People give themselves to others.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Take a class at Dulangkou School, and you'll see lots of things different from other schools, You can see the desks are not in rows and students sit in groups. They put their desks together so they're facing each other. How can they see the blackboard? There are three blackboards on the three walls of the classroom!\n",
      "The school calls the new way of learning \"Tuantuanzuo\", meaning sitting in groups. Wei Liying, a Junior 3 teacher, said it was to give students more chances to communicate.\n",
      "Each group has five or six students, according to Wei, and they play different roles .There is a team leader who takes care of the whole group. There is a \"study leader\"who makes sure that everyone finishes their homework. And there is a discipline leader who makes sure that nobody chats in class.\n",
      "Wang Lin is a team leader. The 15-year-old said that having to deal with so many things was tiring.\n",
      "\"I just looked after my own business before,\"said Wang. \"But now I have to think about my five group members.\"\n",
      "But Wang has got used to it and can see the benefits now.\n",
      "\"I used to speak too little. But being a team leader means you have to talk a lot. You could even call me an excellent speaker today.\"\n",
      "Zhang Qi, 16, was weak in English. She used to get about 70 in English tests. But in a recent test, Zhang got a grade of more than 80.\n",
      "\"I rarely  asked others when I had problems with my English tests. But now I can ask the team leader or study leader. They are really helpful.\"\n",
      "\n",
      "Question: We can see from the story that some students  _  this new way of learning.\n",
      "A. get benefits from\n",
      "B. are tired of\n",
      "C. cannot get used to\n",
      "D. hate\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Dear Mr. Lee,\n",
      "I am Jack. I want to be in a club in our school. I can't sing or dance or act in movies, but I can do many other things. I can play three _ , the guitar, the violin   and the piano. I think I can be in the music club. Maybe   I can be a famous musician. I like reading story books and I can write stories. Maybe I can be a famous writer. I like sports too, but I don't think I can be a famous and successful sportsman  . Can I join you?\n",
      "Yours,\n",
      "Jack\n",
      "\n",
      "Question: Jack thinks he can be a famous   _   or a famous writer.\n",
      "A. sportsman\n",
      "B. singer\n",
      "C. actor\n",
      "D. musician\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: The word, \"photography\", was first used in 1839. It comes from the Greek words that mean \"to write with light\". But photography could only give people _ pictures. So scientists were trying hard to find ways to make pictures that can move. They made lots of experiments, but failed again and again. It was Eadweard Muybridge who finally succeeded. He was the first photographer to try this successfully. But how did he make it? It was an interesting story.\n",
      "Back in 1872, people didn't know exactly whether all four of a horse's hooves   left the ground at the same time when it was running. A gentleman called Leland Stanford made a bet with his friend about it. Most people believed that a horse always had one hoof on the ground, or it would fall over. But Stanford didn't think so.\n",
      "At that time, it was hard to know who could win the bet, because a horse's legs move so fast that it is impossible to tell just by looking. So they needed a way to record the movement of a running horse. Then Stanford offered $25,000 to the famous photographer, Muybridge, to help find the answer. In the beginning, Muybridge failed to get clear images, but he didn't give up. He continued to improve his cameras. In 1878, after many experiments, he managed to get a sequence   of 12 photos. One of them clearly showed that all four of the horse's hooves were off the ground at the same time. And when the photos moved fast, people could see a horse running.\n",
      "Though is usually considered as the person who created the first movie in 1889, it was the work of Eadweard Muybridge and the bet that led to Edison's invention.\n",
      "\n",
      "Question: The passage mainly tells us   _  .\n",
      "A. that Thomas Edison created the first movie .\n",
      "B. that Eadweard Muybridge created the first static pictures\n",
      "C. how photography helped people know more about animals\n",
      "D. how Eadweard Muybridge got pictures of motion   successfully\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "{'predicted_text': {'exact_match': 0.41999998688697815, 'accuracy': 0.42}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.27670118808746336}, 'time_per_token': {'mean': 0.06243986744433641}, 'tokens_per_second': {'mean': 18.121601114273073}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "  1%|          | 1/100 [00:00<00:40,  2.47it/s]\n",
      "  3%|▎         | 3/100 [00:00<00:15,  6.34it/s]\n",
      "  4%|▍         | 4/100 [00:00<00:15,  6.24it/s]\n",
      "  6%|▌         | 6/100 [00:00<00:10,  8.87it/s]\n",
      "  8%|▊         | 8/100 [00:00<00:08, 10.80it/s]\n",
      " 10%|█         | 10/100 [00:01<00:07, 11.96it/s]\n",
      " 12%|█▏        | 12/100 [00:01<00:07, 12.39it/s]\n",
      " 15%|█▌        | 15/100 [00:01<00:05, 14.81it/s]\n",
      " 17%|█▋        | 17/100 [00:10<01:54,  1.38s/it]\n",
      " 20%|██        | 20/100 [00:10<01:09,  1.15it/s]\n",
      " 22%|██▏       | 22/100 [00:11<01:01,  1.26it/s]\n",
      " 24%|██▍       | 24/100 [00:12<00:45,  1.69it/s]\n",
      " 26%|██▌       | 26/100 [00:12<00:32,  2.25it/s]\n",
      " 28%|██▊       | 28/100 [00:12<00:24,  3.00it/s]\n",
      " 30%|███       | 30/100 [00:12<00:18,  3.88it/s]\n",
      " 32%|███▏      | 32/100 [00:12<00:13,  4.90it/s]\n",
      " 34%|███▍      | 34/100 [00:12<00:10,  6.12it/s]\n",
      " 36%|███▌      | 36/100 [00:12<00:08,  7.60it/s]\n",
      " 38%|███▊      | 38/100 [00:12<00:06,  9.08it/s]\n",
      " 40%|████      | 40/100 [00:13<00:05, 10.09it/s]\n",
      " 42%|████▏     | 42/100 [00:13<00:05, 11.11it/s]\n",
      " 44%|████▍     | 44/100 [00:24<01:36,  1.73s/it]\n",
      " 46%|████▌     | 46/100 [00:24<01:06,  1.23s/it]\n",
      " 48%|████▊     | 48/100 [00:24<00:45,  1.14it/s]\n",
      " 50%|█████     | 50/100 [00:24<00:31,  1.58it/s]\n",
      " 52%|█████▏    | 52/100 [00:24<00:22,  2.16it/s]\n",
      " 54%|█████▍    | 54/100 [00:25<00:15,  2.92it/s]\n",
      " 56%|█████▌    | 56/100 [00:25<00:11,  3.85it/s]\n",
      " 58%|█████▊    | 58/100 [00:25<00:08,  4.99it/s]\n",
      " 60%|██████    | 60/100 [00:25<00:06,  6.28it/s]\n",
      " 63%|██████▎   | 63/100 [00:25<00:04,  8.52it/s]\n",
      " 65%|██████▌   | 65/100 [00:25<00:03,  9.90it/s]\n",
      " 67%|██████▋   | 67/100 [00:25<00:02, 11.03it/s]\n",
      " 69%|██████▉   | 69/100 [00:25<00:02, 12.22it/s]\n",
      " 71%|███████   | 71/100 [00:26<00:02, 13.07it/s]\n",
      " 73%|███████▎  | 73/100 [00:26<00:01, 13.99it/s]\n",
      " 75%|███████▌  | 75/100 [00:26<00:01, 14.30it/s]\n",
      " 77%|███████▋  | 77/100 [00:26<00:01, 14.79it/s]\n",
      " 79%|███████▉  | 79/100 [00:26<00:01, 15.74it/s]\n",
      " 81%|████████  | 81/100 [00:26<00:01, 15.76it/s]\n",
      " 84%|████████▍ | 84/100 [00:26<00:00, 17.86it/s]\n",
      " 86%|████████▌ | 86/100 [00:26<00:00, 16.84it/s]\n",
      " 88%|████████▊ | 88/100 [00:27<00:00, 16.87it/s]\n",
      " 90%|█████████ | 90/100 [00:27<00:00, 16.54it/s]\n",
      " 92%|█████████▏| 92/100 [00:27<00:00, 17.31it/s]\n",
      " 95%|█████████▌| 95/100 [00:27<00:00, 17.86it/s]\n",
      " 97%|█████████▋| 97/100 [00:27<00:00, 17.03it/s]\n",
      " 99%|█████████▉| 99/100 [00:27<00:00, 16.85it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard benchmark for dataset: race_h\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.17138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12317\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0187225341796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: In the days when an ice cream sundae cost much less, a 10-year-old boy entered a hotel coffee shop and sat at a table. A waitress (woman assistant) put a glass of water in front of him. \"How much is an ice cream sundae?\" \"Fifty cents\", replied the waitress. The little boy pulled his hand out of his pocket and studied a number of coins in it. \"How much is a dish of _ ice cream?\" he asked. Some people were now waiting for a table and the waitress was a bit worried. \"Thirty-five cents,\" she said rudely(not politely). The little boy again counted the coins. \"I'll have the plain ice cream,\" he said. The waitress brought the ice cream, put the bill on the table and walked away. The boy finished the ice cream, paid the bill at the counter and went out. When the waitress came back, she began cleaning the table and then she couldn't believe what she had seen. There, placed nearly beside the empty dish, were two five-cent coins and five one-cent coins---her tip .\n",
      "\n",
      "Question: How much money did the boy probably have in his pocket?\n",
      "A. Just fifty cents.\n",
      "B. More than fifty cents.\n",
      "C. Not more than fifty cents.\n",
      "D. Less than forty cents.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 51492\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005710601806640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Many boys and girls love watching TV. They spend many hours watching TV every day. But many parents let their children watch TV at special time.\n",
      "TV shows are like books and movies. There are many kinds of TV shows, such as sitcoms, soap opera, sports shows, fashion shows, and so on. A kid can learn good things and bad things from them. Some shows help children know the news all over the world. Children don't have to go to the zoos or the parks to see animals. They can see on TV at home. Some shows teach children how to cook, how to paint or how to study.\n",
      "Many boys and girls think it is interesting to watch TV but it is also interesting to read books , to play games or to visit the friends.\n",
      "\n",
      "Question: Many boys and girls spend time   _   every day.\n",
      "A. watching TV\n",
      "B. playing sports\n",
      "C. playing games\n",
      "D. visiting friends\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.381591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85179\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005855560302734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Why do we come to school? Most of us may say we come to school to study. But to study needs a right way, or you either waste the time or the money. The following are the ways for studying.\n",
      "The best time for reading is morning. In the morning the air is fresh and the mind is clear. For that reason we can get good results.\n",
      "In studying we must have patience . If we have not known a text well, we must read it again. We should not read the next one until we have learned the first one well.\n",
      "When we are studying, we must put our hearts into the books, or we can get nothing from the books while we are reading.\n",
      "We must always ask \"whys\". If it is not well understood, write it down and ask our teachers or our parents, brothers or friends. In any possible way, we must know it completely and what we have learned can be used well and made better.\n",
      "Though there are many ways for studying, yet what I have said above will be enough if we can keep them in heart and do so.\n",
      "\n",
      "Question: How many ways for studying does the passage tell us?\n",
      "A. Three\n",
      "B. Four\n",
      "C. Five\n",
      "D. Six\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29826\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00012350082397460938\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68882\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018701553344726562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Music education hasn't changed much since the 1970s. Students are still taught to read notation so they can recite compositions that they would never listen to on their MP3 players or play with friends. Playing music enriches life. The question is: Why do schools teach music in a way that _ so many young people rather than catch their imagination? Can we do a better job of using the power of music to get kids excited about school?\n",
      "The experience of an organization called Little Kids Rock suggests the answer is yes -- if we change the way music is taught. Little Kids Rock has helped music programs in over a thousand public schools and served 150,000 children. The organization has given 30,000 free instruments out, mainly guitars, and trained 1,500 teachers to run music classes in which students quickly experience the joys of playing their favorite songs, performing in bands , and writing their own music.\n",
      "The key to Little Kids Rock is that it teaches children to play music the way many musicians learn to play it -- not by notation, but by listening, imitation and meaningful experimentation. \"The knowledge you need to get started playing rock music is very limited,\" explains Dave Wish, the founder of Little Kids Rock. \"In high school, my friend Paul taught me a couple of chords and my life was changed forever. On the first day of class, Little Kids Rock teachers place guitars in the hands of their students and get them practicing chords that will enable them to play thousands of songs. The kids decide what songs they want to learn and the class is off and running. Their progress is surprising. Within a year, eight and nine-year-olds are playing musical instruments, and giving concerts, even performing their own songs.\n",
      "One of the biggest advantages that music offers is the ability to encourage students who are otherwise bored by school. \"I've had students start coming back to school because of this program,\" said Adkison Thomas, who heads up music for the Dallas Independent School District. He added, \"One of the best things is that the teachers discover a new side of their students. They see kids become successful who weren't before.\"\n",
      "\n",
      "Question: Little Kids Rock is successful because   _  .\n",
      "A. it encourages kids to experience music\n",
      "B. it helps kids learn from great musicians\n",
      "C. it allows kids to decide how to learn music\n",
      "D. it offers musical programs all over the country\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74032\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002735137939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22868\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0010967254638671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: We are all learning English, but how can we learn English well? A student can know a lot about English, but maybe  he can't speak English. If you want to know how to   swim, you must get into the river. And if you want to be a football player, you must play football.\n",
      "So, you see. You can learn English only by  using it. You must listen to your teacher in class. You must read your lessons every day. You must speak English to your classmates and also you must write something sometimes. Then one day, you may find your English very good.\n",
      "\n",
      "Question: The story of learning swimming and playing football tells us  _\n",
      "A. we learn English by using it\n",
      "B. swimming needs water\n",
      "C. playing football is easy\n",
      "D. learning English is difficult\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19715\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005588531494140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 119714\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05242919921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
      "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
      "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
      "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
      "\n",
      "Question: The best title for the passage is \"  _  \".\n",
      "A. Drugs are dangerous\n",
      "B. A famous Taiwan actor\n",
      "C. Apologizing for taking drugs\n",
      "D. At the press conference\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.384765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 108698\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006927490234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Why do we come to school? Most of us may say we come to school to study. But to study needs a right way, or you either waste the time or the money. The following are the ways for studying.\n",
      "The best time for reading is morning. In the morning the air is fresh and the mind is clear. For that reason we can get good results.\n",
      "In studying we must have patience . If we have not known a text well, we must read it again. We should not read the next one until we have learned the first one well.\n",
      "When we are studying, we must put our hearts into the books, or we can get nothing from the books while we are reading.\n",
      "We must always ask \"whys\". If it is not well understood, write it down and ask our teachers or our parents, brothers or friends. In any possible way, we must know it completely and what we have learned can be used well and made better.\n",
      "Though there are many ways for studying, yet what I have said above will be enough if we can keep them in heart and do so.\n",
      "\n",
      "Question: In writing this passage, the writer wants to tell us to   _  .\n",
      "A. save our time and money\n",
      "B. know the importance of reading\n",
      "C. have more patience in reading\n",
      "D. learn about the ways for reading\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17592\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.396936416625977e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: On my first holiday in America, I went to a large supermarket to buy breakfast. And although this was an English-speaking country that I knew well through films and TV, I was amazed. Everything came in unfamiliar   packaging  ,with things I'd never heard of, Even things as simple as corn chips were strange, in different colours including black and purple.\n",
      "Tilse, who works for Nutrition Australia, first realized there was a problem six years ago. After teachers at her children's school quietly shared their opinions about the diets, she knew something about it. \"They cared for what many children were  bringing to school for lunch,\" she said. \"Mostly packaged foods, such as chips are not healthy.\"\n",
      "Tilse said, \"They've managed to escape war areas and get to Australia, only to face the very real risk of running into heart disease. All because they're making wrong choices about food.\"\n",
      "\"Before I came to Australia, I'd never seen a sandwich,\" said Joseline Ntunzusenimanima, a 33-year-old mother of seven from Burundi in East Africa. \"There were so many fruits I had either never seen or not been able to buy for many years. I was in shock for the first four days after I arrived. I didn't know what to do or where to go because I was just amazed to see plenty of food, peace and safety.\"\n",
      "\n",
      "Question: What is the best title for the passage?\n",
      "A. Wrong choice about food.\n",
      "B. Have a big breakfast.\n",
      "C. How to choose food.\n",
      "D. What to bring to school.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.051483154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4091796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: A young man woke up one morning under a bridge and checked his pocket. All he had left was less than ten dollars. He bought food and as he sat down to eat, an old man and two children came along. The old man asked him to help them with food as they had not eaten for almost a week.\n",
      "The young man looked at the children---they were so weak that they could hardly stand. With the last bit of kindness he had he gave them all the food. The old man and children thanked the young man and then gave him a dirty old coin. The young man said, \"You need this coin more than I do--- just keep it.\" The old man insisted  that the young man put it in his pocket---and finally he did.\n",
      "The old man and children sat down to eat. And with no money, no job and no food, the young man went back under the bridge to lie down. As he was about to fall asleep he saw an old newspaper on the ground. He picked it up and saw an ad inviting people with old coins to come to a store. He decided to go there with the dirty old coin the man gave him.\n",
      "When he arrived at the store, he gave the keeper the dirty old coin. The keeper cried loudly. It was part of a Spanish treasure ship that had never been found. This same old coin was worth 67,000 dollars. The young man was pleased. He immediately sold the coin for money and then looked for the old man and little children to thank them and share the money. By the time he got to where he left them eating, they had gone.\n",
      "\n",
      "Question: How did the young man learn about the ad for old coins?\n",
      "A. By watching TV.\n",
      "B. By reading a newspaper.\n",
      "C. By listening to the old man.\n",
      "D. By reading an ad on the wall.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11696\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001705169677734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47830\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.058990478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: In today's world many people seem to be hungry for money. Some of them even have lost their lives for it. Money does have a great effect on the poor, but if a person has a rich life, a lot more money doesn't mean more happiness.\n",
      "If money were everything, all millionaires would have true love, real friendship, health and a long life. However, this is not always true.\n",
      "Nothing else is more pleasant than the three words \"I love you\", but can love be bought? I'm afraid not. Love means \"give\", not \" take\". Health and a long life are precious things for every person. Well, can health and a long life be bought with money? The answer is \"No\". Of all the people who live longest in the world, few of them are millionaires. Real friendship can't be bought, either.\n",
      "In a word, where money is _ , money can cause brothers to quarrel, lovers to hate, strangers to fight and so on. No matter how much money you have, _ is still not enough to make you a happy person if you have no one to laugh with and no one to cry for.\n",
      ",\n",
      "\n",
      "Question: What does the passage mainly tell us?\n",
      "A. Money is as important as true love.\n",
      "B. Money isn't necessary.\n",
      "C. Money is important, but not the most important.\n",
      "D. Money can cause some problems.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11427\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008759498596191406\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27337\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 8.505582809448242e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: While Nick was on the bus reading his newspaper, the man sitting next to him suddenly pushed a large envelope into his hands. \"Here, take this!\" the man said, stood up and got off the bus before Nick could say a word.\n",
      "Nick sat there, holding the envelope. It felt heavy.  There was paper inside, or money perhaps. \"I'd better hand it over to the police,\" he thought. There was a police station close to his office. But, as he got off the bus, a man came to him. He seemed to be waiting for something.   \"He wants the envelope,\" Nick thought. Nick began to walk quickly, and the man hurried after him. Nick managed to lose the man in the crowd .When he entered the police station, the man was no longer in sight.\n",
      "Inside the police station, Nick handed over the envelope to the policeman who was on duty.  The man opened it. The envelope was full of money, false money.\"Clearly the man made a mistake,\" the policeman said. \"He thought you were one of the gang !\"\n",
      "\"However,\" the policeman went on. \"I'm afraid I must ask you to keep quiet about all this.  We are trying to catch some very clever thieves, and we don't want them to know that we have some of the money. So you mustn't say a word to anyone-not even to your boss!\"\n",
      "\n",
      "Question: The man who suddenly gave Nick an envelope was most probably  _  .\n",
      "A. Nick's friend\n",
      "B. the bus driver\n",
      "C. a thief\n",
      "D. a postman\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2357\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.292236328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43044\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.008270263671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Colourful fruit and vegetables are good for our health. Their natural colours help protect our bodies from disease(,). Think about the colours of fruit and vegetables: the red of tomatoes, the orange of carrots, the green of kiwi and the purple of grapes.\n",
      "You can enjoy eating fruit and vegetables of all colours---green, yellow, blue, purple, and white. Each colour is important to our health. These colours work together to protect our bodies. Scientists have studied them and discovered the good of colourful fruit and vegetables. The list below shows the good of some colours in fruit and vegetables:\n",
      "Red gives us a healthy heart. It can reduce(,) heart disease. Red helps improve our memory .\n",
      "Yellow is good for our eyes.\n",
      "White can reduce cholesterol   .\n",
      "Green is good for our eyes, too. It also gives us strong bones and teeth.\n",
      "Blue helps us keep a good memory as we grow old. It also help fight heart disease. So when you are buying or eating fruit and vegetables, remember to try different colours of fruit and vegetables.\n",
      "\n",
      "Question: If you want to keep your body strong, which colours are good for you\n",
      "A. Red and green.\n",
      "B. Yellow and blue.\n",
      "C. White and orange.\n",
      "D. All the above.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2203\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0022335052490234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.814453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Children in England mustn't work until they are 13. They need to have a work permit   to start working.\n",
      "The jobs teenagers can do\n",
      "Delivering   newspapers\n",
      "Many teenagers will get up early to deliver newspapers to houses in their local area before going to school. They are known as Paper-boys or Papergirls.\n",
      "Babysitting: Looking after young children in their home while their parents have gone out for the evening is a popular job for teenagers, as they get money for watching children and television all at the same time!\n",
      "Helping the Milkman: From the age of 14 some teenagers help the milkman deliver milk to houses.\n",
      "Other popular jobs : Working in a shop; Office work; Washing cars ; In a cafe or restaurant. The hours teenagers (13 and 14 year olds )can work:\n",
      "School Days\n",
      "Not more than 2 hours in one day during the following periods:\n",
      "Morning 7 a. m. --start of school or Evening\n",
      "close of school-- 7 p. m.\n",
      "Saturdays: Up to 5 hours between 7 a.m. and 7 p.m.\n",
      "Sundays\n",
      "Up to 2 hours between 7 a.m. and 11 a. m.\n",
      "Term time\n",
      "Up to 12 hours a week (Including weekends)\n",
      "\n",
      "Question: Paper-boys and Papergirls deliver newspapers    _\n",
      "A. early in the morning\n",
      "B. at noon\n",
      "C. in the afternoon\n",
      "D. in the evening\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79678\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0203704833984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45999\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.043426513671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: In many countries, holidays are important parts in people's life. Let's show some countries to you.\n",
      "America\n",
      "American people's holidays are flexible ( ). They can use up their holidays once, and they can also use them up a few times. During the holidays, they still get money.\n",
      "Canada\n",
      "Many people in Canada can rest three days a week. They have all kinds of activities   for holidays. They may go fishing, boating or mountain climbing. Also, they have long holidays. They may go to the beach to spend a sunny winter holiday. Like American people, Canadians also get money during the holidays.\n",
      "France\n",
      "People in France are very good at enjoying life. They have a 6-week holiday every year, and they work less than 40 hours a week.\n",
      "\n",
      "Question: In which country can people work less than 40 hours a week?\n",
      "A. America.\n",
      "B. Canada.\n",
      "C. France.\n",
      "D. China.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5205078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96265\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00022351741790771484\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: When you look at the sky at night, the moon looks bigger than the stars. Actually, the moon is much smaller than the stars and the sun. It's much smaller than the earth. But the moon is much closer to us than any star. That is why it looks so big. If you hold a coin close to your eye, it looks big. If you look at it across the moon, it looks small.\n",
      "The moon moves around the earth. It makes one trip in about four weeks. The moon looks flat to us. But it is a round ball, like the earth.\n",
      "People once thought the moon had fire on it. They thought the fire made it bright. Now we know the moon is like a mirror. It gets its light from the sun.\n",
      "Our sunlight comes from the sun, too. What is the sun? The sun is a star. The stars we can see have their own light. There are many big stars we cannot see. Their light had burned out. Others are still bright, but they are so far away that we cannot see them. The sun looks bigger and much brighter than other stars because it is the nearest of all stars. The sun and the other stars we see are very hot, but the air around us saves us from the heat of the sun.\n",
      "The sun gives us light and warmth. It makes plants grow and turns leaves green. It makes life possible on our earth. It is a life giving star.\n",
      "\n",
      "Question: The passage tells us   _  .\n",
      "A. the sun is not the biggest star\n",
      "B. the sun is bigger than any other star\n",
      "C. only the sun can shine\n",
      "D. the sun is one of the farthest stars to us\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79678\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009822845458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06695556640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Have you heard of EXO? EXO is a Chinese-South Korean boy band with 12 people. They are in two teams: EXO-M and EXO-K. There's even a \"competition\" between the two teams. \"I will not call it a competition. It's always in good fun,\" said Sehun of EXO-K.\n",
      "Here comes the new superstar! His name is Austin Mahone. The 18-year-old is a pop singer in the US. His success story is just like that of Justin Bieber. Last month Mahone's new album The Secret came out. Maybe it's a good chance for us to know more about him and his music.\n",
      "Forget about Super Junior. We now have TFBOYS. TFBOYS is a popular Chinese boy band made up of three members. They are Wang Junkai, 14, Wang Yuan, 13, and Yi Yangqianxi, 13. The boys are all junior middle school students. Their songs are full of positive energy  . In their latest album, they call on teenagers not to be afraid of dreaming big.\n",
      "\n",
      "Question: Members of EXO come from   _  .\n",
      "A. the UK and the US\n",
      "B. China and South Korea\n",
      "C. China and America\n",
      "D. South Korea and Japan\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 977\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009317398071289062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002613067626953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Tony is a boy. He is 16 years old. He studies in a middle school. He often watches TV and likes the popular hair style . His parents and teachers tell him not to do so, but he doesn't listen to them.\n",
      "One Sunday afternoon his mother buys a beautiful shirt for him and he loves it very much. The next morning, it is cold, but he still puts it on. That evening he has a bad cold. His parents take him to hospital.\n",
      "About thirty minutes later, a nurse brings him to a women's ward .\"Don't you know I am a boy\"? says Tony.\"Oh, I'm sorry. I don't know you are a boy, because your hair is too long\".\n",
      "\n",
      "Question: Why do Tony's parents take him to hospital?\n",
      "A. Because he doesn't listen to them.\n",
      "B. Because he has a bad cold.\n",
      "C. Because he likes watching TV.\n",
      "D. Because he likes the popular hair style.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.92822265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.034393310546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
      "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
      "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
      "\n",
      "Question: What can we learn from the story?\n",
      "A. Appearance is the most important in our life.\n",
      "B. A friend in need is a friend indeed.\n",
      "C. Don t tell a person by his appearance.\n",
      "D. Many hands make light work.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1543\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00397491455078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89606\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.031158447265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear Dr Jackson,\n",
      "My parents are never happy with me. They are always criticizing my clothes, my hair and the music I listen to. They hate my friends' looks and they keep complaining when I go with them. I'm not allowed to stay out as late as my friends do, so I can't have any fun. My parents only seem to care about my school grades. Although I love them, sometimes I feel we live in different worlds. If they love me, can't they understand me? How can I make them understand me?\n",
      "Angel\n",
      "Dear Angel,\n",
      "Your problem is common to both teenagers and parents. Don't worry, because all this is natural. You see, your parents have grown up at a different time and they have different experiences. So, they think some things are strange, but you find the same things are all right. For example, the music you like may sound like noise to them. Your parents love you, so they feel they must stop you from doing whatever they find strange. On the other hand, you don't want to be different from other teenagers, so you feel that your parents\n",
      "you.\n",
      "I think you should talk about this problem with your parents. Try to explain to them what you want and make them know they can believe you. And then they'll find you are a responsible person and they will give you more freedom.\n",
      "Jackson\n",
      "\n",
      "Question: Why has Angel written to Dr Jackson?\n",
      "A. Because her parents make her happy.\n",
      "B. Because her parents can't understand her.\n",
      "C. Because her friends don't like her.\n",
      "D. Because she is not good enough at school.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 18821\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003192901611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81702\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.12408447265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
      "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
      "\n",
      "Question: What's Wendy's favourite sport?\n",
      "A. Running.\n",
      "B. Basketball.\n",
      "C. Football.\n",
      "D. Table tennis.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98055\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006580352783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8777\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001049041748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77735\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0206298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40590\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23956\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06842041015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59041\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003647804260253906\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011072158813476562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003440380096435547\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 115668\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018835067749023438\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 115097\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.57958984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103978\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9541015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14373\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.85888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14373\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.65234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95143\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.490478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 109383\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05828857421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2247314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62063\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00031304359436035156\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103978\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15556\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002033233642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103978\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09564208984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34423\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.324951171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76027\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.279541015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35525\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09814453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64883\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007717132568359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19491\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05706787109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 84137\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0182342529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23581\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.21142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3981\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0038547515869140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26116\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0157318115234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 51246\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0462646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59693\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006732940673828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 105139\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0015239715576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103978\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.042999267578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32420\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8974609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1231\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.234130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21733\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.463623046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23346\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10467529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127843\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005504608154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59768\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0251007080078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 119014\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01483154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70030\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01507568359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26894\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.29296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56644\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01059722900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 65833\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.178466796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39627\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.050994873046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 125962\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014514923095703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63726\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005612373352050781\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111760\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0049285888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007305145263671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10010\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 8.958578109741211e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 112466\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002980232238769531\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 33554\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.159912109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57116\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0104827880859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40222\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003749847412109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 113547\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01422119140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21811\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23581\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014009475708007812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68369\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004638671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 41711\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.050018310546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48447\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0015621185302734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85996\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1185302734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52893\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.048095703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1538\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00662994384765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30977\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1517333984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 78548\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.54248046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89829\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.025970458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42183\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006084442138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96304\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0465087890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95221\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.65380859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96331\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3837890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13284\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00894927978515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 93186\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10302734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 37180\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.025115966796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 119531\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 4.875659942626953e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006076812744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 122864\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.038970947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 113136\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005313873291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52960\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002994537353515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38627\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.052337646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 97684\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003551483154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103099\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002330780029296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46590\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.045501708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64567\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77834\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.72314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102201\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6103515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009012222290039062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5775\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.032379150390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Animals do many different, amazing things to get through the winter. Some of them _ . They travel to other places where the weather is warmer or where they can find food.\n",
      "Many birds migrate in autumn. Because the trip can be dangerous, some travel in large groups. For example, geese  fly in noisy, \"V\"-shaped groups. Other kinds of birds fly alone.\n",
      "Some animals stay active in winter. They must change themselves as the weather changes. Many change their doing or their bodies. For example, snowshoe rabbits grow white fur to help them hide in the snow.\n",
      "Food is hard to find in winter. Some animals, like mice, collect lots of food in autumn and store it to eat later. Some animals eat different kinds of food as the seasons change.\n",
      "Some animals hibernate for part or all of the winter. This is a special, very deep sleep. The animal's body temperature drops, and its heartbeat and breathing slow down. It uses very little energy. In autumn, these animals get ready for winter by eating much more food than in summer and storing it as body fat. They use this fat to keep them alive while hibernating.\n",
      "Water makes good protection for many animals. When the weather gets cold, they move to the bottom of lakes and rivers. There, frogs and many fish hide under rocks or fallen leaves. Cold water holds more oxygen than warm water, and frogs can breathe through their skin.\n",
      "Every type of insect has its own life cycle and that is the way it grows and changes. Different insects spend the winter in different forms of their lives. Some insects also spend the winter without moving. Some insects spend the winter as pupae . Other insects die after laying eggs in autumn. The eggs change into new insects in spring and everything begins all over again.\n",
      "\n",
      "Question: Why do many birds fly in large groups?\n",
      "A. They can easily find food this way.\n",
      "B. They will use little energy.\n",
      "C. They can get warm at night.\n",
      "D. There may be danger during the trip.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "\n",
      "Question: What happens to animals that live in the cold?\n",
      "A. They move to warmer places.\n",
      "B. They eat more food.\n",
      "C. They store it for winter.\n",
      "D. They sleep very deep.\n",
      "Answer: C\n",
      "\n",
      "Question: Why do some animals sleep very deep?\n",
      "A. They need to conserve energy.\n",
      "B. They are cold.\n",
      "C. They are tired.\n",
      "D. They are hungry.\n",
      "Answer: C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0399169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102090\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004444122314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Happiness is for everyone. You don't need to care about those who have beautiful houses with large  gardens and swimming pools or those who have nice cars and lots of money and so on. Why? .Because  those who have big house may often feel lonely and those who have cars may want to walk on the country roads at their free time.\n",
      "In fact, happiness is always around you if you put your heart into it. When you are in trouble at school, your friends will help you; when you study hard at your lessons, your parents are always taking good care of your life and your health; when you get success, your friends will say congratulations to you; when you  do something good to others, you will feel happy, too.All these are your happiness. If you notice them, you can see that happiness is always around you.\n",
      "Happiness is not the same as money.It is a feeling of your heart. When you are poor, you can also say you are very happy, because you have something else that can't be bought with money. When you meet with difficulties, you can say loudly you are very happy, because you have bad luck. As the saying goes, life is like a _ door. When it closes, it also opens.  If you take every chance you get,  you  can be a happy and lucky person.\n",
      "\n",
      "Question: We say \"Happiness is not the same as money.\" because  _   .\n",
      "A. money always brings happiness\n",
      "B. money doesn't always bring happiness\n",
      "C. everything can be bought with money\n",
      "D. only rich always bring happiness\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38627\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0240325927734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear readers,\n",
      "Imagine a little girl who knows there will not be enough food for dinner, who can't fill her stomach with water because it's polluted  , and who has watched lives slipped away   from her father, little brother and sister because the family is too poor to see a doctor. She would gladly walk miles to school, but her mother needs her badly   at home. What will her future be?\n",
      "Is it hard to believe? For Maria Pestora, it is real life.\n",
      "But with just 52 pennies a day, you can sponsor   a child like Maria. Through\"Save the Children\",you can help Maria's mother get the tools and ways she needs to turn their poor food into a good dinner, and get the money she needs to buy clothes and school things for Maria.\n",
      "To help Maria most, your money is put together with that of other sponsors. Building schools, hospitals, bringing in clean water is what\"Save the Children\"has been working on since 1932.\n",
      "For you there are many rewards. You have the chance to write to or hear from the child you sponsored, to receive photos or progress reports, to know you are reaching out to another person, not with a handout  , but a hand up. That's how \"Save the Children\" works. But without you, it can't work. Please take a moment now to fill in and post the form below to help a child like Maria.\n",
      "It can make a difference in his/her life and yours.\n",
      "For the children\n",
      "David Li Guyer\n",
      ",.\n",
      "\n",
      "Question: What's Maria's most serious problem?\n",
      "A. She has no chance to go to school.\n",
      "B. Her father died of a serious disease.\n",
      "C. Hard work has made her suffer a lot.\n",
      "D. Her mother needs her badly at home.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.64697265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 37689\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0025424957275390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: One thing that British and Chinese cultures share is a love for fine tea. Today, when we think of western tea culture, we often think of the English and beautiful china cups.\n",
      "Afternoon tea\n",
      "People believe that an English lady, Anna, first introduced the idea of afternoon tea. In the 18thand 19thcenturies, the English are only two main meals each day ----breakfast and a heavy dinner that would last several hours in the evening. As a result, people often got very hungry during the long wait between these two meals. To solve this problem, Anna came up with the clever idea of inviting some friends to join her for an afternoon meal between four and five o`clock. This meal included cakes and sandwiches, and tea was served to wash down the food. In order to make this afternoon meal important,  fine china cups and plates, and silver teapots, forks and spoons were used. Soon, afternoon tea parties became popular social occasions. Today, afternoon tea parties continue to play an important part in the social life in the modern Britain.\n",
      "Will you come for coffee?\n",
      "Coffee also has an important role in British culture. People often use the words \"Will you come for coffee?\" to mean \"Would you like to come to my home for a chat?\"Normally, several different drinks such as tea, hot chocolate or a soft drink like orange juice will be served as well as coffee, and you will be asked what you would like. However, you will not normally be offered wine at a \"coffee\" party.\n",
      "Coffeehouses and the London Stock Exchange \n",
      "In the 17thcentury London, coffeehouses were busy and noisy places. Businessmen and bankers went to coffeehouses to do their business, as well as to drink coffee. In fact, the London Stock Exchange is believed to have started from these coffeehouses.\n",
      ",,.\n",
      "\n",
      "Question: Which is the best title of the article?\n",
      "A. British and Chinese Cultures\n",
      "B. English Tea and Coffee Culture\n",
      "C. Coffeehouses and Business\n",
      "D. Chinese Tea and Coffee\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11696\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002490997314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60519\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007076263427734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: It was the golden season. I could see the yellow leaves dancing in the cool wind. I felt lonely and life is uninteresting. But one day, the sound of a violin came into my ears. I was so surprised that I ran out to see where it was from. A young girl, standing in the wind, was lost in playing her violin.\n",
      "I had never seen her before. The music was so wonderful that I forgot who I was.\n",
      "Leaves were still falling. Every day she played the violin in the same place and I was the only listener. It seemed that I no longer felt lonely and life became interesting. We didn't know each other, but I thought we were already good friends.\n",
      "One day, when I was listening, the sound suddenly stopped. The girl came over to me.\n",
      "\"You must like violin.\" she said.\n",
      "\"Yes. And you play very well. Why did you stop?\" I asked.\n",
      "Suddenly, a sad expression appeared on her face and I could feel something unusual.\n",
      "\"I came here to see my grandmother, but now I must leave. I once played very badly. It is your listening every day that has _ me.\" she said.\n",
      "\"In fact, it is your music that has given me those meaningful days.\" I answered. \"Let us be friends.\"\n",
      "The girl smiled and I smiled.\n",
      "I never heard her play again in my life. Only thick leaves were left behind. But I will always remember the girl. She is like a dream; so short, so bright that it makes life beautiful.\n",
      "There are many kinds of friends. Some are always with you, but don't understand you. Some say only a few words to you, but are close to you. I shall always think of those golden days and the girl with the violin. She will always bring back the friendship between us. I know she will always be my best friend.\n",
      "\n",
      "Question: The writer's life was   _   because of the girl.\n",
      "A. boring\n",
      "B. colourful\n",
      "C. unhappy\n",
      "D. sad\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49222\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004456043243408203\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34486\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.065185546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Hello! My name is Kitty. I want to talk about my home town today.\n",
      "My home town is small but pretty. It's about two hours away from London by train. In the centre of the town there is a small lake. There are lots of trees and flowers around the lake. My parents often walk around the lake at the weekend. The air in my home town is very fresh   and clean.\n",
      "There are two schools in my home town, one primary school and one secondary school. I study in the secondary school and my younger sister studies in the primary school. I often ride my bike to school.\n",
      "I usually go to the youth centre to learn drawing with my sister on Friday afternoons. I like going shopping at the weekend. There are two big shopping malls there.[:Zxxk.Com]\n",
      "\n",
      "Question: The air in Kitty's home town is very  _  .\n",
      "A. high\n",
      "B. dirty\n",
      "C. polluted\n",
      "D. fresh and clean\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49715\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00481414794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 37689\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.017059326171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
      "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
      "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
      "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
      "\n",
      "Question: The old lady smiled because   _  .\n",
      "A. she met the boy before\n",
      "B. she wanted to get some drinks\n",
      "C. she saw her grandson\n",
      "D. she liked the little boy\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14504\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001443624496459961\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10888\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1256103515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Today is July 21. Most people are enjoying their weekend now. John is watching a magic show at the Capital Stadium with his parents and a friend from Australia.\n",
      "The girl is Megan, she is staying at John's for her holiday now. Her parents and brother Andy are now visiting the zoo. Their father is taking photos of many animals, like elephants, pandas, zebras and tigers. But Andy likes monkeys most and he is now watching them jumping and playing.\n",
      "Andy's cousin Julia is at her friend's birthday party. There she meets Lily, Daming, Joy and Lingling. They are having a happy talk and drinking some juice. Julia's grandparents are having a Taijiquan class, while her mother is shopping for presents. Julia's family is going back home to the Unite States next Thursday, so her father is booking plane ticket on the Internet.\n",
      "\n",
      "Question: ---Where's Megan's father?  ---He is   _  .\n",
      "A. at John's with Lily\n",
      "B. at a party\n",
      "C. at the Capital Stadium with his daughter\n",
      "D. in the zoo\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5987\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0254974365234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09063720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: John lives on a farm. The farm is not very big. His parents grow rice and corn. They don't use animals to do farm work any more. Today they use a tractor . It works faster and better. After he does his work in the fields, he likes to sit and look at the blue sky and the green hills. He thinks the country is more beautiful than the city. In the city, he can't hear the animals. In the country, he can hear birds singing. He likes to play with his dog, Cody. Cody is a very interesting dog. He likes to follow people. When they stop, he stops.\n",
      "When they walk, he walks. John thinks Cody is the best dog of all.\n",
      "\n",
      "Question: What does John do after his work?\n",
      "A. He sit down and looks at the blue sky and the green hills.\n",
      "B. He goes shopping in the tractor in town.\n",
      "C. He helps his parents with some more farm work.\n",
      "D. He walks his dog in the fields.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3653\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.009063720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01181793212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Emily Urich 18 years old Canada\n",
      "A lot of teens aren't responsible ,and that's where I'm different. Not just about school but everyday things like being able to pay my own credit card bills on time.\n",
      "The first time I got a cartoon book was on my third birthday. From then on , I fell in deep love with it. And can you guess how many cartoon books I've read? I don't really know the exact number. But I have three full boxes of them under my bed. I also like drawing cartoons and wish to be an art teacher in a sch001.\n",
      "Joe Miller 16 year's old America\n",
      "I'm proud of doing things my own way. So whether somebody wants me to do something or whatever it is , I feel like they're all other people's thoughts , not really mine. But like others , I love reading , too. When I first took skiing lessons , I found it exciting. For ski racing,there's no question I'm better shape than most guys . I think it's fun. I mean,it is a challenge . It's where I picked up the idea of needing a challenge always in my life. In order to improve my skiing skills,I have read many books and magazines about it. No doubt it's my dream to win gold medals in the Olympic Games.\n",
      "An Oi 15 years old China\n",
      "I'm different because I prefer to drop out of the world to create my own world. I'd like to build a house on a mountain. And I choose to live without electricity, a telephone,or even indoor plumbing . I have many hobbies such as traveling,reading , writing and spending time with children. I love children because they are smart and creative. They always have many strange ideas. It makes me excited. I want to do something for Hope Project and become a country school teacher .\n",
      "\n",
      "Question: We know that Joe Miller    _    .\n",
      "A. doesn't like to follow others\n",
      "B. thinks skiing is too dangerous\n",
      "C. does well in drawing cartoons\n",
      "D. Enjoys living somewhere quiet\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63726\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004085540771484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 78798\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016222000122070312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: In China, there're many different kinds of food. Some of them are very popular. The real Chinese food is dumplings. Now let's talk about them, OK?\n",
      "Everyone in China likes dumplings very much, and there are many different kinds of dumplings. Some have meat and vegetables in them, others have sugar, eggs and so on. I like dumplings with vegetables and pork better than any other kind.\n",
      "Usually people make dumplings at home. If you have no time to make them, you can buy them from any supermarket. Then you take them home and eat them with _ .\n",
      "The Spring Festival is very important in China. When it comes, we make dumplings, usually we put a coin  in a dumpling. If one eats the dumpling with the coin in it, he or she will be lucky in the year.\n",
      "In the old days, people couldn't often eat dumplings, because they were very poor. Now our country is becoming stronger and stronger, and our people are richer and richer. We can eat them very often.\n",
      "Now tell me, do you like dumplings?\n",
      "Welcome to China, and we'll invite you to eat the real Chinese food --dumplings.\n",
      "\n",
      "Question: You can buy dumplings from the supermarket when  _  .\n",
      "A. you have time\n",
      "B. you are tired\n",
      "C. you are busy\n",
      "D. you are happy\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1259765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.064697265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Detective Wolf and Miss Fox\n",
      "Detective Wolf has waited in the doorway all the morning. He is going to meet Miss Fox. She bought a bag of diamonds from Africa. A few hours ago, someone told the police that a group of thieves would try to steal the diamonds, so the police asked Detective Wolf to make sure Miss Fox and her diamonds would be safe.\n",
      "Miss Fox arrived in the airport. Detective Wolf quickly helped her get into the police car and took her to the hotel. While they were talking, Detective Wolf noticed that Miss Fox was left-handed. Half and hour later, they got to the room, two policemen checked it over and made sure there wasn't anyone else in it. Miss Fox said she was tired and wanted to have a shower. She asked Detective Wolf and the policemen to keep the diamonds for her. Half an hour later, Miss Fox didn't get out. Detective Wolf felt a little strange. Just then he got a call from the airport-a woman was found in the toilet on the plane. She said she was Miss Fox and reported the criminal was left-handed. Detective Wolf rushed to the bathroom but saw nobody in it. He opened the bag immediately and found there were only stones in it.(<<>> )\n",
      "\n",
      "Question: Where were the diamonds in the end?\n",
      "A. They were in the bag.\n",
      "B. They were on the plane.\n",
      "C. They were in the bathroom.\n",
      "D. They were taken away by the criminal.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47428\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00029468536376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002880096435546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear John, Thank you very much for your letter. I am glad that you enjoyed your holiday with me. We enjoyed having you and your sister here. We hope that you will both be able to come again next year. Perhaps you'll be able to stay longer next time you come. A week is not really long enough, is it? If your school has a five-week holiday next year, perhaps  you'll be able to stay with us for two or three weeks.\n",
      "We have been back at school three weeks now. It feels like three months! I expect  that you are both working very hard now that you are in Grade One. I shall have to work hard next year when I am in Grade One. Tom and Ann won't be in Grade One until 2011.\n",
      "They went for a picnic yesterday but I didn't go with them because I cut my foot and I couldn't walk very well. They went to an island and enjoyed themselves. Do you still remember the island? That's where all five of us spent the last day of our holiday.\n",
      "Tom, Ann and I send our best wishes to Betty and you. We hope to see you soon.\n",
      "Yours sincerely,\n",
      "Michael\n",
      "\n",
      "Question: Their holiday lasted for  _  .\n",
      "A. one week\n",
      "B. two weeks\n",
      "C. three weeks\n",
      "D. five weeks\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111198\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00206756591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.857421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: When you were very young, you liked to play with your friends. Did you find that playtime was always more fun when everyone shared the toys? Everyone got a turn. No one was left out.\n",
      "That's a life lesson that changes as you get older. As you grow up, you begin to understand that others have less than you do - in China and in the world. And that those of us who \"have\" things should help those who \" have less\" than we do. The idea of sharing _ \n",
      "At your age, you can \"share\" with people in need in three ways.\n",
      "1. You can give them a part of your money. Many adults do that regularly.\n",
      "2. You can share items you no longer use, such as clothing and toys. You can pass them onto others who cannot buy them.\n",
      "3. You can help people by giving your time and your energy.\n",
      "The last one is also called volunteering. Volunteering is about giving your time to take part in activities that will help others. Every year, many thousands of volunteers in the world give the most valuable gift of all. They give their time. They give their talent. They give of themselves. And they are enjoying it. Volunteering isn't just about work. It's about fun too.\n",
      ",.\n",
      "\n",
      "Question: What do children think was more fun when they played with friends?\n",
      "A. They could have more toys than other children.\n",
      "B. Every child could have a toy and they played together.\n",
      "C. Some children were left out with no toys.\n",
      "D. They had more friends to play with.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.021514892578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.52001953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Here are some ideas for learning English well.\n",
      "You are like a new baby.\n",
      "Babies learn their language slowly, First they learn to listen .Then they learn to talk .Finally , they can read and talk.\n",
      "Listen to English every day\n",
      "Listen to English radio , watch English TV, go to see English movies or use online lessons.\n",
      "Practise the conversations\n",
      "Make up conversations and practise the conversations .You'd better use beginner textbooks.\n",
      "Reading English stories\n",
      "Start with children's storybooks .Try to read stories for ESL readers , Read ads and so on ,Try English Club.com for young learners.\n",
      "Write down new words\n",
      "Start a new word notebook.Write words in _ (A...B...C)Make some sentences.Try to use an English-English dictionary.\n",
      "Keep an English diary\n",
      "Start with one sentence.Like how do you feel? What did you do today?Write another sentence tomorrow.\n",
      "\n",
      "Question: What kind of books do we start to read when learning English?\n",
      "A. Children'storybooks\n",
      "B. Children's textbooks\n",
      "C. Children's picture books\n",
      "D. Children's music books\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 977\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0032787322998046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36544\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016222000122070312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: In many countries, holidays are important parts in people's life. Let's show some countries to you.\n",
      "America\n",
      "American people's holidays are flexible ( ). They can use up their holidays once, and they can also use them up a few times. During the holidays, they still get money.\n",
      "Canada\n",
      "Many people in Canada can rest three days a week. They have all kinds of activities   for holidays. They may go fishing, boating or mountain climbing. Also, they have long holidays. They may go to the beach to spend a sunny winter holiday. Like American people, Canadians also get money during the holidays.\n",
      "France\n",
      "People in France are very good at enjoying life. They have a 6-week holiday every year, and they work less than 40 hours a week.\n",
      "\n",
      "Question: Which of the following activities is not mentioned in the passage?\n",
      "A. Go fishing.\n",
      "B. Go boating.\n",
      "C. Go skating.\n",
      "D. Go mountain climbing.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 115636\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004286766052246094\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08343505859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: As Danny put his lunch tray onto the cafeteria table, milk spilled all over his sandwich. \"This is the worst thing I've ever done!\" he said, \"It's not that bad,\" said his friend Elena, who was sitting across from him. \"Just get another sandwich.\"\n",
      "\"Sandwich? What sandwich? I am talking about the talent contest . It's only two weeks away and I don't know what I'm doing! Everybody will laugh at me. There's no way to avoid it!\"\n",
      "\"Don't be so _ , Danny,\" said Elena as she rolled her eyes. \"You're going to be great. You have the skills to do just about anything.\"\n",
      "Danny moved his lunch tray to the side and rested his head on the table.\n",
      "\"Sit up Danny,\" ordered Elena, \"I have an idea. Let's brainstorm a list of things you could do. We'll divide the list into categories or groups. Let's start with music. You play the piano, right?\"\n",
      "\"I stopped taking lessons in the third grade,\" said Danny.\n",
      "\"What about singing a song?\" suggested Elena.\n",
      "Danny shook his head no. \"Let's move on to another category.\"\n",
      "\"What about performing magic tricks?\" asked Elena, as she twisted thin strands of hair around her finger.\n",
      "\"I don't know how to play magic tricks!\" Danny almost shouted.\n",
      "\"Stop being so...\" Elena paused, \"That's it, DRAMATIC!\" Elena shouted excitedly. \"You could do a dramatic reading. You definitely have the talent for it. Mrs. Pace always calls on you to read aloud in class. You could read a play aloud. Maybe you could even get extra credit from Mrs. Pace. She rewards students with points for doing extra reading work.\"\n",
      "Danny thought for a minute. Then he smiled. \"Elena,\" Danny said, \"You are a great friend!\"\n",
      "Elena smiled back. \"I just want to make sure you are a bright, shiny star when you step out on stage.\"\n",
      "\n",
      "Question: With the help of Elena, Danny finally decided to   _  .\n",
      "A. play the piano\n",
      "B. sing a song\n",
      "C. perform magic tricks\n",
      "D. do a dramatic reading\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.434326171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29667\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1986083984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: South Korean stars shined brightly at the Opening Ceremony of the 17th Asian Games held here on Friday, Sept. 19 in Inchen .\n",
      "Many stars gave shows during the welcoming performance.The most famous K-pop boy group, EXO, performed two songs on stage.Famous actors followed to show up on stage, including Jang Dong-gun, Hyun Bin, and Kim Soo-hyun.Lee Young-ae, the South Korean actress known for volunteering, was the last torchbearer  and lighted the cauldron  with two children.\n",
      "After the lighting of the flame, 16 more minutes of other K-pop performances were held. JYJ sang the theme song 'Only One' and Psy and Chinese pianist Lang Lang finally performed \"Gangnam Style\" with the 60,000-strong audience.\n",
      "\n",
      "Question: The Opening Ceremony of the 17thAsian Games was held on   _  .\n",
      "A. Sept. 16\n",
      "B. Sept. 17\n",
      "C. Sept. 18\n",
      "D. Sept. 19\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19438\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009899139404296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11163330078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Tom is a schoolboy. He is only seven years old, but he is very busy on weekdays. One Saturday he decided to relax himself, so he went to the cinema.\n",
      "It was the first time for him to do that. He bought a ticket and then went in. But after two or three minutes he came out, bought a second ticket and went in again. After a few minutes he came out again and bought a third ticket. Two or three minutes later he came out and asked for another ticket. Then the girl in the ticket office asked him,\"Why did you buy so many tickets? How many friends did you meet?\"Tom answered, \"No, I have no friends here. But a big boy always stops me at the door and tears  my ticket.\"\n",
      "\n",
      "Question: The big boy was  _  at the cinema.\n",
      "A. a bookseller\n",
      "B. a policeman\n",
      "C. a shopkeeper\n",
      "D. a worker\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2469482421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38731\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00666046142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The scientists from the Lockheed Space Company   work in Felton, California, with the help of a computer. But the computer is placed in Sunnyside, about 80 kilometers away. What the scientists input is sent by telephone lines to the computer, and after a time, copies of the designs are needed back in Felton as possible. Lockheed people have tried several ways of sending the prints  , but the most effective seems to be by pigeon  . Are pigeons really used to carry messages in these days? They are, and they send the prints faster and cheaper than any other way.\n",
      "Human   messengers (persons carrying messages) are much more expensive and slower than the pigeons. The road to Felton goes through the mountains, and the driving is not easy. An electronic printout system  could do the work in Felton, but at a cost of 10 dollars a print. Pigeons carry the designs for about 1 dollar each.\n",
      "Now Lockheed people have ten pigeon messengers. The pigeons do the work, and they have made Lockheed more famous. You can often read the news about the pigeons in the newspapers around the world.\n",
      "\n",
      "Question: The story is mainly about_.\n",
      "A. Felton, California\n",
      "B. the scientists\n",
      "C. how to work with computers\n",
      "D. sending prints by pigeon\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 235\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0025463104248046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Joe, an outgoing girl, is from a rich family. Therefore she can afford almost everything. But Joe's parents are too busy to spend enough time with her, which makes Joe more than lonely. So, she always goes to WeChat. On WeChat, she can do a lot of things like buying things, reading articles, and making friends with those she either knows or not.\n",
      "She uses the name Linda on WeChat and has made a lot of friends there. Last year Joe made a foreign friend on WeChat. Her name was Catherine and she lived in Sydney. Catherine once sent a picture of \"herself\": a tall, good-looking young woman with big eyes. Catherine and Joe were both interested in rock music and modern dance. So, they liked each other very much.\n",
      "When Joe's father told her that he was meeting a client in Sydney this summer, she went with him to give Catherine a surprise for her birthday. When Joe came to Catherine's house in Sydney, she found that her foreign \"girlfriend\" was a ten-year-old boy named Jim! What a surprise!\n",
      "\n",
      "Question: Joe spends time on WeChat to  _  .\n",
      "A. make friends\n",
      "B. kill time\n",
      "C. read articles\n",
      "D. buy things\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63894\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005955696105957031\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98445\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003447532653808594\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Mr. Evans lives in a city. He was a math teacher three years ago. He taught well and his students liked him. So he decided to work in the middle school all his life. But a terrible accident changed his fortune .\n",
      "One spring he took his class to visit a place of interest. The children saw a lot of interesting things and had a good time there. But on their way to school, their bus was hit by a truck because the young driver was drunk . Five students died and more than half of the children were injured in the accident. He didn't know how it had happened and was very sad about it and after he came out of hospital, he left the school and became a policeman. He tried his best to stop the drivers from breaking the traffic regulations . He worked hard and was strict with the drivers. So they were afraid of him.\n",
      "One afternoon it was very hot. Mr. Evans was on duty. He was standing at the crossing and watching the traffic. Suddenly he saw a car rushing towards the crossing. It ran so fast that it almost hit a man on a bike. He stopped it at once and saw a girl in it.\n",
      "\"Show your license to me, madam,\" said Mr. Evans.\n",
      "The girl handed her bag to him and said: \"Please look for it in it. I can't see anything without glasses.\"\n",
      "\n",
      "Question: In the accident   _  .\n",
      "A. more than half of the children died\n",
      "B. five children were injured\n",
      "C. more than half of those children were injured\n",
      "D. Mr. Evans was injured\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.57080078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07537841796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Most people follow others blindly mainly under the effect of peer  pressure. Some people also feel it safe to follow a large number of people. In some _ cases it might be right to follow the crowd  , but in most cases this can be one big mistake. Ninety-five percent of people never succeed because they are following the wrong group. Actually there are reasons why we shouldn't follow the crowd blindly.  According to a study, people tend to follow the crowd when they aren't sure about the direction they should take. This means a large number of people could be following others without understanding what's right and what's wrong! This attracts more people to follow them and the result is that most people move in a certain direction even if it isn't right.\n",
      "A man who wants to be successful always hopes for others' guidance and he usually follows the same path of most people, but the question this man never asks himself is: are all of those people successful? Of course not! If you want to follow a crowd, then follow a successful one. However, in real life you'll only find one successful person among hundreds of people, and that's why following the crowd makes no sense at all.\n",
      "Most people act without thinking wisely. If you always follow others because\n",
      "they're greater than you in number, then sooner or later you'll discover that you're\n",
      "making decisions you might regret later.\n",
      "However, should we never follow the crowd?No. I'm not trying to say you should never follow the crowd, but instead I'm just asking you to think wisely before you take a decision. If you find others are right, there is no problem in following them, but if you have doubts about the direction they're moving in, don't follow them blindly.\n",
      "\n",
      "Question: A man who wants to succeed should  _  .\n",
      "A. follow the crowd\n",
      "B. follow others' guidance\n",
      "C. follow a successful person\n",
      "D. follow the same path of most people\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.357666015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38731\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.016693115234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Tony is a boy. He is 16 years old. He studies in a middle school. He often watches TV and likes the popular hair style . His parents and teachers tell him not to do so, but he doesn't listen to them.\n",
      "One Sunday afternoon his mother buys a beautiful shirt for him and he loves it very much. The next morning, it is cold, but he still puts it on. That evening he has a bad cold. His parents take him to hospital.\n",
      "About thirty minutes later, a nurse brings him to a women's ward .\"Don't you know I am a boy\"? says Tony.\"Oh, I'm sorry. I don't know you are a boy, because your hair is too long\".\n",
      "\n",
      "Question: --What does Tony do? --He is  _  .\n",
      "A. a teacher\n",
      "B. a student\n",
      "C. a worker\n",
      "D. a driver\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00969696044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21038\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0029850006103515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Ann was my best friend. She had come to play half an hour ago, and I didn't want her to go. \"Your mother said you could stay an hour.\" I said.\n",
      "Ann pointed at the Teddy Bear on my desk. \"I'll stay if you give me your Teddy Bear.\" she said.\n",
      "I couldn't imagine giving it to her. It was a special gift from Aunt Reba on my tenth birthday. My aunt was a beautiful and kind woman who was never too busy to spend time with me. The day she died, I cried for hours, unable to believe that I would never see her again. Now, when I saw the Teddy Bear, I was filled with memories  of Aunt Reba.\n",
      "\"Come on,\" Ann shouted, \"I'm your best friend.\"\n",
      "I don't know what came over me, but I really wanted someone to play with me. So I handed Ann the Teddy Bear! Then, she stayed.\n",
      "That evening I went to bed without dinner. The memories of Aunt Reba brought tears to my eyes. How _ I felt. I was sad all night.\n",
      "Alone in the dark, I asked myself, \"Is Ann really my best friend?\"\n",
      "At school the next day, I found Ann. I asked for the Teddy Bear. She was surprised at first. Then she thought for a few seconds and finally said, \"Okay, I don't like it anyway.\"\n",
      "After that, Ann and I stopped playing together. Through the years, I have had other best friends. I have come to understand that best friends are people who want to spend time with you, and they ask nothing in return.\n",
      "\n",
      "Question: Ann finally stayed to play with the writer because   _  .\n",
      "A. she wanted to play with the writer\n",
      "B. Ann's mother ordered her to stay\n",
      "C. she was the writer's best friend\n",
      "D. the writer gave her the Teddy Bear\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15702\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0214996337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5693359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: My name is Lin Tao. I'm a Chinese boy. Now I'm studying in America. There are many kinds of clubs here. When I first come here, l don't know anything about clubs.\n",
      "I'm a shy boy, so I can't speak English well. In my first year in America, l don't like to speak to others. In my second year I have to change myself by doing some new things. I _ that school is not just about getting good grades , it's also about being part of a club. One day, when I go to the Media Center with my classmate Jim, he tells me something about the club, It's interesting, so 1 join it.\n",
      "I am in many clubs now, it's good to be part of a club. These clubs help me to make new friends.\n",
      "\n",
      "Question: Where is Lin Tao studying now?\n",
      "A. In America\n",
      "B. In China.\n",
      "C. In Canada.\n",
      "D. In Australia.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.15673828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1969\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0037097930908203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Kites have a long history. They may date back  long time ago. They were made of bamboo and silk in China. Nobody knows exactly how or when a kite was first flown, but it is said that when a Chinese farmer tied a string  to his hat to keep it from blowing away in a strong wind, the first kite was born.\n",
      "Children like playing with kites. Kites for work or play are made of wood, bamboo, paper, or silk. In 478 B.C., a Chinese philosopher , Mo Zi, spent three years making a kite out of light wood and bamboo. The earliest record of kite flying was in about 200 B.C. when the Chinese General  Han Xin of Han Dynasty flew a kite over the walls of a city. He wanted to know how far his army would have to travel.\n",
      "In the 13thcentury, Marco Polo wrote about how the shipping businessmen flew the huge kite in the wind before the ship set sail. They predicted the voyage  in this way. If the kite went high and straight it meant a quick and successful voyage, but if it did not fly well, it was a bad omen . In the late 1500s, the kite was introduced to Europe by the Italians. Kite flying was first mentioned in England in a popular book in 1589.\n",
      "\n",
      "Question: Kites are made of the following materials EXCEPT   _   according to the passage.\n",
      "A. silk\n",
      "B. bamboo\n",
      "C. cloth\n",
      "D. paper\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52325\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.056793212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: How much should you save? You may be able to save 100% of your money. Does that mean you should? Not at all. The best way to develop good saving habits is to make saving a regular part of your life, along with spending.\n",
      "Here is the rule you should remember: save before spending. Whenever some money gets into your hands, from a job or your pocket money or whatever, take your savings out immediately, before spending any of the money. The beauty of this system is that if you take away your savings, you are free to spend the rest.\n",
      "Here are some more suggestions on how to successfully get into the saving habit from teens. Let's see!\n",
      "Tony,13: I put my money in a bank instead of my wallet, so the money is not there. And I have to take an extra step to get it.\n",
      "Bill,14: When considering a major purchase , wait a week or so, at least. This will help you make sure if you still want it, and the price might go down.\n",
      "Dick, 13: Carry very little money always. You can't spend money if you don't have it. A cake would be nice, but without a dollar, you can't get it. Little things like that really add up quickly.\n",
      "Steve,16: I used to be weak when it came to money. I bought something whenever I went into a store. I'm glad I'm not that person now. I taught myself discipline by keeping a $20 bill in my pocket while waking around the mall all day and not buying anything. Now I have no strong wish to buy things when I go into a store. It works for me.\n",
      "These ideas should help you get started. If you have some questions about anything you've read here, or would like to share your ideas about saving money, please write to us.\n",
      "\n",
      "Question: The writer wrote the passage in order to ask teens to  _  .\n",
      "A. make major purchases\n",
      "B. save 100% of their money\n",
      "C. spend all their savings regularly\n",
      "D. save money regularly as well as spending\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.038360595703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.051910400390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
      "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
      "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
      "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
      "\n",
      "Question: How long did the press conference last?\n",
      "A. We don't know.\n",
      "B. 1 hour.\n",
      "C. Half an hour.\n",
      "D. 10 minutes\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.091796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49568\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0112152099609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Do you help with chores at home? These are what some people say about it.\n",
      "Manuel, 19:   \"I only like to do the laundry. My mom does the other chores. When she isn't at home, I can cook an easy dinner myself, but please don't ask me whether I'm a good cook or not. \"\n",
      "Vivian, 38:  \"I do everything because I live by myself now. I think I can do everything because I watched and helped my mom cook our family meals all the time when I was young. At first I was told to help my mom, but later I began to like cooking. Now I can cook many kinds of dishes. \"\n",
      "Arthur, 67:  \"I do many things around the house because everyday is like Sunday for me now. I have to do something to keep busy. I help with gardening and cleaning the most. I enjoy doing these things. Cooking and laundry are my wife's chores. \"\n",
      "\n",
      "Question: Who did Vivian learn cooking from?\n",
      "A. Arthur.\n",
      "B. Her friend.\n",
      "C. Her mom.\n",
      "D. Her teacher.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5673828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15144\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0252227783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The Chinese tradition of giving gifts of money in red envelopes at Lunar New Year has turned into big business for Web giants Alibaba and Tencent, which now both offer electronic \"hong bao\".\n",
      "At the end of each lunar year, it is common in China to give children hong bao -- some money in envelopes that are red, the colour of success. But now theold also take part in this activity.\n",
      "It is now possible to exchange \"red envelopes\" with smartphone, which is popular in China and has caused a battle  for the _ market between the two companies providing the service, Tencent and Alibaba.\n",
      "\"You don't have to pay the same cost or wait as long as you would for a traditional bank transfer . It's more convenient, simple and fun,\" Wang Le, a 28-year-old Beijinger, told AFP. \" With electronic red envelopes, you're not limited by your identity  or the time of year. It's a new, fresh way of playing the game.\"\n",
      "The idea was introduced in 2014 by WeChat, a mobile messaging system with over 400 million users and run[:**]by Tencent, China's largest Internet service system. It was successful at once.\n",
      "This year, Alipay Wallet , the payment system run by Alibaba, is ready to take on the competition. It is allowing its 190 million users to send digital gifts, especially on the Twitter-like Sina Weibo.\n",
      "For the past few weeks a digital battle has been terrible, with Tencent banning  Alipay from sending red envelopes on WeChat, saying they were at a risk. Recently, WeChat also blocked  Alibaba's music app Xiami.\n",
      "To attract the public's attention, the two companies have launched lotteries through which they award red envelopes to users in an online game.\n",
      "It's easy to send and receive hong bao or take part in the lotteries: you simply need to register  your bank details.\n",
      "According to market research group iResearch, Alipay controls 82.6 percent of the Chinese mobile phone payment market, compared to 10 percent for Tencent's Tenpay.\n",
      "\n",
      "Question: Which one is TRUE according to the passage?\n",
      "A. Tencent allows Alipay to send red envelopes via Wechat.\n",
      "B. The idea of electronic red envelope was introduced by Wechat in 2014.\n",
      "C. It's complicated   to send and receive hongbao or participate in the lotteries.\n",
      "D. Alipay controls a smaller payment market of the Chinese microphone thanTencent's Tenpay.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11212158203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15144\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03179931640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Mr. Evans lives in a city. He was a math teacher three years ago. He taught well and his students liked him. So he decided to work in the middle school all his life. But a terrible accident changed his fortune .\n",
      "One spring he took his class to visit a place of interest. The children saw a lot of interesting things and had a good time there. But on their way to school, their bus was hit by a truck because the young driver was drunk . Five students died and more than half of the children were injured in the accident. He didn't know how it had happened and was very sad about it and after he came out of hospital, he left the school and became a policeman. He tried his best to stop the drivers from breaking the traffic regulations . He worked hard and was strict with the drivers. So they were afraid of him.\n",
      "One afternoon it was very hot. Mr. Evans was on duty. He was standing at the crossing and watching the traffic. Suddenly he saw a car rushing towards the crossing. It ran so fast that it almost hit a man on a bike. He stopped it at once and saw a girl in it.\n",
      "\"Show your license to me, madam,\" said Mr. Evans.\n",
      "The girl handed her bag to him and said: \"Please look for it in it. I can't see anything without glasses.\"\n",
      "\n",
      "Question: What was Mr. Evans' job three years ago?\n",
      "A. policeman\n",
      "B. a math teacher\n",
      "C. a guide\n",
      "D. a drive\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.59326171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20894\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01039886474609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: A story is told about a soldier who was finally coming home after having fought in Vietnam. He called his parents from San Francisco.\n",
      "\"Mom and Dad, I'm coming home, but I have a friend I'd like to bring with me.\"\n",
      "\"Sure,\" they replied, \"we'd love to meet him.\"\n",
      "\"There is something you should know,\" the son continued, \" he was hurt badly in the fighting. He lost an arm and a leg. He has nowhere else to go, and I want him to live with us.\"\n",
      "\"I'm sorry to hear that, son. Maybe we can help him find somewhere to live.\"\n",
      "\"No, Mom and Dad, I want him to live with us.\"\n",
      "\"Son,\" said the father, \"you don't know what you're asking. Someone like the young man would be a terrible burden for us. We have our own lives to live, and we can't let something like this stay with our lives. I think you should just come home and forget about this guy. He'll find a way to live on his own.\"\n",
      "At that point, the son hung up the phone. A few days later, however, they received a call from the San Francisco police. Their son had died after falling down from a building. The police believed it was suicide .\n",
      "The parents flew to San Francisco. To their surprise, they found their son had only one arm and one leg.\n",
      "The parents in this story are like many of us. We find it easy to love those who are good-looking or fun, but we don't like people who make us feel uncomfortable. We would rather stay away from people who aren't as healthy, beautiful, or smart as we are.\n",
      "\n",
      "Question: What can we learn from the story\n",
      "A. Parents don't like their disabled children.\n",
      "B. We should stay away from the unhealthy people.\n",
      "C. It's easy for us to love the disabled.\n",
      "D. We can't judge a person by his appearance.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.44921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87133\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.915496826171875e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: We are all learning English, but how can we learn English well? A student can know a lot about English, but maybe  he can't speak English. If you want to know how to   swim, you must get into the river. And if you want to be a football player, you must play football.\n",
      "So, you see. You can learn English only by  using it. You must listen to your teacher in class. You must read your lessons every day. You must speak English to your classmates and also you must write something sometimes. Then one day, you may find your English very good.\n",
      "\n",
      "Question: You know a lot about English but maybe you  _\n",
      "A. can speak\n",
      "B. can study it\n",
      "C. can't study it\n",
      "D. can't use it\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8093\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01117706298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88760\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005558013916015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear Mr. Lee,\n",
      "I am Jack. I want to be in a club in our school. I can't sing or dance or act in movies, but I can do many other things. I can play three _ , the guitar, the violin   and the piano. I think I can be in the music club. Maybe   I can be a famous musician. I like reading story books and I can write stories. Maybe I can be a famous writer. I like sports too, but I don't think I can be a famous and successful sportsman  . Can I join you?\n",
      "Yours,\n",
      "Jack\n",
      "\n",
      "Question: Jack can't   _   .\n",
      "A. act in movies\n",
      "B. write stories\n",
      "C. play the violin\n",
      "D. read\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.53369140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 90458\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002086639404296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: There are two main kinds of sports. These two kinds of sports are team sports and individual   sports. Team sports are such sports as baseball, basketball, and volleyball. Team sports need two separate   teams. The teams play against each other. They compete against each other to get the best score. For example, in a football game, if team A gets 8 points and team B gets 4 points, team A wins the game. Team sports are sometimes called competitive   sports.\n",
      "Another kind of sports is individual sports. In individual sports there are no teams. There isn't any competition. People play individual sports in order to get some exercise, not to win a game. Individual sports are such sports as swimming, skiing, and running.\n",
      "Of course, it is possible   to compete in individual sports. It is possible to keep a score in individual sports. The main difference, however, between team sports and individual sports is that individual sports can be finished alone. But team sports always need more than one person.\n",
      ",.\n",
      "\n",
      "Question: There are   _   kinds of sports according to the passage.\n",
      "A. one\n",
      "B. two\n",
      "C. three\n",
      "D. four\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5888\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003654956817626953\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53115\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.021575927734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Robots are supposed to run on batteries, right? Well not all of them.\n",
      "Scientists in England have built a kind of small robots that get their energy from dead flies, bad apples, or sugar.\n",
      "One robot, called Slugbot, was even designed to hunt  garden slugs for dinner!\n",
      "What's up with all that food?\n",
      "Well, scientists at the Bristol Robotics Laboratory want to invent robots that can operate for a long time in dark, dirty, or dangerous places.\n",
      "Many of those spots, like the seafloor or Antarctica, don't have electrical sockets .\n",
      "So inventor Chris Melhuish came up with a better idea: Build robots that get their energy just like animals do by hunting and eating food from their environment.\n",
      "One robot, called Ecobot II, could run for 12 days on a diet of eight flies! Of course, it'd still get a lot more power from one AA battery, though.\n",
      "Melhuish says his team is now working on a new and improved robot, called Ecobot III, which will have a better digestion system.\n",
      "It seems that after an eight fly dinner, Ecobot II couldn't deal with the leftover  \"waste\".\n",
      "Maybe restrooms in the future will have signs for boys, girls, and robots.\n",
      "\n",
      "Question: From the passage, we can infer that a slug .\n",
      "A. is a kind of insect\n",
      "B. is a kind of fish\n",
      "C. can't see Slugbot\n",
      "D. can eat Slugbot\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.49169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.148193359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: If you won a lottery and had lots of money, what would you do? Most people start by buying themselves things, such as a new car or a bigger TV.\n",
      "Many people who win lots of money may suddenly find that they have a lot of socalled friends. The new friends they make may follow them for their money but they may also leave them when all the money is spent. Besides that, they can't decide what to do with the money, so they try to think what they want. In the end, most people usually decide to save the money.\n",
      "There are some lottery winners who decide to quit their jobs, because they think they have enough money and don't need to work any longer. Some big lottery winners make even bigger changes--they end their marriages. They think that winning a lot of money has suddenly made them more intelligent and more attractive .So they feel that they have to be with a younger or more attractive man or woman.\n",
      "They don't know their new money is just a bit of luck. _ can't change everything.\n",
      "Next time when you buy a lottery ticket, think about what you would like to do and what you wouldn't  like to do with the money if you won.\n",
      "\n",
      "Question: Some lottery winners end their marriages, because  _\n",
      "A. they don't like their husband or wives.\n",
      "B. They think winning a lot of money is lucky.\n",
      "C. they feel they should be with a younger or more beautiful man or woman.\n",
      "D. they think they should change everything.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39720\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0049591064453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 579\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0247955322265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Many families do not eat very healthy food now . If   you do not eat good food ., then you are not healthy . Doctor Smith from the hospital says that people need   to eat a lot of healthy food in this order   :\n",
      "Rice and noodles .\n",
      "Fruit , such as oranges and apples , and vegetables , such as carrots , tomatoes and potatoes .\n",
      "Meat , such as pork , chicken , beef and fish .\n",
      "Doctor Smith says that people should not   eat unhealthy food like hamburgers , candy chocolate or ice cream , or have some drink such as cola . And they should drink milk , juice or water .\n",
      "So , to stay healthy and away from hospital , eat only healthy food !\n",
      "\n",
      "Question: To stay healthy , people should eat   _  .\n",
      "A. rice , fruit , meat and fish\n",
      "B. hamburgers and candy\n",
      "C. noodles and ice cream\n",
      "D. Carrots and chocolate\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2247314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01265716552734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Years ago I worked at a factory in a small county. Every day I got up very early and often did much extra work at night. I was so tired and exhausted. My whole life was hopeless. Then one day I read the following article from a magazine:\n",
      "\"A woman went to live with her husband in camp on the Mojave Desert during the war. She simply hated the place: the heat was almost un-bearable, 125 degrees in the shade, the wind blew incessantly, and there was sand everywhere. Finally, in desperation   she wrote her parents in Ohio that she couldn't stand it another minute and was coming home.\n",
      "Quickly came the reply by airmail from her father----just two lines:\n",
      "\"Two men looked out from prison bars. One saw the mud, the other saw stars.\"\n",
      "The daughter did some real thinking, not only with the intellect   but also with her heart. She decided to stick to her post.\n",
      "She made friends with the natives, learned to love the country, and eventually wrote a book about it.\n",
      "The desert hadn't changed, but her attitude had. Because she listened with her heart  to the words her father sent, a whole new world opened up to her.\n",
      "A change of attitude could change everything.\n",
      "After reading the article, I was deep in thought  ...\n",
      "\n",
      "Question: The woman's father wanted to tell his daughter to  _  .\n",
      "A. look at the mud.\n",
      "B. look at the stars.\n",
      "C. come home.\n",
      "D. stay with her husband.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79767\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0171966552734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04168701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Four girls go to school every day by taxi. One day one of the girls says, \"There is a test this morning. Let's get to school late. Then we will not have the test.\"\n",
      "\"What can we tell the teacher?\" One of the girls says. \"He will be angry. We will need a good excuse.\"\n",
      "The girls think for a moment, then one of them says, \"Let's tell him that our taxi has a flat tire .\"\n",
      "\"That's a good idea,\" the other girls say. \"We will tell him that.\"\n",
      "They get to school an hour later. The test is over. \"Why are you late? You missed the test.\"\n",
      "\"Our taxi had a flat tire.\" One of the girls said.\n",
      "The teacher thought for a moment, then he said, \"sit down, One of you in each corner of the room.\" The four girls do this.\n",
      "Then the teacher says, \"Write down a piece of paper the answer to this question: Which tire is flat?\"\n",
      "\n",
      "Question: How do the girls go to school every day?\n",
      "A. By bus\n",
      "B. By taxi\n",
      "C. By bike\n",
      "D. On foot\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1424560546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12737\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005008697509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Emily Urich 18 years old Canada\n",
      "A lot of teens aren't responsible ,and that's where I'm different. Not just about school but everyday things like being able to pay my own credit card bills on time.\n",
      "The first time I got a cartoon book was on my third birthday. From then on , I fell in deep love with it. And can you guess how many cartoon books I've read? I don't really know the exact number. But I have three full boxes of them under my bed. I also like drawing cartoons and wish to be an art teacher in a sch001.\n",
      "Joe Miller 16 year's old America\n",
      "I'm proud of doing things my own way. So whether somebody wants me to do something or whatever it is , I feel like they're all other people's thoughts , not really mine. But like others , I love reading , too. When I first took skiing lessons , I found it exciting. For ski racing,there's no question I'm better shape than most guys . I think it's fun. I mean,it is a challenge . It's where I picked up the idea of needing a challenge always in my life. In order to improve my skiing skills,I have read many books and magazines about it. No doubt it's my dream to win gold medals in the Olympic Games.\n",
      "An Oi 15 years old China\n",
      "I'm different because I prefer to drop out of the world to create my own world. I'd like to build a house on a mountain. And I choose to live without electricity, a telephone,or even indoor plumbing . I have many hobbies such as traveling,reading , writing and spending time with children. I love children because they are smart and creative. They always have many strange ideas. It makes me excited. I want to do something for Hope Project and become a country school teacher .\n",
      "\n",
      "Question: Who wants to be teacher?\n",
      "A. Emily and Joe.\n",
      "B. Joe and An Qi.\n",
      "C. Emily and An Qi.\n",
      "D. Only An Qi.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26522\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003161430358886719\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.377685546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: 108 Wensan Road London, 85 A 100  England\n",
      "March 1st, 2013\n",
      "Dear Lin Tao,\n",
      "I am writing to you in English. I hope you can understand  it.\n",
      "I love studying in London and I have many new friends. Most of them are my classmates. From Monday to Friday, we have English, math, physics and P. E. in the morning. I like English and physics, because they're interesting. I don't like math. It's too boring. At noon, I have to have lunch at school because my home is far from my school. We usually have two classes in the afternoon--art and politics. We finish our classes at 3:30 p. m. After school, my friends and I always play football on the playground. And then we go home by bus.\n",
      "On weekends, we have no classes. We often go to the park and sometimes we go to the movies in the evening. We see movies twice a month. I like some famous  actors like Jackie Chan.\n",
      "Oh, I have no time to write more. Please write back soon.\n",
      "Best wishes,\n",
      "Wang Gang\n",
      ",.\n",
      "\n",
      "Question: How does Wang Gang go home every day?\n",
      "A. On foot.\n",
      "B. By bike.\n",
      "C. By bus.\n",
      "D. By car.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 105747\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0025653839111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.220458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: A long time ago, in 1893, in the United States, some people were talking about fruits and vegetables. They asked, \"What are fruits and what are vegetables? How are fruits different from vegetables and vegetables different from fruits?\" They talked for a long time and then they decided, \"We eat vegetables as part of a meal, but we eat fruits before or after a meal.\"\n",
      "In real life, people do not think the dictionaries give the right meaning of a word. For example, the dictionaries say that tomatoes are fruits. But few people know that. Most people think they are vegetables. They call them vegetables and eat them as vegetables. To most people, fruits mean sweet things like apples, pears, oranges and watermelons.\n",
      "What are vegetables then? We call many plants and grasses vegetables. Some people think some fruits are vegetables, such as apples, pears and bananas. But to most people, vegetables mean things like potatoes, onions and carrots.\n",
      "\n",
      "Question: People usually eat vegetables   _  .\n",
      "A. before a meal\n",
      "B. after a meal\n",
      "C. alone\n",
      "D. during a meal\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3653\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00942230224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.181396484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: My name is David and I have two brothers, Mark and Bruce. We like hamburgers for lunch. Mark and I like French fries, but Bruce doesn't. I don't like eggs for breakfast, but Mark and Bruce do. I like fruit for breakfast. We really like chicken and salad for dinner.\n",
      "\n",
      "Question: _   doesn't like French fries.\n",
      "A. David\n",
      "B. Mark\n",
      "C. Bruce\n",
      "D. David and Mark\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27347\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006551742553710938\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.137939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
      "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
      "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
      "She understood that she hadn't worn the hair clip to school at all.\n",
      "\n",
      "Question: Why was the girl so happy?\n",
      "A. She found that everyone who saw her smiled at her.\n",
      "B. She heard most of her schoolmates said \"Hello\" to her.\n",
      "C. She thought what she experienced today never happened before.\n",
      "D. Both A, B, and C\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8862\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006374359130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.322509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
      "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
      "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
      "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
      "\n",
      "Question: When Mike got home, he was   _  .\n",
      "A. sad\n",
      "B. happy\n",
      "C. tired\n",
      "D. busy\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0965576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12737\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01351165771484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Mr. Smith is one of my friends. He can run very fast and he is always ready to show  how fast he can run.\n",
      "One day a thief  breaks into his house,takes some things of his and runs off as fast as he can. Mr. Smith runs after him and shouts :\"Stop! Stop! Don't you know you can't run away from me?\"\n",
      "But the thief only runs faster. Mr. Smith gets angry. He tries his best to run. He is soon a few miles away from his house. He doesn't see anything or anybody and is still rushing  alone  when he runs into  me.\n",
      "\"Why are you in such a hurry?\"\n",
      "\"I'm trying to catch a thief.\"\n",
      "\"But where is the thief?\" I ask.\n",
      "\"Far, far behind me,\" says Mr. Smith with a smile on his face.\n",
      "\"He thinks he can run faster than me,but you see he is wrong.\"\n",
      "\n",
      "Question: Mr. Smith gets angry because the thief   _  .\n",
      "A. stops\n",
      "B. runs away\n",
      "C. doesn't stop\n",
      "D. runs into him\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.53076171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67324\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.058563232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Thursday, April 24th\n",
      "We got to the clean, lovely city of Yangzhou early in the morning. This is our first trip to China. All the different smells attract our attention to the local food. We are going to try something special for dinner tonight. The hotel we are staying in is not expensive but very clean. We plan to stay here for a few days, visit some places in the city, and then travel to the Great Wall in the north.\n",
      "Sunday, April 27th\n",
      "We visited the famous Slender West Lake   which was crowded with visit ors from all over the world, and bought a lot of toys for our friends outside the gate of the park. Everything is so colourful, and we have taken hundreds of photos already! Later today we will do the famous foot massage   and then leave for the Great Wall. We will take the night train north, stay in Beijing for two days, and then catch a bus to the Great Wall.\n",
      "Wednesday, April 30th\n",
      "Our trip to the Great Wall was long and boring. We visited a small village in the mountains. People in the village love the quiet life. They are the kindest people I had ever met. They always smile and say \"Hello\". Ralph and I can speak only a few words in Ch inese, so smiling is the best way to show our kindness.\n",
      "\n",
      "Question: The writer didn't   _  in Yangzhou.\n",
      "A. taste delicious food\n",
      "B. visit places of interest\n",
      "C. do foot massage\n",
      "D. climb mountains\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9007\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003485679626464844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25817\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007061958312988281\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: I am Wang Lin, I am twelve years old. My pen pal Tom is form the United States. He is the same age as I. He is a middle school student in Beijing. There are three people in his family. His father is a teacher, he teaches English in a high school in Beijing. His mother is an English teacher, too. But they work in different schools. Tom goes to school in his mother's car every day. They all like Chinese food. Tom's father likes Guangdong food, he thinks it is delicious. Tom's mother's favorite food is Sichuan food. But Tom doesn't like Sichuan food, he thinks it is too hot. So they often eat out on weekends.\n",
      "\n",
      "Question: They often eat out on weekends because   _  .\n",
      "A. they like Chinese food\n",
      "B. they like American food\n",
      "C. they are lazy\n",
      "D. they have different hobbies  .\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28206\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0023345947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10089111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: An Internet game named Happy Farm is becoming more and more popular among young office workers and students. People can work on a farm. They can also grow, water, sell and steal vegetables, flowers, fruits and so on. They can earn some e-money from their working on the farm. Then they can use it to buy more seeds, pets and even houses. Of course, all these are not true, they are only on the Internet.\n",
      "Why do so many young people enjoy the kind of Farm game? I think maybe some of them are afraid of facing the real world, and they have to look for fun from the Internet. Some feel lonely and want to make friends during growing vegetables on the Internet. Some have great fun _ others' vegetables because they needn't work on their farm.\n",
      "Most parents and teachers are worried about these young people and students. Students spend too much time playing the game. It's bad for their health and study.\n",
      "\n",
      "Question: What's the name of this kind of game?\n",
      "A. Happy Farm.\n",
      "B. Vegetables and Fruits.\n",
      "C. Working on a Farm.\n",
      "D. Computer Came.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7294921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005573272705078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Ann was my best friend. She had come to play half an hour ago, and I didn't want her to go. \"Your mother said you could stay an hour.\" I said.\n",
      "Ann pointed at the Teddy Bear on my desk. \"I'll stay if you give me your Teddy Bear.\" she said.\n",
      "I couldn't imagine giving it to her. It was a special gift from Aunt Reba on my tenth birthday. My aunt was a beautiful and kind woman who was never too busy to spend time with me. The day she died, I cried for hours, unable to believe that I would never see her again. Now, when I saw the Teddy Bear, I was filled with memories  of Aunt Reba.\n",
      "\"Come on,\" Ann shouted, \"I'm your best friend.\"\n",
      "I don't know what came over me, but I really wanted someone to play with me. So I handed Ann the Teddy Bear! Then, she stayed.\n",
      "That evening I went to bed without dinner. The memories of Aunt Reba brought tears to my eyes. How _ I felt. I was sad all night.\n",
      "Alone in the dark, I asked myself, \"Is Ann really my best friend?\"\n",
      "At school the next day, I found Ann. I asked for the Teddy Bear. She was surprised at first. Then she thought for a few seconds and finally said, \"Okay, I don't like it anyway.\"\n",
      "After that, Ann and I stopped playing together. Through the years, I have had other best friends. I have come to understand that best friends are people who want to spend time with you, and they ask nothing in return.\n",
      "\n",
      "Question: From the passage we learn   _  .\n",
      "A. the Teddy Bear had a sweet face\n",
      "B. Anna and the writer were friends again at last\n",
      "C. the writer loved Aunt Reba deeply\n",
      "D. best friends always ask something in return\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14452\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.046600341796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 86449\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009937286376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: My name is Peter.I am 12.I have one brother and one sister.My brother is 15 and my sister is 9.I have a friend.He is an English boy.His name is Tanaka.He is in my class.I have a dog, too.Its name is Billy.Billy is 2.I like sports.I play basketball, soccer and volleyball after class .I have one pencil case, two English books and three Chinese books.\n",
      "\n",
      "Question: Peter and Tanaka are   _  .\n",
      "A. brothers\n",
      "B. sisters\n",
      "C. friends\n",
      "D. Chinese\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.42529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87363\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0015230178833007812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: If you won a lottery and had lots of money, what would you do? Most people start by buying themselves things, such as a new car or a bigger TV.\n",
      "Many people who win lots of money may suddenly find that they have a lot of socalled friends. The new friends they make may follow them for their money but they may also leave them when all the money is spent. Besides that, they can't decide what to do with the money, so they try to think what they want. In the end, most people usually decide to save the money.\n",
      "There are some lottery winners who decide to quit their jobs, because they think they have enough money and don't need to work any longer. Some big lottery winners make even bigger changes--they end their marriages. They think that winning a lot of money has suddenly made them more intelligent and more attractive .So they feel that they have to be with a younger or more attractive man or woman.\n",
      "They don't know their new money is just a bit of luck. _ can't change everything.\n",
      "Next time when you buy a lottery ticket, think about what you would like to do and what you wouldn't  like to do with the money if you won.\n",
      "\n",
      "Question: Some lottery winners want to be with a more attractive man or woman because they   _  .\n",
      "A. don't like their husbands or wives any more\n",
      "B. think winning a lot of money has made them more intelligent and more attractive\n",
      "C. have some new friends\n",
      "D. don't  know how to spend the money\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3653\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002666473388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62000\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016584396362304688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13966\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00035691261291503906\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11948\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0094757080078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12812\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03753662109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106700\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00034999847412109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110559\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0200347900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49800\n",
      "  Verified Probability: 0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "  1%|          | 1/100 [00:00<01:05,  1.50it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:39,  2.48it/s]\n",
      "  3%|▎         | 3/100 [00:01<00:30,  3.13it/s]\n",
      "  4%|▍         | 4/100 [00:01<00:27,  3.44it/s]\n",
      "  5%|▌         | 5/100 [00:01<00:25,  3.69it/s]\n",
      "  6%|▌         | 6/100 [00:01<00:24,  3.78it/s]\n",
      "  7%|▋         | 7/100 [00:02<00:23,  4.00it/s]\n",
      "  8%|▊         | 8/100 [00:02<00:22,  4.06it/s]\n",
      "  9%|▉         | 9/100 [00:02<00:21,  4.20it/s]\n",
      " 10%|█         | 10/100 [00:02<00:21,  4.15it/s]\n",
      " 11%|█         | 11/100 [00:03<00:21,  4.09it/s]\n",
      " 12%|█▏        | 12/100 [00:03<00:21,  4.17it/s]\n",
      " 13%|█▎        | 13/100 [00:03<00:20,  4.20it/s]\n",
      " 14%|█▍        | 14/100 [00:03<00:20,  4.29it/s]\n",
      " 15%|█▌        | 15/100 [00:03<00:20,  4.16it/s]\n",
      " 16%|█▌        | 16/100 [00:04<00:19,  4.23it/s]\n",
      " 17%|█▋        | 17/100 [00:04<00:19,  4.29it/s]\n",
      " 18%|█▊        | 18/100 [00:04<00:18,  4.40it/s]\n",
      " 19%|█▉        | 19/100 [00:04<00:18,  4.36it/s]\n",
      " 20%|██        | 20/100 [00:05<00:17,  4.50it/s]\n",
      " 21%|██        | 21/100 [00:14<03:49,  2.91s/it]\n",
      " 22%|██▏       | 22/100 [00:14<02:44,  2.11s/it]\n",
      " 23%|██▎       | 23/100 [00:14<01:59,  1.55s/it]\n",
      " 24%|██▍       | 24/100 [00:14<01:28,  1.16s/it]\n",
      " 25%|██▌       | 25/100 [00:15<01:06,  1.13it/s]\n",
      " 26%|██▌       | 26/100 [00:15<00:50,  1.47it/s]\n",
      " 27%|██▋       | 27/100 [00:15<00:39,  1.85it/s]\n",
      " 28%|██▊       | 28/100 [00:15<00:32,  2.23it/s]\n",
      " 29%|██▉       | 29/100 [00:16<00:26,  2.68it/s]\n",
      " 30%|███       | 30/100 [00:16<00:23,  2.99it/s]\n",
      " 31%|███       | 31/100 [00:16<00:21,  3.26it/s]\n",
      " 32%|███▏      | 32/100 [00:16<00:19,  3.50it/s]\n",
      " 33%|███▎      | 33/100 [00:17<00:18,  3.69it/s]\n",
      " 34%|███▍      | 34/100 [00:17<00:16,  3.89it/s]\n",
      " 35%|███▌      | 35/100 [00:17<00:16,  4.05it/s]\n",
      " 36%|███▌      | 36/100 [00:17<00:15,  4.23it/s]\n",
      " 37%|███▋      | 37/100 [00:17<00:15,  4.02it/s]\n",
      " 38%|███▊      | 38/100 [00:18<00:15,  4.12it/s]\n",
      " 39%|███▉      | 39/100 [00:18<00:14,  4.17it/s]\n",
      " 40%|████      | 40/100 [00:18<00:13,  4.33it/s]\n",
      " 41%|████      | 41/100 [00:18<00:13,  4.41it/s]\n",
      " 42%|████▏     | 42/100 [00:19<00:13,  4.42it/s]\n",
      " 43%|████▎     | 43/100 [00:19<00:13,  4.12it/s]\n",
      " 44%|████▍     | 44/100 [00:19<00:13,  4.25it/s]\n",
      " 45%|████▌     | 45/100 [00:19<00:12,  4.24it/s]\n",
      " 46%|████▌     | 46/100 [00:20<00:12,  4.25it/s]\n",
      " 47%|████▋     | 47/100 [00:20<00:12,  4.31it/s]\n",
      " 48%|████▊     | 48/100 [00:20<00:12,  4.25it/s]\n",
      " 49%|████▉     | 49/100 [00:20<00:11,  4.26it/s]\n",
      " 50%|█████     | 50/100 [00:20<00:11,  4.44it/s]\n",
      " 51%|█████     | 51/100 [00:21<00:11,  4.14it/s]\n",
      " 52%|█████▏    | 52/100 [00:21<00:11,  4.24it/s]\n",
      " 53%|█████▎    | 53/100 [00:21<00:11,  4.12it/s]\n",
      " 54%|█████▍    | 54/100 [00:21<00:10,  4.28it/s]\n",
      " 55%|█████▌    | 55/100 [00:22<00:10,  4.46it/s]\n",
      " 56%|█████▌    | 56/100 [00:22<00:09,  4.46it/s]\n",
      " 57%|█████▋    | 57/100 [00:22<00:09,  4.54it/s]\n",
      " 58%|█████▊    | 58/100 [00:22<00:09,  4.48it/s]\n",
      " 59%|█████▉    | 59/100 [00:22<00:09,  4.55it/s]\n",
      " 60%|██████    | 60/100 [00:23<00:08,  4.49it/s]\n",
      " 61%|██████    | 61/100 [00:23<00:08,  4.56it/s]\n",
      " 62%|██████▏   | 62/100 [00:23<00:08,  4.41it/s]\n",
      " 63%|██████▎   | 63/100 [00:23<00:08,  4.42it/s]\n",
      " 64%|██████▍   | 64/100 [00:24<00:08,  4.48it/s]\n",
      " 65%|██████▌   | 65/100 [00:24<00:07,  4.68it/s]\n",
      " 66%|██████▌   | 66/100 [00:24<00:07,  4.54it/s]\n",
      " 67%|██████▋   | 67/100 [00:24<00:07,  4.48it/s]\n",
      " 68%|██████▊   | 68/100 [00:24<00:07,  4.55it/s]\n",
      " 69%|██████▉   | 69/100 [00:25<00:06,  4.50it/s]\n",
      " 70%|███████   | 70/100 [00:25<00:06,  4.55it/s]\n",
      " 71%|███████   | 71/100 [00:25<00:06,  4.50it/s]\n",
      " 72%|███████▏  | 72/100 [00:25<00:06,  4.46it/s]\n",
      " 73%|███████▎  | 73/100 [00:26<00:05,  4.55it/s]\n",
      " 74%|███████▍  | 74/100 [00:26<00:05,  4.37it/s]\n",
      " 75%|███████▌  | 75/100 [00:34<01:08,  2.75s/it]\n",
      " 76%|███████▌  | 76/100 [00:35<00:47,  1.98s/it]\n",
      " 77%|███████▋  | 77/100 [00:35<00:33,  1.46s/it]\n",
      " 78%|███████▊  | 78/100 [00:35<00:23,  1.08s/it]\n",
      " 79%|███████▉  | 79/100 [00:35<00:17,  1.19it/s]\n",
      " 80%|████████  | 80/100 [00:36<00:13,  1.53it/s]\n",
      " 81%|████████  | 81/100 [00:36<00:10,  1.90it/s]\n",
      " 82%|████████▏ | 82/100 [00:36<00:07,  2.27it/s]\n",
      " 83%|████████▎ | 83/100 [00:36<00:06,  2.66it/s]\n",
      " 84%|████████▍ | 84/100 [00:37<00:05,  3.04it/s]\n",
      " 85%|████████▌ | 85/100 [00:37<00:04,  3.38it/s]\n",
      " 86%|████████▌ | 86/100 [00:37<00:03,  3.63it/s]\n",
      " 87%|████████▋ | 87/100 [00:37<00:03,  3.83it/s]\n",
      " 88%|████████▊ | 88/100 [00:37<00:02,  4.05it/s]\n",
      " 89%|████████▉ | 89/100 [00:38<00:02,  4.07it/s]\n",
      " 90%|█████████ | 90/100 [00:38<00:02,  4.15it/s]\n",
      " 91%|█████████ | 91/100 [00:38<00:02,  4.22it/s]\n",
      " 92%|█████████▏| 92/100 [00:38<00:01,  4.26it/s]\n",
      " 93%|█████████▎| 93/100 [00:39<00:01,  4.42it/s]\n",
      " 94%|█████████▍| 94/100 [00:39<00:01,  4.50it/s]\n",
      " 95%|█████████▌| 95/100 [00:39<00:01,  4.54it/s]\n",
      " 96%|█████████▌| 96/100 [00:39<00:00,  4.56it/s]\n",
      " 97%|█████████▋| 97/100 [00:39<00:00,  4.56it/s]\n",
      " 98%|█████████▊| 98/100 [00:40<00:00,  4.52it/s]\n",
      " 99%|█████████▉| 99/100 [00:40<00:00,  4.43it/s]\n",
      "100%|██████████| 100/100 [00:40<00:00,  4.29it/s]\n",
      "100%|██████████| 100/100 [00:40<00:00,  2.46it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Draft Probability: 0.006988525390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52858\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0085601806640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43813\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0088958740234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54698\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00038886070251464844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87455\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0269775390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10090\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00095367431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88914\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.000453948974609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 78162\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005275726318359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83131\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.80322265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43909\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00010454654693603516\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59408\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.78564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101289\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008797645568847656\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59408\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.170654296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19704\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04962158203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36217\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00435638427734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56956\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.48193359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 107346\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.107421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70591\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 118673\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0557861328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94342\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.311279296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89204\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.50341796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23547\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0017404556274414062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00025272369384765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127823\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.19970703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43277\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00024819374084472656\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7404\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005329132080078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83017\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 112425\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06451416015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70776\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.067138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101694\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00020551681518554688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20481\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00023305416107177734\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104781\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0167236328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53218\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.043487548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35010\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.048797607421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7443\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009107589721679688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47967\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00018596649169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101369\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0263671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42240\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.249755859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91137\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6810\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009112358093261719\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21903\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0545654296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.022247314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70776\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.80322265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70776\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.26611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 80040\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00026226043701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94848\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013513565063476562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76153\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005687713623046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2196\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001651763916015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 86126\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.022857666015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 90611\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005313873291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 115386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006856918334960938\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 119711\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.013641357421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55489\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008220672607421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 72719\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006914138793945312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70776\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.453857421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111408\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 6.884336471557617e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 118635\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001424551010131836\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102882\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00644683837890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2768\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1949462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42240\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3115234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 109529\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016260147094726562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79159\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2919921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47172\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018463134765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61885\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.169677734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15205\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002390146255493164\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 37708\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.009918212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91627\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.016937255859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74418\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03546142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106521\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003230571746826172\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 125424\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.260009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21047\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1187744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76043\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0114288330078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73237\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00867462158203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Almost everyone likes to eat apples. Apples grow  in nearly every part of the world. The United States produces  more apples than any other country except France. The states of Washington and New York grow the most apples. New York is on the east coast and Washington is on the west near Canada.\n",
      "Apples are red, yellow or green. _ Many people like to carry apples to work or to school to eat with their lunches. Most American people are often too busy or too tired to cook, so they often have their lunches very simply. Apple juice is also a popular drink and apple pie is the favorite dessert of many Americans. The state of Washington is proud  of its apples. The trees there produce nearly five billion  apples every year - one apple for every man, woman and child in the whole world.\n",
      "\n",
      "Question: Many Americans like to eat apples during lunch because they   _   at noon.\n",
      "A. eat nothing but apples\n",
      "B. feel it better to eat apples\n",
      "C. always eat simple food\n",
      "D. can get apples easily\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "\n",
      "### Outcomes\n",
      "\n",
      "#### By the end of the section, students will be able to:\n",
      "\n",
      "• Describe the origins of apples and their use in cooking.\n",
      "• Explain the importance of apple varieties and their use in the United States.\n",
      "• Describe the role of apple trees in the United States.\n",
      "• Describe the role of apples in the United States.\n",
      "• Describe the role of apples in the United States.\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.250732421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.052215576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The seahorse is a very strange fish. Do you know what its head looks like? It looks like a horse. Of course it is not as big as a horse. You can pick it up with one hand. It swims with its head up and tail down.\n",
      "This strange looking fish often remains still. It will hang on to a bit of weed  with its tail. Then when a small fish swims by, the seahorse will suddenly jump and eat it up.\n",
      "Mother seahorse lays eggs .These eggs are kept in Father's pouch .When the eggs hatch, the babies pop out of the pouch into the sea.\n",
      "\n",
      "Question: A seahorse is   _  .\n",
      "A. bigger than a horse\n",
      "B. the same size as a horse\n",
      "C. as big as a horse\n",
      "D. much smaller than a horse\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34286\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00859832763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1304931640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Can plants eat people? Probably not, but there are many plants that eat meat. Some of them are big. And they can eat small animals. One famous meat-eating plant is the Venus flytrap .\n",
      "The Venus flytrap is a very strange plant. It grows in dry parts of the United States. Its leaves are like the pages of a book. They can open and close very quickly. Inside the leaves, there are three small hairs. If a fly touches one of the hairs, the leaf closes quickly. The fly cannot get out. In about half an hour, the leaf _ the fly until it is dead. Then, the plant covers the fly. Slowly, the plant eats the fly.\n",
      "Why do plants do it? Most plants get what they need from the sun, the air, and the ground. In some places, the ground is very poor. It doesn't have all these important things, especially nitrogen . Animal meat has a lot of nitrogen, so some plants eat meat to get what they need. Let's hope that some of the bigger plants don't get the same idea!\n",
      "\n",
      "Question: The Venus flytrap is a kind of   _  .\n",
      "A. plant\n",
      "B. animal\n",
      "C. food\n",
      "D. meat\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1424560546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85725\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003216266632080078\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: There was a man playing the piano in a bar. He was a good piano player. People came out just to hear him play. But one night, a customer told him he didn't want to hear him just play anymore. He wanted him to sing a song.\n",
      "The man said, \"I don't sing.\"\n",
      "But the customer was persistent . He told the bartender, \"I'm tired of listening to the piano. I want the man to sing!\"\n",
      "The bartender shouted. \" Hi! If you want to get paid, sing a song. The customers are asking you to sing!\"\n",
      "So he did. He sang a song. A piano player who had never sung in public did so for the very first time. And nobody believed that he sang so well.\n",
      "He has talent he was _ ! He may have lived the rest of his life as a no-name piano player in a no-name bar, but because he had to sing, he went on to become one of the best-known entertainers in America.\n",
      "\n",
      "Question: There was a man playing the piano in a bar,   _   likes his music.\n",
      "A. everyone\n",
      "B. someone\n",
      "C. no one\n",
      "D. anyone\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.90283203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60519\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002727508544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: One day in the eighth grade, I was taking a Math Test on basic trigonometry  . Now for a middle school student, there was nothing basic at all about it. So I had studied for about two hours the night before. After reviewing it for some time, I had started to understand it, so then I closed the book and  _ . However, it was not until midnight that I fell asleep. The next day, when I got the test, it might as well have been written in Serbian (which I don't know how to read). I tried my best to work out the hard problems, but the numbers I came up with were strange. I sat back on my chair and looked for any possible answers, but I could not remember anything or think correctly. I started thinking about my dad coming home from work to find that I failed the test ...\n",
      "\"How could you have failed the test? I am certain that nobody else in the whole class got as bad a grade as you did!\"\n",
      "Naturally I didn't want that to happen. My dad was also really busy at work at present, so I was afraid that this might make him mad. When feeling hopeless, I noticed that my table partner was writing fast on his test. I could see smoke rising up from how fast he was writing. I was attracted to look over at his test, but then the many bad results I had heard about cheating   came into my mind. I reasoned that if I started cheating now, it would be hard to give up that habit during high school. In the end, I decided not to copy his answers, and got a B- on that test. Even though my dad gave me a hard time about it, it would have been a lot worse if he found out that I had given in and cheated.\n",
      "\n",
      "Question: From the passage, we know that the writer   _  .\n",
      "A. could read Serbian\n",
      "B. didn't cheat at last\n",
      "C. got a good grade at last\n",
      "D. didn't work hard that night\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.464111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95351\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008034706115722656\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Joe Read studied in this school for fourteen years. When he finished school, he was already eighteen years old. And then his father said to him, \"You finished school, and you are a good student. Now you may go to town and get a good job. They need some clever people to work in the office. The people there can get a lot of money now. If you stay at home, you can't get money from our family.\" A few weeks later, Joe went to the office and asked for a job there. A man took him into a small room and gave him some questions on a piece of paper. Joe answered the questions quickly, and he gave the paper to the man. The man looked at the paper for a few minutes and then asked, \"You were born on Sep. 23. But which year were you born in?\" Joe answered, \"Oh, every year.\"\n",
      "\n",
      "Question: From Joe's answered, \"Oh, every year.\", we can infer  that  _  .\n",
      "A. he didn't want to work in the office\n",
      "B. he was hardworking but dishonest\n",
      "C. he was outgoing and clever\n",
      "D. in fact, he didn't really answer the man's question\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22529\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001049041748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10296630859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Bush takes ice bucket challenge . Bush has joined a growing list of celebrities across the world to take the ice bucket challenge. He did it to help raise money for Lou Gehrig's disease and chose his predecessor  Bill Clinton  to do it next.\n",
      "In a video posted on Wednesday on Bush's Facebook page, the former president, wearing a navy blue coat while sitting at a table, said he was challenged by his daughter Jenna Bush Hager to take the challenge.\n",
      "As he wrote the check, Laura Bush appeared with a white bucket and poured ice water over her husband's head and then said, \"That check is for me. I don't want to ruin my hairstyle.\"\n",
      "Bush then announced his choice. \"Now it's my right to challenge my friend Bill Clinton to the ALS Challenge,\" he said. \"Yesterday was Bill's birthday and my gift to him is a bucket of cold water.\"\n",
      "The online campaign challenges people to either dump a bucket of ice water over their heads or donate to support research for Lou Gehrig's disease. When a person accepts the ice bucket challenge, he or she must challenge another person to partake in the raising money effort. Many famous people in different fields around the world took part in the activity, including Bill Gates, Stephen King, Christiano Ronaldo, and Lady Gaga, and so on.\n",
      "\n",
      "Question: _   challenge Bush to do so.\n",
      "A. His mother\n",
      "B. His wife\n",
      "C. His daughter\n",
      "D. His sister\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2000732421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.488525390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Zhao Tao, a student from No.2 Middle School, has just come back from Shanghai. This morning, he told us something about his pleasant trip .When he talked about the Shanghai World Expo, he was so excited and so proud that he kept telling about it for several hours. The Shanghai World Expo held by China has been on for more than one month .It started on May 1st, and will end on October 31st, 2010. Its main idea is \"Better City, Better Life.\" About 242 countries and organizations are attending this expo. Many new products can be seen here, such as we can see the snow in the South Korea Corporate Pavilion  every day during this hot summer though it seldom snows in Shanghai. And we can see, hear, touch and smell the 4-D films at the Oil Pavilion. How wonderful all these new products are!\n",
      "China Pavilion is in the center of the expo garden. It is very beautiful. It represents the development of China from ancient time to now. It's a pride of our China!\n",
      "Thousands of people from all over the world are coming to the expo every day. And many volunteers are working for them. All the tourists are very pleased and they say that the Shanghai World Expo is the greatest one in the world so far.\n",
      "However, Zhao said, \"The expo garden is now so crowded. If you want to visit it, you'd better go there during the summer vacation.\"\n",
      "\n",
      "Question: In which pavilion can we see the snow during this hot summer?\n",
      "A. China Pavilion.\n",
      "B. the Oil Pavilion.\n",
      "C. the South Korea Corporate Pavilion.\n",
      "D. I don't know.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006011962890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 65869\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 8.314847946166992e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Mr. and Mrs. Green lived in a big city. One summer they went to the country for their holiday. They enjoyed it very much because it was a quiet, clean place.\n",
      "One day they went for a walk early in the morning and met an old man. He lived on a farm, and he was sitting in the warm sun in front of his house. Mr. Green asked him, \"Do you like to live in this quiet place?\"\n",
      "The old man said, \"Yes, I do.\"\n",
      "Mr. Green then asked, \"What are the good things about it?\"\n",
      "The old man answered, \"Well, the people here know each other. They often come and visit me, and I often go and visit them. And there are also many children here.\" Mr. Green said, \"That's interesting, and what are the bad things?\"\n",
      "The old man thought for a moment and then said, \"Well, the same things, really.\"\n",
      "\n",
      "Question: Mr. and Mrs. Green went to the country   _  .\n",
      "A. to see the old man\n",
      "B. to spend their holiday\n",
      "C. to see the quiet place\n",
      "D. to have a walk\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2587890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88818\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005321502685546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Do you know why different animals or pests have their special colours? Colours in them seem to be mainly used to protect themselves.\n",
      "Some birds like eating locusts , but birds cannot easily catch them. Why? It is because locusts change their colurs with the changes of the colours of crops .When crops are green, locusts look green .But as the harvest time comes, locusts change into the same brown colour as crops have .Some other pests whose colours are different from plants are easily found and eaten by others .So they have to hide themselves for lives and appear only at night.\n",
      "If you study the animals' life, you'll find the main use of colours is to protect themselves .Bears, lions and other animals move quietly through forests .They cannot be easily seen by hunters because their colours are much like the trees.\n",
      "Colours are useful not only on the land , but also in the sea .A kind of fish in the sea can give out a kind of black liquid when the fish face danger. The liquid spreads over quickly, so they cannot be found by their enemies and can quickly swim away. That is why they can live safely though they are not strong at all.\n",
      "\n",
      "Question: Which is the best title for this passage?\n",
      "A. The colours of the seasons\n",
      "B. Animals on the land and in the sea\n",
      "C. The main use of colours for animals and pests\n",
      "D. How to keep safe in the sea\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53645\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00876617431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0640869140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Be honest. That's all you have to do on Honesty Day. It would be great if we were all honest every day of the year. It's good that there is a day to encourage honesty. M. Hirsh Goldberg started Honesty Day. He chose the last day of April because the first day is April Fool's Day, which celebrate lies. On Honesty Day, anyone may ask you any question and you should give a true and honest answer. That means that you have knowledge of Honesty Day.\n",
      "M. Hirsh Goldberg wrote a book on telling lies. He said in his book that almost all person lie about 200 times a day. In our daily life, a typical life for a man is \"I did not drink that much\" and for a woman is \"Nothing is wrong, I'm fine.\" It is found that nurses are the most honest people, while sales people and politicians are the biggest liars.\n",
      "Every Honesty Day, M. Hirsh Goldberg hands out prizes to honest people.\n",
      "\n",
      "Question: M. Hirsh Goldberg  started Honesty Day to  _  .\n",
      "A. celebrate lies\n",
      "B. encourage honesty\n",
      "C. ask questions\n",
      "D. hand out prizes\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5987\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00942230224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.83642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Jeff  Keith has only one leg. When he was 12 years old ,Jeff had cancer . Doctors had to cut off most of his right leg.\n",
      "Every day Jeff puts on an artificial leg. The leg is plastic. With the plastic leg Jeff can ski ,ride a bicycle ,swim and play soccer. He can also run.\n",
      "Jeff made a plan with his friends who had plastic legs, too. They decided to run across America. They all wore special T-shirts. On it was \"Run ,Jeff, Run ,Jeff Keith's Run Across America.\"\n",
      "When he was 22 years old,Jeff  Keith ran across the United States from the east to the west. He started running in Boston. Seven  months later ,he stopped running in Los Angeles . He ran 3200 miles. Jeff wore out 36 pairs of running shoes and five plastic legs. Jeff stopped in cities on the way to Los Angeles. In every city people gave Jeff money .The money was not for Jeff ,but for American Cancer Society .The Society used the money to know more about cancer .\n",
      "On the way to Los Angeles Jeff talked to people about cancer. Jeff is disabled ,but he can do many things. He finished college and is studying to be a lawyer .Jeff says, \"People can do anything they want to do .I want people to know that I ran not only for disabled people ,I ran for everybody.\"\n",
      "\n",
      "Question: Jeff's friends ran across America with him .They all have no   _\n",
      "A. T-shirts\n",
      "B. legs\n",
      "C. shoes\n",
      "D. bicycles\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4581\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004987716674804688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20234\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006336212158203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
      "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
      "\n",
      "Question: Where is Wendy from?\n",
      "A. China.\n",
      "B. England.\n",
      "C. America.\n",
      "D. Australia.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52822\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003077983856201172\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106623\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013723373413085938\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: My friends like different clothes. Sue likes red clothes. She is often in a red skirt and red shoes. Mina likes white clothes. She is in a white shirt. Her sister Emma likes to wear a green skirt. She looks nice. David often wears a white cap and black pants. Peter often wears a white coat and black pants.\n",
      ",.\n",
      "\n",
      "Question: Mina is in a white   _  .\n",
      "A. shirt\n",
      "B. skirt\n",
      "C. dress\n",
      "D. coat\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0439453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98681\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004730224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Driving a car at a high speed along a highway seems to be fun. You only need to follow the bright traffic signs beside the highway and it will take you where you wish to go. But to a London taxi driver, driving is not an easy job. A taxi driver needs to have not only good driving skills but also a good knowledge of the city of London, from the loneliest street to the popular restaurant around. He has to be at the service of all kinds of passengers   at all times.\n",
      "A London taxi driver said the following about his job.\n",
      "During the night it is usual for him to stop two or three times for some food. He said, \"I never drink when I'm working, otherwise I'd lose my license  .\"\n",
      "He normally goes home between two and three o'clock in the morning. There are times he has to stay longer and try to make more runs. He said, \"That's the worst thing about working for yourself. If you don't make money, no one is going to give it to you. \"\n",
      "London taxi drivers not only \"take\" but also \"give\". Every summer hundreds of poor children from London go for a day at the sea -- by taxi! There rides are paid by the taxi drivers. At the sea, they are met by the mayor   , and a lunch party is also held for the taxi drivers and the children. After a happy day's running around the beaches and visiting the market there, the children go home again by taxi, free of charge of course!\n",
      "\n",
      "Question: London taxi drivers try to make more runs sometimes mainly because    _   .\n",
      "A. they make a living by driving\n",
      "B. they prefer to work for themselves\n",
      "C. they want to help more passengers\n",
      "D. they are used to working deep into the night\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63726\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0031490325927734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00841522216796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Mother loves her son. But he is a bad boy. He doesn't listen to what his mother says. He slaps  his mother. Another time he makes her fall to the floor.\n",
      "He goes out of school. He plays games on the computer day and night. He shouts loudly when he wins a game. He doesn't care( ) if  his mum is sleeping. She asks him to be quiet. He asks her to be out. But he loves her cooking. She cooks delicious food. \"Mum, I'm hungry,\" he says every day. She spends hours every day cooking for him. He never  says \"thank you\". He never says the food is delicious. He finishes his food and goes back to his computer. His mum washes the dishes by hand. She cleans the kitchen. She does all the shopping. She works when he plays.\n",
      "One day she thinks that's enough. When he is 19 years old, she leaves  her son. She goes into her car and drives away.\n",
      "\n",
      "Question: What does the boy do to his mother?\n",
      "A. He loves his mother.\n",
      "B. He makes her mother fall to the floor.\n",
      "C. He is quiet when mother is sleeping.\n",
      "D. He helps mother clean the kitchen.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.35009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102679\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005893707275390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: This year, \"Wild China\" is famous, it shows us the beautiful scenes .But in fact, the environment around  us is getting worse and worse .In some places,we can't see fish swimming in the river or trees on the mountains. Many animals are facing the danger of living .At the same time, man is killing animals just for getting their skin and meat. In our country, the number of wild animals is becoming smaller and smaller. Some of them are even dying out .\n",
      "It's time to protect  our environment .But what can we do? How to protect _ ? For example,we can go to school on foot or by bike . we can use shopping baskets not plastic  bags when we go shopping,and we can use both sides of the paper to write . Also , we should plant more trees to protect the animals' living.\n",
      "In a word,if everyone does more to our environment ,our life will be better. \"There is only one earth\",I hope everyone will protect our environment well.\n",
      "\n",
      "Question: Which of the following is NOT true?\n",
      "A. We should go to school on foot or by bike.\n",
      "B. We should use plastic  bags when we go shopping.\n",
      "C. We should use both sides of the paper to write.\n",
      "D. We should plant more trees to protect the animals' living.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.18212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.67529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Hunan TV's new program,   Dad,Where Are We Going? has become very popular since last year. The show tells us that fathers should take part in their children's growing-up. In fact, this topic was always mentioned by Zeng Guofan (1811-1872). a famous official during the late Daoguang Period of the Qing Dynasty (1644-1912).\n",
      "Although Zeng spent most of his time away from his family, his letters back home to his children and younger brothers have become famous. In these letters, there are many helpful suggestions on proper behavior . Many of his ways on child education are popular among today's Chinese parents, including reading classical books and so on. His child-raising methods are useful for today's busy fathers. Like Zeng, they also spend most of their time away from home.\n",
      "According to Zeng,  the purpose of education was to learn wisdom from books, rather than getting an official position. Children should know that the most important purpose of studies is to get more knowledge about nature and life.\n",
      "\"But now ,parents just want their children to be rich and powerful. \" Mr. Tang, a writer in China, said.\n",
      "Some teachers say that parents need to build a good relationship with their children. Parents shouldn't force  their children to realize their wishes.\n",
      "In Zeng's letters, he asked his young children to do housework as part of their daily life, even though his children had many helpers. He believed that doing housework would make his children more confident and independent .\n",
      "\n",
      "Question: When was Zeng Guofan born?\n",
      "A. In 1811.\n",
      "B. In 1644.\n",
      "C. In 1872.\n",
      "D. In 1912.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03643798828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9501953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
      "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
      "\n",
      "Question: We have   _   in the dining hall.\n",
      "A. breakfast\n",
      "B. lunch\n",
      "C. dinner\n",
      "D. supper\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5703\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00010836124420166016\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53709\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0023365020751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: My name is David and I have two brothers, Mark and Bruce. We like hamburgers for lunch. Mark and I like French fries, but Bruce doesn't. I don't like eggs for breakfast, but Mark and Bruce do. I like fruit for breakfast. We really like chicken and salad for dinner.\n",
      "\n",
      "Question: _   like chicken.\n",
      "A. David and Mark\n",
      "B. Mark and Bruce\n",
      "C. David and Bruce\n",
      "D. David, Mark, and Bruce\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66533\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018482208251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05474853515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Many boys and girls love watching TV. They spend many hours watching TV every day. But many parents let their children watch TV at special time.\n",
      "TV shows are like books and movies. There are many kinds of TV shows, such as sitcoms, soap opera, sports shows, fashion shows, and so on. A kid can learn good things and bad things from them. Some shows help children know the news all over the world. Children don't have to go to the zoos or the parks to see animals. They can see on TV at home. Some shows teach children how to cook, how to paint or how to study.\n",
      "Many boys and girls think it is interesting to watch TV but it is also interesting to read books , to play games or to visit the friends.\n",
      "\n",
      "Question: What does the writer think of watching TV?\n",
      "A. It's good for kids\n",
      "B. It's bad for kids\n",
      "C. Children don't need to watch TV\n",
      "D. Something is good, but something is bad\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55839\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0732421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0204925537109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: This is Kim and Kate's bedroom. The blue bed is Kate's and the green one is Kim's. They are sisters. Kate's schoolbag is red. It's on the bed. Kim's schoolbag is yellow. It's on the chair. They have a computer. It's on the table. Their alarm clock is on the table, too. There is a baseball under their table. It's Lily's. Lily is Kim and Kate's good friend.\n",
      "\n",
      "Question: _   bed is green.\n",
      "A. Kim's\n",
      "B. Kate's\n",
      "C. Lily's\n",
      "D. Kim's friend's\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30173\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009036064147949219\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17570\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00974273681640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Mo, the first Nobel winner in literature born and living in China, said he had trouble with the sudden publicity, which put a lot of pressure on him.\n",
      "\"I only hope to return to my writing desk as soon as possible, and I would also like to do well in society anonymously. \" Mo said. He was bothered by a large number of requests asking him to offer help that took advantage of his fame. \" I was upset the first several days after the prize announcement, but then I realized the prize is just like a mirror that reflects various attitudes about my winning, and more, reflects the real me,\" Mo said. \"I still consider myself an ordinary citizen who writes. And presenting quality works is my duty and best way of giving back to society. I'm no superstar,\" he emphasized  several times.\n",
      "Mo believes Chinese literature has achieved much in the past thirty years, and the driving force behind that is not the prize. Writers' creations should not be driven by awards, or criticism, or readers' expectations. Mo said he misunderstood the standards of the academy's selection before he visited Stockholm  to receive the prize in December.\n",
      "\"I thought they were judging the authors' personality or political features, then I learned the sole standard of their selection is literature itself, which is also deeply based in the Swedish people's long-established practice of reading a large number of books,\" Mo said.\n",
      "During the forum, established Chinese and Australian writers discussed subjects as diverse as tradition and modernity, the local and the universe and cultural inclusiveness. And they will also read works to each other and the readers. The writers communication will further promote  Chinese writers to a global audience.\n",
      "Australian Ambassador  to China Frances Adamson agreed. \"It's a milestone  of literary exchanges between the two countries, who are longtime friends,\" Adamson said.\n",
      "\n",
      "Question: Mo is the first Nobel winner in   _   born and living in China.\n",
      "A. literature.\n",
      "B. peace\n",
      "C. physics\n",
      "D. chemistry\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1806640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03717041015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: China and the Netherlands   are long-time friends. The Netherlands is more than 41,500 square kilometres in area. It is a bit larger than the size of Taiwan, China.\n",
      "The Netherlands is rich in culture and art. It is home of many great artists, for example, Vincent van Gogh. Besides fine art, the Netherlands is also called the country of tulips  . It has the world's largest tulip garden: Keukenhof garden.\n",
      "Dutch people are very hard-working. There's a saying: \"God made the Earth, but the Dutch made Holland.\" More than a quarter of the country is below sea level. So Dutch people build many dams   to protect the country from flooding. They have created almost one sixth of the country from seas and rivers!\n",
      "Did you know?\n",
      "* Rubber ducks are popular around the world. Dutch artist Florentijn Hofman created it in 2007. The yellow duck is 26 metres high.\n",
      "* Wooden clogs   are traditional shoes in the Netherlands. They make good gifts for tourists.\n",
      "* In the Netherlands, it is impolite to start eating at once. Dutch people will sometimes say \"delicious\" before eating.\n",
      "* Like the UK, the Netherlands also has\n",
      "kings and queens.\n",
      "\n",
      "Question: What is not talked about in the reading?\n",
      "A. Table manners.\n",
      "B. Artists.\n",
      "C. Weather.\n",
      "D. Tulips.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98373\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008373260498046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74652\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011453628540039062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Hi, dear boys and girls! Do you know how to be a healthy kid? Here are some rules you should follow.\n",
      "First, eat different foods, especially fruit and vegetables. You may have a favourite food, but you'd better eat something different, if you eat different foods, you will probably get more nutrients  your body needs.\n",
      "Second, drink water and milk as often as possible. When you're really thirsty, cold water is the No. 1 choice. Milk is a great drink that can give you more calcium your body needs to grow strong bones.\n",
      "Third, listen to your body. How do you feel when you are full? When you are eating, notice how your body feels and when your stomach feels comfortably full. Eating too much will not make you feel comfortable and make you fat.\n",
      "Fourth, limit  screen times. Screen time is the time you watch TV, DVDs and videos, or using computers. It is good to take more exercise, such as basketball, bike riding and swimming. You can't watch TV for more than two hours a day.\n",
      "Fifth, be active. One thing you'd like to do as a kid is to find out which activity you like best. Find ways to be active every day.\n",
      "Follow these rules and you can be a healthy kid.\n",
      ", , .\n",
      "\n",
      "Question: Which of the following isNOT True?\n",
      "A. We should try to live in an active way in our life.\n",
      "B. You can eat your favourite food as much as possible.\n",
      "C. When you're eating, you don't have to notice how your body feels.\n",
      "D. Don't limit screen times.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47830\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08636474609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Tiger Mom,\n",
      "You've been criticized  a lot since your book, Battle Hymn of the Tiger Mother, came out. One problem is that some people don't get your humor. They think you're serious about all things and Lulu and I are suffering a lot from such a strict mother. That is not true.\n",
      "But for real, it's not their fault. No outsider can know what our family is really like. They don't hear us laughing over each other's jokes. They don't see us eating our hamburgers with fried rice. They don't know how much fun we have when the six of us dogs included squeeze into one bed and argue about what movies to download from Netflix.\n",
      "I admit it: Having you as a mother was no tea party. There were some play dates I wish I'd gone to and some piano camps I wish I'd got away from. But now that I'm 18 and about to leave the tiger den , I'm glad you and Daddy raised me the way you did.\n",
      "A lot of people have accused you of producing robot kids who can't think for themselves. Well, I came to the opposite conclusion: your strict parenting made me more independent .\n",
      "Everybody's talking about the birthday cards we once made for you, which you refused to take because they weren't good enough. Funny how some people believe that Lulu and I will feel hurt for life. But let's face it: It took me 30 second; I didn't put my heart into it. That's why, when you rejected it, I didn't feel hurt at all.\n",
      "There's one more thing: I have come to understand what it really means to live a meaningful life to the fullest. To me, it's about knowing that you've tried your best, body and mind. You feel _ when the piano piece you've practiced for days and hours finally comes to life beneath your fingertips. You feel _ when you do something on your own that you never thought you could. And for that, Tiger Mom, thank you.\n",
      "Yours,\n",
      "Sophia\n",
      "\n",
      "Question: Which of the following sentences is Wrong\n",
      "A. Sophia is thankful for what her strict mother has made her\n",
      "B. Sophia has never been disturbed by tea parties.\n",
      "C. Sophia is satisfied with her parents' way of raising her.\n",
      "D. Tiger Mom was blamed for rejecting her daughters' birthday cards.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "{'predicted_text': {'exact_match': 0.4399999976158142, 'accuracy': 0.44}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.40503167629241943}, 'time_per_token': {'mean': 0.22933704748749734}, 'tokens_per_second': {'mean': 4.492270936965943}}\n",
      "Using standard benchmark for dataset: race_h\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Sales of laptop computers passed desktops in the U.S. for the first time ever this fall, according to market-research firm IDC. That's bad news for backs, necks and shoulders.\n",
      "Laptops are bad for our body. When you work at a computer, the keyboard should be at elbow height and the monitor should be roughly at eye level, so you can sit well in a chair. But most users simply set their laptops on a desk or table. The keyboard is too high, which makes your arms reach up, your shoulders feel tired and your wrists bend down. The monitor is too low, which pulls your head and neck forward and down and your back may feel hurt.\n",
      "That's OK if you use your laptop for a short time. But if you use one for hours without stopping - as do millions of college students, business travelers, telecommuters, video-gamers and growing numbers of office workers - your body may feel hurt. Ergonomics experts have warned about laptop problems for years. But people still like laptops better than the desktops. And they use laptops anywhere - in bed, on the floor - in all kinds of positions.\n",
      "\"How can a mouse or a keyboard hurt you?\" says Thomas Caffrey, the founder of Myofactors LLC, \"Wrong positions can be bad for your body. As time goes by, a wrong position can lead to pain in the neck, shoulders, back and arms, as well as headaches.\"\n",
      "\n",
      "Question: The writer asks us not to use the laptop   _  .\n",
      "A. for a short time\n",
      "B. to play video games\n",
      "C. for hours without stopping\n",
      "D. to buy things on the Internet\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [423]\n",
      "[Prompt]:\n",
      "Article: South Korean stars shined brightly at the Opening Ceremony of the 17th Asian Games held here on Friday, Sept. 19 in Inchen .\n",
      "Many stars gave shows during the welcoming performance.The most famous K-pop boy group, EXO, performed two songs on stage.Famous actors followed to show up on stage, including Jang Dong-gun, Hyun Bin, and Kim Soo-hyun.Lee Young-ae, the South Korean actress known for volunteering, was the last torchbearer  and lighted the cauldron  with two children.\n",
      "After the lighting of the flame, 16 more minutes of other K-pop performances were held. JYJ sang the theme song 'Only One' and Psy and Chinese pianist Lang Lang finally performed \"Gangnam Style\" with the 60,000-strong audience.\n",
      "\n",
      "Question: The Opening Ceremony of the 17thAsian Games was held on   _  .\n",
      "A. Sept. 16\n",
      "B. Sept. 17\n",
      "C. Sept. 18\n",
      "D. Sept. 19\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: How much do you know about Albert Einstein?\n",
      "Albert Einstein, born on March 14, 1579 in Germany, was a great scientist in the world. He was strange because he hated haircuts and new clothes. He believed in peace. All his life, he hated war. However, his most famous idea, E=mc2, helped create the world's most dangerous weapon . Many people think he was the smartest person in the world. But Einstein said that _ \n",
      "What did he like?\n",
      "Einstein liked learning sailing . He sailed in small boats all his life. He once joked, \"Sailing is the sport that takes the least energy!\"\n",
      "When Einstein was a child, his mother made him take violin lessons. At first, he didn't like the violin. But then he learned to love music and became a good violinist. Later, he said, \"Love is the best teacher.\"\n",
      "Why is the sky blue?\n",
      "In 1910, Einstein asked a question which many children often ask, \"Why is the sky blue?\" After his careful research, he answered the question like this: \"It's because light is made up of many colors including blue. When light travels to Earth, gas particles spread the blue light all over the sky.\" His answer is true in physics.\n",
      "\n",
      "Question: Einstein  _   learning sailing and playing the violin.\n",
      "A. was interested in\n",
      "B. looked forward to\n",
      "C. was known for\n",
      "D. had no interest in\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Mr. Yang is a doctor. He cares a lot about not only others' health but also his own. He controls( )his weight carefully. To him, _ is the most important thing to do if one wants to enjoy good health.\n",
      "Mr. Yang controls his weight in two ways: exercising and not eating much. As a doctor. Mr. Yang is too busy to go to the gym. He exercises by getting off the bus one or two stops early and walking the rest of the way to his office.\n",
      "Besides, he doesn't eat much. Mr. Yang has a special habit. When he buys a belt, he asks the salesperson to punch a hole in the belt at 90cm from the buckle end of the belt, so that he ca always remind  himself. He will stop eating if he feels the belt a little too tight . Mr. Yang thinks exercising doesn't work as well as eating less.\n",
      "\n",
      "Question: Mr.Yang controls his weight in   _   way(s).\n",
      "A. one\n",
      "B. two\n",
      "C. ninety\n",
      "D. many\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Foreign visitors are often puzzled   in Japan because most streets there don't have names. In Japan, people use _ in their directions instead of street names. For example, the Japanese will say to travelers, \"Go straight down to the corner. Turn left at the big hotel and go pass a fruit market. The post office is across from the bus stop.\"\n",
      "In the countryside of the American Midwest, usually there are not many landmarks. There are no mountains, so the land is very flat  . In many places there are no towns or buildings within miles. Instead of landmarks, people will tell you directions and distance. In Kansas or lowa, for example, people will say, \"Go north two miles. Turn east, and then go another mile.\"\n",
      "People in Los Angeles, California, have no idea of distance on the map: the measure   distance by means of time, not miles. \"How far away is the post office?\" you ask. \"Oh,\" they answer, \"it's about five minutes from here.\" you say, \"Yes, but how many miles away is it?\" They don't know.\n",
      "People in Greece sometimes do not even try to give directions because visitors seldom understand the Greek language. Instead of giving you the direction, a Greek will often say, \"Follow me.\" Then he'll lead you through the streets of the city to the post office.\n",
      "Sometimes a person doesn't know the answer to your question. What happen in this situation? A New Yorker might say, \"sorry, I have no idea.\" But in Yucatan, Mexico, no one answer, \"I don't know.\" They think that it is impolite. They usually give an answer, often a wrong one. A visitor can get lost in Yucatan.\n",
      "One thing will help you everywhere. You might not understand a person's words, by maybe you can understand his body language. He or she will usually turn and then point in the correct direction.\n",
      "\n",
      "Question: How many ways of giving directions in the passage?\n",
      "A. Four\n",
      "B. Five\n",
      "C. Six\n",
      "D. seven\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Trees are useful to man in three very important ways. The first important way is that they provide man with food, wood and other products. Trees provide not only man with food, but also many animals with food. Without trees many animals could not live on the earth. It's not easy for man to live on the earth, either.\n",
      "The second important way is that trees give us shade. On a hot summer day, people are eager to have a rest under the shade of a tree after they have walked a long way. You can imagine how important the shade of a tree is to man and to animals.\n",
      "The third important way is that trees help to prevent drought and floods . However, in many parts of the world, man has not realized the third important way. _ has cut trees down in large numbers. In the end he finds that he has lost the best friends he had.\n",
      "\n",
      "Question: In many parts of the world, man has not realized that trees help to  _\n",
      "A. give us food\n",
      "B. give us shade\n",
      "C. prevent drought and floods\n",
      "D. give us wood\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Hello! My name is Kitty. I want to talk about my home town today.\n",
      "My home town is small but pretty. It's about two hours away from London by train. In the centre of the town there is a small lake. There are lots of trees and flowers around the lake. My parents often walk around the lake at the weekend. The air in my home town is very fresh   and clean.\n",
      "There are two schools in my home town, one primary school and one secondary school. I study in the secondary school and my younger sister studies in the primary school. I often ride my bike to school.\n",
      "I usually go to the youth centre to learn drawing with my sister on Friday afternoons. I like going shopping at the weekend. There are two big shopping malls there.[:Zxxk.Com]\n",
      "\n",
      "Question: Kitty often goes to school  _  .\n",
      "A. on foot\n",
      "B. by bus\n",
      "C. by underground\n",
      "D. by bike\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: To make sure that you enjoy your visit to the Harper Hot Springs and that you are safe during your visit, please take time to read the following:\n",
      "Do not put your head under the hot water because it may be bad for your eyes.\n",
      "Do not run around because the floors may be _ \n",
      "Do not leave your children alone.\n",
      "Do not leave your things about. Just ask one of our workers to look after your things.\n",
      "Do not eat or drink anything in the area because we want to keep the area clean .There is a place for you to eat and soft drinks when you need to have a rest.\n",
      "Do not bring anything made of glass into the area, because it maybe easily to broken when you fall.\n",
      "Do not bring any hard drinks into the area.\n",
      "Do not smoke in the area.\n",
      "Do not stay in the sunlight for too long.\n",
      "We hope that you will enjoy your visit here\n",
      ",. . (10)\n",
      "\n",
      "Question: _  is not mentioned in the notice.\n",
      "A. How long visitors can stay in the area\n",
      "B. What visitors cannot come to the area.\n",
      "C. Who can take care of the visitors things\n",
      "D. Whether smoking is allowed in the area\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: The seahorse is a very strange fish. Do you know what its head looks like? It looks like a horse. Of course it is not as big as a horse. You can pick it up with one hand. It swims with its head up and tail down.\n",
      "This strange looking fish often remains still. It will hang on to a bit of weed  with its tail. Then when a small fish swims by, the seahorse will suddenly jump and eat it up.\n",
      "Mother seahorse lays eggs .These eggs are kept in Father's pouch .When the eggs hatch, the babies pop out of the pouch into the sea.\n",
      "\n",
      "Question: The seahorse is   _  .\n",
      "A. a small horse\n",
      "B. a fish\n",
      "C. an egg\n",
      "D. a sea\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
      "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
      "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
      "\n",
      "Question: What did the white lambs think of the black lamb?\n",
      "A. Friendly.\n",
      "B. Kind.\n",
      "C. Ugly.\n",
      "D. Beautiful.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Foreign visitors are often puzzled   in Japan because most streets there don't have names. In Japan, people use _ in their directions instead of street names. For example, the Japanese will say to travelers, \"Go straight down to the corner. Turn left at the big hotel and go pass a fruit market. The post office is across from the bus stop.\"\n",
      "In the countryside of the American Midwest, usually there are not many landmarks. There are no mountains, so the land is very flat  . In many places there are no towns or buildings within miles. Instead of landmarks, people will tell you directions and distance. In Kansas or lowa, for example, people will say, \"Go north two miles. Turn east, and then go another mile.\"\n",
      "People in Los Angeles, California, have no idea of distance on the map: the measure   distance by means of time, not miles. \"How far away is the post office?\" you ask. \"Oh,\" they answer, \"it's about five minutes from here.\" you say, \"Yes, but how many miles away is it?\" They don't know.\n",
      "People in Greece sometimes do not even try to give directions because visitors seldom understand the Greek language. Instead of giving you the direction, a Greek will often say, \"Follow me.\" Then he'll lead you through the streets of the city to the post office.\n",
      "Sometimes a person doesn't know the answer to your question. What happen in this situation? A New Yorker might say, \"sorry, I have no idea.\" But in Yucatan, Mexico, no one answer, \"I don't know.\" They think that it is impolite. They usually give an answer, often a wrong one. A visitor can get lost in Yucatan.\n",
      "One thing will help you everywhere. You might not understand a person's words, by maybe you can understand his body language. He or she will usually turn and then point in the correct direction.\n",
      "\n",
      "Question: Why does a traveler get lost in Yucatan?\n",
      "A. People in Yucatan don't know what the traveler said, so they give a wrong answer.\n",
      "B. People in Yucatan think that \"I don't know\" is impolite, so they give a wrong answer.\n",
      "C. People in Yucatan like making a joke, so they usually give a wrong answer.\n",
      "D. People in Yucatan are bad men, so they usually give a wrong answer.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Did you notice the number on the book in a library? That number is part of the system used by libraries to organize their collections of books. And it's used in many countries. The number on each book tells you exactly what kind of book it is. This system is also useful for knowing where to go in the library to find a book.\n",
      "In this system, there are ten large groups of books. Each of these groups has its own number, such as 100, 200, etc. So, for example, any books about language will have a number 400. On the other hand, any books about history will have a number 900. So, a number in the hundreds place tells you what general group a book is in. If you find a book that has a number in the 500s, you know it is a book about science.\n",
      "However, science is a big group, so the tens place is used to make a more detailed set of science books. For example, math books are included in the group of science books. Math books all have numbers between 510 and 519. Books about the history of Africa have numbers between 960 and 969.\n",
      "The system uses the ones place to give a more exact limit for the subject of a book. A book on the history of South Africa will have the number 968.\n",
      "As you can see, it is a simple system to use as long as you understand what the numbers mean. With this system, the library can keep its books well organized, and people can easily find the book that they want.\n",
      "\n",
      "Question: According to the reading, which sentence is TRUE?\n",
      "A. The number on a book can't be bigger than 900.\n",
      "B. There are ten big groups for books in this system.\n",
      "C. History books can have any number between 500 and 900.\n",
      "D. This system uses both numbers and letters for some books.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: I am an English girl. My name is Lily. I am thirteen. I am at school. Look! This is my school. It is No. 14 Middle School. I am in Class 1, Grade 1. I am in row 3. I am No. 12 at schhol. I have a good friend. She is a girl. Her name is Mary. She is not at school today. I think she is at home. My Chinese teacher is Miss Gao. She is a very good teacher. I don't know her age.\n",
      "\n",
      "Question: I am a/an  _   girl.\n",
      "A. English\n",
      "B. Chinese\n",
      "C. Japanese.\n",
      "D. good\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: \"Make-A-Wish\" is one of the world's most well-known charities . It makes wishes come true for children who have serious illnesses. It gives them hope and joy and helps them forget about their health problems and have fun.\n",
      "It all started in 1980 in Phoenix,Arizona.Christopher was a 7-year-old boy who was very sick. He always dreamed of becoming a police officer.Tommy Austin and Ron Cox,two police officers, made his wish come true. They gave Cristopher a tour of the city  in a police helicopter( )and made a real police uniform for him.\n",
      "There are four kinds of wishes children usually have:\n",
      "I wish to go. Children ueually want to travel or go to a concert ,a game or a park.\n",
      "I wish to meet. Children sometimes want to meet their favourite actors,singers or players.\n",
      "I wish to be. Some children wish to become actors,singers or police officers.\n",
      "I wish to have. They often want to have a computer, a game, a bike or many other things.\n",
      "Let's hope more wishes will come true in the future.People who work in the charity always try for the best.Almost 25,000 volunteers help,work or give money. Will you be one of them?\n",
      "\n",
      "Question: Which of the following is True according to the passage?\n",
      "A. Sick children just wish to get well.\n",
      "B. Christopher and Tommy are two officers.\n",
      "C. A few people are working for \"Make-A-Wish \".\n",
      "D. \"Make-A-Wish \"has a history of over 30 years.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Air is all around us. It is around us as we talk and play. From the moment we were born, We are surrounded by air. When we sit down, it is around us. When we go to bed, air is also around us. Wherever we are on the earth, We are surrounded by air. We live in air.\n",
      "All living things need air, living things can't live without air. We can go without food or water for a few days, but we can't live for more than a few minutes without air. We breathe in air. When we are working or running, We need more air. So we breathe faster than usual. When we are asleep, We need less air.\n",
      "\n",
      "Question: The writer tells us that   _\n",
      "A. there is less air on the earth than on the moon\n",
      "B. the earth is covered with air\n",
      "C. the earth is covered with water\n",
      "D. there is no air on the earth\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: What are some successful foods? McDonald's Big Macs  are popular. Instant noodles have also become a global  success. Now instant noodles are celebrating their 56thbirthday!\n",
      "Instant noodles were invented in Japan by Momofuku Ando. Trying to find a way to make noodles last longer, Ando began experimenting and in 1958, he made the first ever pack of _ Now, 56 years later, they're eaten all around the world. In fact, they're so popular the Japanese voted   instant noodles as their best invention!\n",
      "Each year, 95 billion packets of instant noodles are eaten, according to the World Instant Noodles Association. In the U.K., people call instant noodles \"pot noodles\". University students like them a lot. During your first semester ,you may be given a gift bag that includes instant noodles! But watch out, people may think you're lazy if you are a pot noodle lover. Why? Because they are cheap and easy to eat!\n",
      "Despite  the bad reputation , the U.N. send instant noodles as part of food aid packages. This is because of their long shelf life and high fat content,, which makes you feel full for longer.\n",
      "However, instant noodles aren't innocent . They're high in fat and salt. Health experts say they're bad for us and we shouldn't eat them too often.\n",
      "\n",
      "Question: From the passage, we can know that instant noodles  _  .\n",
      "A. Can be kept longer than common noodles\n",
      "B. were the best invention in the world\n",
      "C. were the best food aid package\n",
      "D. are good for us and we should eat them often\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Hello! My name is Kitty. I want to talk about my home town today.\n",
      "My home town is small but pretty. It's about two hours away from London by train. In the centre of the town there is a small lake. There are lots of trees and flowers around the lake. My parents often walk around the lake at the weekend. The air in my home town is very fresh   and clean.\n",
      "There are two schools in my home town, one primary school and one secondary school. I study in the secondary school and my younger sister studies in the primary school. I often ride my bike to school.\n",
      "I usually go to the youth centre to learn drawing with my sister on Friday afternoons. I like going shopping at the weekend. There are two big shopping malls there.[:Zxxk.Com]\n",
      "\n",
      "Question: There is  _  in the centre of the town.\n",
      "A. a primary school\n",
      "B. a secondary school\n",
      "C. a small lake\n",
      "D. a shopping mall\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: I am a Chinese boy. My name is Li Ming. I'm a student. In my class, some of the boys like playing football very much. Wu Jun and I are on school football team. And some of them like playing basketball. _ Han Mei and Zhang Hong are on school volleyball team. Each of them has a tennis racket. In a word  , everyone in our class likes sports very much.\n",
      "\n",
      "Question: The girls like playing   _  .\n",
      "A. tennis and basketball\n",
      "B. football and basketball\n",
      "C. tennis and volleyball\n",
      "D. volleyball and basketball\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: One day when Jack was walking in the park, he saw a woman, who lived a few miles away, sitting on a bench  with a dog beside her. The dog was looking up at the woman.\n",
      "Jack walked up to the woman and said, \"Hello, Sue, how are you? May I sit and talk with you for a while?\" \"Of course, please sit down,\" Sue said. Jack sat down next to Sue on the bench, and they talked quietly together. The dog continued to look up at Sue, as if waiting to be fed.\n",
      "\"That's a nice dog, isn't he?\" Jack said, pointing  at the animal.\n",
      "\"Yes, he is. He's handsome. He's a bit of a mixture , but that's not a bad thing. He's strong and healthy.\"\n",
      "\"And hungry,\" Jack said. \"He hasn't taken his eyes off you. He thinks you've got some food for him.\"\n",
      "\"That's true,\" Sue said. \"But I haven't.\"\n",
      "They both laughed and then Jack said, \"Does your dog bite?\"\n",
      "\"No,\" Sue said, \"He's never bitten anyone. He's always gentle and friendly.\"\n",
      "Hearing this, Jack decided to hold out his hand and touched the animal's head. Suddenly it jumped up and bit him.\n",
      "\"Hey!\" Jack shouted. \"You said your dog didn't bite.\"\n",
      "Sue answered in surprise, \"Yeah, I did. But this is not my dog. Mine's at home.\"\n",
      "\n",
      "Question: Jack and Sue were   _  .\n",
      "A. friends\n",
      "B. next-door neighbours\n",
      "C. looking for a dog\n",
      "D. feeding the dog\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Kinsale may be one of the smallest towns in Southern Ireland, and it's also one of the most famous towns. It is well known for its wonderful fish restaurants. Some of the best known chiefs in the world have practiced in the restaurants there. The town itself is very beautiful in Southern Ireland by the sea. Here it is cooler in summer than other island towns. A big building overlooks the town and it is one of the most beautiful in the whole country. To the north of the town there is a high mountain standing in the country. The town is very beautiful, with its many craft shops and narrow cobbled streets. Most travelers visit Kinsale for its fish restaurants, which are family owned. This means that the service is better than that in other restaurants. People are more welcoming there than those anywhere else. The food may be expensive but you'll have one of the most pleasant evenings in your life there. So go ahead and visit Kinsale.\n",
      "\n",
      "Question: The town of Kinsale is beautiful for its   _   .\n",
      "A. fish restaurants\n",
      "B. service\n",
      "C. weather\n",
      "D. shops and streets\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Checking output ids: [426]\n",
      "[Prompt]:\n",
      "Article: One day my wife and I went shopping at  the shop. We took the car as we had a lot of things to buy because my brother and his family were going to spend the weekend with us. We stopped the car in front of the shop. An hour later we came back to the car with a lot of things. Then the trouble started. We could not open the car door.\n",
      "\"Oh, dear,\" said my wife, \"What are you going to do?\"\n",
      "\"Let's ask that policeman,\" I said. The policeman was very kind and glad to help us. A few minutes later he got the door open. Just at that moment an angry man came up and shouted, \"What are you doing with my car?\"\n",
      "We looked at the number of the car and our faces turned very red.\n",
      "\n",
      "Question: The husband and the wife went shopping   _  .\n",
      "A. by bus\n",
      "B. in their car\n",
      "C. by bike\n",
      "D. on foot\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Dear readers,\n",
      "Imagine a little girl who knows there will not be enough food for dinner, who can't fill her stomach with water because it's polluted  , and who has watched lives slipped away   from her father, little brother and sister because the family is too poor to see a doctor. She would gladly walk miles to school, but her mother needs her badly   at home. What will her future be?\n",
      "Is it hard to believe? For Maria Pestora, it is real life.\n",
      "But with just 52 pennies a day, you can sponsor   a child like Maria. Through\"Save the Children\",you can help Maria's mother get the tools and ways she needs to turn their poor food into a good dinner, and get the money she needs to buy clothes and school things for Maria.\n",
      "To help Maria most, your money is put together with that of other sponsors. Building schools, hospitals, bringing in clean water is what\"Save the Children\"has been working on since 1932.\n",
      "For you there are many rewards. You have the chance to write to or hear from the child you sponsored, to receive photos or progress reports, to know you are reaching out to another person, not with a handout  , but a hand up. That's how \"Save the Children\" works. But without you, it can't work. Please take a moment now to fill in and post the form below to help a child like Maria.\n",
      "It can make a difference in his/her life and yours.\n",
      "For the children\n",
      "David Li Guyer\n",
      ",.\n",
      "\n",
      "Question: We can read the letter in   _  .\n",
      "A. somebody's diary\n",
      "B. a piece of newspaper\n",
      "C. a progress report\n",
      "D. a story book\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Kids have unbelievable imaginations. We asked one hundred kids how robots might help them learn better. This is what they thought.\n",
      "Roberts can make learning fun\n",
      "Kids dreamed robots would make learning fun. One 9-year-old boy in Germany says, \"When I get home, my robot helps me with my homework. My mother and father came in and said 'no video games now, homework first'. When they saw that I had finished my homework, they'd be surprised\".\n",
      "Robots take care of the dirty work\n",
      "Dirty dishes? No problem. A quarter of kids surveyed imagined that their robots could do chores and boring work so that they might be freed up.\n",
      "Robots are our friends\n",
      "Two-thirds of the kids thought that their robots could be friends. One 10-year-old French boy describes his dream robot: \"He created books for me to read, we played with toy cars. He keeps my secrets. I can tell him anything, and he gives me suggestions.\"\n",
      "Robots are cool\n",
      "An 8-year-old girl in the U.S. imagines that her robot is \"really smart and everyone likes to talk to her. She has a funny voice, but we do not laugh at her.\"\n",
      "\n",
      "Question: How many kids imagined robots could help do chores?\n",
      "A. 20\n",
      "B. 25\n",
      "C. 100\n",
      "D. 50\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: On February 9 th,2013,Sarah Darling was walking along the street when she met a homeless man named Billy Ray Harris.She reached into her change purse,emptied out all the coins she had and gave them to the homeless man.Neither of them realized that this small generous act would change their lives.\n",
      "Sarah didn't realize that she had given Billy not only all her change but also her diamond ring that she had put in her change purse earlier until the following morning.She and her husband,Bill Krejci,rushed to see if they could find Billy.The homeless man was not only in the same place,he also immediately returned the ring.The grateful couple paid him back for his honesty by emptying out their pockets of all the money they had.\n",
      "Bill Krejci,a web designer,felt that he needed to do something more for this amazingly\n",
      "honest man.So on February 18th,he set up a special page to raise money for him.In just four days,Billy received over $ 85,000 and there seems to be no end yet.\n",
      "That is not enough.Billy is 1iving with a person who is generous instead of living in the streets.And that's not all--thanks to the news report,he got together again with his older brother,Edwin Harris who he had been unable to find for 27 years.\n",
      "All the good luck is just because Billy did the right thing--returning something that did not belong to him.\n",
      "\n",
      "Question: When did Sarah realize that she had also given Billy her diamond ring?\n",
      "A. On February 9 th,2013.\n",
      "B. On February 10th,2013.\n",
      "C. On February 18th,2013.\n",
      "D. On February 22nd,2013.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: I never wanted a dog, but now I'm so glad I have one. About two years ago, my wife, Cathy, got a little dog with a face only a mother could love. We named her Gertie.\n",
      "Gertie is the kind of dog that has to grow on you. So I dicided that the dog would be trained. This didn't quite go as planned. At 15 weeks old, she was nearly made to leave the Petsmart Training School. She spent every night lying in our bed-snoring  so loudly that I hardly got a good night's sleep.\n",
      "Then, about six months after she arrived, I felt that something in my heart was taking place, and I was unable to stop it. My behaviour began to change. I began to smile at people when passing them in a street. I returned from neighbours. I started calling my kids, and to my surprise, they started calling me. I even tried to speak to my grandchildren over the phone once. I even was glad to listen to laughter from a 10-month-old granddaughter. The point is that I was changing.\n",
      "My wife and I both agree that it is Gertie who has changed my behaviour. Gertie is now nearly two years old and almost fully grown.I have come to like the pet little by little, though she is my wife's dog.\n",
      "\n",
      "Question: What can we learn from this passage?\n",
      "A. The dog has been trained very well.\n",
      "B. The man has become more confident.\n",
      "C. The man has become more friendly.\n",
      "D. The man likes the dog better than his wife.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Ken and Anthony were childhood friends. They went to elementary and high school together. They went to college in different states, and then they lost touch. That was twenty years ago.\n",
      "One morning Ken was reading the newspaper with his morning coffee. Inside he saw an announcement for a poetry reading at a nearby bookstore. He was surprised to find that the featured poet was none other than his friend Anthony. Ken decided to see what his old pal was up to.\n",
      "Ken sat in the last row of the area set up inside the bookstore. When Anthony was introduced and came up the podium, Ken hardly recognized him. Anthony was almost completely bald and had a little potbelly  . When Anthony was in high school, he was very handsome. What Anthony had lost in looks was made up for in talent. Anthony's poetry was quite good.\n",
      "Anthony recognized Ken sitting in the back row. When the reading was over, Ken stood in line with the others waiting for Anthony to sign a copy of his book. When it was Ken's turn, Anthony stood up and hugged his long lost friend. Anthony invited Ken to stay until he had finished signing books. Ken did, and the two men grabbed a cup of coffee at a nearby cafe.\n",
      "Even though so many years had passed since the two had seen each other, both men had a lot in common. Both graduated from college with degrees in comparative literature  . Both went to graduate school. Anthony got his Master's of Fine Art in writing. Ken went to law school. Both men married Mexican women. Both men also had sons that were only a year apart. Ken and Anthony decided not to lose touch again. They planned to meet once a month for breakfast on Saturdays.\n",
      "\n",
      "Question: What can be the best title for the passage?\n",
      "A. Childhood friends\n",
      "B. Childhood memories\n",
      "C. Changes of friends\n",
      "D. Ways to get friends back\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Each morning a rich man found a poor man sitting on a park bench  . The poor man always sat there, looking at the big hotel in which the rich man lived. One day the rich man got out of his car and said to the poor man, \"Excuse me, but I just want to know why you sit here and look at my hotel every morning.\" \"Sir\", said the poor man, \"I am a failure  . I have no money, no family, no home. I sleep on this bench, and every night I dream that one day I'll sleep in that hotel.\" The rich man said, \"Tonight your dream will come true. I'll pay for the best room in that hotel for you for a whole month.\n",
      "A few days later, the rich man went by the poor man's room to ask him how he was enjoying himself. To his surprise, he found that the man had moved out of the hotel, back to his park bench. When the rich man asked why, the poor man said, \"you see, when I am down here sleeping on my bench, I dream I'm up there, in that big hotel. It's a wonderful dream. But when I was up there, I dreamed I was back to this cold bench. It was a terrible dream, and I couldn't get any sleep at all.\"\n",
      "\n",
      "Question: The poor man lived in   _   before he met the rich man.\n",
      "A. the hotel\n",
      "B. his home\n",
      "C. the park\n",
      "D. the car\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Hello! My name is Zhang Fei. I am Chinese. I am twelve. I'm in No.1 Middle School in Nanjing. This is my friend. His name is Tony Green. He is an English boy .He is twelve. He and I are in the same  class. Our classroom is next to  the teachers' office .We have Chinese and English lessons  every day. Our English teacher is Mr. Read. He is English but he can speak Chinese. Our Chinese teacher is Mr. Ding. They are good teachers, and they are our friends, too\n",
      "\n",
      "Question: Tony Green has a Chinese friend in   _  now.\n",
      "A. England\n",
      "B. America\n",
      "C. No.2Middle School.\n",
      "D. China\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Today is Saturday. The students of Grade Seven go to school early, but they have no classes. Their teachers are going to take them to the zoo. They take buses there. They get there at 8:30 a.m.\n",
      "The zoo is very beautiful. There are many trees, some hills and a big lake. And they have a big lunch there. It's spring now, and you can see many flowers there, too. There are also many people. They like to watch monkeys. They have a good time there. They leave the zoo at 3:30 p.m.\n",
      "\n",
      "Question: The students have lunch  _  .\n",
      "A. on the bus\n",
      "B. at school\n",
      "C. in the zoo\n",
      "D. at home\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: As kids, we learn how to write, maybe play a musical instrument and draw. So why don't we learn to code   computer programs too? What coding has in common with writing, playing music and creating art is that it lets you bring your ideas to life. Coding is all about creativity and music and creating art Crearbing with code CoderDojo helps young perople around the world to learn computer  programming for free. When I went to my first CoderDojo class in Dublin City University in Ireland, at age nine, I didn't know anything about coding or even what it was. But I remember making my very first web page that first day, and being surprised that I could create such a thing. It was a great feeling that I think every young person should experience!\n",
      "By going to CoderDojo every week, I learned how to make websites, apps and games. One of my apps is called Auto-Journalist. It can help journalists   and interwewees do interviews even if they are both really busy or live in different time zones. It is still in development, and I have showed it at an event called Coolest Projects Awards, where young people get to show the public what they have created with code. It's so mucbt fun to share one's creations, and to see what everyone else has made too.\n",
      "Learnuing environment\n",
      "For the past three years I have also been helping to teach other young people at CoderDojo DCU. In recent years I have also noticed many more girls attending CoderDojo DCU to try out coding. This has a lot to do with the CoderDojo girls' classes -- girls and young women take part in it with their friends, and it doesn't feel like coding is a \"boy thing\". It is really wonderful to see this, because we need more girls and women in STEM ( Science, Technology, Engineering and Maths). It's a good way to leam more about technology.\n",
      "Start early\n",
      "One of the main things I have leamed in the last few years is that coding is not only for adults, coding is for young people, too. And when you are a child it is a great time to start coding, because your imagination is the limit for what you can create !\n",
      "Want to leam more? Find out if there is a CoderDojo near you at www. coderdojo. com or set one up yourself! Also check out Code. org which has lots of fun drag-and-drop coding games.\n",
      "\n",
      "Question: In the writer's first coding class, she  _  .\n",
      "A. made apps and games\n",
      "B. created a web page\n",
      "C. wrote for newspapers\n",
      "D. did some interviews\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
      "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
      "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
      "\n",
      "Question: How did Victory deal with the money finally?\n",
      "A. He gave it away to a very sick baby.\n",
      "B. He kept it himself.\n",
      "C. He gave it back to the owner.\n",
      "D. He gave it to the police.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [423]\n",
      "[Prompt]:\n",
      "Article: The Monkey Buffet Festival is on the last Sunday of November. It is a great day for monkeys in Thailand  . The festival has a history of 25 years. People there think monkeys can bring good luck to them. So, to thank monkeys, they have this special festival.\n",
      "On that day every year, people put lots of fruit, vegetables, cakes and even drinks on the tables outside. They are all for monkeys. Many people come to see the monkeys on that day.\n",
      "During the festival, there are a lot of interesting activities about monkeys. Young people always dress like monkeys and they sing and dance and play some music on the street.\n",
      "Monkeys always live in groups. Most of them live in the trees. They are good at running and jumping. They eat fruit, vegetables, flowers and birds' eggs. Monkeys are clever. Do you think so?\n",
      "\n",
      "Question: People have the festival because they think monkeys   _  .\n",
      "A. are cute\n",
      "B. are clever\n",
      "C. can work for them\n",
      "D. can bring good luck\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
      "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
      "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
      "She understood that she hadn't worn the hair clip to school at all.\n",
      "\n",
      "Question: Why was the girl so happy?\n",
      "A. She found that everyone who saw her smiled at her.\n",
      "B. She heard most of her schoolmates said \"Hello\" to her.\n",
      "C. She thought what she experienced today never happened before.\n",
      "D. Both A, B, and C\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
      "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
      "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
      "\n",
      "Question: The writer thinks that Victory is   _  .\n",
      "A. very poor\n",
      "B. very funny\n",
      "C. very kind\n",
      "D. very lucky\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Kate is an American girl. Now she lives in New York with her parents. She lives in a community called Sunny Community. It's on Blue Street. There are five rows  of buildings in the community. Her house is in the first row. She lives on the third floor.\n",
      "There is a post office on Blue Street . Next to it ,there is a bank. Across from the bank ,there is a bookstore. The workers in the bookstore are very friendly to people. Mrs Green works in it. She is Kate's new neighbor. She has a son. His name is Bob. He is in the same class as Kate.\n",
      "Kate thinks the traffic here is very good, because she never meets any accidents here. She loves her community very much.\n",
      "\n",
      "Question: Where does Mrs Green work ?\n",
      "A. In a post office.\n",
      "B. In a bank.\n",
      "C. In a bookstore.\n",
      "D. In a school.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Sam is twenty-seven now. He's tall and strong. He worked hard in the small field. He's known a girl called Mabel for three years, who lives in another village. He wishes she could marry him soon, but she won't marry him until he has built a new house. He hasn't enough money. Of course it's difficult for him to do so.\n",
      "Winter had come and the fields were covered with thick snow. Sam had nothing to do at home. Mabel told him to find some _ in the town. He thought she was right and came to Mr White's factory, where he carried stones from the hill to the workplaces. It was hard work but he was paid more. At the end of the month Mr White paid the young man nearly two thousand dollars. He was very happy. He hurried to the post office, but it was closed. He had a look at the clock on the wall. It was half past five, and he was told to go there the next morning. He had to return to the factory. He felt hungry and went into a restaurant and ate something. He didn't see a thief following him, and as soon as he sat at table, the man sat down next to him and asked him to drink a cup with him. He agreed and drank a lot. And when he woke up two hours later, his money was stolen. He was sad of it and cried for a long time.\n",
      "The following day Mr White saw the young man's eyes were red and asked what had happened to him. He told him about it and at last he said, \"I worked for the thief last month!\"\n",
      ",.\n",
      "\n",
      "Question: The money was stolen when   _  .\n",
      "A. Sam left the factory\n",
      "B. Sam went into the restaurant\n",
      "C. Sam ate something in the restaurant\n",
      "D. the thief got Sam drunk.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: In Britain ,people often invite friends for a meal , a party or just coffee. People who know each other very well may visit each other's houses without  an invitation ,but if we invite new friends, usually an invitation is needed. When people invite someone to their homes , they often say ,\"Would you like to come for dinner on Saturday ?\" Answers are, \"Thanks, we'd love to. What time?\" or \"I'm sorry, We'd love to ,but we have tickets for the concert.\" However, it is not polite to say,\"No, we wouldn't.\"\n",
      "Sometimes, the British use expressions that sound like invitations but which are not invitations. For example. \"You must come over for a drink sometime .\" or \"Let's go out for a meal one of these days.\"  These are usually just polite ways of ending a talk . They are not real invitations because they don't mention an exact time or day. They just show that the person is trying to be friendly and the answers are ,\"Yes , that would be nice .\" or \"OK, yes ,thanks.\"\n",
      "So next time you hear what sounds like an invitation, listen carefully. Is it a real invitation or is the person just being friendly?\n",
      "\n",
      "Question: The British often use \"  _  \"to answer the invitations that are not real.\n",
      "A. Yes , what time ?\n",
      "B. No, that's not a real invitation.\n",
      "C. OK, yes , thanks.\n",
      "D. No, you just want to be friendly.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: My name is Lin Tao. I'm a Chinese boy. Now I'm studying in America. There are many kinds of clubs here. When I first come here, l don't know anything about clubs.\n",
      "I'm a shy boy, so I can't speak English well. In my first year in America, l don't like to speak to others. In my second year I have to change myself by doing some new things. I _ that school is not just about getting good grades , it's also about being part of a club. One day, when I go to the Media Center with my classmate Jim, he tells me something about the club, It's interesting, so 1 join it.\n",
      "I am in many clubs now, it's good to be part of a club. These clubs help me to make new friends.\n",
      "\n",
      "Question: What can you learn from the passage ?\n",
      "A. Lin Tao lives in America with his parents.\n",
      "B. The Media Center is Lin Tao's first club.\n",
      "C. Lin Tao doesn't like joining clubs.\n",
      "D. Lin Tao makes many new friends in the first year.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
      "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
      "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
      "She understood that she hadn't worn the hair clip to school at all.\n",
      "\n",
      "Question: Her classmates wanted to know what had happened to the girl because  _\n",
      "A. she didn't tell her classmates about her beautiful hair clip.\n",
      "B. she was always unhappy but that day she was so happy.\n",
      "C. she looked more beautiful wearing the hair clip.\n",
      "D. she wanted to talk to others.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
      "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
      "\n",
      "Question: We have   _   in the dining hall.\n",
      "A. breakfast\n",
      "B. lunch\n",
      "C. dinner\n",
      "D. supper\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Do you have a headache? Take an aspirin or eat bird brains. Do you want beautiful skin? Use skin cream or eat pearls. Is your hair turning gray? Color your hair or eat black rice.\n",
      "\"Eat bird brains, pearls, and black rice?\" some people ask. \"How strange!\" But for many Chinese people, bird brains, pearls, and black rice are not strange things to eat. Instead, they are good medicines.\n",
      "Food that people use for medicines is called medical  food. The Chinese have eaten medicinal food and spices  for centuries. Ginger, for example, is a common spice in Chinese cooking. Ginger gives food a nice flavor. The Chinese began to use ginger many years ago. They used ginger not because it tasted good. They used ginger because it was medicinal. Ginger, they thought, was good for the digestion. It also helped people who had colds. Pepper and garlic, too, were probably medicines a long time ago.\n",
      "Some people don't believe that food and spices are good medicines. They want to buy their medicine in drugstores, not in supermarkets. Other people want to try medicinal food. They say, \"Maybe medicinal food can't help me. But it can't hurt me, either.\"\n",
      "People can try medicinal food at a Chinese restaurant in San Francisco, California. The restaurant serves medicinal food. The menus at the restaurant have a list of dinners. Next to each dinner there is information about the food. The information helps people order \"Queen's Secret,\" for example, is one dinner at the restaurant. This dinner has meat from chickens with black feathers. It is for women who want to look young.\n",
      "\n",
      "Question: What do you know about medicinal food?\n",
      "A. The Chinese have eaten medicinal food for a long time.\n",
      "B. Many Chinese believe medicinal food tastes good.\n",
      "C. Medicinal food may be bad for your health.\n",
      "D. Medicinal food is served all over the world.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: In China, there're many different kinds of food. Some of them are very popular. The real Chinese food is dumplings. Now let's talk about them, OK?\n",
      "Everyone in China likes dumplings very much, and there are many different kinds of dumplings. Some have meat and vegetables in them, others have sugar, eggs and so on. I like dumplings with vegetables and pork better than any other kind.\n",
      "Usually people make dumplings at home. If you have no time to make them, you can buy them from any supermarket. Then you take them home and eat them with _ .\n",
      "The Spring Festival is very important in China. When it comes, we make dumplings, usually we put a coin  in a dumpling. If one eats the dumpling with the coin in it, he or she will be lucky in the year.\n",
      "In the old days, people couldn't often eat dumplings, because they were very poor. Now our country is becoming stronger and stronger, and our people are richer and richer. We can eat them very often.\n",
      "Now tell me, do you like dumplings?\n",
      "Welcome to China, and we'll invite you to eat the real Chinese food --dumplings.\n",
      "\n",
      "Question: You can buy dumplings from the supermarket when  _  .\n",
      "A. you have time\n",
      "B. you are tired\n",
      "C. you are busy\n",
      "D. you are happy\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Checking output ids: [423]\n",
      "[Prompt]:\n",
      "Article: Dear John, Thank you very much for your letter. I am glad that you enjoyed your holiday with me. We enjoyed having you and your sister here. We hope that you will both be able to come again next year. Perhaps you'll be able to stay longer next time you come. A week is not really long enough, is it? If your school has a five-week holiday next year, perhaps  you'll be able to stay with us for two or three weeks.\n",
      "We have been back at school three weeks now. It feels like three months! I expect  that you are both working very hard now that you are in Grade One. I shall have to work hard next year when I am in Grade One. Tom and Ann won't be in Grade One until 2011.\n",
      "They went for a picnic yesterday but I didn't go with them because I cut my foot and I couldn't walk very well. They went to an island and enjoyed themselves. Do you still remember the island? That's where all five of us spent the last day of our holiday.\n",
      "Tom, Ann and I send our best wishes to Betty and you. We hope to see you soon.\n",
      "Yours sincerely,\n",
      "Michael\n",
      "\n",
      "Question: From the words of  \"It feels like three months!\" we know that  _  .\n",
      "A. Michael's teacher is very strict with the students\n",
      "B. Michael is pleased with his school report\n",
      "C. Michael has no interest in learning\n",
      "D. Michael works very hard at his studies\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Thursday, April 24th\n",
      "We got to the clean, lovely city of Yangzhou early in the morning. This is our first trip to China. All the different smells attract our attention to the local food. We are going to try something special for dinner tonight. The hotel we are staying in is not expensive but very clean. We plan to stay here for a few days, visit some places in the city, and then travel to the Great Wall in the north.\n",
      "Sunday, April 27th\n",
      "We visited the famous Slender West Lake   which was crowded with visit ors from all over the world, and bought a lot of toys for our friends outside the gate of the park. Everything is so colourful, and we have taken hundreds of photos already! Later today we will do the famous foot massage   and then leave for the Great Wall. We will take the night train north, stay in Beijing for two days, and then catch a bus to the Great Wall.\n",
      "Wednesday, April 30th\n",
      "Our trip to the Great Wall was long and boring. We visited a small village in the mountains. People in the village love the quiet life. They are the kindest people I had ever met. They always smile and say \"Hello\". Ralph and I can speak only a few words in Ch inese, so smiling is the best way to show our kindness.\n",
      "\n",
      "Question: What is the best title for the passage?\n",
      "A. My First Visit to Yangzhou\n",
      "B. My Travelling in China\n",
      "C. Delicious Food and Beautiful Places\n",
      "D. A Trip to the Great Wall\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Mr Smith goes to the town   to see his son, Tom. Tom is studying music in a school there. He tells his father he does well and his father is very happy. That evening Mr Smith buys two tickets for a concert  . They get there early after dinner. They're sitting in the hall   and listening to them playing. The music is beautiful and Mr Smith enioys it very much. But he finds  his son doesn't like it at all. Mr Smith wants to know something about Tom. So he asks, \"Do you know the music?\" \"Yeah,\" answers Tom. \" And what's the musician playing now?\" Mr Smith asks. Tom doesn't know how to answer it. He thinks hard and then says, \"... the piano.\"\n",
      "\n",
      "Question: Mr Smith's son is studying  _  now.\n",
      "A. in town\n",
      "B. at home\n",
      "C. in a hall\n",
      "D. in a Tv station\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Each morning a rich man found a poor man sitting on a park bench  . The poor man always sat there, looking at the big hotel in which the rich man lived. One day the rich man got out of his car and said to the poor man, \"Excuse me, but I just want to know why you sit here and look at my hotel every morning.\" \"Sir\", said the poor man, \"I am a failure  . I have no money, no family, no home. I sleep on this bench, and every night I dream that one day I'll sleep in that hotel.\" The rich man said, \"Tonight your dream will come true. I'll pay for the best room in that hotel for you for a whole month.\n",
      "A few days later, the rich man went by the poor man's room to ask him how he was enjoying himself. To his surprise, he found that the man had moved out of the hotel, back to his park bench. When the rich man asked why, the poor man said, \"you see, when I am down here sleeping on my bench, I dream I'm up there, in that big hotel. It's a wonderful dream. But when I was up there, I dreamed I was back to this cold bench. It was a terrible dream, and I couldn't get any sleep at all.\"\n",
      "\n",
      "Question: The poor man moved out of the hotel because   _  .\n",
      "A. he didn't want to live in such a fine room\n",
      "B. he didn't like the rich man\n",
      "C. he couldn't pay for the room\n",
      "D. he couldn't get any sleep at all there\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: 0ur village carpenter ,John Hill, came one day and made a dining table for my wife.  He made it just the right size to fill the space between the two window.  When I got home that evening, John was drinking a cup of tea and writing out his bill( ) for his job.\n",
      "My wife said to me quietly, \"That's his ninth cup of tea today. \"But she said in a loud voice, \"It's a beautiful table, dear, isn't it?\" \"I'll decide about that when I see the bill,\" I said.  John laughed and gave me his bill for the work.  I read:\n",
      "One dining table                 10thNovember, 2011\n",
      "Cost of wood                    $ 17:00\n",
      "Paint                           $1. 50\n",
      "Work, 8 hours($1 an hour)          $8. 00\n",
      "Total                           $36. 50\n",
      "When I was looking at the bill, John said,\" It's been a fine day, hasn't it? Quite sunny. \"\n",
      "\"Yes,\" I said.  \"I'm glad it's only the 10thof November. \"\n",
      "\"Me, too,\" said John, \"you wait--it will be a lot colder by the end of the month. \"\n",
      "\"Yes, colder--and more expensive! Dining table will be $20 more expensive on November 30th, won't they, John?\"\n",
      "John looked hard at me for half a minute.  Was there a little smile in his two blue eyes? I gave his bill back to him.\n",
      "\"If it's not too much trouble, John,\" I said,\"Please add  it up again, You can forget the date-------\"\n",
      "I paid him $26. 50 and he was happy to get it.\n",
      "\n",
      "Question: How much would John ask for if he made a dining table on the last day of December according to his bill?\n",
      "A. $ 26. 50\n",
      "B. $36. 50\n",
      "C. $56. 50\n",
      "D. $57. 50\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Mr. Jackson lives in a small town. He is a kind and funny man. And he is friendly to everyone. He likes talking with others very much. But he is always absent-minded  .\n",
      "One day, Mr Jackson went to visit a friend. His friend works on a farm and lives not far from the market and often goes to the market to sell things.\n",
      "They had dinner together and then talked and talked. Mr Jackson was very excited to meet his friend. He told his friend a lot of things. Midnight came, and then one o'clock, two o'clock and still Mr Jackson kept on talking. But by this time his friend was feeling very tired and kept on looking at the clock on the wall. He didn't want to be impolite, but at last he said, \"My dear friend, I don't want to put you out, but you see, it's too late now. I have to go to the market at six o'clock, and I must go to bed now.\"\n",
      "\"Oh, my God!\" said Mr Jackson in surprise, \"I thought you were at my house.\"\n",
      "\n",
      "Question: Mr Jackson's friend went to bed   _   that day.\n",
      "A. at midnight\n",
      "B. at one o'clock\n",
      "C. at two o'clock\n",
      "D. after two o'clock\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: A mother and her young son got into a bus in New York City and sat down. The bus conductor  came to them for their money. The mother said, \"I want one ticket  to Central Park, \"and gave him two dollars. The conductor looked at the small boy for a few seconds and then asked him, \"How old are you, young man?\"  The mother just began to speak, but the conductor stopped her, and the boy said, \"I'm four years old at home, and two and a half on buses and trains.\"  The mother felt shamed , so she took another dollar out of her bag and gave the money to the conductor. The conductor gave her one and a half tickets.\n",
      "\n",
      "Question: One day the mother took a bus   _  .\n",
      "A. to a small city\n",
      "B. to get some money\n",
      "C. with her son\n",
      "D. to school\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [423]\n",
      "[Prompt]:\n",
      "Article: If someone asks you to draw a picture of a robot, what will it look like? Like a person? We always think the robot looks like a person. But real robot have many different looks. What robots look like has something to do with the jobs they do.\n",
      "Robot don't get bored. They don't get tired. They don't worry about getting dirty.\n",
      "Some people are worried that robots will become the _ of the earth one day. But I think it won't happen. After all, robots are controlled   by people. They work according to people's orders.\n",
      "With the help of robots, we are living a safer, happier and more comfortable life.\n",
      "\n",
      "Question: What robots look like?\n",
      "A. Real persons.\n",
      "B. Pictures.\n",
      "C. Cars.\n",
      "D. They have many different looks.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Before I started school, people felt that I was not going to be successful.At the age of four I started speech lessons because I could not speak well enough for anyone to understand me.\n",
      "The first grade was a struggle  .I had difficulty speaking, I also couldn't learn to read.The second grade was not much better.I still struggled with the inability to read.In the third grade a new school was built. It was near my home. I went there with my parents and helped to get the school ready so that we could move to the new one. However, things didn't get better for the next two years.\n",
      "It was in the fifth grade.Mrs.Wakefield was my teacher, and she was a good teacher.She did not make me feel unconfident. Instead, she did her best to let me know that I could be whatever I wanted to be.And that is just what I did.\n",
      "For the past 22 years, I have been a fifth grade teacher.Because of Mrs.Wakefield's influence on my life, I am now encouraging students who have had difficulties in their lives to believe that they can deal with any difficulty successfully and become someone.I have won many awards  up to now, such as Teacher of the Year.I think I should thank my fifth grade teacher. She believed in me and helped me to be all that I could be.\n",
      "\n",
      "Question: The writer   _   when he was in the third grade.\n",
      "A. did better in reading\n",
      "B. met a good teacher\n",
      "C. received a high award\n",
      "D. went to a new school\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: In Britain ,people often invite friends for a meal , a party or just coffee. People who know each other very well may visit each other's houses without  an invitation ,but if we invite new friends, usually an invitation is needed. When people invite someone to their homes , they often say ,\"Would you like to come for dinner on Saturday ?\" Answers are, \"Thanks, we'd love to. What time?\" or \"I'm sorry, We'd love to ,but we have tickets for the concert.\" However, it is not polite to say,\"No, we wouldn't.\"\n",
      "Sometimes, the British use expressions that sound like invitations but which are not invitations. For example. \"You must come over for a drink sometime .\" or \"Let's go out for a meal one of these days.\"  These are usually just polite ways of ending a talk . They are not real invitations because they don't mention an exact time or day. They just show that the person is trying to be friendly and the answers are ,\"Yes , that would be nice .\" or \"OK, yes ,thanks.\"\n",
      "So next time you hear what sounds like an invitation, listen carefully. Is it a real invitation or is the person just being friendly?\n",
      "\n",
      "Question: It is not polite to answer the real invitation by saying \"  _  \"\n",
      "A. Sorry. We'd love to, but we have tickets for the concert .\n",
      "B. Thanks. We'd love to, what time?\n",
      "C. Sure. We'd like to. Thanks a lot.\n",
      "D. No, we wouldn't!\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Many boys and girls love watching TV. They spend many hours watching TV every day. But many parents let their children watch TV at special time.\n",
      "TV shows are like books and movies. There are many kinds of TV shows, such as sitcoms, soap opera, sports shows, fashion shows, and so on. A kid can learn good things and bad things from them. Some shows help children know the news all over the world. Children don't have to go to the zoos or the parks to see animals. They can see on TV at home. Some shows teach children how to cook, how to paint or how to study.\n",
      "Many boys and girls think it is interesting to watch TV but it is also interesting to read books , to play games or to visit the friends.\n",
      "\n",
      "Question: Many parents   _  .\n",
      "A. don't let their children watch TV\n",
      "B. ask their children to watch TV only about study\n",
      "C. let their children watch TV only at special time\n",
      "D. want their children to watch TV all night\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [426]\n",
      "[Prompt]:\n",
      "Article: \"High tech\" and \"state of the art\" are two expressions that describe very modern technology. High tech is just a shorter way of saying high technology. And high technology describes any invention or system that uses the newest ideas or discoveries of science and engineering.\n",
      "What is high tech? A computer is high tech. So is a communications satellite. A modern manufacturing     system is surely high tech.\n",
      "High tech became a popular expression in the United States during the early 1980's. Because of improvements in technology, people could buy many new kinds of products in American stores, such as home computers, microwave ovens  , etc. \"State of the art\" is something that is as modern as possible. It is a product that is based on the very latest ways and technology. Something that is \"state of the art\" is the newest possible design or product of a business or industry. A state of the art television set, for example, uses the most modern electronic design and parts. It is the best that one can buy.\n",
      "\"State of the art\" is not a new expression. Engineers have used it for years, to describe the best and most modern way of doing something.\n",
      "Millions of Americans began to use the expression in the late 1970's. The reason was the computer revolution . Every computer company claimed   that its computers were \"state of the art\".\n",
      "Computer technology changes so fast that a state of the art computer today might be old tomorrow. The expression \"state of the art\" has become as common and popular as computers themselves. Now all kinds of products are said to be \"state of the art\".\n",
      "\n",
      "Question: The best title for the passage is  _  .\n",
      "A. Computer Technology\n",
      "B. High Tech and State of the Art\n",
      "C. Most Advanced Technology\n",
      "D. Two New Expressions\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Many people like to watch TV. Watching TV is one of the most important activities of the day. TV brings the outside closer to people's homes. Some people say the world is smaller than before because of TV.\n",
      "What's going on in the other countries? How do people live in places far away? Is there a good sports game somewhere? What's the life like in the deepest  part of the sea?\n",
      "If you want to answer these and other kinds of questions, just turn on the TV. Turn it on and watch. You can see a lot and learn a lot. Of course, people can also learn through reading or listening to the radio. But with TV they can learn better and more easily. Why? Because they can hear and watch, too.\n",
      "TV helps to open our eyes. TV also helps to open our minds . TV often give us new ideas. We learn newer and better ways of doing something.\n",
      "\n",
      "Question: We can  _  when we watch TV.\n",
      "A. go to live in the other countries\n",
      "B. answer TV many questions\n",
      "C. get a lot of information\n",
      "D. ask TV some questions\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [423]\n",
      "[Prompt]:\n",
      "Article: 20Today it is found that school students hardly pay much attention to sports. Is it because they aren't interested in sports? No. They often say they have other more important things to do.\n",
      "What are these important things? Examinations! Students have to spend much time on all kinds of examinations at school. So many of them almost become bookworms  . Books stop them from doing sports. Because of the pressure from their parents and teachers, the students have to work harder and spend most of their time on books. As for (......) the students, they want to get good results so that they can improve their studies. So it is necessary for them to give all of their free time to their studies and stop their school sports.\n",
      "In fact, education can't go without physical   exercises, because a quick mind hardly goes along with a weak body. If you don't have a strong body, you can never get anything, let alone   a great success in your life.\n",
      "\n",
      "Question: The writer thinks the students should  _  .\n",
      "A. work hard all day and all night\n",
      "B. have all kinds of sports after studying\n",
      "C. do not have sports\n",
      "D. spend the free time on the studies and give up the sports.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: B\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Mr. Yang is a doctor. He cares a lot about not only others' health but also his own. He controls( )his weight carefully. To him, _ is the most important thing to do if one wants to enjoy good health.\n",
      "Mr. Yang controls his weight in two ways: exercising and not eating much. As a doctor. Mr. Yang is too busy to go to the gym. He exercises by getting off the bus one or two stops early and walking the rest of the way to his office.\n",
      "Besides, he doesn't eat much. Mr. Yang has a special habit. When he buys a belt, he asks the salesperson to punch a hole in the belt at 90cm from the buckle end of the belt, so that he ca always remind  himself. He will stop eating if he feels the belt a little too tight . Mr. Yang thinks exercising doesn't work as well as eating less.\n",
      "\n",
      "Question: Mr. Yang punches a hole in his new belt, because   _  .\n",
      "A. he is too heavy\n",
      "B. the belt is too long\n",
      "C. he doesn't like his new belt\n",
      "D. it can remind him not to eat too much\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: There are two main kinds of sports. These two kinds of sports are team sports and individual   sports. Team sports are such sports as baseball, basketball, and volleyball. Team sports need two separate   teams. The teams play against each other. They compete against each other to get the best score. For example, in a football game, if team A gets 8 points and team B gets 4 points, team A wins the game. Team sports are sometimes called competitive   sports.\n",
      "Another kind of sports is individual sports. In individual sports there are no teams. There isn't any competition. People play individual sports in order to get some exercise, not to win a game. Individual sports are such sports as swimming, skiing, and running.\n",
      "Of course, it is possible   to compete in individual sports. It is possible to keep a score in individual sports. The main difference, however, between team sports and individual sports is that individual sports can be finished alone. But team sports always need more than one person.\n",
      ",.\n",
      "\n",
      "Question: _   is a kind of individual sports.\n",
      "A. The high jump\n",
      "B. Table tennis\n",
      "C. Volleyball\n",
      "D. Basketball\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Sam is twenty-seven now. He's tall and strong. He worked hard in the small field. He's known a girl called Mabel for three years, who lives in another village. He wishes she could marry him soon, but she won't marry him until he has built a new house. He hasn't enough money. Of course it's difficult for him to do so.\n",
      "Winter had come and the fields were covered with thick snow. Sam had nothing to do at home. Mabel told him to find some _ in the town. He thought she was right and came to Mr White's factory, where he carried stones from the hill to the workplaces. It was hard work but he was paid more. At the end of the month Mr White paid the young man nearly two thousand dollars. He was very happy. He hurried to the post office, but it was closed. He had a look at the clock on the wall. It was half past five, and he was told to go there the next morning. He had to return to the factory. He felt hungry and went into a restaurant and ate something. He didn't see a thief following him, and as soon as he sat at table, the man sat down next to him and asked him to drink a cup with him. He agreed and drank a lot. And when he woke up two hours later, his money was stolen. He was sad of it and cried for a long time.\n",
      "The following day Mr White saw the young man's eyes were red and asked what had happened to him. He told him about it and at last he said, \"I worked for the thief last month!\"\n",
      ",.\n",
      "\n",
      "Question: Sam went the post office to   _  .\n",
      "A. ring up Mabel\n",
      "B. post the money\n",
      "C. buy some stamps\n",
      "D. post a letter\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: A long time ago, in 1893, in the United States, some people were talking about fruits and vegetables. They asked, \"What are fruits and what are vegetables? How are fruits different from vegetables and vegetables different from fruits?\" They talked for a long time and then they decided, \"We eat vegetables as part of a meal, but we eat fruits before or after a meal.\"\n",
      "In real life, people do not think the dictionaries give the right meaning of a word. For example, the dictionaries say that tomatoes are fruits. But few people know that. Most people think they are vegetables. They call them vegetables and eat them as vegetables. To most people, fruits mean sweet things like apples, pears, oranges and watermelons.\n",
      "What are vegetables then? We call many plants and grasses vegetables. Some people think some fruits are vegetables, such as apples, pears and bananas. But to most people, vegetables mean things like potatoes, onions and carrots.\n",
      "\n",
      "Question: People usually eat vegetables   _  .\n",
      "A. before a meal\n",
      "B. after a meal\n",
      "C. alone\n",
      "D. during a meal\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: In the days when an ice cream sundae cost much less, a 10-year-old boy entered a hotel coffee shop and sat at a table. A waitress (woman assistant) put a glass of water in front of him. \"How much is an ice cream sundae?\" \"Fifty cents\", replied the waitress. The little boy pulled his hand out of his pocket and studied a number of coins in it. \"How much is a dish of _ ice cream?\" he asked. Some people were now waiting for a table and the waitress was a bit worried. \"Thirty-five cents,\" she said rudely(not politely). The little boy again counted the coins. \"I'll have the plain ice cream,\" he said. The waitress brought the ice cream, put the bill on the table and walked away. The boy finished the ice cream, paid the bill at the counter and went out. When the waitress came back, she began cleaning the table and then she couldn't believe what she had seen. There, placed nearly beside the empty dish, were two five-cent coins and five one-cent coins---her tip .\n",
      "\n",
      "Question: Why did the little boy have only a dish of a plain ice cream?\n",
      "A. The plain ice cream cost him much less.\n",
      "B. He enjoyed the cheaper ice cream better.\n",
      "C. The coins were not enough for an ice cream sundae.\n",
      "D. He wanted to save some coins to tip the waitress.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: It is very important for children to get to school safely and on time every day. Luckily, there is a new program called Free Home to School Transport . It gives children free rides to school. But to enjoy the free trip. Children have to qualify .\n",
      "Children can take free home to school transport if they:\n",
      "*are between 5 and 16 years old\n",
      "*are going to the nearest school\n",
      "*live far away from school\n",
      "No matter how far away children live from school, they Can take the free transport if they have walking problems or there is no safe road for them. A safe road usually has crossings, lights and should be clean.\n",
      "Also, there are still free home to school _ for children in poor families and children with special educational needs, you can find out more on the Internet and see if your children are qualified.\n",
      "\n",
      "Question: According to the passage, it is very important for children not to be   _  for school every day.\n",
      "A. late\n",
      "B. away\n",
      "C. early\n",
      "D. ill\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: An Internet game named Happy Farm is becoming more and more popular among young office workers and students. People can work on a farm. They can also grow, water, sell and steal vegetables, flowers, fruits and so on. They can earn some e-money from their working on the farm. Then they can use it to buy more seeds, pets and even houses. Of course, all these are not true, they are only on the Internet.\n",
      "Why do so many young people enjoy the kind of Farm game? I think maybe some of them are afraid of facing the real world, and they have to look for fun from the Internet. Some feel lonely and want to make friends during growing vegetables on the Internet. Some have great fun _ others' vegetables because they needn't work on their farm.\n",
      "Most parents and teachers are worried about these young people and students. Students spend too much time playing the game. It's bad for their health and study.\n",
      "\n",
      "Question: Why do some people enjoy the game?\n",
      "A. Some people feel lonely and want to make friends.\n",
      "B. They can get some money for living.\n",
      "C. They don't need to buy vegetable for lunch.\n",
      "D. They can learn English from the game.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Most people follow others blindly mainly under the effect of peer  pressure. Some people also feel it safe to follow a large number of people. In some _ cases it might be right to follow the crowd  , but in most cases this can be one big mistake. Ninety-five percent of people never succeed because they are following the wrong group. Actually there are reasons why we shouldn't follow the crowd blindly.  According to a study, people tend to follow the crowd when they aren't sure about the direction they should take. This means a large number of people could be following others without understanding what's right and what's wrong! This attracts more people to follow them and the result is that most people move in a certain direction even if it isn't right.\n",
      "A man who wants to be successful always hopes for others' guidance and he usually follows the same path of most people, but the question this man never asks himself is: are all of those people successful? Of course not! If you want to follow a crowd, then follow a successful one. However, in real life you'll only find one successful person among hundreds of people, and that's why following the crowd makes no sense at all.\n",
      "Most people act without thinking wisely. If you always follow others because\n",
      "they're greater than you in number, then sooner or later you'll discover that you're\n",
      "making decisions you might regret later.\n",
      "However, should we never follow the crowd?No. I'm not trying to say you should never follow the crowd, but instead I'm just asking you to think wisely before you take a decision. If you find others are right, there is no problem in following them, but if you have doubts about the direction they're moving in, don't follow them blindly.\n",
      "\n",
      "Question: What is the passage mainly about?\n",
      "A. Ways of finding successful people to follow.\n",
      "B. Advantages of making a right direction.\n",
      "C. Examples of not following others blindly.\n",
      "D. Reasons of not following others balindly.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Lin Tao and Chen Hai are good friends. They are in the same class. They are in the same team. Lin Tao sits behind Chen Hai. Now it is four o'clock. School is over. They often go to play games after school. They can't look after their things very well. So their mothers don't give them watches. They don't have watches. They don't know the time. But they can ask a man under the big tree. His watch is very nice. They can also see the clock on the wall of the classroom. Now it's about five in the afternoon. It's time to go home. They must put on their clothes and go home.\n",
      "\n",
      "Question: Where do Lin Tao and Chen Hai sit in the classroom?\n",
      "A. They sit in the same row  .\n",
      "B. Chen Hai sits behind Lin Tao.\n",
      "C. They sit in the same class.\n",
      "D. Lin Tao sits behind Chen Hai.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Hearing what I said, my dad laughed kindly. I continued, \"I owe your thanks, and I hope you realize how much you did for me as my dad.\"\n",
      "I could almost hear him smiling one the other end. I knew he was touched and felt a little shy. His voice sounded shaky.\n",
      "\"Well, we got you educated,\" he said, laughing generously.\n",
      "\"You did more than that,\" I said, \"You did well.\"\n",
      "\"You like your house now, and your life?\" he asked quietly.\n",
      "\"Yeah, Dad, I'm happy. You don't have to worry--things are going great for us.\"\n",
      "I told him I loved him and he told me he loved me and I hung up the phone. As I got ready for bed, I thought about what an amazing conversation we had.\n",
      "Ten hours later, my mother called, waking me up. I could hardly understand what she was trying to say.\n",
      "\"Your father's dead!\" she cried. \"I found him lying on the dinning room floor.\"\n",
      "Suddenly I was standing straight up beside my bed, holding the phone and sobbing .\n",
      "I was a thousand miles away. All I could think about was how many hours, minutes and seconds it would take me to jump on a plane and get there. I thought about my mother sitting there alone with my father, and I couldn't move fast enough.\n",
      "The flight was long and painful. I had planned on going home to see my dad and mom in another month, and I cried aloud, thinking I was too late. Then I suddenly realized the incredible miracle of it all: I hadn't been late at all. Actually, everything had been right on time.\n",
      "\n",
      "Question: When did Dad die?\n",
      "A. Soon after he made the telephone call.\n",
      "B. The next morning.\n",
      "C. Before the writer hung up the phone.\n",
      "D. Ten hours later after the telephone call.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: A young British man called Luke Cameron has done a good deed  every day for more than a year and he says it has completely changed his life.\n",
      "Luke made a decision at the beginning of 2014.He started by doing one small good thing every single day from January 1st, 2014.For example, he greeted the waiter at a cafe on New Year's Day and he bought food and drink for some homeless people the next day.\n",
      "He set up a website where he could write down all his good deeds, like helping the neighbor take out the rubbish or spending a few hours in helping a disabled lady pick out a dress for a party.\n",
      "\"I've never thought of any return from helping others.Actually, it has given me happiness and I have become more thankful and grateful for the things I have now.\" Luke said.He has decided to continue doing good deeds in 2015.\n",
      "Luke won the competition for the job of National Philanthropy  Manager because of his kind deeds.He will travel all over the UK and help 45 different charities in 2015.\n",
      "\"I used to work as a part-time worker in a shop.Now I become the National Philanthropy Manager.\" Luke said, \"I think I've helped myself by helping others.\"\n",
      "\n",
      "Question: The passage is probably from   _  .\n",
      "A. a newspaper\n",
      "B. a novel\n",
      "C. an advertisement\n",
      "D. a scientific book\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Kids have unbelievable imaginations. We asked one hundred kids how robots might help them learn better. This is what they thought.\n",
      "Roberts can make learning fun\n",
      "Kids dreamed robots would make learning fun. One 9-year-old boy in Germany says, \"When I get home, my robot helps me with my homework. My mother and father came in and said 'no video games now, homework first'. When they saw that I had finished my homework, they'd be surprised\".\n",
      "Robots take care of the dirty work\n",
      "Dirty dishes? No problem. A quarter of kids surveyed imagined that their robots could do chores and boring work so that they might be freed up.\n",
      "Robots are our friends\n",
      "Two-thirds of the kids thought that their robots could be friends. One 10-year-old French boy describes his dream robot: \"He created books for me to read, we played with toy cars. He keeps my secrets. I can tell him anything, and he gives me suggestions.\"\n",
      "Robots are cool\n",
      "An 8-year-old girl in the U.S. imagines that her robot is \"really smart and everyone likes to talk to her. She has a funny voice, but we do not laugh at her.\"\n",
      "\n",
      "Question: kids  _  according to the passage.\n",
      "A. are full of ideas\n",
      "B. depend robots do everything\n",
      "C. hate robots\n",
      "D. need care from their parents\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Dear Mr Green,\n",
      "I am not happy these days. Please help me.\n",
      "I want to be a member of the class volleyball team. I think I am good at volleyball. But our PE teacher says I can't get into the team. He says I am too fat  .\n",
      "I really want to be a good volleyball player. This is my dream. Can you help me?\n",
      "Jane\n",
      "Dear Jane,\n",
      "I'm sorry to know that you're not happy.\n",
      "You play volleyball well. But your PE teacher doesn't like fat girls. If   you want to be a good volleyball player, you must be slim. Why not go running with Mary every morning? Mary is the best volleyball player in our class. You can be like her if you\n",
      "Allan Green\n",
      "\n",
      "Question: Which of the following is TRUE?\n",
      "A. Jane doesn't play volleyball well.\n",
      "B. Jane is really slim.\n",
      "C. Jane's PE teacher doesn't like fat girls.\n",
      "D. Jane wants to play for the school team.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: My mother used to say things just to make me mad. Like most teenagers, I thought I knew everything. And what I didn't know, I didn't want to be told. For example, if I said I was going to a movie, my mother would roll her eyes. On my way out, she'd shout, \" _ You don't want to learn that the hard way!\" I didn't know what that meant. I thought she just wanted me to stay at home.\n",
      "Many years later I had three teenagers of my own. They thought they knew everything. I would say the same things to them like my mom. That's when I first saw it. My mother wasn't trying to help me.\n",
      "Why do we always have to learn things \"the hard way\"? Why can't we just accept our elders' wisdom? It's a good lesson for anyone. Clearly, I still haven't learned it.\n",
      "Yesterday, I stepped out of the shower when I heard my cell phone ringing in the kitchen. Grabbing a towel, I ran through the house. I grabbed the phone and hit my left foot against the table. The X-ray showed that I'd broken two toes.\n",
      "We all need to slow ourselves down once in a while, before something bad does it for us. My mother was right about a lot of things. I wish I could have told her.\n",
      "\n",
      "Question: What's the best title of the passage?\n",
      "A. An hurt experience\n",
      "B. Learning the hard way\n",
      "C. Mother's words are always right\n",
      "D. Teenagers should learn from their mothers\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Jeff  Keith has only one leg. When he was 12 years old ,Jeff had cancer . Doctors had to cut off most of his right leg.\n",
      "Every day Jeff puts on an artificial leg. The leg is plastic. With the plastic leg Jeff can ski ,ride a bicycle ,swim and play soccer. He can also run.\n",
      "Jeff made a plan with his friends who had plastic legs, too. They decided to run across America. They all wore special T-shirts. On it was \"Run ,Jeff, Run ,Jeff Keith's Run Across America.\"\n",
      "When he was 22 years old,Jeff  Keith ran across the United States from the east to the west. He started running in Boston. Seven  months later ,he stopped running in Los Angeles . He ran 3200 miles. Jeff wore out 36 pairs of running shoes and five plastic legs. Jeff stopped in cities on the way to Los Angeles. In every city people gave Jeff money .The money was not for Jeff ,but for American Cancer Society .The Society used the money to know more about cancer .\n",
      "On the way to Los Angeles Jeff talked to people about cancer. Jeff is disabled ,but he can do many things. He finished college and is studying to be a lawyer .Jeff says, \"People can do anything they want to do .I want people to know that I ran not only for disabled people ,I ran for everybody.\"\n",
      "\n",
      "Question: Jeff's right leg was cut off  because of  the  _  .\n",
      "A. .TB\n",
      "B. an accident\n",
      "C. cancer\n",
      "D. hurt\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Most People don't like mice, but they love one mouse -- Mickey Mouse. In their mind, this mouse is their favourite animal. About 70 years ago, an American man called Walt Disney created  a cartoon mouse for films. He named this mouse Mickey Mouse. From the beginning, Mickey Mouse is a clean mouse. He always does many interesting things. That's why many children and people love him. He makes them happy and _ . In the film, Mickey Mouse also has a lot of friends, for example, Donald Duck and Pluto. Donald can do many things that Mickey cannot. Pluto is a dog. He always does foolish things and makes foolish mistakes. Many children like these cartoon animals, but they like Mickey most because the mouse is a star of beauty and wisdom .\n",
      "\n",
      "Question: Many children and people like Mickey Mouse because  _  .\n",
      "A. He never makes mistakes\n",
      "B. He is like a real mouse.\n",
      "C. He always does many interesting things\n",
      "D. He has many friends.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Han Bin, a 15-year-old Chinese boy, likes eating snacks very much.He prefers cream   biscuits, McDonald's food and Beijing roast duck.Sometimes he eats two packages of biscuits a day.As a result, he becomes fatter and fatter.\n",
      "Today in China, there are many children like Han Bin.They like snacks.They don't eat enough healthy food like vegetables and fruit.It's bad for their health.Bad eating habit is a serious   problem.\n",
      "Health experts   say that children should have healthy eating habits.First, they must eat regular meals and have a good breakfast.Then, they should have different kinds of foods, such as fruit, vegetables, eggs, milk, meat and so on.Third, children shouldn't eat too many snacks and too much fried food. They are delicious, but eating too much of them is unhealthy.\n",
      "If children do as the experts say, they won't become fat.They will be healthier.And they will have enough energy to study well.\n",
      "\n",
      "Question: If the students do as the experts say, they will   _  .\n",
      "A. be experts when they grow up\n",
      "B. become more and more beautiful\n",
      "C. have enough energy to study\n",
      "D. become fatter and fatter\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Luke Dollar has spent many years in Madagascar studying lemurs  .\n",
      "Reporter: What were you like as a kid?\n",
      "Dollar: As a kid, I was an explorer. I lived with my grandparents on a farm in Alabama. It wasn't unusual for me to go to the woods. And I enjoyed that. From the time I was 6 to 16 years old I was an actor. My mom asked me to audition\n",
      "  for a show in Birmingham. I asked my mom to buy me some video games and she promised  , so I got the part. Later, I became a professional actor. So for several years I went everywhere from the Alabama farm to many other cities -- all over the USA doing stage productions.\n",
      "Reporter: How did you get into your field of work?\n",
      "Dollar: I grew up on a farm and I was really a wild child and came to love wild things. I did a lot of photography in high school. I became a photographer and did photography for the local paper. Then I became a student of Duke University. Duke has a primate   centre -- Lemur Centre. I got a job there as a work study student and met lemurs there for the first time.\n",
      "Later I had a chance to go to Madagascar and decided to study lemurs.\n",
      "Reporter: What's the one thing you can't travel without?\n",
      "Dollar: A sense of humour   or a can-do attitude is necessary, but my first response   was soy sauce. If we run out of soy sauce, the journey is over.\n",
      ",.\n",
      "\n",
      "Question: What do we know from the dialogue ?\n",
      "A. Luke's mother is a good photographer.\n",
      "B. Luke come to love wild animals because of his mother .\n",
      "C. Luke had been to Madagascar before he went to Duke University.\n",
      "D. Luck doesn't think he can travel without soy sauce.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [426]\n",
      "[Prompt]:\n",
      "Article: Dan was the doorman of a club in a big city. Every day, thousands of people passed his door, and a lot of them stopped and asked him, \"What's the time, please?\"\n",
      "After a few months, Dan said to himself, \"I'm not going to answer all those stupid people any more. I'm going to buy a big clock and put it on the wall here.\" Then he did so.\n",
      "\"Now people aren't going to stop and ask me the time.\" He thought happily.\n",
      "But after that, a lot of people stopped, looked at the clock and asked Dan, \"Is that clock right?\"\n",
      "\n",
      "Question: What does Dan do?\n",
      "A. a policeman\n",
      "B. a doorman\n",
      "C. a worker\n",
      "D. a waiter\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Lucy is a student in Class Two , Grade Seven . She is eleven years old . She had a beautiful toothbrush . But it was broken last Sunday . She was very sad because not only it was beautiful ,but also it was blue --- her favorite color . So her mother went shopping with her to buy a toothbrush on Sunday afternoon .\n",
      "There are many toothbrushes in the shop . They bought a blue one . There is a blue bird in it . And it is made in Guangzhou . It's ten yuan . _ . But it is so beautiful . And she likes it very much . Then they went home . Lucy can brush teeth now . How happy she is !\n",
      "A, B, C, D.\n",
      "\n",
      "Question: Where is Lucy's toothbrush from ?\n",
      "A. The US\n",
      "B. China\n",
      "C. Japan\n",
      "D. Singapore\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [426]\n",
      "[Prompt]:\n",
      "Article: Would you like to adopt an animal? Although this sounds very unusual, some children have done just this. The Natural Zoo has given people the chance to adopt animals by paying for all of its food for one year. One of the animals that needed parents was a young tiger named Brocky. The people at the zoo said that it would cost about $900 a year for the food for Brocky.\n",
      "Not many boys and girls have $900 to spend. That is why several hundred children and grown-ups each have sent a little money to the zoo to help pay for Brocky's food. Some children sent in only a quarter because that was all the money they had. Other children sent in more money than that.\n",
      "Since so many people sent money to the zoo to help pay for Brocky's food, he now will be able to eat as much as he wants. Brocky surely must be a happy tiger to know that he has so many adopted parents. Many children must also be happy to know that they have helped to feed him. It really will be thrilling for those children to go to the Natural Zoo to visit their adopted tiger Brocky.\n",
      "\n",
      "Question: With so many people's money, Brocky now can   _  .\n",
      "A. play with many toys\n",
      "B. live without being hungry\n",
      "C. eat meat every day\n",
      "D. have an air-conditioned room to live in\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Checking output ids: [423]\n",
      "[Prompt]:\n",
      "Article: \"Can I see my baby?\" asked the happy new mother. When the baby was in her arms, she couldn't believe her eyes. The baby was born without ears.\n",
      "Time proved  that the baby's hearing was very good though he had no ears. He got on well with his classmates. But one day, he said to his mother, tears in his eyes, \"A big boy called me a freak  .\"\n",
      "The boy's father asked the family doctor. \"Could nothing be done?\"\n",
      "\"I believe I could graft   on a pair of outer ears if they could be got,\" the doctor said. They tried to find a person who was helpful for the young man.\n",
      "One day, his father said to the son, \"You're going to the hospital, son. Mother and I have someone who will donate the ears you need. But we must keep it a secret who the person is.\"\n",
      "The operation  was a great success, and a new person appeared. His cleverness and hard work made him a very successful person. He married and lived a happy life.\n",
      "He once asked his father, \"Who gave me the ears? I could do enough for him or her.\"\n",
      "\"I do not believe you could, \"said the father.\" The agreement was that you are not to know...not yet.\"\n",
      "For years they kept it a secret, but the day did come. He stood with his father over his mother's body. Slowly, the father raised the thick, brown hair. To his surprise, the son found his mother had no outer ears.\n",
      "\"Mother said she was glad she never needed to cut her hair,\" his father said in a low voice, \"and nobody ever thought mother less beautiful, did they?\"\n",
      "\n",
      "Question: Why did the boy's mother never cut her hair?\n",
      "A. Because she liked her thick, brown hair.\n",
      "B. Because her work didn't allow her to do that\n",
      "C. Because the hair was good for her health\n",
      "D. Because she wanted to keep the fact a secret\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Jake is going on a trip. He and Mum take a taxi to the airport.\n",
      "\"It's my first plane trip,\" he tells the taxi driver.\n",
      "\"That' s great!\" the taxi driver says.\n",
      "Jake rolls his suitcase onto the plane.\n",
      "\"It's my first plane trip,\" he tells the pilot.\n",
      "\"Welcome aboard,\" the pilot says.\n",
      "Jake finds his seat and buckles his seatbelt . The plane's engines _ Jake opens his backpack and pulls out Panda.\n",
      "\"It's my first plane trip,\" he whispers. He holds Panda's paw.\n",
      "The plane moves faster and faster. Then-Whoosh! On the ground, cars and houses look like toys.\n",
      "Jake smiles. \"Guess what, Panda?\" he says. \"Flying is fun!\"\n",
      "\n",
      "Question: Who is Panda?\n",
      "A. Jake's brother\n",
      "B. A large animal\n",
      "C. Jake's pet\n",
      "D. A toy animal\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
      "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
      "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
      "\n",
      "Question: Where did Victory Bacelis grow up?\n",
      "A. in California\n",
      "B. in America\n",
      "C. in Mexico\n",
      "D. at McDonal's\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Driving a car at a high speed along a highway seems to be fun. You only need to follow the bright traffic signs beside the highway and it will take you where you wish to go. But to a London taxi driver, driving is not an easy job. A taxi driver needs to have not only good driving skills but also a good knowledge of the city of London, from the loneliest street to the popular restaurant around. He has to be at the service of all kinds of passengers   at all times.\n",
      "A London taxi driver said the following about his job.\n",
      "During the night it is usual for him to stop two or three times for some food. He said, \"I never drink when I'm working, otherwise I'd lose my license  .\"\n",
      "He normally goes home between two and three o'clock in the morning. There are times he has to stay longer and try to make more runs. He said, \"That's the worst thing about working for yourself. If you don't make money, no one is going to give it to you. \"\n",
      "London taxi drivers not only \"take\" but also \"give\". Every summer hundreds of poor children from London go for a day at the sea -- by taxi! There rides are paid by the taxi drivers. At the sea, they are met by the mayor   , and a lunch party is also held for the taxi drivers and the children. After a happy day's running around the beaches and visiting the market there, the children go home again by taxi, free of charge of course!\n",
      "\n",
      "Question: How do London taxi drivers \"give\"?\n",
      "A. They give the poor children a lunch party at the sea each summer.\n",
      "B. They give poor children the chance to meet the maor.\n",
      "C. They pay for some poor children's rides for a day's tour each summer.\n",
      "D. They play with some poor children at the sea for a day each summer.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: This is a special class. The students come from different countries. Some come from America. Others come from Canada, Japan, Australia and England. They speak different languages,but all of them can speak English. They are good friends. They study together, play together and live together. They help each other. All the teachers of this class are Chinese, but they can speak English. They are very kind and friendly. They work hard. The students in this class study Chinese cooking and Chinese gongfu.\n",
      "All the students like China. They say China is a great country and the Chinese people are very friendly. And they are happy in China.\n",
      ",.\n",
      "\n",
      "Question: What language can all the students speak?\n",
      "A. Chinese\n",
      "B. French\n",
      "C. English\n",
      "D. Japanese\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: 0ur village carpenter ,John Hill, came one day and made a dining table for my wife.  He made it just the right size to fill the space between the two window.  When I got home that evening, John was drinking a cup of tea and writing out his bill( ) for his job.\n",
      "My wife said to me quietly, \"That's his ninth cup of tea today. \"But she said in a loud voice, \"It's a beautiful table, dear, isn't it?\" \"I'll decide about that when I see the bill,\" I said.  John laughed and gave me his bill for the work.  I read:\n",
      "One dining table                 10thNovember, 2011\n",
      "Cost of wood                    $ 17:00\n",
      "Paint                           $1. 50\n",
      "Work, 8 hours($1 an hour)          $8. 00\n",
      "Total                           $36. 50\n",
      "When I was looking at the bill, John said,\" It's been a fine day, hasn't it? Quite sunny. \"\n",
      "\"Yes,\" I said.  \"I'm glad it's only the 10thof November. \"\n",
      "\"Me, too,\" said John, \"you wait--it will be a lot colder by the end of the month. \"\n",
      "\"Yes, colder--and more expensive! Dining table will be $20 more expensive on November 30th, won't they, John?\"\n",
      "John looked hard at me for half a minute.  Was there a little smile in his two blue eyes? I gave his bill back to him.\n",
      "\"If it's not too much trouble, John,\" I said,\"Please add  it up again, You can forget the date-------\"\n",
      "I paid him $26. 50 and he was happy to get it.\n",
      "\n",
      "Question: When John got the money, he was happy because  _  .\n",
      "A. he felt lucky to get the money for his work\n",
      "B. he got paid a lot more than usual for his work\n",
      "C. he got as much money as he had expected\n",
      "D. he didn't have to add up the costs any more\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Several years ago, Kevin Stephan, then aged 11, was playing baseball when a player accidentally hit him with a bat.\n",
      "Kevin fell down and his heart stopped. Penny Brown, the mother of another player, was watching the game.Penny usually worked in the evenings as a nurse, but luckily that evening she wasn't working. Penny ran to helped Kevin and saved his life.\n",
      "Nearly seven years later, Kevin was washing up in the kitchen of the Hillview Restaurant in Buffalo, New York State. Normally, 18-year-old Kevin had school in the afternoon, but that week there were exams and he didn't have any class. At about 2 p.m., Penny Brown was having lunch with her family in the restaurant. She was eating when some food got stuck in her throat. She was very frightened because she couldn't breathe.\n",
      "Kevin was a volunteer firefighter in his free time and he ran to help. A waitress tried to help her, but the food was still stuck in Penny's throat. Kevin pulled his hands quickly into her stomach and saved Penny's life. He didn't know it was Penny, but his mother, Lorraine Stephan, was also having lunch in the restaurant. She realized that Penny was the woman who saved Kevin's life, seven years before, at the baseball game. Both Penny and Kevin were completely amazed by the coincidence !\n",
      "\n",
      "Question: What did Kevin usually do in the afternoon when he was 18?\n",
      "A. He had some exams.\n",
      "B. He studied at school.\n",
      "C. He worked as firefighter.\n",
      "D. He worked in a restaurant.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Music education hasn't changed much since the 1970s. Students are still taught to read notation so they can recite compositions that they would never listen to on their MP3 players or play with friends. Playing music enriches life. The question is: Why do schools teach music in a way that _ so many young people rather than catch their imagination? Can we do a better job of using the power of music to get kids excited about school?\n",
      "The experience of an organization called Little Kids Rock suggests the answer is yes -- if we change the way music is taught. Little Kids Rock has helped music programs in over a thousand public schools and served 150,000 children. The organization has given 30,000 free instruments out, mainly guitars, and trained 1,500 teachers to run music classes in which students quickly experience the joys of playing their favorite songs, performing in bands , and writing their own music.\n",
      "The key to Little Kids Rock is that it teaches children to play music the way many musicians learn to play it -- not by notation, but by listening, imitation and meaningful experimentation. \"The knowledge you need to get started playing rock music is very limited,\" explains Dave Wish, the founder of Little Kids Rock. \"In high school, my friend Paul taught me a couple of chords and my life was changed forever. On the first day of class, Little Kids Rock teachers place guitars in the hands of their students and get them practicing chords that will enable them to play thousands of songs. The kids decide what songs they want to learn and the class is off and running. Their progress is surprising. Within a year, eight and nine-year-olds are playing musical instruments, and giving concerts, even performing their own songs.\n",
      "One of the biggest advantages that music offers is the ability to encourage students who are otherwise bored by school. \"I've had students start coming back to school because of this program,\" said Adkison Thomas, who heads up music for the Dallas Independent School District. He added, \"One of the best things is that the teachers discover a new side of their students. They see kids become successful who weren't before.\"\n",
      "\n",
      "Question: How did Little Kids Rock help the school?\n",
      "A. By writing music for kids.\n",
      "B. By playing kids' favorite songs.\n",
      "C. By making instruments for school.\n",
      "D. By training teachers for music classes.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Today is July 21. Most people are enjoying their weekend now. John is watching a magic show at the Capital Stadium with his parents and a friend from Australia.\n",
      "The girl is Megan, she is staying at John's for her holiday now. Her parents and brother Andy are now visiting the zoo. Their father is taking photos of many animals, like elephants, pandas, zebras and tigers. But Andy likes monkeys most and he is now watching them jumping and playing.\n",
      "Andy's cousin Julia is at her friend's birthday party. There she meets Lily, Daming, Joy and Lingling. They are having a happy talk and drinking some juice. Julia's grandparents are having a Taijiquan class, while her mother is shopping for presents. Julia's family is going back home to the Unite States next Thursday, so her father is booking plane ticket on the Internet.\n",
      "\n",
      "Question: Megan's brother is   _  .\n",
      "A. Joy\n",
      "B. John\n",
      "C. Andy\n",
      "D. Julia\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: A young man woke up one morning under a bridge and checked his pocket. All he had left was less than ten dollars. He bought food and as he sat down to eat, an old man and two children came along. The old man asked him to help them with food as they had not eaten for almost a week.\n",
      "The young man looked at the children---they were so weak that they could hardly stand. With the last bit of kindness he had he gave them all the food. The old man and children thanked the young man and then gave him a dirty old coin. The young man said, \"You need this coin more than I do--- just keep it.\" The old man insisted  that the young man put it in his pocket---and finally he did.\n",
      "The old man and children sat down to eat. And with no money, no job and no food, the young man went back under the bridge to lie down. As he was about to fall asleep he saw an old newspaper on the ground. He picked it up and saw an ad inviting people with old coins to come to a store. He decided to go there with the dirty old coin the man gave him.\n",
      "When he arrived at the store, he gave the keeper the dirty old coin. The keeper cried loudly. It was part of a Spanish treasure ship that had never been found. This same old coin was worth 67,000 dollars. The young man was pleased. He immediately sold the coin for money and then looked for the old man and little children to thank them and share the money. By the time he got to where he left them eating, they had gone.\n",
      "\n",
      "Question: Which of the following is True?\n",
      "A. The old man and children had nothing to eat for a month.\n",
      "B. The young man had a big meal after getting so much money.\n",
      "C. The young man thought the old man needed the coin more than he did.\n",
      "D. The young man sold the coin for 67,000 dollars and gave half of the money to the old man.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: When Kyle walked into Ernie's Pet World, he looked very worried. He walked quickly to the front counter . Ernie jumped out to greet Kyle. He was the shop's first shopper of the day.\n",
      "\"Good morning, sir!\" Ernie said. \"What can I do for you?\"\n",
      "\"Well, I...,\" Kyle started to say.\n",
      "\"Wait, don't tell me,\" Ernie stopped him. \"You're looking for a ... a little dog... for your daughter 's birthday. Right?\"\n",
      "\"Not really, l just...\"\n",
      "Ernie didn't let him finish.\"Ah, I've got it, You just moved into a new house, and you want some fish for it. I have some very nice fish over here.\"\n",
      "\"In fact, I...\" Kyle was starting to look very nervous  . His face had a strange expression on it.\n",
      "\"No fish? Ah, a cat! You look like a cat person. At Ernie's Pet World, we have the best kinds. Look at this Persian -- long, white hair, and look at that cute expression. She's looking at you. She's thinking, 'Take me home. Take me home.' Would you like some cat food and toys as well?\"\n",
      "\"No, thank you,\" Kyle said. By this time, he was walking up and down. He had a pained   look on his face. \"Really, I'm not interested in cats or fish or little dogs.\"\n",
      "\"What do you want, then?\" Ernie asked.\n",
      "Kyle looked like he was going to cry. \"I just want to know if I can use your bathroom !\"he finally said.\n",
      "\n",
      "Question: Why did Kyle look anxious and pained?\n",
      "A. He wanted to get a cat very much.\n",
      "B. He didn't like animals.\n",
      "C. He was late for work.\n",
      "D. He wanted to go to the bathroom.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Four girls go to school every day by taxi. One day one of the girls says, \"There is a test this morning. Let's get to school late. Then we will not have the test.\"\n",
      "\"What can we tell the teacher?\" One of the girls says. \"He will be angry. We will need a good excuse.\"\n",
      "The girls think for a moment, then one of them says, \"Let's tell him that our taxi has a flat tire .\"\n",
      "\"That's a good idea,\" the other girls say. \"We will tell him that.\"\n",
      "They get to school an hour later. The test is over. \"Why are you late? You missed the test.\"\n",
      "\"Our taxi had a flat tire.\" One of the girls said.\n",
      "The teacher thought for a moment, then he said, \"sit down, One of you in each corner of the room.\" The four girls do this.\n",
      "Then the teacher says, \"Write down a piece of paper the answer to this question: Which tire is flat?\"\n",
      "\n",
      "Question: Can the girls answer the teacher's question?\n",
      "A. No, they can't. Because they can't remember which tire is flat.\n",
      "B. Yes, they can. Because there is a flat tire.\n",
      "C. No, they can't. Because they may give a different answer.\n",
      "D. Yes, they can. Because all four tires are flat.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [423]\n",
      "[Prompt]:\n",
      "Article: Raising pets is a popular online game among teenagers. \"More than 20 of my classmates have adopted pets online, while last year the number was just 10,\" said Wang Hui,a middle school student from Beijing, who also raises pets online.\n",
      "If you go to some websites, you can adopt virtual pets like penguins, chickens, dogs and elephants. You can feed,wash, talk to and play with your pet.\n",
      "Dai Yingshuang of Shanghai raises pets on KaixinOOl. com. The 15-year-old girl said it is great fun. She thinks that she has also learned how to take care of others.\n",
      "If one doesn't feed and care for the pet, it becomes unhappy and unhealthy. So raising an online pet means spending a lot of time online.\n",
      "This makes many parents worried. They fear there will be bad influence in the children's studies.\n",
      "Dai said that she usually asks her uncle to take care of her pet, while she is at school.\n",
      "Wang Zhaotong, from Anhui,has been raising a penguin on QQ. com since last year. The 14-year-old girl takes good care of the penguin.\n",
      "She said her parents knew about the penguin and think it's Okay. If the students can keep the balance between studying and playing, it's not bad for them to \"raise\" pets online.\n",
      ",,.\n",
      "\n",
      "Question: What does Dai Yingshuang think of raising pets online?\n",
      "A. It's not interesting at all.\n",
      "B. It wastes time.\n",
      "C. It's not good for her study.\n",
      "D. It is great fun.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Once upon a time, there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day the feelings were told that the island would sink, so all built boats and left, except Love. Love was the only one who stayed. Love wanted to hold out  until the last possible moment.\n",
      "When the island had almost sunk, Love decided to ask for help.\n",
      "Richness was passing by Love in a big boat. Love said, \"Richness, can you take me with you?\"\n",
      "Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
      "Love decided to ask Vanity  who was also passing by in a beautiful ship.\"Vanity, please help me!\"\n",
      "\"I can't help you, Love. You are all wet and might damage  my boat, \"Vanity answered.\n",
      "Sadness was close by so Love asked, \"Sadness, let me go with you.\"\n",
      "\"Oh...Love, I am so sad that I need to be by myself!\"\n",
      "Happiness passed by Love, too, but she was so happy that she did not even hear when Love called her.\n",
      "Suddenly, there was a voice, \"Come, Love, I will take you.\"It was an elder. So thankful and happy, Love even forgot to ask the elder where they were going. When they arrived at dry land, the elder went her own way. Realizing how much was owed  the elder, Love asked Knowledge, another elder, \"Who helped me?\"\n",
      "\"It was Time, \"Knowledge answered.\n",
      "\"Time?\"asked Love.\"But why did Time help me?\"\n",
      "Knowledge smiled with deep wisdom  and answered, \"Because only Time is able to understand how valuable Love is.\"\n",
      "\n",
      "Question: How many feelings did Love ask for help but failed?\n",
      "A. 2.\n",
      "B. 3\n",
      "C. 4\n",
      "D. 5\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Lin Tao and Chen Hai are good friends. They are in the same class. They are in the same team. Lin Tao sits behind Chen Hai. Now it is four o'clock. School is over. They often go to play games after school. They can't look after their things very well. So their mothers don't give them watches. They don't have watches. They don't know the time. But they can ask a man under the big tree. His watch is very nice. They can also see the clock on the wall of the classroom. Now it's about five in the afternoon. It's time to go home. They must put on their clothes and go home.\n",
      "\n",
      "Question: Why don't they have watches?\n",
      "A. Because they don't need watches.\n",
      "B. Because they can't look after their things well.\n",
      "C. Because their watches are in their desks.\n",
      "D. Sorry, I don't know.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: October is getting closer and it also means that the year of 2014 is coming to an end. \"Hooray! It's a holiday!\" While you are thinking of putting textbooks aside and playing video games, let's take a look at what children in other continents usually do during their holidays.\n",
      "Children in America don't have much homework to do. They keep themselves busy by playing camp games. A parent says, \"My daughter Shirley usually attends different camps. We don't ask her to spend plenty of time on maths problems or spelling tests.\"\n",
      "Children in Australia take partin activities on over twenty different themes  . They learn painting, dancing, singing, history, culture and so on. Parents can _ their kids to enjoy the learning process and to build a closer relationship with them.\n",
      "These are what African kids do: build a boat, have a camel race, make a drum and make a rag   football. Don't you think it is interesting that kids in other places have no idea how to make a drum, but kids in Africa do?\n",
      "Plan your holiday well and try what you want to try. Make a good plan and you will have a lot of fun.\n",
      "\n",
      "Question: According to the passage, only kids in Africa know how to   _  .\n",
      "A. play camp games\n",
      "B. do spelling tests\n",
      "C. build a boat\n",
      "D. make a drum\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: My name is David and I have two brothers, Mark and Bruce. We like hamburgers for lunch. Mark and I like French fries, but Bruce doesn't. I don't like eggs for breakfast, but Mark and Bruce do. I like fruit for breakfast. We really like chicken and salad for dinner.\n",
      "\n",
      "Question: _   doesn't like eggs for breakfast.\n",
      "A. Mark and Bruce\n",
      "B. David\n",
      "C. Mark\n",
      "D. Bruce\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Hip-hop dancing    is popular with many young people today. They like it because they can invent their own moves. They use this dance to show their love for life. It also shows that they feel good about life, that they just want to be themselves and enjoy life, and that they are not afraid of problems.\n",
      "Hip-hop dancing has a history of more than 20 years. It first began in the 1980s in the USA. In early times, in New York and Los Angles, many young black people often danced to the music in the streets. They used their legs, arms, heads and even shoulders to dance. Many young people still use most of these moves today.\n",
      "Hip-hop dancing became popular all over the world because of the 1983 film Flashdance. Some people performed   Hip-hop dancing in the movie. People enjoyed their performance. They began to dance like them. Then it became popular. There are two kinds of Hip-hop dancing: new school and old school. More and more young people are learning Hip-hop dancing. People believe that it is a good way to exercise their bodies, and that it is good for their health.\n",
      "\n",
      "Question: At first , people can see Hip-hop dancing   _  .\n",
      "A. in movies\n",
      "B. in streets\n",
      "C. in old schools\n",
      "D. in new schools\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: We have two new students in our class. They are Cindy and Kate. They look the same. But they aren't twins.\n",
      "Cindy is American. She is thirteen. Her father and mother are both teachers. She likes green and blue. She is often in blue pants. She often plays the guitar after school. She is good at math and English. She says math is her favorite because it is interesting.\n",
      "Kate is English. She is twelve. Her parents are not teachers. Her father is a doctor and her mother is a worker. Kate likes yellow and orange. She can't play the guitar. But she plays volleyball very well. Her favorite subject is Chinese. She say she wants to learn about Chinese history. Kate likes documentaries very much.\n",
      "\n",
      "Question: Cindy is   _  .\n",
      "A. 12 years old\n",
      "B. American\n",
      "C. English\n",
      "D. Kate's sister\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Checking output ids: [362]\n",
      "[Prompt]:\n",
      "Article: Today is Sunday. All of us go to school early. Our teachers are going to take us to Blue Sky Park. The park is near our school. We can go to the park on foot.\n",
      "Blue Sky Park is very beautiful. There are many trees, a football field, a big playground and a small lake in it. It's a sunny day today, but there are not many people in the park. Li Lei is sitting under the tree. Han Mei and Lu Lu are playing on the playground. A bird in the tree is watching them. Look at me. I am playing football with other boys. How happy we are! Where are Miss Fang and Mr. Wu? They are boating on the lake. All of us have a good time in the park. We want to visit it again.\n",
      "\n",
      "Question: Miss Fang and Mr. Wu are  _  .\n",
      "A. near the river\n",
      "B. under the tree\n",
      "C. on the playground\n",
      "D. in the boat\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: Train-spotting\n",
      "Many people around the world have seen Danny Boyle's movie Train spotting starring Ewan McGregor, but how many of us really know what train-spotting is all about? Now this is not considered cool in town and the word \"train-spotter\" in Britain is related to \"geek\" or \"nerd\" (someone who seems very ridiculous). But is this reputation really deserved?\n",
      "First of all, let's see what train-spotting is. It is said that there are some 100,000 train spotters in the UK. Exactly as the title suggests, they spot trains, that is, they stand in train stations, look at the number of each train that leaves and arrives and write it down. The eventual aim is to have seen every train in the country.\n",
      "Being crazy about railways and trains is not modern and it dates back to 1804. As the number of trains grew and they got faster and faster, so did the interest in them grow? Is this any stranger than people who love cars?\n",
      "So, what do you need to be a train-spotter? Well, all you really need is a pen or pencil and a notebook to write down the train numbers. Other equipment  includes hot tea in a thermos, a camera and some sandwiches for those long afternoons spent on train platforms when you don't want to risk the delights of railway station food.\n",
      "It's interesting to note that despite the \"bad name\" of train-spotting, there have been famous railway lovers in history, such as Alfred Hitchcock, who filmed them regularly, especially The 39 Steps. There is evidence, too, that being a train-spotter is not necessarily a strange phenomenon in Britain.\n",
      "One glance at the US train stations should be enough to convince you that train-spotters there are alive and well. In America, they try to call rail lovers \"train-fans\" and talk of \"train-fanning\". Don't let this fool you--these people are train spotters and there are a lot of them. Each month, two million pages are visited on the website TrainWeb.org.\n",
      "340words\n",
      "\n",
      "Question: The writer writes the passage to_.\n",
      "A. introduce some famous train-spotters\n",
      "B. encourage readers to do more train-spotting\n",
      "C. try to present a true picture of train-spotting\n",
      "D. describe the necessary equipment in train-spotting\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Checking output ids: [426]\n",
      "[Prompt]:\n",
      "Article: Mo, the first Nobel winner in literature born and living in China, said he had trouble with the sudden publicity, which put a lot of pressure on him.\n",
      "\"I only hope to return to my writing desk as soon as possible, and I would also like to do well in society anonymously. \" Mo said. He was bothered by a large number of requests asking him to offer help that took advantage of his fame. \" I was upset the first several days after the prize announcement, but then I realized the prize is just like a mirror that reflects various attitudes about my winning, and more, reflects the real me,\" Mo said. \"I still consider myself an ordinary citizen who writes. And presenting quality works is my duty and best way of giving back to society. I'm no superstar,\" he emphasized  several times.\n",
      "Mo believes Chinese literature has achieved much in the past thirty years, and the driving force behind that is not the prize. Writers' creations should not be driven by awards, or criticism, or readers' expectations. Mo said he misunderstood the standards of the academy's selection before he visited Stockholm  to receive the prize in December.\n",
      "\"I thought they were judging the authors' personality or political features, then I learned the sole standard of their selection is literature itself, which is also deeply based in the Swedish people's long-established practice of reading a large number of books,\" Mo said.\n",
      "During the forum, established Chinese and Australian writers discussed subjects as diverse as tradition and modernity, the local and the universe and cultural inclusiveness. And they will also read works to each other and the readers. The writers communication will further promote  Chinese writers to a global audience.\n",
      "Australian Ambassador  to China Frances Adamson agreed. \"It's a milestone  of literary exchanges between the two countries, who are longtime friends,\" Adamson said.\n",
      "\n",
      "Question: What did Mo say about himself after he got the prize?\n",
      "A. He considered he was a superstar.\n",
      "B. He still considered he was an ordinary citizen who writes.\n",
      "C. He considered he was famous all over the world.\n",
      "D. He considered he became rich.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Checking output ids: [356]\n",
      "[Prompt]:\n",
      "Article: What are your clothes made of? Are they made of cotton or wool? Some students in Shandong wear different things. Their clothes are made of discs  or old clothes!\n",
      "On October 7th, 36 students in Linyi, Shandong Province, wore beautiful clothes in a show. Their clothes were made of all kinds of things.\n",
      "The show gave the students a chance to make things with their own hands. It also helped them learn to make good use of waste and not to throw everything away.\n",
      "Students had lots of good ideas. Some found used things, like old clothes, to make new dresses.\n",
      "\"We hope to save energy. Our world is _ of energy. So I don't want to just throw old things away,\" said Xie Jing at Linyi Art School.\n",
      "Xie had more than 20 discs on her nice blue dress. She got them from her family and friends.\n",
      "\"Though the discs are old, I look very cool in them!\" she said.\n",
      "Song Dandan, a student from the school, looked like a farmer in her straw  coat and hat. She picked the straw from the fields and put them all together.\n",
      "\"I want to show what people wore in the past.\" she said.\n",
      "Du Yue made clothes for astronauts ! She had white cloth all over her. When she walked, she tried to be slow. It looked like she was walking on the moon.\n",
      "\"I hope to wear it in space  some day. I wish that I could walk on the moon!\" she said.\n",
      "\n",
      "Question: The show tells people   _  .\n",
      "A. we should save energy\n",
      "B. they are clever\n",
      "C. how to make use of old things\n",
      "D. A, B and C\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "{'predicted_text': {'exact_match': 0.4099999964237213, 'accuracy': 0.41}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.06352775096893311}, 'time_per_token': {'mean': 0.06352775096893311}, 'tokens_per_second': {'mean': 17.077705254554747}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "  1%|          | 1/100 [00:00<00:42,  2.33it/s]\n",
      "  3%|▎         | 3/100 [00:00<00:15,  6.27it/s]\n",
      "  5%|▌         | 5/100 [00:00<00:10,  8.97it/s]\n",
      "  7%|▋         | 7/100 [00:00<00:08, 11.37it/s]\n",
      "  9%|▉         | 9/100 [00:00<00:06, 13.10it/s]\n",
      " 11%|█         | 11/100 [00:01<00:06, 13.72it/s]\n",
      " 13%|█▎        | 13/100 [00:01<00:05, 14.56it/s]\n",
      " 15%|█▌        | 15/100 [00:01<00:05, 15.17it/s]\n",
      " 17%|█▋        | 17/100 [00:01<00:05, 15.59it/s]\n",
      " 19%|█▉        | 19/100 [00:01<00:04, 16.34it/s]\n",
      " 21%|██        | 21/100 [00:01<00:04, 16.94it/s]\n",
      " 23%|██▎       | 23/100 [00:01<00:04, 16.30it/s]\n",
      " 25%|██▌       | 25/100 [00:01<00:04, 15.86it/s]\n",
      " 27%|██▋       | 27/100 [00:02<00:04, 15.73it/s]\n",
      " 30%|███       | 30/100 [00:02<00:04, 15.56it/s]\n",
      " 32%|███▏      | 32/100 [00:02<00:04, 16.30it/s]\n",
      " 34%|███▍      | 34/100 [00:02<00:03, 16.75it/s]\n",
      " 36%|███▌      | 36/100 [00:02<00:03, 17.03it/s]\n",
      " 38%|███▊      | 38/100 [00:02<00:03, 17.05it/s]\n",
      " 40%|████      | 40/100 [00:02<00:03, 17.22it/s]\n",
      " 42%|████▏     | 42/100 [00:02<00:03, 16.33it/s]\n",
      " 44%|████▍     | 44/100 [00:03<00:03, 15.92it/s]\n",
      " 46%|████▌     | 46/100 [00:03<00:03, 16.18it/s]\n",
      " 48%|████▊     | 48/100 [00:03<00:03, 15.69it/s]\n",
      " 51%|█████     | 51/100 [00:03<00:02, 16.85it/s]\n",
      " 53%|█████▎    | 53/100 [00:03<00:02, 17.03it/s]\n",
      " 55%|█████▌    | 55/100 [00:03<00:02, 16.86it/s]\n",
      " 57%|█████▋    | 57/100 [00:03<00:02, 17.17it/s]\n",
      " 59%|█████▉    | 59/100 [00:03<00:02, 16.99it/s]\n",
      " 61%|██████    | 61/100 [00:04<00:02, 16.96it/s]\n",
      " 63%|██████▎   | 63/100 [00:04<00:02, 17.75it/s]\n",
      " 65%|██████▌   | 65/100 [00:04<00:02, 17.02it/s]\n",
      " 67%|██████▋   | 67/100 [00:04<00:02, 16.44it/s]\n",
      " 69%|██████▉   | 69/100 [00:04<00:01, 16.73it/s]\n",
      " 71%|███████   | 71/100 [00:04<00:01, 15.71it/s]\n",
      " 73%|███████▎  | 73/100 [00:04<00:01, 16.56it/s]\n",
      " 75%|███████▌  | 75/100 [00:04<00:01, 17.01it/s]\n",
      " 77%|███████▋  | 77/100 [00:04<00:01, 17.54it/s]\n",
      " 79%|███████▉  | 79/100 [00:05<00:01, 17.10it/s]\n",
      " 81%|████████  | 81/100 [00:05<00:01, 16.54it/s]\n",
      " 83%|████████▎ | 83/100 [00:05<00:01, 16.60it/s]\n",
      " 85%|████████▌ | 85/100 [00:05<00:00, 15.54it/s]\n",
      " 87%|████████▋ | 87/100 [00:05<00:00, 15.59it/s]\n",
      " 89%|████████▉ | 89/100 [00:05<00:00, 15.64it/s]\n",
      " 91%|█████████ | 91/100 [00:05<00:00, 15.21it/s]\n",
      " 93%|█████████▎| 93/100 [00:06<00:00, 16.02it/s]\n",
      " 95%|█████████▌| 95/100 [00:06<00:00, 16.68it/s]\n",
      " 97%|█████████▋| 97/100 [00:06<00:00, 17.53it/s]\n",
      " 99%|█████████▉| 99/100 [00:06<00:00, 15.81it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 15.50it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard benchmark for dataset: race_h\n",
      "Layer 4/16: Halt prob: 0.2211, Accumulated: 0.2211, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1097, Accumulated: 0.3308, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0612, Accumulated: 0.3920, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0381, Accumulated: 0.4301, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0331, Accumulated: 0.4632, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0319, Accumulated: 0.4951, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0457, Accumulated: 0.5408, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1064, Accumulated: 0.6472, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1170, Accumulated: 0.7642, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0941, Accumulated: 0.8583, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0713, Accumulated: 0.9296, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0401, Accumulated: 0.9697, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0138, Accumulated: 0.9835, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0075, Accumulated: 0.0075, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0143, Accumulated: 0.0218, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0139, Accumulated: 0.0357, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0930, Accumulated: 0.1288, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0118, Accumulated: 0.1406, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0083, Accumulated: 0.1489, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0289, Accumulated: 0.1779, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0141, Accumulated: 0.1919, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0386, Accumulated: 0.2306, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7435, Accumulated: 0.9741, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0258, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Sometimes it may seem difficult to improve our health. If so, the following health habits may help you.\n",
      "Eat breakfast every morning.\n",
      "Research shows that if you eat a meal in the morning you may not become too fat or eat too much during lunch. Eating breakfast can help people feel better through the day.\n",
      "Get enough sleep.\n",
      "Poor sleep can influence our memory and learning. It can also cause traffic accidents! Studies show that people who don't get enough sleep seem to get into more accidents. So stay safe and get enough sleep!\n",
      "Take a walk every day.\n",
      "Walking is an easy way to exercise. You'd better meet friends for a walk, not for a meal. As you walk, you will see the beautiful world around you. Once you try, you will find that adding a walk into your daily life is very easy.\n",
      "Join social groups.\n",
      "Social groups can provide support. They might include sport teams, art or music groups. The people in the group can offer advice and can help each other in difficult times. Also, being in a group keeps your mind busy. An active mind is a healthy mind!\n",
      "Have a hobby.\n",
      "A hobby could be running reading or making something with your hands. Hobbies help people to relax and rest. Hobbies bring us joy as well.\n",
      ",A, B, C, D ,.\n",
      "\n",
      "Question: You may have a good memory and learn better if you    _   .\n",
      "A. eat breakfast every morning\n",
      "B. have a good sleep\n",
      "C. take a walk every day\n",
      "D. join a social group\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1853, Accumulated: 0.1853, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0837, Accumulated: 0.2690, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0534, Accumulated: 0.3224, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0366, Accumulated: 0.3590, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0300, Accumulated: 0.3890, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0422, Accumulated: 0.4312, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0487, Accumulated: 0.4799, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0950, Accumulated: 0.5749, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1455, Accumulated: 0.7204, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1139, Accumulated: 0.8343, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0823, Accumulated: 0.9166, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0472, Accumulated: 0.9638, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0162, Accumulated: 0.9801, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0082, Accumulated: 0.0082, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0251, Accumulated: 0.0333, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0099, Accumulated: 0.0432, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0325, Accumulated: 0.0757, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0078, Accumulated: 0.0834, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0052, Accumulated: 0.0887, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0040, Accumulated: 0.0927, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0119, Accumulated: 0.1046, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0097, Accumulated: 0.1143, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8243, Accumulated: 0.9386, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0604, Accumulated: 0.9990, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: More and more parents leave their homes and come into the big cities to make money. But their children can't go with them because their children have to go to school in their hometown. They are called home-left children. The problems of home-left children become more and more serious. And it becomes a big _ of our society. The main problem is that some home-left children become very lonely when they don't have their parents' love. And they are too young to tell right or wrong in many things. So they are fooled very easily by others.\n",
      "Xiao Mei , a 14-year-old girl, is a home-left child. Her parents are both in Shanghai. She is in her hometown with her grandpa. She likes playing games on the Internet. Her parents and grandpa only give her money and food. They hardly ever care for her studies. One day, she had no money to pay for the games in the Net bar. So she stole some money from her neighbor. Just at that time, Xiao Fang, a 9-year-old girl saw it. Xiao Mei was afraid that Xiao Fang would tell others about it. She cut Xiao Fang's throat with a knife, and then she went to school just like nothing happened. Luckily, Xiao Fang was saves by doctors. When she opened her eyes and wrote the fact to the policeman with a pencil, everybody was very surprised. This sad story reminds the parents to care for their children no matter how busy they are.\n",
      "Are you one of the home-left children? What do you need from your parents? Food, money or love? I think most children need love mostly. Let's care for the group together.\n",
      ",A, B, C, D,. 5,2,10\n",
      "\n",
      "Question: What does the story of Xiao Mei mainly tell us?\n",
      "A. We can't play computer games.\n",
      "B. Parents should care for their children.\n",
      "C. We should get along well with neighbors.\n",
      "D. Going to the big cities is not good.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1820, Accumulated: 0.1820, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0865, Accumulated: 0.2685, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0555, Accumulated: 0.3240, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0477, Accumulated: 0.3717, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0397, Accumulated: 0.4114, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0441, Accumulated: 0.4555, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0526, Accumulated: 0.5081, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1187, Accumulated: 0.6268, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1471, Accumulated: 0.7740, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1106, Accumulated: 0.8846, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0640, Accumulated: 0.9486, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0302, Accumulated: 0.9788, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0098, Accumulated: 0.9886, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0066, Accumulated: 0.0066, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0304, Accumulated: 0.0370, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0327, Accumulated: 0.0697, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0600, Accumulated: 0.1297, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0212, Accumulated: 0.1509, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0071, Accumulated: 0.1580, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0437, Accumulated: 0.2017, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0138, Accumulated: 0.2155, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0211, Accumulated: 0.2366, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7470, Accumulated: 0.9836, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0160, Accumulated: 0.9996, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Dear Dr Jackson,\n",
      "My parents are never happy with me. They are always criticizing my clothes, my hair and the music I listen to. They hate my friends' looks and they keep complaining when I go with them. I'm not allowed to stay out as late as my friends do, so I can't have any fun. My parents only seem to care about my school grades. Although I love them, sometimes I feel we live in different worlds. If they love me, can't they understand me? How can I make them understand me?\n",
      "Angel\n",
      "Dear Angel,\n",
      "Your problem is common to both teenagers and parents. Don't worry, because all this is natural. You see, your parents have grown up at a different time and they have different experiences. So, they think some things are strange, but you find the same things are all right. For example, the music you like may sound like noise to them. Your parents love you, so they feel they must stop you from doing whatever they find strange. On the other hand, you don't want to be different from other teenagers, so you feel that your parents\n",
      "you.\n",
      "I think you should talk about this problem with your parents. Try to explain to them what you want and make them know they can believe you. And then they'll find you are a responsible person and they will give you more freedom.\n",
      "Jackson\n",
      "\n",
      "Question: What advice does Dr Jackson give to Angel?\n",
      "A. Be different from other teenagers.\n",
      "B. Pay no attention to whatever her parents tell her.\n",
      "C. Discuss her problem with her parents.\n",
      "D. Don't tell her parents what she wants to do.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1790, Accumulated: 0.1790, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0594, Accumulated: 0.2384, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0404, Accumulated: 0.2788, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0359, Accumulated: 0.3147, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0281, Accumulated: 0.3429, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0327, Accumulated: 0.3756, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0334, Accumulated: 0.4090, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0718, Accumulated: 0.4808, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1214, Accumulated: 0.6022, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1107, Accumulated: 0.7129, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1261, Accumulated: 0.8391, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0818, Accumulated: 0.9209, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0332, Accumulated: 0.9541, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0071, Accumulated: 0.0071, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0110, Accumulated: 0.0181, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0276, Accumulated: 0.0457, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1560, Accumulated: 0.2017, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0257, Accumulated: 0.2274, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0108, Accumulated: 0.2382, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0039, Accumulated: 0.2421, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0068, Accumulated: 0.2489, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0223, Accumulated: 0.2713, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7220, Accumulated: 0.9932, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: I am a Chinese boy. My name is Li Ming. I'm a student. In my class, some of the boys like playing football very much. Wu Jun and I are on school football team. And some of them like playing basketball. _ Han Mei and Zhang Hong are on school volleyball team. Each of them has a tennis racket. In a word  , everyone in our class likes sports very much.\n",
      "\n",
      "Question: Each of the girls has a   _  .\n",
      "A. tennis racket\n",
      "B. baseball bat\n",
      "C. volleyball\n",
      "D. basketball\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1827, Accumulated: 0.1827, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0987, Accumulated: 0.2814, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0678, Accumulated: 0.3492, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0527, Accumulated: 0.4019, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0458, Accumulated: 0.4477, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0491, Accumulated: 0.4967, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0538, Accumulated: 0.5506, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0949, Accumulated: 0.6454, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1317, Accumulated: 0.7772, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0972, Accumulated: 0.8744, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0664, Accumulated: 0.9408, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0352, Accumulated: 0.9760, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0113, Accumulated: 0.9873, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0130, Accumulated: 0.0130, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0186, Accumulated: 0.0315, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0255, Accumulated: 0.0570, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1342, Accumulated: 0.1912, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0112, Accumulated: 0.2024, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0087, Accumulated: 0.2112, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0322, Accumulated: 0.2433, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0097, Accumulated: 0.2530, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0173, Accumulated: 0.2703, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6549, Accumulated: 0.9252, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0736, Accumulated: 0.9988, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: \"Depend on yourself\" is what nature says to every man. Parents can help you. Teachers can help you. Others still can help you. But all these people only help you to help yourself.\n",
      "There have been many great men in history. Many of them were very poor when they were young, and had no uncles, aunts, or friends to help them. Schools were few and not very good. They could not depend on them for education. They tried their best to learn something and never gave up till they became well-known. One of the most famous teachers in England used to tell his pupils, \"I cannot make worthy men of you, but I can help you make men of yourselves.\"\n",
      "Some young men don't try their best to make themselves valuable to the human beings. If they see their weak points and change their ways, they can be successful. They are nothing now, and will be nothing as long as  they live, unless they accept the advice of their parents and teachers, and depend on themselves.\n",
      "\n",
      "Question: Why did many men succeed?\n",
      "A. Because they had good education.\n",
      "B. Because they wanted very much to become well-known.\n",
      "C. Because they worked hard.\n",
      "D. Because their families were very rich.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1392, Accumulated: 0.1392, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0774, Accumulated: 0.2166, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0591, Accumulated: 0.2757, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0443, Accumulated: 0.3199, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0414, Accumulated: 0.3613, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0416, Accumulated: 0.4030, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0481, Accumulated: 0.4511, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0736, Accumulated: 0.5247, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0984, Accumulated: 0.6231, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1102, Accumulated: 0.7333, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1123, Accumulated: 0.8456, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0912, Accumulated: 0.9368, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0336, Accumulated: 0.9705, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0091, Accumulated: 0.0091, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0293, Accumulated: 0.0385, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0225, Accumulated: 0.0609, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0907, Accumulated: 0.1516, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0254, Accumulated: 0.1770, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0091, Accumulated: 0.1861, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0066, Accumulated: 0.1927, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0103, Accumulated: 0.2031, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0087, Accumulated: 0.2118, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7740, Accumulated: 0.9858, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0142, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Hi, friends! Welcome to our Family Rock Band. There are four members in our band. They are Wangwang, Mimi, Yingying and I. Wangwang is my dog. It can sing and dance. Mimi is my cat. It can't dance but it can sing and do Chinese kung fu. Yingying is a parrot . It can sing very well. I can play the guitar. When I play the guitar, they sing and dance. We have a show in our home every Sunday evening. Many boys and girls come to my show. They like it very much.\n",
      "\n",
      "Question: Wangwang, Mimi and Yingying can all  _  .\n",
      "A. dance\n",
      "B. do Chinese kungfu\n",
      "C. play the guitar\n",
      "D. sing\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.2323, Accumulated: 0.2323, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0790, Accumulated: 0.3113, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0521, Accumulated: 0.3634, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0473, Accumulated: 0.4107, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0355, Accumulated: 0.4462, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0439, Accumulated: 0.4901, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0441, Accumulated: 0.5342, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0939, Accumulated: 0.6281, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1245, Accumulated: 0.7526, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0983, Accumulated: 0.8509, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0791, Accumulated: 0.9300, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0403, Accumulated: 0.9702, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0152, Accumulated: 0.9854, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0096, Accumulated: 0.0096, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0049, Accumulated: 0.0145, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0068, Accumulated: 0.0213, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0695, Accumulated: 0.0908, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0055, Accumulated: 0.0964, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0074, Accumulated: 0.1037, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0096, Accumulated: 0.1134, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0398, Accumulated: 0.1531, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0122, Accumulated: 0.1654, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8049, Accumulated: 0.9703, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0295, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Almost everyone likes to eat apples. Apples grow  in nearly every part of the world. The United States produces  more apples than any other country except France. The states of Washington and New York grow the most apples. New York is on the east coast and Washington is on the west near Canada.\n",
      "Apples are red, yellow or green. _ Many people like to carry apples to work or to school to eat with their lunches. Most American people are often too busy or too tired to cook, so they often have their lunches very simply. Apple juice is also a popular drink and apple pie is the favorite dessert of many Americans. The state of Washington is proud  of its apples. The trees there produce nearly five billion  apples every year - one apple for every man, woman and child in the whole world.\n",
      "\n",
      "Question: How many kinds of food made(......) from apples are mentioned  in the passage?\n",
      "A. one\n",
      "B. two\n",
      "C. three\n",
      "D. Four\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1771, Accumulated: 0.1771, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0833, Accumulated: 0.2604, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0535, Accumulated: 0.3139, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0378, Accumulated: 0.3517, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0348, Accumulated: 0.3865, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0425, Accumulated: 0.4290, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0549, Accumulated: 0.4840, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1141, Accumulated: 0.5981, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1249, Accumulated: 0.7230, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1129, Accumulated: 0.8359, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0805, Accumulated: 0.9163, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0457, Accumulated: 0.9620, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0161, Accumulated: 0.9781, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0072, Accumulated: 0.0072, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0079, Accumulated: 0.0150, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0133, Accumulated: 0.0283, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0136, Accumulated: 0.0419, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0126, Accumulated: 0.0544, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0163, Accumulated: 0.0708, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0129, Accumulated: 0.0837, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0243, Accumulated: 0.1080, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0345, Accumulated: 0.1424, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8174, Accumulated: 0.9598, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0399, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: When someone says, \"Well, I guess I'll have to face the music\", it doesn't mean that he is going to hear a singer. It is something far less happy, as you are called in by your leader to explain why you did this and did that or why you did not do this or that.\n",
      "At some time or another, every one of us has to \"face the music\", especially as children. We can all remember father's angry words \"I want to talk to you.\" And only because we did not listen to him. What a bad thing it was!\n",
      "In the middle or at the end of every term, we students have to \"face the music\". The result of the exam will decide whether we will face the music or not. If you got a \"D\" in the exam, that means parents' cold faces and the contempt  of the classmates.\n",
      "\"To face the music\" is well-known to every American, young or old. It is at least 100 years old. It really means that you have to do something, no matter how terrible the whole thing might be, because you have no choice.\n",
      "\n",
      "Question: After the exam, we'll have to \"face the music\". That's why  _  .\n",
      "A. we like to take the exam\n",
      "B. we are afraid of taking the exam\n",
      "C. the exam is very important\n",
      "D. we are afraid of passing the exam\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1924, Accumulated: 0.1924, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0793, Accumulated: 0.2717, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0497, Accumulated: 0.3213, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0337, Accumulated: 0.3551, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0269, Accumulated: 0.3819, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0366, Accumulated: 0.4186, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0520, Accumulated: 0.4705, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1221, Accumulated: 0.5926, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1495, Accumulated: 0.7421, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1150, Accumulated: 0.8571, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0824, Accumulated: 0.9395, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0370, Accumulated: 0.9765, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0105, Accumulated: 0.9870, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0096, Accumulated: 0.0096, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0080, Accumulated: 0.0176, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0114, Accumulated: 0.0290, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0513, Accumulated: 0.0804, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0082, Accumulated: 0.0886, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0119, Accumulated: 0.1005, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0108, Accumulated: 0.1113, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0356, Accumulated: 0.1469, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0519, Accumulated: 0.1988, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7937, Accumulated: 0.9926, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Most people follow others blindly mainly under the effect of peer  pressure. Some people also feel it safe to follow a large number of people. In some _ cases it might be right to follow the crowd  , but in most cases this can be one big mistake. Ninety-five percent of people never succeed because they are following the wrong group. Actually there are reasons why we shouldn't follow the crowd blindly.  According to a study, people tend to follow the crowd when they aren't sure about the direction they should take. This means a large number of people could be following others without understanding what's right and what's wrong! This attracts more people to follow them and the result is that most people move in a certain direction even if it isn't right.\n",
      "A man who wants to be successful always hopes for others' guidance and he usually follows the same path of most people, but the question this man never asks himself is: are all of those people successful? Of course not! If you want to follow a crowd, then follow a successful one. However, in real life you'll only find one successful person among hundreds of people, and that's why following the crowd makes no sense at all.\n",
      "Most people act without thinking wisely. If you always follow others because\n",
      "they're greater than you in number, then sooner or later you'll discover that you're\n",
      "making decisions you might regret later.\n",
      "However, should we never follow the crowd?No. I'm not trying to say you should never follow the crowd, but instead I'm just asking you to think wisely before you take a decision. If you find others are right, there is no problem in following them, but if you have doubts about the direction they're moving in, don't follow them blindly.\n",
      "\n",
      "Question: A man who wants to succeed should  _  .\n",
      "A. follow the crowd\n",
      "B. follow others' guidance\n",
      "C. follow a successful person\n",
      "D. follow the same path of most people\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1549, Accumulated: 0.1549, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0595, Accumulated: 0.2144, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0476, Accumulated: 0.2620, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0441, Accumulated: 0.3061, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0323, Accumulated: 0.3384, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0393, Accumulated: 0.3777, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0414, Accumulated: 0.4191, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0935, Accumulated: 0.5126, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1095, Accumulated: 0.6220, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1167, Accumulated: 0.7388, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1155, Accumulated: 0.8543, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0805, Accumulated: 0.9347, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0276, Accumulated: 0.9623, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0124, Accumulated: 0.0124, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0138, Accumulated: 0.0262, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0110, Accumulated: 0.0372, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0272, Accumulated: 0.0644, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0117, Accumulated: 0.0761, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0170, Accumulated: 0.0931, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0268, Accumulated: 0.1199, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0578, Accumulated: 0.1777, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1230, Accumulated: 0.3007, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6976, Accumulated: 0.9983, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Do You Want To Be A Musician?\n",
      "Do you want to be a musician? Come to our club, and you'll be very happy in the club. We have _ about the piano, the drums, the bamboo flute,the trumpet, the guitar and the violin for just $20 each.You can also learn to sing , to dance for $25 each. If you like art, you can be satisfied , too. It's just for $30 each!\n",
      "\n",
      "Question: If you want to learn about guitar and singing, you should pay  _  .\n",
      "A. $45\n",
      "B. $20\n",
      "C. $30\n",
      "D. $25\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2048, Accumulated: 0.2048, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1013, Accumulated: 0.3062, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0615, Accumulated: 0.3677, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0464, Accumulated: 0.4140, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0339, Accumulated: 0.4480, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0423, Accumulated: 0.4902, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0493, Accumulated: 0.5395, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0950, Accumulated: 0.6345, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1324, Accumulated: 0.7669, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1008, Accumulated: 0.8677, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0663, Accumulated: 0.9340, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0373, Accumulated: 0.9713, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0128, Accumulated: 0.9841, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0085, Accumulated: 0.0085, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0210, Accumulated: 0.0295, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0224, Accumulated: 0.0519, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0554, Accumulated: 0.1072, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0244, Accumulated: 0.1317, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0427, Accumulated: 0.1744, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0100, Accumulated: 0.1844, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0129, Accumulated: 0.1973, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0253, Accumulated: 0.2226, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7626, Accumulated: 0.9852, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0147, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
      "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
      "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
      "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
      "\n",
      "Question: When Mike got home, he was   _  .\n",
      "A. sad\n",
      "B. happy\n",
      "C. tired\n",
      "D. busy\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.2032, Accumulated: 0.2032, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0834, Accumulated: 0.2866, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0397, Accumulated: 0.3264, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0315, Accumulated: 0.3579, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0247, Accumulated: 0.3826, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0345, Accumulated: 0.4171, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0455, Accumulated: 0.4626, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1092, Accumulated: 0.5718, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1376, Accumulated: 0.7094, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1104, Accumulated: 0.8198, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0805, Accumulated: 0.9003, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0530, Accumulated: 0.9533, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0203, Accumulated: 0.9736, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0071, Accumulated: 0.0071, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0157, Accumulated: 0.0228, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0112, Accumulated: 0.0340, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0310, Accumulated: 0.0651, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0101, Accumulated: 0.0751, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0202, Accumulated: 0.0953, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0080, Accumulated: 0.1033, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0817, Accumulated: 0.1850, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0979, Accumulated: 0.2829, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7098, Accumulated: 0.9926, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: There is lots of junk  in space .Some of it is from rockets. In 1996, a rocket broke into about 300,000 small pieces. So far, scientists have found over 10,000 man-made pieces flying around in space. Only 6-7%of them are satellites and space probes  . Astronauts also lose small things while working in space. In 1965, during the first American spacewalk , astronaut Edward White lost a glove .For a month, the glove stayed in space, travelling at a speed of 28,000 kilometers per hour .It became the most dangerous piece of clothing for the Earth in history it flew away. Things move very fast in space. If they hit one another, it can be dangerous .A little piece of paint from a satellite once made a hole in a spacecraft window. Last year two US spacecraft dropped some bolts , and scientists on the Earth worried a lot. Luckily the bolts floated  away into space. They couldn't hit the spacecraft.\n",
      ",.\n",
      "\n",
      "Question: The glove in space may travel at a speed of    _    kilometers per hour.\n",
      "A. 300,000\n",
      "B. 28,000\n",
      "C. 10,000\n",
      "D. 21,000\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1725, Accumulated: 0.1725, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0807, Accumulated: 0.2532, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0557, Accumulated: 0.3089, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0388, Accumulated: 0.3477, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0296, Accumulated: 0.3773, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0380, Accumulated: 0.4153, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0375, Accumulated: 0.4527, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1007, Accumulated: 0.5535, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1524, Accumulated: 0.7059, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1109, Accumulated: 0.8168, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0925, Accumulated: 0.9093, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0519, Accumulated: 0.9612, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0179, Accumulated: 0.9791, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0085, Accumulated: 0.0085, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0113, Accumulated: 0.0198, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0104, Accumulated: 0.0302, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0956, Accumulated: 0.1258, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0137, Accumulated: 0.1394, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0345, Accumulated: 0.1739, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0172, Accumulated: 0.1910, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0599, Accumulated: 0.2510, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0729, Accumulated: 0.3239, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6718, Accumulated: 0.9957, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Tony is a boy. He is 16 years old. He studies in a middle school. He often watches TV and likes the popular hair style . His parents and teachers tell him not to do so, but he doesn't listen to them.\n",
      "One Sunday afternoon his mother buys a beautiful shirt for him and he loves it very much. The next morning, it is cold, but he still puts it on. That evening he has a bad cold. His parents take him to hospital.\n",
      "About thirty minutes later, a nurse brings him to a women's ward .\"Don't you know I am a boy\"? says Tony.\"Oh, I'm sorry. I don't know you are a boy, because your hair is too long\".\n",
      "\n",
      "Question: His mother buys a beautiful   _  for him.\n",
      "A. computer\n",
      "B. book\n",
      "C. shirt\n",
      "D. flower\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1987, Accumulated: 0.1987, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0977, Accumulated: 0.2964, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0625, Accumulated: 0.3590, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0537, Accumulated: 0.4127, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0387, Accumulated: 0.4514, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0463, Accumulated: 0.4977, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0503, Accumulated: 0.5479, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0836, Accumulated: 0.6315, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0944, Accumulated: 0.7259, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0889, Accumulated: 0.8148, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0846, Accumulated: 0.8994, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0569, Accumulated: 0.9563, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0199, Accumulated: 0.9763, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0133, Accumulated: 0.0133, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0306, Accumulated: 0.0439, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0114, Accumulated: 0.0552, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0141, Accumulated: 0.0694, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0094, Accumulated: 0.0788, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0163, Accumulated: 0.0951, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0218, Accumulated: 0.1169, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2081, Accumulated: 0.3250, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1154, Accumulated: 0.4404, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5552, Accumulated: 0.9956, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
      "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
      "\n",
      "Question: Which is TRUE ?\n",
      "A. Nancy and Wendy are 12 years old.\n",
      "B. Wendy is a student and she is English.\n",
      "C. Everyone in Class Four likes Wendy.\n",
      "D. Nancy has a cat and Wendy has a dog.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1912, Accumulated: 0.1912, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0931, Accumulated: 0.2843, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0619, Accumulated: 0.3461, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0458, Accumulated: 0.3919, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0428, Accumulated: 0.4347, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0427, Accumulated: 0.4774, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0465, Accumulated: 0.5239, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0926, Accumulated: 0.6165, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1394, Accumulated: 0.7559, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1023, Accumulated: 0.8582, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0712, Accumulated: 0.9295, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0390, Accumulated: 0.9684, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0137, Accumulated: 0.9822, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0072, Accumulated: 0.0072, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0102, Accumulated: 0.0174, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0101, Accumulated: 0.0275, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0709, Accumulated: 0.0985, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0129, Accumulated: 0.1113, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0136, Accumulated: 0.1249, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0132, Accumulated: 0.1381, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0059, Accumulated: 0.1440, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0049, Accumulated: 0.1489, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6957, Accumulated: 0.8446, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1436, Accumulated: 0.9882, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0091, Accumulated: 0.9972, Threshold: 0.9900\n",
      "Early exit at layer 15/16\n",
      "[Prompt]:\n",
      "Article: As prices and building costs keep rising, \"the do-it-yourself\"(DIY)trend  in the US continues to grow.\n",
      "\"We needed furniture for our living room,\" says John Kose, \"and we didn't have enough money to buy it.\" So we decided to try making a few tables and chairs. John got married six months ago, and like many young people these days, they are struggling  to make a home when the cost of living is very high. The Koses took a 2-week course for $ 280 at a night school. Now they build all their furniture and make repairs around the house.\n",
      "Jim Hatfield has three boys and his wife died. He has a full-time job at home as well as in a shoe-making factory. Last month, he received a car repair bill for $420. \"I was very upset about it. Now I've finished a car repair course. I should be able to fix the car myself. \"\n",
      "John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and his wife went to evening classes to learn how to   _   .\n",
      "A. improve the quality of life\n",
      "B. save time and money\n",
      "C. make or repair things\n",
      "D. run a DIY shop\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1780, Accumulated: 0.1780, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0785, Accumulated: 0.2564, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0489, Accumulated: 0.3053, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0376, Accumulated: 0.3430, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.3745, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0445, Accumulated: 0.4189, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0549, Accumulated: 0.4738, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0982, Accumulated: 0.5720, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1323, Accumulated: 0.7043, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1113, Accumulated: 0.8156, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0853, Accumulated: 0.9010, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0530, Accumulated: 0.9540, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0211, Accumulated: 0.9751, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0052, Accumulated: 0.0052, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0141, Accumulated: 0.0193, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0092, Accumulated: 0.0285, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0665, Accumulated: 0.0949, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0210, Accumulated: 0.1159, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0153, Accumulated: 0.1312, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0291, Accumulated: 0.1603, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0132, Accumulated: 0.1735, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0211, Accumulated: 0.1946, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7570, Accumulated: 0.9516, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0476, Accumulated: 0.9992, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Even though she's quite young, Drew Barrymore can be a Hollywood legend  . She was born on February 22, 1975, in California. Being from a family that produced great actors, she quickly found her way into the spotlight  .\n",
      "When she was 11 months old, she made her first advertisement  on TV. She made her first movie at the age of 2. Five years later, she acted Gertie in Steven Spielberg's famous film E.T. the Extra-Terrestrial(1982).[:,However, it wasn't all roses and sunshine when Barrymore was growing up. Most kid stars in Hollywood can't become stars as adults. And once they're out of order, their lives are in the darkness, smoking and drinking. So does Drew Barrymore\n",
      "As she was growing older, Barrymore started to realize that life is more meaningful than dangerous actions in the films. She started to build a career in 1997. She has made a series of successful films since then, including Charlie's Angels (2000) and 50 First Dates (2004).\n",
      "\"In my life, there is darkness and drama , and I have yet to explore some of that in my work life. I just want to challenge   myself and prove that I can do more.\"\n",
      "Actually, anyone who's not familiar with her disordered childhood might find it hard to believe she's such a sweet person now. Like many of the characters she plays in her comedy, Drew is easy-going and laughs a lot. In 2007, she was on the cover of People magazine's 100 Most Beautiful People issue.\n",
      "\"Life is very interesting ... in the end, some of your greatest pains, become your greatest strengths ,\" Drew said.\n",
      "\n",
      "Question: Drew Barrymore made her first movie in  _  .\n",
      "A. 1975\n",
      "B. 1977\n",
      "C. 1979\n",
      "D. 1982\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1841, Accumulated: 0.1841, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0837, Accumulated: 0.2678, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0538, Accumulated: 0.3216, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0436, Accumulated: 0.3651, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0351, Accumulated: 0.4002, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0458, Accumulated: 0.4460, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0621, Accumulated: 0.5080, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1026, Accumulated: 0.6106, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1145, Accumulated: 0.7252, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1061, Accumulated: 0.8313, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0782, Accumulated: 0.9095, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0487, Accumulated: 0.9581, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0188, Accumulated: 0.9769, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0101, Accumulated: 0.0101, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0139, Accumulated: 0.0241, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0113, Accumulated: 0.0354, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1191, Accumulated: 0.1545, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0156, Accumulated: 0.1700, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0188, Accumulated: 0.1889, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0145, Accumulated: 0.2033, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0130, Accumulated: 0.2164, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0134, Accumulated: 0.2298, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6348, Accumulated: 0.8646, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1256, Accumulated: 0.9902, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Do you know the phrase \"Weibo Addicts\"  ? Do you write a Weibo? If you don't, you are \"out\"!\n",
      "Weibo means microblog. People may spend much time writing a blog, but it takes a little time to write a microblog. Why? Because every message on a microblog is less than 140 words.\n",
      "Microblog started in the USA. It came to China in 2009 and it grows very fast. In 2011, the number of Chinese micro-bloggers grew to 300 million. People write microblogs for many reasons. For many microblog users, it is a great way of learning the freshest news, talking with friends and sharing different kinds of information, including news, everyday life, pictures, music, videos and so on.\n",
      "It is easy and fast to send a message on a microblog. However, this can also bring problems and even panic  . For example, when the big earthquake and tsunami   hit Japan in March, 2011, messages like \"Salt can help people fight radiation  \" were hot on microblogs. Then a crazy buying of salt followed. Later people knew it was just a rumor  .\n",
      "In a word, microblog plays a new part in the life of Chinese people.\n",
      "\n",
      "Question: What does Para. 2 mainly talk about?\n",
      "A. How to use Weibo.\n",
      "B. Why Weibo is so popular.\n",
      "C. Who is using Weibo.\n",
      "D. What Weibo is.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1902, Accumulated: 0.1902, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0847, Accumulated: 0.2749, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0540, Accumulated: 0.3289, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0437, Accumulated: 0.3726, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0345, Accumulated: 0.4071, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0428, Accumulated: 0.4499, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0553, Accumulated: 0.5052, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0904, Accumulated: 0.5955, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1327, Accumulated: 0.7282, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1090, Accumulated: 0.8373, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0828, Accumulated: 0.9201, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0438, Accumulated: 0.9639, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0163, Accumulated: 0.9802, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0084, Accumulated: 0.0084, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0120, Accumulated: 0.0203, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0164, Accumulated: 0.0368, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0188, Accumulated: 0.0556, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0464, Accumulated: 0.1020, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0172, Accumulated: 0.1192, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0096, Accumulated: 0.1288, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0453, Accumulated: 0.1741, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0571, Accumulated: 0.2312, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7650, Accumulated: 0.9962, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Zhao Tao, a student from No.2 Middle School, has just come back from Shanghai. This morning, he told us something about his pleasant trip .When he talked about the Shanghai World Expo, he was so excited and so proud that he kept telling about it for several hours. The Shanghai World Expo held by China has been on for more than one month .It started on May 1st, and will end on October 31st, 2010. Its main idea is \"Better City, Better Life.\" About 242 countries and organizations are attending this expo. Many new products can be seen here, such as we can see the snow in the South Korea Corporate Pavilion  every day during this hot summer though it seldom snows in Shanghai. And we can see, hear, touch and smell the 4-D films at the Oil Pavilion. How wonderful all these new products are!\n",
      "China Pavilion is in the center of the expo garden. It is very beautiful. It represents the development of China from ancient time to now. It's a pride of our China!\n",
      "Thousands of people from all over the world are coming to the expo every day. And many volunteers are working for them. All the tourists are very pleased and they say that the Shanghai World Expo is the greatest one in the world so far.\n",
      "However, Zhao said, \"The expo garden is now so crowded. If you want to visit it, you'd better go there during the summer vacation.\"\n",
      "\n",
      "Question: Which of the following is NOT talked about in this passage?\n",
      "A. Zhao Tao is a middle school student.\n",
      "B. China's new products are excellent.\n",
      "C. The volunteers are working very hard.\n",
      "D. The expo garden is now very crowded.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.2061, Accumulated: 0.2061, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1066, Accumulated: 0.3127, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0665, Accumulated: 0.3792, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0400, Accumulated: 0.4191, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0326, Accumulated: 0.4517, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0342, Accumulated: 0.4860, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0473, Accumulated: 0.5333, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0886, Accumulated: 0.6219, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1249, Accumulated: 0.7468, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1066, Accumulated: 0.8534, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0763, Accumulated: 0.9297, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0399, Accumulated: 0.9696, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0132, Accumulated: 0.9828, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0072, Accumulated: 0.0072, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0204, Accumulated: 0.0276, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0198, Accumulated: 0.0474, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0917, Accumulated: 0.1391, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0296, Accumulated: 0.1686, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0235, Accumulated: 0.1922, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0126, Accumulated: 0.2048, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0281, Accumulated: 0.2329, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0299, Accumulated: 0.2628, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7063, Accumulated: 0.9690, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0306, Accumulated: 0.9996, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Have you ever complained why life is so tiring? Does the sky sometimes seem dark to you? Are your studies sometimes not successful? Well, friends, cheer up and smile all the time. If you see the world with your warm heart , you'll find that the whole world smiles to you. While in school, sometimes you are tired of your lessons, but have you ever noticed the happy smile on your teacher's face when you did a good job?\n",
      "One day it is fine. Just before you want to go out, it suddenly starts to rain . Maybe you would feel very sad and start complaining about the weather. But dear friends, why don't you sit down and listen to the free concert that the nature offers you? And with the timely rain , crops in the fields will grow better and better and farmers will have a good harvest.\n",
      "Although everyone wants to succeed in what he tries to do, sometimes failure can't be avoided . I think failure is not terrible, and the terrible thing is that we are afraid of it and give up hope .\n",
      "When we face failure , we must be confident in ourselves, draw a useful lesson from it and try our best to finish what we have to do. As a popular saying goes , \" Failure is the mother of success .\"\n",
      "Attitude decides everything . With an optimistic  attitude life is easy and pleasant . Let's smile to whatever we meet and the whole world will smile to us .\n",
      "\n",
      "Question: If there is a timely rain ,  _  .\n",
      "A. you want to go out\n",
      "B. you can listen to a concert\n",
      "C. crops in the fields will grow better\n",
      "D. farmers can't have a good harvest\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2023, Accumulated: 0.2023, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1005, Accumulated: 0.3028, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0597, Accumulated: 0.3624, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0478, Accumulated: 0.4103, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0373, Accumulated: 0.4475, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0440, Accumulated: 0.4916, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0516, Accumulated: 0.5432, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0959, Accumulated: 0.6391, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1316, Accumulated: 0.7707, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1008, Accumulated: 0.8715, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0635, Accumulated: 0.9350, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0349, Accumulated: 0.9699, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0128, Accumulated: 0.9826, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0326, Accumulated: 0.0326, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0145, Accumulated: 0.0470, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0111, Accumulated: 0.0581, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0175, Accumulated: 0.0756, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0042, Accumulated: 0.0797, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0207, Accumulated: 0.1004, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0087, Accumulated: 0.1092, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0514, Accumulated: 0.1605, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0750, Accumulated: 0.2355, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7551, Accumulated: 0.9907, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Hearing what I said, my dad laughed kindly. I continued, \"I owe your thanks, and I hope you realize how much you did for me as my dad.\"\n",
      "I could almost hear him smiling one the other end. I knew he was touched and felt a little shy. His voice sounded shaky.\n",
      "\"Well, we got you educated,\" he said, laughing generously.\n",
      "\"You did more than that,\" I said, \"You did well.\"\n",
      "\"You like your house now, and your life?\" he asked quietly.\n",
      "\"Yeah, Dad, I'm happy. You don't have to worry--things are going great for us.\"\n",
      "I told him I loved him and he told me he loved me and I hung up the phone. As I got ready for bed, I thought about what an amazing conversation we had.\n",
      "Ten hours later, my mother called, waking me up. I could hardly understand what she was trying to say.\n",
      "\"Your father's dead!\" she cried. \"I found him lying on the dinning room floor.\"\n",
      "Suddenly I was standing straight up beside my bed, holding the phone and sobbing .\n",
      "I was a thousand miles away. All I could think about was how many hours, minutes and seconds it would take me to jump on a plane and get there. I thought about my mother sitting there alone with my father, and I couldn't move fast enough.\n",
      "The flight was long and painful. I had planned on going home to see my dad and mom in another month, and I cried aloud, thinking I was too late. Then I suddenly realized the incredible miracle of it all: I hadn't been late at all. Actually, everything had been right on time.\n",
      "\n",
      "Question: When did Dad die?\n",
      "A. Soon after he made the telephone call.\n",
      "B. The next morning.\n",
      "C. Before the writer hung up the phone.\n",
      "D. Ten hours later after the telephone call.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2068, Accumulated: 0.2068, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0942, Accumulated: 0.3010, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0665, Accumulated: 0.3675, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0474, Accumulated: 0.4148, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0378, Accumulated: 0.4526, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0411, Accumulated: 0.4938, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0571, Accumulated: 0.5509, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0909, Accumulated: 0.6418, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1274, Accumulated: 0.7692, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0920, Accumulated: 0.8612, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0640, Accumulated: 0.9253, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0403, Accumulated: 0.9655, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0162, Accumulated: 0.9817, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0067, Accumulated: 0.0067, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0146, Accumulated: 0.0214, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0092, Accumulated: 0.0306, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.2499, Accumulated: 0.2805, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0533, Accumulated: 0.3338, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0162, Accumulated: 0.3500, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0247, Accumulated: 0.3748, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0116, Accumulated: 0.3864, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0165, Accumulated: 0.4028, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5767, Accumulated: 0.9796, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0202, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Hunan TV's new program,   Dad,Where Are We Going? has become very popular since last year. The show tells us that fathers should take part in their children's growing-up. In fact, this topic was always mentioned by Zeng Guofan (1811-1872). a famous official during the late Daoguang Period of the Qing Dynasty (1644-1912).\n",
      "Although Zeng spent most of his time away from his family, his letters back home to his children and younger brothers have become famous. In these letters, there are many helpful suggestions on proper behavior . Many of his ways on child education are popular among today's Chinese parents, including reading classical books and so on. His child-raising methods are useful for today's busy fathers. Like Zeng, they also spend most of their time away from home.\n",
      "According to Zeng,  the purpose of education was to learn wisdom from books, rather than getting an official position. Children should know that the most important purpose of studies is to get more knowledge about nature and life.\n",
      "\"But now ,parents just want their children to be rich and powerful. \" Mr. Tang, a writer in China, said.\n",
      "Some teachers say that parents need to build a good relationship with their children. Parents shouldn't force  their children to realize their wishes.\n",
      "In Zeng's letters, he asked his young children to do housework as part of their daily life, even though his children had many helpers. He believed that doing housework would make his children more confident and independent .\n",
      "\n",
      "Question: When was Zeng Guofan born?\n",
      "A. In 1811.\n",
      "B. In 1644.\n",
      "C. In 1872.\n",
      "D. In 1912.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2062, Accumulated: 0.2062, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0821, Accumulated: 0.2883, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0532, Accumulated: 0.3414, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0433, Accumulated: 0.3848, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0296, Accumulated: 0.4143, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0386, Accumulated: 0.4529, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0426, Accumulated: 0.4956, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0895, Accumulated: 0.5851, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1180, Accumulated: 0.7031, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1090, Accumulated: 0.8121, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0888, Accumulated: 0.9010, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0530, Accumulated: 0.9540, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0204, Accumulated: 0.9744, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0150, Accumulated: 0.0150, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0075, Accumulated: 0.0225, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0199, Accumulated: 0.0423, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0963, Accumulated: 0.1387, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0097, Accumulated: 0.1483, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0124, Accumulated: 0.1607, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0062, Accumulated: 0.1668, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0081, Accumulated: 0.1749, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0113, Accumulated: 0.1862, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7546, Accumulated: 0.9408, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0583, Accumulated: 0.9991, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: When the Audet family turns on the lights at Blue Farm, they are using electricity that comes from cows--cow manure  , to be specific.\n",
      "Cows produce a lot of wastes. One cow can create 30 gallons of wastes each day. Now imagine the output of over 1,000 cows at Blue Farm. That's really a big amount.\n",
      "When farmers clean their barns, they put the wastes in a big heap, and spread some of them on their fields for fertilizer . But now places like Blue Spruce Farm have a new way of using cow wastes. They use them to produce electricity.\n",
      "Here's how it works: A big machine moves back and forth cleaning the barn floor. \"The cows aren't bothered,\" says Marie Audet. \"They are animals of habit; they get used to it, and just lift one foot and then another to let it go by.\"\n",
      "The machine pushes the manure into a big 600-gallon tank like a small swimming pool. The tank is called a digester   because what happens there is just like what happens inside a cow: Bacteria  get to work and continue to digest the manure.\n",
      "Methane gas (, )in the atmosphere is known as a \"greenhouse\" gas because it keeps heat just like a greenhouse does, causing our planet to warm up. That's an environmental concern. But the digester has a good result. Its gas is kept and used to power electric generators  .\n",
      "At Blue Farm, the generators make enough electricity to power 400 homes. The Audet family sells the extra electricity they can't use themselves.\n",
      "\n",
      "Question: The new way of using cow wastes at Blue Farm might be best described as   _  .\n",
      "A. reducing\n",
      "B. saving\n",
      "C. recycling\n",
      "D. changing\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1610, Accumulated: 0.1610, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0779, Accumulated: 0.2389, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0505, Accumulated: 0.2895, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0390, Accumulated: 0.3285, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0400, Accumulated: 0.3685, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0413, Accumulated: 0.4098, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0422, Accumulated: 0.4520, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0898, Accumulated: 0.5418, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1365, Accumulated: 0.6783, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1094, Accumulated: 0.7877, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0961, Accumulated: 0.8838, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0704, Accumulated: 0.9542, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0228, Accumulated: 0.9770, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0168, Accumulated: 0.0168, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0344, Accumulated: 0.0513, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0172, Accumulated: 0.0685, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0122, Accumulated: 0.0807, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0038, Accumulated: 0.0845, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0202, Accumulated: 0.1047, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0098, Accumulated: 0.1145, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0818, Accumulated: 0.1962, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1001, Accumulated: 0.2964, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6700, Accumulated: 0.9663, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0333, Accumulated: 0.9996, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: We have two new students in our class. They are Cindy and Kate. They look the same. But they aren't twins.\n",
      "Cindy is American. She is thirteen. Her father and mother are both teachers. She likes green and blue. She is often in blue pants. She often plays the guitar after school. She is good at math and English. She says math is her favorite because it is interesting.\n",
      "Kate is English. She is twelve. Her parents are not teachers. Her father is a doctor and her mother is a worker. Kate likes yellow and orange. She can't play the guitar. But she plays volleyball very well. Her favorite subject is Chinese. She say she wants to learn about Chinese history. Kate likes documentaries very much.\n",
      "\n",
      "Question: Cindy is   _  .\n",
      "A. 12 years old\n",
      "B. American\n",
      "C. English\n",
      "D. Kate's sister\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1858, Accumulated: 0.1858, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0764, Accumulated: 0.2622, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0438, Accumulated: 0.3060, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0451, Accumulated: 0.3511, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.3826, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0438, Accumulated: 0.4264, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0398, Accumulated: 0.4663, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0743, Accumulated: 0.5405, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1206, Accumulated: 0.6611, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1147, Accumulated: 0.7759, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0956, Accumulated: 0.8715, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0686, Accumulated: 0.9401, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0260, Accumulated: 0.9661, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0105, Accumulated: 0.0105, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0075, Accumulated: 0.0180, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0072, Accumulated: 0.0252, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0659, Accumulated: 0.0911, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0181, Accumulated: 0.1092, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0134, Accumulated: 0.1226, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0271, Accumulated: 0.1497, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0442, Accumulated: 0.1939, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0442, Accumulated: 0.2381, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7496, Accumulated: 0.9877, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0122, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
      "\n",
      "Question: In fact , the tall man and the short man are   _   .\n",
      "A. thieves\n",
      "B. policemen\n",
      "C. actors\n",
      "D. clerks\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1962, Accumulated: 0.1962, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0789, Accumulated: 0.2751, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0506, Accumulated: 0.3257, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0426, Accumulated: 0.3682, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0319, Accumulated: 0.4002, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0413, Accumulated: 0.4414, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0435, Accumulated: 0.4850, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0975, Accumulated: 0.5825, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1424, Accumulated: 0.7249, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1214, Accumulated: 0.8463, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0816, Accumulated: 0.9280, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0420, Accumulated: 0.9699, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0141, Accumulated: 0.9840, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0077, Accumulated: 0.0077, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0151, Accumulated: 0.0229, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0086, Accumulated: 0.0314, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1361, Accumulated: 0.1675, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0350, Accumulated: 0.2026, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0253, Accumulated: 0.2279, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0112, Accumulated: 0.2391, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0855, Accumulated: 0.3246, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0362, Accumulated: 0.3608, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6299, Accumulated: 0.9906, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: I hurried into the store to get Christmas gifts. Suddenly, I saw a little boy holding a lovely doll. He kept touching her hair. I watched him turn to a woman and say, \"Are you sure I don't have enough money?\" She said yes and told the boy not to go anywhere before she came back. Then she left.\n",
      "The boy continued to hold the doll. I asked the boy who the doll was for. He said, \"It's the doll that my sister wanted so badly for Christmas. She just knew that Santa would bring it.\" I told him that Santa was going to bring it. He said, \"No, Santa can't go where my sister is. I have to give the doll to my mom to take it to her.\"\n",
      "I asked him where his sister was. He looked at me sadly and said, \"She's gone to heaven. My daddy said that Mom was going to be there with her.\" My heart nearly stopped beating. Then the boy said, \"I told my daddy to tell her not to go there until I got back.\" He took out some pictures of him and said, \"I want my mom to take these with her so she'll never forget me. I love my mom so much that I wish she didn't have to leave me, but Daddy said that she needed to be with my sister.\"\n",
      "The boy lowered his head. While he was not looking, I reached into my purse and asked him, \"Shall we count that money again?\" He grew excited and said, \"Yes, I just know it has to be enough.\" So I put my money with his and we began to count it. He said, \"Thank you for giving me enough money.\" He continued, \"I just asked God to give me enough money to buy this doll, and he heard my _ .\"\n",
      "Soon the woman came back and I left. I remembered a story I had read in the newspaper several days earlier about a drunk driver who hit a car. A little girl was killed and her mother was in serious condition. Two days later, I read the news that the mother had died.\n",
      ",.\n",
      "\n",
      "Question: What do you think of the writer?\n",
      "A. Rich.\n",
      "B. Kind.\n",
      "C. Brave.\n",
      "D. Careful.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1506, Accumulated: 0.1506, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0709, Accumulated: 0.2215, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0429, Accumulated: 0.2644, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0342, Accumulated: 0.2985, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0243, Accumulated: 0.3229, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0337, Accumulated: 0.3566, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0447, Accumulated: 0.4013, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1033, Accumulated: 0.5046, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1176, Accumulated: 0.6222, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1111, Accumulated: 0.7333, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1115, Accumulated: 0.8449, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0848, Accumulated: 0.9296, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0337, Accumulated: 0.9633, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0091, Accumulated: 0.0091, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0126, Accumulated: 0.0217, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0085, Accumulated: 0.0302, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.2189, Accumulated: 0.2491, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0393, Accumulated: 0.2883, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.3023, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0263, Accumulated: 0.3286, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0089, Accumulated: 0.3374, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0227, Accumulated: 0.3601, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6355, Accumulated: 0.9956, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Hello! My name is Zhang Fei. I am Chinese. I am twelve. I'm in No.1 Middle School in Nanjing. This is my friend. His name is Tony Green. He is an English boy .He is twelve. He and I are in the same  class. Our classroom is next to  the teachers' office .We have Chinese and English lessons  every day. Our English teacher is Mr. Read. He is English but he can speak Chinese. Our Chinese teacher is Mr. Ding. They are good teachers, and they are our friends, too\n",
      "\n",
      "Question: Tony green is from  _\n",
      "A. China\n",
      "B. America\n",
      "C. England\n",
      "D. Australia\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2314, Accumulated: 0.2314, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1016, Accumulated: 0.3330, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0595, Accumulated: 0.3926, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0472, Accumulated: 0.4398, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0360, Accumulated: 0.4758, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0476, Accumulated: 0.5233, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0600, Accumulated: 0.5834, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0908, Accumulated: 0.6742, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1145, Accumulated: 0.7887, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0845, Accumulated: 0.8732, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0616, Accumulated: 0.9348, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0329, Accumulated: 0.9677, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0137, Accumulated: 0.9815, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0078, Accumulated: 0.0078, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0088, Accumulated: 0.0166, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0086, Accumulated: 0.0252, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0156, Accumulated: 0.0409, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.0724, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0129, Accumulated: 0.0853, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0172, Accumulated: 0.1025, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0256, Accumulated: 0.1281, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0247, Accumulated: 0.1527, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8108, Accumulated: 0.9636, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0360, Accumulated: 0.9996, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: When my wife left this world, I chose to travel in Antigua looking for a peaceful place to rest my old body. Not quite old and weak, I felt I wanted something more than the usual hotel room with 24-hour room service.\n",
      "I decided this year to try something completely new and booked myself a private holiday home in Antigua. This was the best decision I had ever made, as there was plenty to do, plenty to see and lots of lovely restaurants to visit. There was a private swimming pool, and a cool, wide yard where I ate my breakfast most mornings.\n",
      "Antigua has to be one of the loveliest places on earth to spend a holiday. The bright blue sea and the endless blue around the beach areas proved to be an excellent place for me to spend the long afternoons.\n",
      "I had to hurry to do what I wanted to do before the holiday came to an end. I managed to visit the Sugar Mill and Shirley Heights on my last two days and yet found myself wondering whether I could extend for a few more days.\n",
      "I rented a boat and came home after a day's sailing, refreshed, looking forward to dinner. Everything is so pleasant on these beautiful islands, swept by the trade winds and warmed by the sun for so many summer months. The food just tasted better to me, perhaps because I was having such a great holiday. There was always someone to have a drink with---- that's what I liked most.\n",
      "\n",
      "Question: Which of the following statements is NOT mentioned about the private holiday home the writer stayed in?\n",
      "A. It had a private swimming pool.\n",
      "B. There were lots of restaurants near it.\n",
      "C. The writer often had breakfast in its yard.\n",
      "D. It supplied delicious seafood to the writer.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.2074, Accumulated: 0.2074, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0784, Accumulated: 0.2858, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0502, Accumulated: 0.3360, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0351, Accumulated: 0.3711, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0258, Accumulated: 0.3969, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0320, Accumulated: 0.4289, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0360, Accumulated: 0.4649, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0814, Accumulated: 0.5463, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1369, Accumulated: 0.6832, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1213, Accumulated: 0.8045, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0966, Accumulated: 0.9011, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0582, Accumulated: 0.9593, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0191, Accumulated: 0.9784, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0124, Accumulated: 0.0124, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0216, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0163, Accumulated: 0.0379, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0502, Accumulated: 0.0881, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.0972, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0107, Accumulated: 0.1078, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0070, Accumulated: 0.1148, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0130, Accumulated: 0.1278, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0343, Accumulated: 0.1621, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8272, Accumulated: 0.9894, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0104, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Do you like singing? Do you know how to use the iPod or iPhone to sing? The iPod and iPhone are two _ of the company Apple. Now they will soon teach you how to sing well. The company Apple is planning to turn the two devices into karaoke machines.\n",
      "After Apple invented the iPod, the way people listened to music changed a lot. But now the company wants to teach people to sing with them. By using the iPod or iPhone, you can choose your favourite song, and then you will see lyrics   on the screen, just like traditional karaoke machines. When you sing, the devices will remember your voice. It will also compare your voice with the singer of the song. It can even give you a suitable   mark. If you sing well, you may get a mark of 90-100. If you don't sing well, you may get a poor mark.\n",
      "It is good news for people who like singing. Use your iPod or iPhone to practise more. I am sure you can sing very well.\n",
      "\n",
      "Question: What's the main idea of the passage?\n",
      "A. A famous company Apple.\n",
      "B. A perfect mobile phone.\n",
      "C. Why people often use the iPod or iPhone to sing.\n",
      "D. How people will use the iPod or iPhone to sing.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1888, Accumulated: 0.1888, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0816, Accumulated: 0.2705, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0473, Accumulated: 0.3178, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0380, Accumulated: 0.3559, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0375, Accumulated: 0.3934, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0419, Accumulated: 0.4352, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0597, Accumulated: 0.4950, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1174, Accumulated: 0.6124, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1472, Accumulated: 0.7597, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1040, Accumulated: 0.8636, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0704, Accumulated: 0.9341, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0372, Accumulated: 0.9713, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0125, Accumulated: 0.9838, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0067, Accumulated: 0.0067, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0240, Accumulated: 0.0306, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0179, Accumulated: 0.0485, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0381, Accumulated: 0.0866, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0134, Accumulated: 0.1001, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0239, Accumulated: 0.1240, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0280, Accumulated: 0.1519, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0099, Accumulated: 0.1618, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0219, Accumulated: 0.1836, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8112, Accumulated: 0.9948, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: What are your clothes made of? Are they made of cotton or wool? Some students in Shandong wear different things. Their clothes are made of discs  or old clothes!\n",
      "On October 7th, 36 students in Linyi, Shandong Province, wore beautiful clothes in a show. Their clothes were made of all kinds of things.\n",
      "The show gave the students a chance to make things with their own hands. It also helped them learn to make good use of waste and not to throw everything away.\n",
      "Students had lots of good ideas. Some found used things, like old clothes, to make new dresses.\n",
      "\"We hope to save energy. Our world is _ of energy. So I don't want to just throw old things away,\" said Xie Jing at Linyi Art School.\n",
      "Xie had more than 20 discs on her nice blue dress. She got them from her family and friends.\n",
      "\"Though the discs are old, I look very cool in them!\" she said.\n",
      "Song Dandan, a student from the school, looked like a farmer in her straw  coat and hat. She picked the straw from the fields and put them all together.\n",
      "\"I want to show what people wore in the past.\" she said.\n",
      "Du Yue made clothes for astronauts ! She had white cloth all over her. When she walked, she tried to be slow. It looked like she was walking on the moon.\n",
      "\"I hope to wear it in space  some day. I wish that I could walk on the moon!\" she said.\n",
      "\n",
      "Question: The three students used all these things except   _   to made clothes.\n",
      "A. discs\n",
      "B. straw\n",
      "C. old paper\n",
      "D. cloth\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1919, Accumulated: 0.1919, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0875, Accumulated: 0.2794, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0503, Accumulated: 0.3297, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0400, Accumulated: 0.3697, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0268, Accumulated: 0.3964, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0332, Accumulated: 0.4296, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0402, Accumulated: 0.4699, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0922, Accumulated: 0.5620, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1433, Accumulated: 0.7053, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1237, Accumulated: 0.8290, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0873, Accumulated: 0.9163, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0518, Accumulated: 0.9682, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0158, Accumulated: 0.9840, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0080, Accumulated: 0.0080, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0325, Accumulated: 0.0405, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0088, Accumulated: 0.0493, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0270, Accumulated: 0.0762, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0099, Accumulated: 0.0861, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0592, Accumulated: 0.1453, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0256, Accumulated: 0.1709, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1401, Accumulated: 0.3110, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1028, Accumulated: 0.4137, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5585, Accumulated: 0.9722, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0272, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Would you like to adopt an animal? Although this sounds very unusual, some children have done just this. The Natural Zoo has given people the chance to adopt animals by paying for all of its food for one year. One of the animals that needed parents was a young tiger named Brocky. The people at the zoo said that it would cost about $900 a year for the food for Brocky.\n",
      "Not many boys and girls have $900 to spend. That is why several hundred children and grown-ups each have sent a little money to the zoo to help pay for Brocky's food. Some children sent in only a quarter because that was all the money they had. Other children sent in more money than that.\n",
      "Since so many people sent money to the zoo to help pay for Brocky's food, he now will be able to eat as much as he wants. Brocky surely must be a happy tiger to know that he has so many adopted parents. Many children must also be happy to know that they have helped to feed him. It really will be thrilling for those children to go to the Natural Zoo to visit their adopted tiger Brocky.\n",
      "\n",
      "Question: We can infer from the passage that   _  .\n",
      "A. zoos are too poor to feed the animals\n",
      "B. there are too many animals in the zoo\n",
      "C. many people are kind to animals\n",
      "D. children love animals better than adults do\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2115, Accumulated: 0.2115, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0843, Accumulated: 0.2959, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0575, Accumulated: 0.3534, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0459, Accumulated: 0.3993, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0388, Accumulated: 0.4381, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0427, Accumulated: 0.4808, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0510, Accumulated: 0.5318, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1070, Accumulated: 0.6388, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1333, Accumulated: 0.7721, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1027, Accumulated: 0.8748, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0714, Accumulated: 0.9462, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0326, Accumulated: 0.9788, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0100, Accumulated: 0.9888, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0108, Accumulated: 0.0108, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0302, Accumulated: 0.0410, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0249, Accumulated: 0.0659, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0160, Accumulated: 0.0819, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0213, Accumulated: 0.1033, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0168, Accumulated: 0.1201, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0402, Accumulated: 0.1603, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0317, Accumulated: 0.1920, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1012, Accumulated: 0.2932, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6968, Accumulated: 0.9900, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0098, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: There are many kinds of food in the world. Scientists learn a lot about them. They say that there are some kinds of food people must eat every day. For example, people must eat some green and yellow vegetables. We shouldn't eat too much meat. People also need to eat some fruits, bread and rice. Of course our bodies need some water and milk.\n",
      "Scientists say people in different countries and different places eat different kinds of food. They cook food in different ways. Different people eat at different times. In one place, people eat once or twice a day. But in another place, people eat three or four times. The scientists say when to eat and how many times to eat are not important. What we eat is the most important thing.\n",
      "Nowadays, the world faces two problems. People in some places, for example, in Africa, are not full. Many people are eating junk food. It's bad for people's health. So it's our duty to make everyone full and make everyone healthy.\n",
      ",.\n",
      "\n",
      "Question: We may read this passage in   _  .\n",
      "A. a letter\n",
      "B. a story\n",
      "C. a newspaper\n",
      "D. a health magazine\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1758, Accumulated: 0.1758, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0787, Accumulated: 0.2545, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0430, Accumulated: 0.2975, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0397, Accumulated: 0.3371, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0336, Accumulated: 0.3707, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0384, Accumulated: 0.4091, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0465, Accumulated: 0.4556, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0932, Accumulated: 0.5487, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1474, Accumulated: 0.6962, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1296, Accumulated: 0.8257, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0922, Accumulated: 0.9180, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0510, Accumulated: 0.9690, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0176, Accumulated: 0.9865, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0047, Accumulated: 0.0047, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0177, Accumulated: 0.0224, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0089, Accumulated: 0.0313, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1112, Accumulated: 0.1425, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0125, Accumulated: 0.1550, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0066, Accumulated: 0.1615, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0154, Accumulated: 0.1769, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0502, Accumulated: 0.2272, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0598, Accumulated: 0.2870, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6925, Accumulated: 0.9795, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0204, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Long long ago, there were three tortoises .  They were friends.\n",
      "One of them was a large tortoise, one was a medium-sized tortoise and the third was a small tortoise.\n",
      "One day they went into a restaurant and ordered some cakes. While(......) they were waiting for the cakes, they remembered that they didn't bring any money.\n",
      "\"Hey, we forgot to bring money to pay for our cakes,\" the big tortoise said.\n",
      "\"The little tortoise can go home and get it,\" the medium-sized tortoise said. \"He's the youngest, so he should be the one to go.\"\n",
      "The little tortoise wasn't very happy, but he knew he shouldn't argue with his elders, so he said, \"All right, I'll go. But you must promise  not to eat my cake while I'm away.\"\n",
      "The large tortoise and the medium-sized tortoise agreed, and the little tortoise left for home to get some money.\n",
      "A few days later, the big tortoise said to the medium-sized tortoise, \"Let's eat the little tortoise's cake. I'm hungry again.\"\n",
      "\"So am I,\" the medium-sized tortoise said, and reached for the cake.\n",
      "As she did so, the little tortoise shouted from near the door of the restaurant, \"If you touch  my cake, I won't go and get the money!\"\n",
      ", .\n",
      "\n",
      "Question: The three tortoises found they didn't take money with them   _   .\n",
      "A. when they were ordering the cake\n",
      "B. after they ate up the cake\n",
      "C. before they went into the restaurant\n",
      "D. after they ordered the cake\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1884, Accumulated: 0.1884, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0879, Accumulated: 0.2762, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0549, Accumulated: 0.3311, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0370, Accumulated: 0.3681, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0302, Accumulated: 0.3983, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0417, Accumulated: 0.4401, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0482, Accumulated: 0.4882, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0958, Accumulated: 0.5841, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1477, Accumulated: 0.7317, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1154, Accumulated: 0.8471, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0784, Accumulated: 0.9255, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0431, Accumulated: 0.9686, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0144, Accumulated: 0.9830, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0088, Accumulated: 0.0088, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0148, Accumulated: 0.0236, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0276, Accumulated: 0.0512, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0854, Accumulated: 0.1366, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0181, Accumulated: 0.1547, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0173, Accumulated: 0.1720, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0062, Accumulated: 0.1782, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0037, Accumulated: 0.1820, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0043, Accumulated: 0.1863, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5066, Accumulated: 0.6929, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.2710, Accumulated: 0.9639, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0325, Accumulated: 0.9964, Threshold: 0.9900\n",
      "Early exit at layer 15/16\n",
      "[Prompt]:\n",
      "Article: More and more parents leave their homes and come into the big cities to make money. But their children can't go with them because their children have to go to school in their hometown. They are called home-left children. The problems of home-left children become more and more serious. And it becomes a big _ of our society. The main problem is that some home-left children become very lonely when they don't have their parents' love. And they are too young to tell right or wrong in many things. So they are fooled very easily by others.\n",
      "Xiao Mei , a 14-year-old girl, is a home-left child. Her parents are both in Shanghai. She is in her hometown with her grandpa. She likes playing games on the Internet. Her parents and grandpa only give her money and food. They hardly ever care for her studies. One day, she had no money to pay for the games in the Net bar. So she stole some money from her neighbor. Just at that time, Xiao Fang, a 9-year-old girl saw it. Xiao Mei was afraid that Xiao Fang would tell others about it. She cut Xiao Fang's throat with a knife, and then she went to school just like nothing happened. Luckily, Xiao Fang was saves by doctors. When she opened her eyes and wrote the fact to the policeman with a pencil, everybody was very surprised. This sad story reminds the parents to care for their children no matter how busy they are.\n",
      "Are you one of the home-left children? What do you need from your parents? Food, money or love? I think most children need love mostly. Let's care for the group together.\n",
      ",A, B, C, D,. 5,2,10\n",
      "\n",
      "Question: Why can't the children go to the big cities with their parents?\n",
      "A. Because they have to go to school in their hometown.\n",
      "B. Because their parent have no money.\n",
      "C. Because they don't like to go there.\n",
      "D. Because they are not allowed.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1796, Accumulated: 0.1796, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0894, Accumulated: 0.2689, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0478, Accumulated: 0.3168, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0434, Accumulated: 0.3602, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0368, Accumulated: 0.3970, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0418, Accumulated: 0.4388, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0434, Accumulated: 0.4821, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0774, Accumulated: 0.5595, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0982, Accumulated: 0.6578, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0911, Accumulated: 0.7488, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1001, Accumulated: 0.8490, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0807, Accumulated: 0.9296, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0318, Accumulated: 0.9615, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0122, Accumulated: 0.0122, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0124, Accumulated: 0.0246, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0386, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0734, Accumulated: 0.1120, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0098, Accumulated: 0.1218, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0237, Accumulated: 0.1455, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0200, Accumulated: 0.1655, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0970, Accumulated: 0.2625, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0746, Accumulated: 0.3372, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6589, Accumulated: 0.9961, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: My name is Peter.I am 12.I have one brother and one sister.My brother is 15 and my sister is 9.I have a friend.He is an English boy.His name is Tanaka.He is in my class.I have a dog, too.Its name is Billy.Billy is 2.I like sports.I play basketball, soccer and volleyball after class .I have one pencil case, two English books and three Chinese books.\n",
      "\n",
      "Question: Peter and Tanaka are   _  .\n",
      "A. brothers\n",
      "B. sisters\n",
      "C. friends\n",
      "D. Chinese\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1746, Accumulated: 0.1746, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0749, Accumulated: 0.2495, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0500, Accumulated: 0.2995, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0406, Accumulated: 0.3401, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0396, Accumulated: 0.3798, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0378, Accumulated: 0.4176, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0344, Accumulated: 0.4520, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0685, Accumulated: 0.5205, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1291, Accumulated: 0.6496, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1116, Accumulated: 0.7612, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0911, Accumulated: 0.8523, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0799, Accumulated: 0.9322, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0311, Accumulated: 0.9634, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0111, Accumulated: 0.0111, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0073, Accumulated: 0.0184, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0114, Accumulated: 0.0297, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1095, Accumulated: 0.1392, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0066, Accumulated: 0.1459, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0264, Accumulated: 0.1722, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0122, Accumulated: 0.1844, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1222, Accumulated: 0.3066, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0817, Accumulated: 0.3883, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6087, Accumulated: 0.9970, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: On Children's Day a young woman from America goes to Beihai Park with her little daughter. There are too many people in the park. The woman can't find her daughter, So she goes to the policeman for  help. She tells the policeman her daughter is only six years old. She has two big eyes and a round face. Her hair is golden yellow. And she is in a short blue dress. At last the policeman helps her find her daughter. She thanks him very much.\n",
      "\n",
      "Question: The woman can't find her  _  .\n",
      "A. son\n",
      "B. daughter\n",
      "C. children\n",
      "D. sister\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1982, Accumulated: 0.1982, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0794, Accumulated: 0.2776, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0482, Accumulated: 0.3259, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0343, Accumulated: 0.3601, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0285, Accumulated: 0.3886, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0346, Accumulated: 0.4232, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0449, Accumulated: 0.4681, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1045, Accumulated: 0.5727, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1484, Accumulated: 0.7210, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1227, Accumulated: 0.8437, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0811, Accumulated: 0.9247, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0438, Accumulated: 0.9685, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0135, Accumulated: 0.9820, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0075, Accumulated: 0.0075, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0089, Accumulated: 0.0164, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0077, Accumulated: 0.0241, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0496, Accumulated: 0.0737, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0127, Accumulated: 0.0865, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0075, Accumulated: 0.0940, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0113, Accumulated: 0.1053, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0211, Accumulated: 0.1264, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0288, Accumulated: 0.1551, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8362, Accumulated: 0.9913, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Chinese young people love their smart phones.They play with phone apps every day.But now, a book has let them forget about their phones.The book is called Secret Garden.\n",
      "It is a colouring book for adults'.You don't have to read it, because it has almost no words.All the pages are pictures but no colours.You just need to use colour pens to paint it.An artist in Britain made the book.\n",
      "The book is now the biggest selling book on amazon.Cn.last month, it sold 25,000 copies in China.Many young people bought this book.They like it so much that they stop playing games or surfing the Internet on their phones.These people are mainly young mothers and workers.It is very difficult to take care of babies or do a good job at first, so they feel a lot of pressure.Drawing the book can help them become less nervous.\n",
      "In the past, people thought colouring books are only for children.With Secret Garden getting more and more popular, many young adults also begin to paint as a hobby.\n",
      "\n",
      "Question: What kind of people like the colouring book?\n",
      "A. Children.\n",
      "B. Young adults.\n",
      "C. Old people.\n",
      "D. All the people.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1578, Accumulated: 0.1578, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0918, Accumulated: 0.2496, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0521, Accumulated: 0.3017, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0357, Accumulated: 0.3374, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0335, Accumulated: 0.3710, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0368, Accumulated: 0.4078, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0500, Accumulated: 0.4579, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0958, Accumulated: 0.5536, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1423, Accumulated: 0.6959, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1183, Accumulated: 0.8143, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0931, Accumulated: 0.9074, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0529, Accumulated: 0.9603, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0181, Accumulated: 0.9784, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0090, Accumulated: 0.0090, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0134, Accumulated: 0.0224, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0080, Accumulated: 0.0305, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0886, Accumulated: 0.1190, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0136, Accumulated: 0.1326, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0410, Accumulated: 0.1736, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0417, Accumulated: 0.2153, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0124, Accumulated: 0.2277, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0241, Accumulated: 0.2518, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7274, Accumulated: 0.9792, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0206, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Today is Sunday. All of us go to school early. Our teachers are going to take us to Blue Sky Park. The park is near our school. We can go to the park on foot.\n",
      "Blue Sky Park is very beautiful. There are many trees, a football field, a big playground and a small lake in it. It's a sunny day today, but there are not many people in the park. Li Lei is sitting under the tree. Han Mei and Lu Lu are playing on the playground. A bird in the tree is watching them. Look at me. I am playing football with other boys. How happy we are! Where are Miss Fang and Mr. Wu? They are boating on the lake. All of us have a good time in the park. We want to visit it again.\n",
      "\n",
      "Question: It's  _  today.\n",
      "A. Sunday\n",
      "B. Monday\n",
      "C. Friday\n",
      "D. Saturday\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2385, Accumulated: 0.2385, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1019, Accumulated: 0.3404, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0596, Accumulated: 0.4000, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0445, Accumulated: 0.4445, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0380, Accumulated: 0.4825, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0480, Accumulated: 0.5305, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0553, Accumulated: 0.5858, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0954, Accumulated: 0.6811, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1216, Accumulated: 0.8027, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0920, Accumulated: 0.8948, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0605, Accumulated: 0.9553, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0270, Accumulated: 0.9823, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0086, Accumulated: 0.9909, Threshold: 0.9900\n",
      "Early exit at layer 16/16\n",
      "Layer 4/16: Halt prob: 0.0289, Accumulated: 0.0289, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0313, Accumulated: 0.0602, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0130, Accumulated: 0.0733, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0158, Accumulated: 0.0890, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0962, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0531, Accumulated: 0.1494, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0101, Accumulated: 0.1594, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0083, Accumulated: 0.1677, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0279, Accumulated: 0.1956, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7251, Accumulated: 0.9207, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0771, Accumulated: 0.9978, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Walking is a popular form of exercise. It is an easy activity and offers a good way to improve physical fitness. Walking also gives many of the same benefits as other kinds of exercise.\n",
      "Regular, brisk walks help a person's body work better. Walking builds a stronger heart and lungs. Walking also seems to help protect the heart from heart disease. The lungs work better because they take in and use oxygen more effectively. Walking can help in weight control, too. A quick fifteen-minute walk burns as many calories as jogging the same distance in half the time. Walking causes very injuries, so there is also a lower \"dropout\" rate among walkers than among runners.\n",
      "People are more likely to continue a walking program. This gives a better chance for success. Walking offers some mental benefits, too. It seems to make people feel better. Many walkers say they sleep better at night when they take regular walks. Others say they have a better attitude towards life. Walking offers many of the same physical and mental benefits as other forms of exercise, but walking offers some special advantages, too. Almost everyone can walk. There are no special lessons or training. To become a real walker, a person only needs to walk faster, farther, and more often.\n",
      "People can walk almost anywhere. There are no special playing fields or courts for walking. Sidewalks, streets, parks, fields, and malls are excellent places for walking. People can walk almost anytime. A person doesn't need a team or a partner for walking. There is no \"season\" for walking. Most walkers walk in all kinds of weather.\n",
      "Walking doesn't cost anything. There are no special fees for walking. Good walking shoes and comfortable clothes are the only equipment that a walker needs.\n",
      "Walking offers a form of exercise within the reach of nearly everyone. With a little time and effort, people can rediscover a valuable form of exercise and improve their fitness.\n",
      "\n",
      "Question: When you start walking, you should prepare   _  .\n",
      "A. a good bag\n",
      "B. a hat and gloves\n",
      "C. some food and drinks\n",
      "D. walking shoes and comfortable clothes\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1632, Accumulated: 0.1632, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0591, Accumulated: 0.2224, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0477, Accumulated: 0.2701, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0346, Accumulated: 0.3047, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0334, Accumulated: 0.3381, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0390, Accumulated: 0.3770, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0461, Accumulated: 0.4231, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1141, Accumulated: 0.5372, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1551, Accumulated: 0.6923, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1186, Accumulated: 0.8109, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0839, Accumulated: 0.8948, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0575, Accumulated: 0.9523, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0226, Accumulated: 0.9750, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0098, Accumulated: 0.0098, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0053, Accumulated: 0.0152, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0128, Accumulated: 0.0280, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0211, Accumulated: 0.0490, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.0583, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0172, Accumulated: 0.0754, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0087, Accumulated: 0.0841, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.2359, Accumulated: 0.3200, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1578, Accumulated: 0.4778, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5212, Accumulated: 0.9990, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: An artist who did not have much money, but was a very kind man, was coming home by train one day. He gave his last few coins to a beggar, but then he saw another one, and forgot that he did not have any money. He asked the man if he would like to have lunch with him, and the beggar accepted, so they went into a small restaurant and had a good meal. At the end, the artist could not pay the bill, of course, so the beggar had to do so.\n",
      "The artist was very unhappy about this, so he said to the beggar, \"Come home with me in a taxi, my friend, and I'll give you back the money for money.\"\n",
      "\"Oh, no!\" the beggar answered quickly. \"I had to pay for your lunch, but I'm not going to pay for your taxi home either!\"\n",
      "\n",
      "Question: After the meal,   _   paid the bill.\n",
      "A. The artist\n",
      "B. another man\n",
      "C. the beggar\n",
      "D. no one\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2101, Accumulated: 0.2101, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0890, Accumulated: 0.2990, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0557, Accumulated: 0.3547, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0574, Accumulated: 0.4121, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0395, Accumulated: 0.4516, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0460, Accumulated: 0.4976, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0553, Accumulated: 0.5528, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0895, Accumulated: 0.6424, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1279, Accumulated: 0.7703, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1057, Accumulated: 0.8759, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0652, Accumulated: 0.9412, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0335, Accumulated: 0.9746, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0114, Accumulated: 0.9860, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0214, Accumulated: 0.0214, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0254, Accumulated: 0.0468, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0609, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0141, Accumulated: 0.0750, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0112, Accumulated: 0.0862, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0073, Accumulated: 0.0935, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0118, Accumulated: 0.1053, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0317, Accumulated: 0.1369, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0596, Accumulated: 0.1966, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7971, Accumulated: 0.9937, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: A gentleman put an advertisement in a newspaper to look for a boy to work in his office. From nearly fifty persons, he chose one and refused the others.\n",
      "\"I should like to know,\" said a friend, \"Why you liked that boy better. He did not have a letter or a recommendation  .\"\n",
      "\"You are wrong,\" said the gentleman. \"He had a great many. He cleaned his feet at the door and closed the door behind him. That showed that he was careful. He gave his seat at once to that old man. That showed that he was kind and _ . He took off his cap when he came in and answered my question at once. That showed that he was polite and gentlemanly.\"\n",
      "\"I threw some books on the floor and some persons went over them, but that boy picked them up and put them on the table. He waited quietly for his turn instead of pushing. When I talked to him, I found his clothes were tidy, his hair was brushed clearly and his finger nails   were clean. I think these are more important than a letter and a recommendation.\"\n",
      "\n",
      "Question: That boy was chosen because   _  .\n",
      "A. he had many letters\n",
      "B. he didn't have a recommendation\n",
      "C. he spoke quietly\n",
      "D. he did everything carefully\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1727, Accumulated: 0.1727, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0779, Accumulated: 0.2506, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0513, Accumulated: 0.3020, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0393, Accumulated: 0.3413, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0362, Accumulated: 0.3775, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0393, Accumulated: 0.4168, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0525, Accumulated: 0.4693, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1044, Accumulated: 0.5737, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1367, Accumulated: 0.7105, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1037, Accumulated: 0.8142, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0912, Accumulated: 0.9054, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0523, Accumulated: 0.9577, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0198, Accumulated: 0.9775, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0087, Accumulated: 0.0087, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0209, Accumulated: 0.0296, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0095, Accumulated: 0.0391, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0379, Accumulated: 0.0770, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0081, Accumulated: 0.0851, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0078, Accumulated: 0.0929, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0159, Accumulated: 0.1089, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0225, Accumulated: 0.1314, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0125, Accumulated: 0.1439, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6663, Accumulated: 0.8102, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1843, Accumulated: 0.9945, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: For most people, the word \"fashion\" means \"clothes\". But people may ask the question, \"What clothes are in fashion?\" And they use the word \"fashionable\" in the same way.\n",
      "\"She was wearing a fashionable coat. His shirt was really a fashionable colour. \"\n",
      "But of course there are fashions in many things, not only in clothes. There are fashions in holidays, in restaurants, in films and books. There are even fashions in school subjects, jobs ... and in languages.\n",
      "Fashions change as time goes. If you look at pictures of people or things from the past, you will see that fashions have always changed. An English house of 1750 was different from one of 1650. A fashionable man in 1780 looked very different from his grandson in 1860.\n",
      "Today fashions change very quickly. Some of this is natural. We hear about things much more quickly than in the past. Newspapers, radios, telephones and television send information from one country to another in a few hours.\n",
      "New fashions mean that people will buy new things, so you see _ .\n",
      "\n",
      "Question: \"There is money in fashion\" means  _\n",
      "A. people like fashion and money\n",
      "B. fashionable things are expensive\n",
      "C. one can make money through fashion\n",
      "D. a fashionable man makes much money\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1805, Accumulated: 0.1805, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0857, Accumulated: 0.2662, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0603, Accumulated: 0.3265, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0409, Accumulated: 0.3674, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0323, Accumulated: 0.3997, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0373, Accumulated: 0.4370, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0405, Accumulated: 0.4775, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0990, Accumulated: 0.5765, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1371, Accumulated: 0.7136, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1244, Accumulated: 0.8380, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0889, Accumulated: 0.9269, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0441, Accumulated: 0.9710, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0141, Accumulated: 0.9852, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0091, Accumulated: 0.0091, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0144, Accumulated: 0.0235, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0113, Accumulated: 0.0348, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0290, Accumulated: 0.0638, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0119, Accumulated: 0.0757, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0137, Accumulated: 0.0894, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0147, Accumulated: 0.1041, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1265, Accumulated: 0.2306, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1136, Accumulated: 0.3441, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6501, Accumulated: 0.9942, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Hip-hop dancing    is popular with many young people today. They like it because they can invent their own moves. They use this dance to show their love for life. It also shows that they feel good about life, that they just want to be themselves and enjoy life, and that they are not afraid of problems.\n",
      "Hip-hop dancing has a history of more than 20 years. It first began in the 1980s in the USA. In early times, in New York and Los Angles, many young black people often danced to the music in the streets. They used their legs, arms, heads and even shoulders to dance. Many young people still use most of these moves today.\n",
      "Hip-hop dancing became popular all over the world because of the 1983 film Flashdance. Some people performed   Hip-hop dancing in the movie. People enjoyed their performance. They began to dance like them. Then it became popular. There are two kinds of Hip-hop dancing: new school and old school. More and more young people are learning Hip-hop dancing. People believe that it is a good way to exercise their bodies, and that it is good for their health.\n",
      "\n",
      "Question: Which of the following is TRUE about Hip-hop dancing?\n",
      "A. It's not a good way to exercise.\n",
      "B. It shows that young people feel bad about life.\n",
      "C. Young people use their dance to show their love for life.\n",
      "D. It shows that young people are afraid of problems.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2234, Accumulated: 0.2234, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0811, Accumulated: 0.3044, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0447, Accumulated: 0.3491, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0359, Accumulated: 0.3850, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0280, Accumulated: 0.4130, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0366, Accumulated: 0.4496, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0496, Accumulated: 0.4992, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0927, Accumulated: 0.5919, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1361, Accumulated: 0.7280, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1105, Accumulated: 0.8385, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0811, Accumulated: 0.9196, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0458, Accumulated: 0.9654, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0163, Accumulated: 0.9818, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0074, Accumulated: 0.0074, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0141, Accumulated: 0.0215, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0355, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0307, Accumulated: 0.0662, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0071, Accumulated: 0.0734, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0220, Accumulated: 0.0954, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0313, Accumulated: 0.1266, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0297, Accumulated: 0.1564, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0233, Accumulated: 0.1797, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7998, Accumulated: 0.9796, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0203, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Mr. Evans lives in a city. He was a math teacher three years ago. He taught well and his students liked him. So he decided to work in the middle school all his life. But a terrible accident changed his fortune .\n",
      "One spring he took his class to visit a place of interest. The children saw a lot of interesting things and had a good time there. But on their way to school, their bus was hit by a truck because the young driver was drunk . Five students died and more than half of the children were injured in the accident. He didn't know how it had happened and was very sad about it and after he came out of hospital, he left the school and became a policeman. He tried his best to stop the drivers from breaking the traffic regulations . He worked hard and was strict with the drivers. So they were afraid of him.\n",
      "One afternoon it was very hot. Mr. Evans was on duty. He was standing at the crossing and watching the traffic. Suddenly he saw a car rushing towards the crossing. It ran so fast that it almost hit a man on a bike. He stopped it at once and saw a girl in it.\n",
      "\"Show your license to me, madam,\" said Mr. Evans.\n",
      "The girl handed her bag to him and said: \"Please look for it in it. I can't see anything without glasses.\"\n",
      "\n",
      "Question: Their bus was hit by a truck because  _  .\n",
      "A. the drunk driver broke the traffic rules\n",
      "B. the bus driver broke the traffic rules\n",
      "C. Mr. Evans broke the traffic rules\n",
      "D. the children broke the traffic rules\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1599, Accumulated: 0.1599, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0918, Accumulated: 0.2517, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0506, Accumulated: 0.3023, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0323, Accumulated: 0.3346, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0228, Accumulated: 0.3575, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0303, Accumulated: 0.3877, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0474, Accumulated: 0.4352, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1075, Accumulated: 0.5427, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1337, Accumulated: 0.6763, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1140, Accumulated: 0.7903, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1044, Accumulated: 0.8947, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0632, Accumulated: 0.9578, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0210, Accumulated: 0.9789, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0083, Accumulated: 0.0083, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0201, Accumulated: 0.0285, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0154, Accumulated: 0.0438, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0619, Accumulated: 0.1058, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.1130, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0160, Accumulated: 0.1290, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0110, Accumulated: 0.1399, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0096, Accumulated: 0.1496, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0186, Accumulated: 0.1682, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8111, Accumulated: 0.9793, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0206, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: I am Wang Lin, I am twelve years old. My pen pal Tom is form the United States. He is the same age as I. He is a middle school student in Beijing. There are three people in his family. His father is a teacher, he teaches English in a high school in Beijing. His mother is an English teacher, too. But they work in different schools. Tom goes to school in his mother's car every day. They all like Chinese food. Tom's father likes Guangdong food, he thinks it is delicious. Tom's mother's favorite food is Sichuan food. But Tom doesn't like Sichuan food, he thinks it is too hot. So they often eat out on weekends.\n",
      "\n",
      "Question: They often eat out on weekends because   _  .\n",
      "A. they like Chinese food\n",
      "B. they like American food\n",
      "C. they are lazy\n",
      "D. they have different hobbies  .\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1980, Accumulated: 0.1980, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0808, Accumulated: 0.2788, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0511, Accumulated: 0.3299, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0436, Accumulated: 0.3735, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0326, Accumulated: 0.4061, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0428, Accumulated: 0.4489, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0470, Accumulated: 0.4959, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0843, Accumulated: 0.5802, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1180, Accumulated: 0.6982, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1040, Accumulated: 0.8022, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0863, Accumulated: 0.8886, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0628, Accumulated: 0.9514, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0227, Accumulated: 0.9741, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0080, Accumulated: 0.0080, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0107, Accumulated: 0.0187, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0089, Accumulated: 0.0276, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0502, Accumulated: 0.0778, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0228, Accumulated: 0.1006, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0487, Accumulated: 0.1493, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0157, Accumulated: 0.1650, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0639, Accumulated: 0.2289, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0463, Accumulated: 0.2752, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7110, Accumulated: 0.9862, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0138, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Tom was a farmer. He worked on the farm all day,but sometimes he went to the town market to sell fruit and vegetables. One day, a terrible sound attracted his attention in the town market. He saw a young bull for sale. The bull was white and yellow. It was looking at Tom in fear. Tom walked up and touched its head gently. Just at that time they both seemed to have known each other for a long time. How amazing!Tom bought it at once and called it Amba.\n",
      "From then on , Tom and Amba got on well with each other. But some friends told him that it was dangerous to have such a close relationship with an animal.\n",
      "One afternoon , Tom was walking through the forest with Amba. Suddenly , Amba stopped walking and kept pushing Tom with its head. Tom was very surprised and looked around. There was a big snake in front of him. It was beautiful but poisonous. Quickly Amba stepped on the snake's tail with its foot and at the same time Tom picked up a stick and hit the snake's head heavily. Soon the snake . died.\n",
      "Tom was very grateful for Amba's help. When people heard this, they were shocked at the bull's expression of love for Tom. But for Tom, Amba was not a bull but a member of his family.\n",
      "\n",
      "Question: Amba was   _  .\n",
      "A. a small and nice cow\n",
      "B. a big and beautiful snake\n",
      "C. a white and yellow bull\n",
      "D. a black and white dog\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1509, Accumulated: 0.1509, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0642, Accumulated: 0.2150, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0334, Accumulated: 0.2484, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0269, Accumulated: 0.2754, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0243, Accumulated: 0.2997, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0315, Accumulated: 0.3311, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0365, Accumulated: 0.3677, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0973, Accumulated: 0.4649, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1548, Accumulated: 0.6197, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1421, Accumulated: 0.7619, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1171, Accumulated: 0.8790, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0720, Accumulated: 0.9509, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0240, Accumulated: 0.9749, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0077, Accumulated: 0.0077, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0076, Accumulated: 0.0154, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0159, Accumulated: 0.0312, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0288, Accumulated: 0.0600, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0133, Accumulated: 0.0733, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0152, Accumulated: 0.0885, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0088, Accumulated: 0.0973, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0353, Accumulated: 0.1327, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0249, Accumulated: 0.1576, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8132, Accumulated: 0.9708, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0289, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Dear Mr Green,\n",
      "I am not happy these days. Please help me.\n",
      "I want to be a member of the class volleyball team. I think I am good at volleyball. But our PE teacher says I can't get into the team. He says I am too fat  .\n",
      "I really want to be a good volleyball player. This is my dream. Can you help me?\n",
      "Jane\n",
      "Dear Jane,\n",
      "I'm sorry to know that you're not happy.\n",
      "You play volleyball well. But your PE teacher doesn't like fat girls. If   you want to be a good volleyball player, you must be slim. Why not go running with Mary every morning? Mary is the best volleyball player in our class. You can be like her if you\n",
      "Allan Green\n",
      "\n",
      "Question: Which of the following is TRUE?\n",
      "A. Jane doesn't play volleyball well.\n",
      "B. Jane is really slim.\n",
      "C. Jane's PE teacher doesn't like fat girls.\n",
      "D. Jane wants to play for the school team.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1614, Accumulated: 0.1614, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0771, Accumulated: 0.2385, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0492, Accumulated: 0.2876, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0423, Accumulated: 0.3300, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0324, Accumulated: 0.3624, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0436, Accumulated: 0.4059, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0595, Accumulated: 0.4654, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1216, Accumulated: 0.5870, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1448, Accumulated: 0.7318, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1156, Accumulated: 0.8473, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0809, Accumulated: 0.9283, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0458, Accumulated: 0.9741, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0139, Accumulated: 0.9880, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0051, Accumulated: 0.0051, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0219, Accumulated: 0.0270, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0137, Accumulated: 0.0407, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0818, Accumulated: 0.1225, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.1317, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0432, Accumulated: 0.1749, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0088, Accumulated: 0.1837, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0177, Accumulated: 0.2014, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0170, Accumulated: 0.2184, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7599, Accumulated: 0.9782, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0215, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Mr. and Mrs. Green lived in a big city. One summer they went to the country for their holiday. They enjoyed it very much because it was a quiet, clean place.\n",
      "One day they went for a walk early in the morning and met an old man. He lived on a farm, and he was sitting in the warm sun in front of his house. Mr. Green asked him, \"Do you like to live in this quiet place?\"\n",
      "The old man said, \"Yes, I do.\"\n",
      "Mr. Green then asked, \"What are the good things about it?\"\n",
      "The old man answered, \"Well, the people here know each other. They often come and visit me, and I often go and visit them. And there are also many children here.\" Mr. Green said, \"That's interesting, and what are the bad things?\"\n",
      "The old man thought for a moment and then said, \"Well, the same things, really.\"\n",
      "\n",
      "Question: The old mall said, \"Yes, I do.\" \"I do\" here means   _  .\n",
      "A. I like to live in this place\n",
      "B. I like the people here\n",
      "C. I like to sit in the warm sun\n",
      "D. I like to go out for a walk\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2206, Accumulated: 0.2206, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1098, Accumulated: 0.3304, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0594, Accumulated: 0.3898, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0380, Accumulated: 0.4277, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0347, Accumulated: 0.4624, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0336, Accumulated: 0.4960, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0476, Accumulated: 0.5436, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1060, Accumulated: 0.6496, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1145, Accumulated: 0.7642, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0925, Accumulated: 0.8566, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0711, Accumulated: 0.9278, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0410, Accumulated: 0.9687, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0142, Accumulated: 0.9829, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0074, Accumulated: 0.0074, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0101, Accumulated: 0.0175, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0138, Accumulated: 0.0313, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0960, Accumulated: 0.1273, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0147, Accumulated: 0.1420, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0081, Accumulated: 0.1501, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0123, Accumulated: 0.1624, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0205, Accumulated: 0.1829, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1100, Accumulated: 0.2929, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6981, Accumulated: 0.9910, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Sometimes it may seem difficult to improve our health. If so, the following health habits may help you.\n",
      "Eat breakfast every morning.\n",
      "Research shows that if you eat a meal in the morning you may not become too fat or eat too much during lunch. Eating breakfast can help people feel better through the day.\n",
      "Get enough sleep.\n",
      "Poor sleep can influence our memory and learning. It can also cause traffic accidents! Studies show that people who don't get enough sleep seem to get into more accidents. So stay safe and get enough sleep!\n",
      "Take a walk every day.\n",
      "Walking is an easy way to exercise. You'd better meet friends for a walk, not for a meal. As you walk, you will see the beautiful world around you. Once you try, you will find that adding a walk into your daily life is very easy.\n",
      "Join social groups.\n",
      "Social groups can provide support. They might include sport teams, art or music groups. The people in the group can offer advice and can help each other in difficult times. Also, being in a group keeps your mind busy. An active mind is a healthy mind!\n",
      "Have a hobby.\n",
      "A hobby could be running reading or making something with your hands. Hobbies help people to relax and rest. Hobbies bring us joy as well.\n",
      ",A, B, C, D ,.\n",
      "\n",
      "Question: If you need help and want to help others, you'd better    _   .\n",
      "A. invite your friend to a meal\n",
      "B. make something with your friends\n",
      "C. become a member of a social group\n",
      "D. have a hobby\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2234, Accumulated: 0.2234, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0947, Accumulated: 0.3180, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0589, Accumulated: 0.3769, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0441, Accumulated: 0.4210, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0330, Accumulated: 0.4540, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0415, Accumulated: 0.4955, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0482, Accumulated: 0.5437, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0824, Accumulated: 0.6260, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1260, Accumulated: 0.7520, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1018, Accumulated: 0.8539, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0654, Accumulated: 0.9193, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0429, Accumulated: 0.9622, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0153, Accumulated: 0.9775, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0076, Accumulated: 0.0076, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0250, Accumulated: 0.0326, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0068, Accumulated: 0.0393, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.2624, Accumulated: 0.3018, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0323, Accumulated: 0.3341, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0073, Accumulated: 0.3414, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0065, Accumulated: 0.3480, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0085, Accumulated: 0.3565, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0268, Accumulated: 0.3833, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5968, Accumulated: 0.9801, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0198, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: There was a new maths teacher and some new students in the school. One of the new students named Karl was very _ . The other students tried to explain   numbers to him, but he didn't understand.\n",
      "Before Karl arrived, maths was the most boring lesson of all. Now it was great fun. The children would listen to Karl and correct his mistakes. They all wanted to be the first to find his mistakes, and then tried to think up the best ways to explain them.\n",
      "But little Lewis was sure that Karl felt sad and wanted to talk with him. So, one day, he decided to walk after Karl after school. Lewis was sure he would see him crying. On the way home, Karl walked a few minutes to a park, and there he waited for someone to meet him...\n",
      "It was the new teacher!\n",
      "They went off, hand in hand. Lewis could hear them talking about maths. And that stupid Karl knew everything about it, and even much more than anyone else in the class!\n",
      "\n",
      "Question: Which lesson was the most boring of all before Karl arrived?\n",
      "A. Chinese.\n",
      "B. English.\n",
      "C. Maths.\n",
      "D. Music.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2239, Accumulated: 0.2239, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0932, Accumulated: 0.3171, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0558, Accumulated: 0.3729, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0441, Accumulated: 0.4170, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0343, Accumulated: 0.4513, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0388, Accumulated: 0.4901, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0458, Accumulated: 0.5359, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0832, Accumulated: 0.6191, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1087, Accumulated: 0.7278, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0970, Accumulated: 0.8248, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0810, Accumulated: 0.9057, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0502, Accumulated: 0.9560, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0184, Accumulated: 0.9743, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0115, Accumulated: 0.0115, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0375, Accumulated: 0.0490, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0135, Accumulated: 0.0625, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0219, Accumulated: 0.0844, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0108, Accumulated: 0.0951, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0059, Accumulated: 0.1010, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0095, Accumulated: 0.1105, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0456, Accumulated: 0.1561, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0888, Accumulated: 0.2450, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7473, Accumulated: 0.9923, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Roosegaarde, an artist and designer from Dutch has thought of a device . He hopes it will make Beijing's sky clear again and help the people with masks breathe fresh air again in Beijing.\n",
      "An electromagnetic field  will pull the dirty particles in the air to the ground, and then they can be easily cleaned.\n",
      "Roosegaarde says, \"It's like when you have a balloon which has static electricity  and your hair goes toward it. Smog happens the same way as the hair.\"\n",
      "His workplace has reached an agreement with the Beijing government to test the technology in one of the capital's parks.  Beijing's skies are regularly covered by grey smog. Serious cases of air pollution are often reported in Beijing. Roosegaarde says an indoor test has already shown it works well and he is confident of the results. With the help of a team of scientists and engineers, he is sure that the device can be worked outside.\n",
      "\"Beijing is a very good place to test the device because the smog in Beijing is quite low and there's not so much wind.\" says Roosegaarde. \"We'll be able to make the air pure but the most difficult thing is to remove the smog. As a result, you can see the sun again.\"\n",
      "Roosegaarde also reminds us that his aim is not only to give a plan to solve Beijing's dirty air pollution but also to make people pay attention to the environment problem. He adds, \"This is not the real answer for smog. The real answer to do with it is clean cars, different industry and different lifestyles. \" However, he hopes the project will make the citizens realize the differences between clean air and smog-filled air.\n",
      "\n",
      "Question: After reading the passage, we can know  _  .\n",
      "A. the device doesn't work well indoors\n",
      "B. the people with masks can breathe fresher air\n",
      "C. Beijing government agreed to test the device\n",
      "D. clean cars aren't helpful to the environment in Beijing\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1963, Accumulated: 0.1963, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0739, Accumulated: 0.2702, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0496, Accumulated: 0.3198, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0327, Accumulated: 0.3525, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0272, Accumulated: 0.3797, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0311, Accumulated: 0.4108, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0470, Accumulated: 0.4578, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1019, Accumulated: 0.5597, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1424, Accumulated: 0.7021, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1211, Accumulated: 0.8232, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0838, Accumulated: 0.9070, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0505, Accumulated: 0.9575, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0191, Accumulated: 0.9766, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0087, Accumulated: 0.0087, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0099, Accumulated: 0.0186, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0198, Accumulated: 0.0383, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0519, Accumulated: 0.0903, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0149, Accumulated: 0.1052, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0113, Accumulated: 0.1165, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0176, Accumulated: 0.1341, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0429, Accumulated: 0.1770, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0334, Accumulated: 0.2103, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7623, Accumulated: 0.9726, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0268, Accumulated: 0.9995, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: As Danny put his lunch tray onto the cafeteria table, milk spilled all over his sandwich. \"This is the worst thing I've ever done!\" he said, \"It's not that bad,\" said his friend Elena, who was sitting across from him. \"Just get another sandwich.\"\n",
      "\"Sandwich? What sandwich? I am talking about the talent contest . It's only two weeks away and I don't know what I'm doing! Everybody will laugh at me. There's no way to avoid it!\"\n",
      "\"Don't be so _ , Danny,\" said Elena as she rolled her eyes. \"You're going to be great. You have the skills to do just about anything.\"\n",
      "Danny moved his lunch tray to the side and rested his head on the table.\n",
      "\"Sit up Danny,\" ordered Elena, \"I have an idea. Let's brainstorm a list of things you could do. We'll divide the list into categories or groups. Let's start with music. You play the piano, right?\"\n",
      "\"I stopped taking lessons in the third grade,\" said Danny.\n",
      "\"What about singing a song?\" suggested Elena.\n",
      "Danny shook his head no. \"Let's move on to another category.\"\n",
      "\"What about performing magic tricks?\" asked Elena, as she twisted thin strands of hair around her finger.\n",
      "\"I don't know how to play magic tricks!\" Danny almost shouted.\n",
      "\"Stop being so...\" Elena paused, \"That's it, DRAMATIC!\" Elena shouted excitedly. \"You could do a dramatic reading. You definitely have the talent for it. Mrs. Pace always calls on you to read aloud in class. You could read a play aloud. Maybe you could even get extra credit from Mrs. Pace. She rewards students with points for doing extra reading work.\"\n",
      "Danny thought for a minute. Then he smiled. \"Elena,\" Danny said, \"You are a great friend!\"\n",
      "Elena smiled back. \"I just want to make sure you are a bright, shiny star when you step out on stage.\"\n",
      "\n",
      "Question: Danny was unhappy because of   _  .\n",
      "A. the spilled milk\n",
      "B. her friend Elena\n",
      "C. the talent contest\n",
      "D. the milk-soaked bread\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1779, Accumulated: 0.1779, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0745, Accumulated: 0.2523, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0502, Accumulated: 0.3025, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0400, Accumulated: 0.3425, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0296, Accumulated: 0.3721, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0382, Accumulated: 0.4102, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0479, Accumulated: 0.4582, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1042, Accumulated: 0.5624, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1375, Accumulated: 0.6999, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1154, Accumulated: 0.8153, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0866, Accumulated: 0.9019, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0540, Accumulated: 0.9559, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0201, Accumulated: 0.9761, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0054, Accumulated: 0.0054, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0163, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0066, Accumulated: 0.0229, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0843, Accumulated: 0.1072, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0432, Accumulated: 0.1504, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0105, Accumulated: 0.1610, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0135, Accumulated: 0.1744, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0408, Accumulated: 0.2152, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0727, Accumulated: 0.2879, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6575, Accumulated: 0.9454, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0540, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Once there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day it was said that the island would go down, so all made boats and left except Love.\n",
      "Love was the only one who stayed. Love wanted to offer her help until the last possible moment. When the island had almost gone down, Love decided to ask for help.\n",
      "Richness was passing by Love in a great boat. Love said, \"Richness, can you take me with you?\" Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
      "Sadness was close by, so Love asked, \"Sadness, let me go with you .\" \"Oh, Love, I am so sad that I need to be by myself!\"\n",
      "Happiness passed by Love, too, but she was so happy that she did not even notice when Love called her.\n",
      "Suddenly, there was a voice, \"Come, Love, I will take you.\" It was an elder. Love was so excited that she even forgot to ask who the elder was. So Love asked Knowledge, another elder, \"Who helped me?\" \"It was Time,\" Knowledge answered. \"Time?\" asked Love. \"But why did Time help me?\"\n",
      "Knowledge smiled with deep wisdom and answered, \"Because only Time understands how _ Love is.\"\n",
      "\n",
      "Question: Sadness didn't see Love when he passed by Love, did he?\n",
      "A. Yes, he did.\n",
      "B. Yes, he didn't.\n",
      "C. No, he didn't.\n",
      "D. No, he did.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1870, Accumulated: 0.1870, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0785, Accumulated: 0.2656, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0502, Accumulated: 0.3158, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0380, Accumulated: 0.3538, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0336, Accumulated: 0.3874, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0413, Accumulated: 0.4287, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0455, Accumulated: 0.4742, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0815, Accumulated: 0.5558, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1492, Accumulated: 0.7050, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1102, Accumulated: 0.8152, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0959, Accumulated: 0.9111, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0546, Accumulated: 0.9657, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0176, Accumulated: 0.9833, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0151, Accumulated: 0.0151, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0369, Accumulated: 0.0520, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0256, Accumulated: 0.0777, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0080, Accumulated: 0.0857, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0981, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0153, Accumulated: 0.1134, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0163, Accumulated: 0.1297, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0765, Accumulated: 0.2062, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1644, Accumulated: 0.3706, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6214, Accumulated: 0.9920, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Mr. Yang is a doctor. He cares a lot about not only others' health but also his own. He controls( )his weight carefully. To him, _ is the most important thing to do if one wants to enjoy good health.\n",
      "Mr. Yang controls his weight in two ways: exercising and not eating much. As a doctor. Mr. Yang is too busy to go to the gym. He exercises by getting off the bus one or two stops early and walking the rest of the way to his office.\n",
      "Besides, he doesn't eat much. Mr. Yang has a special habit. When he buys a belt, he asks the salesperson to punch a hole in the belt at 90cm from the buckle end of the belt, so that he ca always remind  himself. He will stop eating if he feels the belt a little too tight . Mr. Yang thinks exercising doesn't work as well as eating less.\n",
      "\n",
      "Question: Mr. Yang punches a hole in his new belt, because   _  .\n",
      "A. he is too heavy\n",
      "B. the belt is too long\n",
      "C. he doesn't like his new belt\n",
      "D. it can remind him not to eat too much\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1989, Accumulated: 0.1989, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0934, Accumulated: 0.2923, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0598, Accumulated: 0.3521, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0419, Accumulated: 0.3940, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0377, Accumulated: 0.4317, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0433, Accumulated: 0.4750, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0546, Accumulated: 0.5296, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1050, Accumulated: 0.6346, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1253, Accumulated: 0.7599, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1020, Accumulated: 0.8620, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0757, Accumulated: 0.9377, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0379, Accumulated: 0.9756, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0113, Accumulated: 0.9869, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0075, Accumulated: 0.0075, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0088, Accumulated: 0.0163, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0107, Accumulated: 0.0270, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0362, Accumulated: 0.0633, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.0724, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0074, Accumulated: 0.0799, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0058, Accumulated: 0.0857, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0162, Accumulated: 0.1019, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0197, Accumulated: 0.1216, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8703, Accumulated: 0.9919, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Happiness is for everyone. You don't need to worry about people who have beautiful houses with large gardens and swimming pools or those who have nice cars and a lot of money and so on. Why? Because those who have big houses may often feel lonely and those who have cars may want to walk on the country roads in their free time.\n",
      "In fact, happiness is always around you if you put your heart into it. When you are in trouble at school, your friends will help you; when you are studying hard at your lessons, your parents are always taking good care of you; When you get success, your friends will say congratulations to you; When you do something wrong, people around you will help you to correct it. All your happiness is always around you.\n",
      "Happiness is not the same as money. It is a feeling of your heart. When you are poor, you can also say you are very happy, because you have something else that can't be bought with money. When you meet with difficulties, you can say loudly you are very happy, because you have more chances to challenge yourself. So you should not always say you are poor and you have bad luck. As the saying goes, life is like a revolving  door. When it closes, it also opens. If you take every chance you get, you can be a happy and lucky person.\n",
      ",. (5,2,10)\n",
      "\n",
      "Question: What is the best title for the passage?\n",
      "A. Happiness is for everyone.\n",
      "B. Lucky life.\n",
      "C. Do something good to others.\n",
      "D. Life and success.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2117, Accumulated: 0.2117, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0907, Accumulated: 0.3023, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0574, Accumulated: 0.3598, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0498, Accumulated: 0.4096, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0382, Accumulated: 0.4478, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0419, Accumulated: 0.4897, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0490, Accumulated: 0.5388, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0822, Accumulated: 0.6210, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1285, Accumulated: 0.7495, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1029, Accumulated: 0.8524, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0718, Accumulated: 0.9242, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0398, Accumulated: 0.9640, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0140, Accumulated: 0.9781, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0059, Accumulated: 0.0059, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0132, Accumulated: 0.0191, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0124, Accumulated: 0.0315, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0396, Accumulated: 0.0711, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0229, Accumulated: 0.0940, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0077, Accumulated: 0.1017, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0095, Accumulated: 0.1112, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1235, Accumulated: 0.2347, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0487, Accumulated: 0.2834, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6592, Accumulated: 0.9426, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0564, Accumulated: 0.9990, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: One afternoon I toured an art museum while waiting for my husband to finish a business meeting.I was looking forward to a quiet view of the art works.\n",
      "A young couple viewing the paintings ahead of me chatted nonstop between themselves.I watched them a moment and decided the wife was doing all the talk.I admired the husband's patience for putting up with her continuous talk.Distracted by their noise,I moved on.\n",
      "I met with them several times as I moved through the different rooms of art.Each time I heard her constant burst of words,I moved away quickly.\n",
      "I was standing at the counter of the museum gift shop making a purchase when the couple came near to the exit.Before they left,the man reached into his pocket and pulled out a white object.He extended it into a long stick and then tapped his way into the coatroom to get his wife's jacket.\n",
      "\"He's a brave man.\"The clerk at the counter said,\"Most of us would give up if wewere blinded at such a young age.During his recovery he made a promise that his life wouldn't change.So ,as before,he and his wife come in whenever there's a new art show.\"\n",
      "\"But what dose he get out of the art?\"I asked,\"He can't see.\"\n",
      "\"Can't see?You're wrong.He sees a lot.More than you or I do.\"The clerk said,\"His wife describes each painting so he can see it in his head.\"\n",
      "I learned something about patience,courage and love that day.I saw the patience of a young wife describing paintings to a person without sight and the courage of a husband who would not allow blindness to change his life.And I saw the love shared by two people as I watched this couple walk away hand in hand.\n",
      "\n",
      "Question: After hearing what the clerk had said about the couple,the writer was   _  .\n",
      "A. encouraged\n",
      "B. excited\n",
      "C. touched\n",
      "D. annoyed\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2368, Accumulated: 0.2368, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0918, Accumulated: 0.3286, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0571, Accumulated: 0.3857, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0403, Accumulated: 0.4260, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0276, Accumulated: 0.4535, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0356, Accumulated: 0.4891, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0408, Accumulated: 0.5299, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0881, Accumulated: 0.6180, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1337, Accumulated: 0.7517, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1063, Accumulated: 0.8580, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0733, Accumulated: 0.9313, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0380, Accumulated: 0.9693, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0143, Accumulated: 0.9837, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0107, Accumulated: 0.0107, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0149, Accumulated: 0.0256, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0096, Accumulated: 0.0352, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0506, Accumulated: 0.0857, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0982, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0174, Accumulated: 0.1156, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0237, Accumulated: 0.1392, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0636, Accumulated: 0.2028, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0851, Accumulated: 0.2878, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7097, Accumulated: 0.9976, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: In America, there is a traditional story called a \"tall tale\". A tall tale is a story about a person who is larger than life. The descriptions in the story are exaggerated  , which makes the story funny. People who had lived in undeveloped areas in America first told tall tales. After a hard day's work, they would get together to tell each other funny stories. One character from these stories was Paul Bunyan, a hero who cut down trees in North America. Tradition says he cleared forests from the northeastern United States to the Pacific Ocean.\n",
      "It is said that Paul Bunyan was born in the northeastern American state of Maine. His mother and father were shocked when they first saw the boy. When the boy was only a few weeks old, he weighed more than forty-five kilograms. As a child, Paul was always hungry. His parents needed ten cows to supply  milk for his meals. Before long, he ate fifty eggs and ten containers of potatoes every day. Young Paul grew so big that his parents did not know what to do with him. Once, Paul rolled over  so much in his sleep that he caused an earthquake. This angered people in the town where his parents lived. So the government told his mother and father they would have to move him somewhere else. Paul's parents had to take him into the woods where he grew up.\n",
      "\n",
      "Question: From the passage we learn that tall tales were first told by   _  .\n",
      "A. workers who cut down trees in America\n",
      "B. people in poor areas in America\n",
      "C. Paul Bunyan, a traditional figure\n",
      "D. forest guards in poor areas in America\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1863, Accumulated: 0.1863, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0857, Accumulated: 0.2720, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0531, Accumulated: 0.3251, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0452, Accumulated: 0.3702, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0357, Accumulated: 0.4060, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0390, Accumulated: 0.4450, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0465, Accumulated: 0.4915, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1030, Accumulated: 0.5945, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1471, Accumulated: 0.7416, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1090, Accumulated: 0.8505, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0751, Accumulated: 0.9256, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0404, Accumulated: 0.9660, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0152, Accumulated: 0.9812, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0100, Accumulated: 0.0100, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0128, Accumulated: 0.0228, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0068, Accumulated: 0.0296, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0442, Accumulated: 0.0738, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0203, Accumulated: 0.0941, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0162, Accumulated: 0.1103, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0448, Accumulated: 0.1551, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0222, Accumulated: 0.1773, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0316, Accumulated: 0.2089, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7548, Accumulated: 0.9637, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0357, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: One evening , my dad asked me to buy some bread for dinner . It was dark and cold outside . I rode a bike to a shop near my school . When I left the shop ,it got even darker , so I got on my bike right away. Then I found a woman in a white dress riding a motorcycle after me . She followed me for a long time . I rode very fast and started to cry for help, but no one was there . I was too scared and too tired to ride any faster . At last , I gave up . The woman stopped in front of me and said , \" Why were you riding so fast , Ken ?It's dangerous !\" I looked at the woman . \" Oh , It's you, mum !You really scared me . Dad said you wouldn't be back for dinner tonight !\"\n",
      "\n",
      "Question: Why was Ken riding fast on his way home ?\n",
      "A. He was hungry\n",
      "B. Someone was following him\n",
      "C. It was getting darker and colder\n",
      "D. His father asked him to go home soon\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1649, Accumulated: 0.1649, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0740, Accumulated: 0.2389, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0515, Accumulated: 0.2904, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0411, Accumulated: 0.3315, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0356, Accumulated: 0.3671, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0386, Accumulated: 0.4056, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0352, Accumulated: 0.4408, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0670, Accumulated: 0.5078, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1230, Accumulated: 0.6308, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1138, Accumulated: 0.7447, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0977, Accumulated: 0.8424, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0844, Accumulated: 0.9268, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0323, Accumulated: 0.9591, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0151, Accumulated: 0.0151, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0172, Accumulated: 0.0324, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0104, Accumulated: 0.0428, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0056, Accumulated: 0.0484, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0115, Accumulated: 0.0599, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0095, Accumulated: 0.0694, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0121, Accumulated: 0.0816, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1826, Accumulated: 0.2642, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1751, Accumulated: 0.4393, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5565, Accumulated: 0.9959, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: On Children's Day a young woman from America goes to Beihai Park with her little daughter. There are too many people in the park. The woman can't find her daughter, So she goes to the policeman for  help. She tells the policeman her daughter is only six years old. She has two big eyes and a round face. Her hair is golden yellow. And she is in a short blue dress. At last the policeman helps her find her daughter. She thanks him very much.\n",
      "\n",
      "Question: The little girl's hair is   _  .\n",
      "A. yellow\n",
      "B. black\n",
      "C. brown\n",
      "D. golden yellow\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1863, Accumulated: 0.1863, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0784, Accumulated: 0.2647, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0514, Accumulated: 0.3160, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0393, Accumulated: 0.3553, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0310, Accumulated: 0.3863, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0445, Accumulated: 0.4308, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0503, Accumulated: 0.4811, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0976, Accumulated: 0.5787, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1317, Accumulated: 0.7104, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1128, Accumulated: 0.8231, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0846, Accumulated: 0.9078, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0516, Accumulated: 0.9593, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0184, Accumulated: 0.9778, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0089, Accumulated: 0.0089, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0246, Accumulated: 0.0335, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0125, Accumulated: 0.0459, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0282, Accumulated: 0.0741, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0099, Accumulated: 0.0840, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0064, Accumulated: 0.0904, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0087, Accumulated: 0.0991, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0120, Accumulated: 0.1112, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0465, Accumulated: 0.1577, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8382, Accumulated: 0.9959, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Joe, an outgoing girl, is from a rich family. Therefore she can afford almost everything. But Joe's parents are too busy to spend enough time with her, which makes Joe more than lonely. So, she always goes to WeChat. On WeChat, she can do a lot of things like buying things, reading articles, and making friends with those she either knows or not.\n",
      "She uses the name Linda on WeChat and has made a lot of friends there. Last year Joe made a foreign friend on WeChat. Her name was Catherine and she lived in Sydney. Catherine once sent a picture of \"herself\": a tall, good-looking young woman with big eyes. Catherine and Joe were both interested in rock music and modern dance. So, they liked each other very much.\n",
      "When Joe's father told her that he was meeting a client in Sydney this summer, she went with him to give Catherine a surprise for her birthday. When Joe came to Catherine's house in Sydney, she found that her foreign \"girlfriend\" was a ten-year-old boy named Jim! What a surprise!\n",
      "\n",
      "Question: From this article, we can say  _  .\n",
      "A. Everyone uses his real name on WeChat\n",
      "B. On WeChat, we can only talk with Chinese people.\n",
      "C. On WeChat, we can talk with Chinese people in Australia.\n",
      "D. Joe's father went to Sydney to meet Joe's friend Catherine.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2303, Accumulated: 0.2303, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0885, Accumulated: 0.3188, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0548, Accumulated: 0.3737, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0425, Accumulated: 0.4162, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0327, Accumulated: 0.4489, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0393, Accumulated: 0.4883, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0489, Accumulated: 0.5372, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1106, Accumulated: 0.6478, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1265, Accumulated: 0.7743, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0962, Accumulated: 0.8705, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0660, Accumulated: 0.9365, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0376, Accumulated: 0.9741, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0132, Accumulated: 0.9873, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0338, Accumulated: 0.0338, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0453, Accumulated: 0.0791, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0207, Accumulated: 0.0998, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0568, Accumulated: 0.1566, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0432, Accumulated: 0.1998, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0113, Accumulated: 0.2111, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0855, Accumulated: 0.2966, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0404, Accumulated: 0.3371, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0231, Accumulated: 0.3602, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6026, Accumulated: 0.9628, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0328, Accumulated: 0.9956, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: \"High tech\" and \"state of the art\" are two expressions that describe very modern technology. High tech is just a shorter way of saying high technology. And high technology describes any invention or system that uses the newest ideas or discoveries of science and engineering.\n",
      "What is high tech? A computer is high tech. So is a communications satellite. A modern manufacturing     system is surely high tech.\n",
      "High tech became a popular expression in the United States during the early 1980's. Because of improvements in technology, people could buy many new kinds of products in American stores, such as home computers, microwave ovens  , etc. \"State of the art\" is something that is as modern as possible. It is a product that is based on the very latest ways and technology. Something that is \"state of the art\" is the newest possible design or product of a business or industry. A state of the art television set, for example, uses the most modern electronic design and parts. It is the best that one can buy.\n",
      "\"State of the art\" is not a new expression. Engineers have used it for years, to describe the best and most modern way of doing something.\n",
      "Millions of Americans began to use the expression in the late 1970's. The reason was the computer revolution . Every computer company claimed   that its computers were \"state of the art\".\n",
      "Computer technology changes so fast that a state of the art computer today might be old tomorrow. The expression \"state of the art\" has become as common and popular as computers themselves. Now all kinds of products are said to be \"state of the art\".\n",
      "\n",
      "Question: What is the purpose of the passage?\n",
      "A. To tell how \"high tech\" and \"state of the art\" have developed.\n",
      "B. To give examples of high tech.\n",
      "C. To tell what \"high tech\" and \"state of the art\" are.\n",
      "D. To describe very modern technology.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2227, Accumulated: 0.2227, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0958, Accumulated: 0.3185, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0595, Accumulated: 0.3780, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0444, Accumulated: 0.4224, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0421, Accumulated: 0.4645, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0410, Accumulated: 0.5055, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0523, Accumulated: 0.5578, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0955, Accumulated: 0.6533, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1230, Accumulated: 0.7763, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0933, Accumulated: 0.8696, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0672, Accumulated: 0.9368, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0344, Accumulated: 0.9712, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0132, Accumulated: 0.9844, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0080, Accumulated: 0.0080, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0066, Accumulated: 0.0146, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0100, Accumulated: 0.0246, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0954, Accumulated: 0.1200, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0186, Accumulated: 0.1386, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0086, Accumulated: 0.1472, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0089, Accumulated: 0.1561, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0142, Accumulated: 0.1702, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0469, Accumulated: 0.2172, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7664, Accumulated: 0.9836, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0163, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: The widespread number of food scandals in  China is making many people pause before they put their chopsticks in their mouths.They are wondering if the food they are eating is clean,healthy and nutritious  or does it contain  something harmful that will cause disease?\n",
      "Most of the food we eat today is processed food .That means the foods we buy in stores and supermarkets,especially packaged foods,are prepared in factories.Chemicals are added to the foods in these factories to  make them look better,taste better and last longer on the shelf.The chemicals are supposed to be harmless and there are laws that regulate  which chemicals can and cannot be used.Unfortunately,some producers do not obey the laws.\n",
      "A producer of steamed buns in Zhejiang Province was recently discovered to be breaking the law.He was adding yellow dye and other banned chemicals to the buns.He was also taking old buns and using them to make new buns.Most of the buns were sold to schools and eaten by students...like you!\n",
      "Why did he do it? Why did he break the law and endanger people's  health? The answer is simple:he wanted to make more money.It was a moral failing,and this is at the heart of the food scandals in China.Too many people focus on making money and not on the effects their actions can have on others.\n",
      "\n",
      "Question: According to the passage, most of the buns were sold to  _   .\n",
      "A. factories\n",
      "B. schools\n",
      "C. hospitals\n",
      "D. companies\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1851, Accumulated: 0.1851, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0792, Accumulated: 0.2643, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0639, Accumulated: 0.3282, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0515, Accumulated: 0.3797, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0394, Accumulated: 0.4191, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0398, Accumulated: 0.4590, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0453, Accumulated: 0.5043, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0854, Accumulated: 0.5897, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1312, Accumulated: 0.7209, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1199, Accumulated: 0.8408, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0840, Accumulated: 0.9247, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0455, Accumulated: 0.9703, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0141, Accumulated: 0.9844, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0132, Accumulated: 0.0132, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0136, Accumulated: 0.0268, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0077, Accumulated: 0.0344, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0579, Accumulated: 0.0923, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0433, Accumulated: 0.1357, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0182, Accumulated: 0.1538, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0178, Accumulated: 0.1716, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0174, Accumulated: 0.1891, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0113, Accumulated: 0.2004, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7629, Accumulated: 0.9633, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0363, Accumulated: 0.9996, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: If you go into the forest with friends, stay with them .If you don't, you may get lost. If you do get lost, this is what you should do. Sit down and stay where you are. Don't try to find your friends. Let them find you. You can help them to find you by stay in one place.\n",
      "There is another way to help your friends or other people to find you. Give them a signal outing or whistling   three times. Stop. Then shout or whistle three times again. Any signal given three times is a call for help.\n",
      "Keep on shouting or whistling, always three times together. When people hear you, they will give two shouts or two whistles. When a signal is given twice, it is an answer to a call for help.\n",
      "If you don't think that you will get help before night comes, try to make a small room with branches. \n",
      "What should you do if you get hungry or need drinking water? You would have to leave your little branch room to look for something to eat and drink. Don't just walk far away. Pick up small branches and drop them as you walk so that you can find your way back.\n",
      "The most important thing you need to do when you are lost ---stay in one place.\n",
      "\n",
      "Question: When you hear two shouts or whistles, what does that mean?\n",
      "A. Some animals are coming.\n",
      "B. Someone is calling for help.\n",
      "C. People will come to help you\n",
      "D. Someone is lost.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1819, Accumulated: 0.1819, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0756, Accumulated: 0.2575, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0482, Accumulated: 0.3057, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0424, Accumulated: 0.3481, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0352, Accumulated: 0.3834, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0414, Accumulated: 0.4248, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0463, Accumulated: 0.4711, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1040, Accumulated: 0.5751, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1411, Accumulated: 0.7162, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1125, Accumulated: 0.8287, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0850, Accumulated: 0.9137, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0499, Accumulated: 0.9636, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0173, Accumulated: 0.9809, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0067, Accumulated: 0.0067, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0099, Accumulated: 0.0166, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0160, Accumulated: 0.0325, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1932, Accumulated: 0.2257, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0332, Accumulated: 0.2589, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0092, Accumulated: 0.2681, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0073, Accumulated: 0.2755, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0104, Accumulated: 0.2859, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0054, Accumulated: 0.2912, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6928, Accumulated: 0.9841, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0158, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Jeff Keith has only one leg. When he was 12 years old, Jeff had cancer. Doctors had to cut off most of his right leg. Everyday Jeff puts on an _ leg. The leg is plastic. With the plastic leg Jeff can ski, ride a bicycle, swim, and play soccer. He can also run.\n",
      "In the photo, Jeff is running with some young men. They have plastic legs, too. They are wearing special T-shirts. The T-shirts say, \"Run, Jeff, Run. Jeff Keith Run Across America.\"\n",
      "When he was 22 years old, Jeff Keith ran across the United State, from the East Coast to the West Coast. He started running in Boston. Seven months later, he stopped running in Los Angeles. He ran 3,200 miles, that's about 16 miles each day. Jeff wore out 36 pairs of running shoes and five plastic legs.\n",
      "Jeff stopped in cities on the way to Los Angeles. In every city people gave Jeff money. The money was not for Jeff. It was for American Cancer Society. The American Cancer Society used the money to learn about cancer.\n",
      "On the way to Los Angeles Jeff talked to people about cancer. He also talked about being disabled. Jeff is disabled, but he can do many things: he skis, swims, plays soccer, and runs. He finished college and is studying to be a lawyer. Jeff says, \"People can do anything they want to do. I want people to know that. I am not only for disabled people. I ran for everyone!\"\n",
      ",.\n",
      "\n",
      "Question: Jeff lost one of his right   _   because of cancer.\n",
      "A. arms\n",
      "B. legs\n",
      "C. eyes\n",
      "D. ears\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1974, Accumulated: 0.1974, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0864, Accumulated: 0.2838, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0504, Accumulated: 0.3342, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0407, Accumulated: 0.3748, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0329, Accumulated: 0.4077, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0398, Accumulated: 0.4475, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0419, Accumulated: 0.4895, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0973, Accumulated: 0.5868, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1371, Accumulated: 0.7239, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1122, Accumulated: 0.8361, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0797, Accumulated: 0.9159, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0479, Accumulated: 0.9637, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0154, Accumulated: 0.9792, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0065, Accumulated: 0.0065, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0317, Accumulated: 0.0382, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0094, Accumulated: 0.0476, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0254, Accumulated: 0.0730, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0214, Accumulated: 0.0944, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0159, Accumulated: 0.1102, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0121, Accumulated: 0.1223, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0208, Accumulated: 0.1431, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0265, Accumulated: 0.1695, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8143, Accumulated: 0.9838, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0162, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: \"It's the doll that my sister loved most and wanted so much for Christmas. She was so sure that Santa Claus would bring it to her.\" he said.\n",
      "I replied to him that maybe Santa Claus will bring it to her, and he shouldn't worry. But he replied to me sadly, \"No, Santa Claus can't bring it to her where she is now. I have to give the doll to my mommy so that she can give it to my sister when she goes there.\" His eyes were so sad while saying this. \"My sister has gone to be with God. Daddy says that Mommy is going to see God very soon too, so I thought that she could take the doll with her to give it to my sister.\" My heart nearly stopped. I quickly reached for my wallet and said to the boy, \"What if we checked again, just in case  you do have enough money?\"\n",
      "\"Ok,\" he said. \"I hope that I have enough.\" I added some of my money to his without letting him see and we started to count it. There was enough for the doll and even some spare money left . The little boy said, \"Thank you God for giving me enough money!\"\n",
      "I left the store, feeling as if my life had been changed forever.\n",
      "\n",
      "Question: The boy finally had enough money for the doll because  _  .\n",
      "A. he didn't count correctly at first\n",
      "B. the writer added some money\n",
      "C. the assistant added some money\n",
      "D. the assistant made the doll cheaper\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1948, Accumulated: 0.1948, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0847, Accumulated: 0.2795, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0493, Accumulated: 0.3288, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0382, Accumulated: 0.3670, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0268, Accumulated: 0.3938, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0336, Accumulated: 0.4275, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0392, Accumulated: 0.4667, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0898, Accumulated: 0.5565, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1348, Accumulated: 0.6913, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1234, Accumulated: 0.8147, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0940, Accumulated: 0.9087, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0562, Accumulated: 0.9649, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0173, Accumulated: 0.9822, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0071, Accumulated: 0.0150, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0162, Accumulated: 0.0312, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0269, Accumulated: 0.0581, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0066, Accumulated: 0.0647, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0085, Accumulated: 0.0732, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0060, Accumulated: 0.0792, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0286, Accumulated: 0.1077, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0646, Accumulated: 0.1724, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8082, Accumulated: 0.9806, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0192, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Would you like to adopt an animal? Although this sounds very unusual, some children have done just this. The Natural Zoo has given people the chance to adopt animals by paying for all of its food for one year. One of the animals that needed parents was a young tiger named Brocky. The people at the zoo said that it would cost about $900 a year for the food for Brocky.\n",
      "Not many boys and girls have $900 to spend. That is why several hundred children and grown-ups each have sent a little money to the zoo to help pay for Brocky's food. Some children sent in only a quarter because that was all the money they had. Other children sent in more money than that.\n",
      "Since so many people sent money to the zoo to help pay for Brocky's food, he now will be able to eat as much as he wants. Brocky surely must be a happy tiger to know that he has so many adopted parents. Many children must also be happy to know that they have helped to feed him. It really will be thrilling for those children to go to the Natural Zoo to visit their adopted tiger Brocky.\n",
      "\n",
      "Question: Brocky is  _  .\n",
      "A. an animal zoo\n",
      "B. an adopted child\n",
      "C. a tiger without children's love\n",
      "D. a tiger in need of adoption\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.2256, Accumulated: 0.2256, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1007, Accumulated: 0.3263, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0718, Accumulated: 0.3980, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0474, Accumulated: 0.4454, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0388, Accumulated: 0.4842, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0446, Accumulated: 0.5288, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0433, Accumulated: 0.5722, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0780, Accumulated: 0.6502, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1037, Accumulated: 0.7539, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0869, Accumulated: 0.8408, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0721, Accumulated: 0.9129, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0424, Accumulated: 0.9554, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0167, Accumulated: 0.9721, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0071, Accumulated: 0.0071, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0075, Accumulated: 0.0146, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0106, Accumulated: 0.0251, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0469, Accumulated: 0.0720, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0075, Accumulated: 0.0795, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0227, Accumulated: 0.1023, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0232, Accumulated: 0.1255, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0093, Accumulated: 0.1347, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0172, Accumulated: 0.1520, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8224, Accumulated: 0.9743, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0255, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Today is July 21. Most people are enjoying their weekend now. John is watching a magic show at the Capital Stadium with his parents and a friend from Australia.\n",
      "The girl is Megan, she is staying at John's for her holiday now. Her parents and brother Andy are now visiting the zoo. Their father is taking photos of many animals, like elephants, pandas, zebras and tigers. But Andy likes monkeys most and he is now watching them jumping and playing.\n",
      "Andy's cousin Julia is at her friend's birthday party. There she meets Lily, Daming, Joy and Lingling. They are having a happy talk and drinking some juice. Julia's grandparents are having a Taijiquan class, while her mother is shopping for presents. Julia's family is going back home to the Unite States next Thursday, so her father is booking plane ticket on the Internet.\n",
      "\n",
      "Question: What is the best title of the passage?\n",
      "A. A Happy Weekend.\n",
      "B. A Magic Show\n",
      "C. In a Zoo.\n",
      "D. At a Party.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2212, Accumulated: 0.2212, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0947, Accumulated: 0.3159, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0510, Accumulated: 0.3669, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0423, Accumulated: 0.4093, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0343, Accumulated: 0.4436, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0414, Accumulated: 0.4850, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0467, Accumulated: 0.5317, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0960, Accumulated: 0.6277, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1115, Accumulated: 0.7392, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0989, Accumulated: 0.8381, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0785, Accumulated: 0.9166, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0451, Accumulated: 0.9617, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0156, Accumulated: 0.9773, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0089, Accumulated: 0.0089, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0181, Accumulated: 0.0270, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0209, Accumulated: 0.0479, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0228, Accumulated: 0.0706, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0209, Accumulated: 0.0916, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0182, Accumulated: 0.1098, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0098, Accumulated: 0.1196, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0420, Accumulated: 0.1616, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0993, Accumulated: 0.2609, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7362, Accumulated: 0.9971, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Music is an important part in our life. We may feel boring without music. Today when you go to stores, stations, restaurants and other places, do you notice music playing at any of these places? The answer must be \"Yes\". And you might even hear music in an office or on a farm.\n",
      "I like many kinds of music. Classical music is great. Rock music is fast. Light music is relaxing. But I like folk music best. It sounds very beautiful. It can bring me into the dream land. It can make me relax and forget all the problems. It makes me learn better and helps me to be more active. It is true that I learn better when I am relaxed.\n",
      "Music can also influence  people's behavior . Classical music makes people feel rich . When a restaurant plays classical music, people spend more money on food and drinks. When the restaurant plays modern music, people spend less money. Without music, people spend evenless. Restaurants can make more money in this way.\n",
      "\n",
      "Question: The passage is mainly about  _  .\n",
      "A. music in restaurants\n",
      "B. good and bad music\n",
      "C. music in our life\n",
      "D. music and behavior\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.2031, Accumulated: 0.2031, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0683, Accumulated: 0.2715, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0415, Accumulated: 0.3130, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0286, Accumulated: 0.3416, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0254, Accumulated: 0.3670, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0327, Accumulated: 0.3997, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0322, Accumulated: 0.4319, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0703, Accumulated: 0.5021, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1058, Accumulated: 0.6079, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0993, Accumulated: 0.7072, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1343, Accumulated: 0.8415, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0921, Accumulated: 0.9336, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0335, Accumulated: 0.9671, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0192, Accumulated: 0.0192, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0162, Accumulated: 0.0354, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0093, Accumulated: 0.0447, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0054, Accumulated: 0.0501, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0165, Accumulated: 0.0666, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0090, Accumulated: 0.0756, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0259, Accumulated: 0.1015, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0237, Accumulated: 0.1252, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1069, Accumulated: 0.2321, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7056, Accumulated: 0.9378, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0607, Accumulated: 0.9985, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Lucy:I like sports. I have ten tennis balls, seven basketballs, four volleyballs and five soccer balls. I play tennis with my friends every day.\n",
      "Mary:I have five baseballs, five volleyballs, two soccer balls. I like ping-pong. It's easy for me. I often play ping-pong with my classmates. I also have three ping-pong bats and some ping-pong balls.\n",
      "Alice:I don't have any balls. I  love sports, but I don't play them. I only watch them on TV.\n",
      "\n",
      "Question: Lucy and Mary have  _  volleyballs.\n",
      "A. four\n",
      "B. five\n",
      "C. eight\n",
      "D. nine\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1964, Accumulated: 0.1964, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0882, Accumulated: 0.2846, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0531, Accumulated: 0.3377, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0456, Accumulated: 0.3834, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0359, Accumulated: 0.4193, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0502, Accumulated: 0.4695, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0540, Accumulated: 0.5235, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0996, Accumulated: 0.6231, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1275, Accumulated: 0.7507, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0966, Accumulated: 0.8473, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0727, Accumulated: 0.9200, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0419, Accumulated: 0.9619, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0160, Accumulated: 0.9779, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0075, Accumulated: 0.0075, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0197, Accumulated: 0.0272, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0413, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0382, Accumulated: 0.0795, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0097, Accumulated: 0.0892, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0130, Accumulated: 0.1022, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0067, Accumulated: 0.1089, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0117, Accumulated: 0.1206, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0412, Accumulated: 0.1618, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8292, Accumulated: 0.9910, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Yang Nan, 17, was happy to move to her new home in a northern area of Beijing. She was told that her neighborhood used to be farmland planted with vegetables, corn and wheat. But looking at the new road, beautiful park and supermarkets, Yang couldn't see any sign that food was once grown there.\n",
      "Yang is not alone. In recent years, many Chinese people have moved into new houses in country areas. Tall buildings have been built everywhere in the suburbs. The crops and fruit trees are no more. But these changes have caused problems too, warns Gan Zang chun, an official at the Ministry of Land and Resources  .\n",
      "\"Chinese cities are growing fast. This has made the area for farmland much smaller. This is really bad for the country's ability to grow food, not to mention the lives of farmers,\" said Gan last Monday.\n",
      "The country needs farmland to grow food for the people of China. But the recent rise in house prices has made selling land a good business. A lot of land has been used to build new houses for sale.\n",
      "Pollution, which makes land useless, is another reason for the big drop in China's farmland. About 2.67 million square kilometers of land in China have been polluted and turned into desert.\n",
      "The government wants China to have at least 120 million hectares  of farmland. But there are only about 121.8 million hectares left. \"It will be really difficult to reach the goal,\" Gan said. He said that the government would fight illegal land use and stop farmland from becoming desert.\n",
      "\n",
      "Question: From what Gan Zangchun said, he is worrying about_.\n",
      "A. China's development\n",
      "B. land and resources\n",
      "C. Chinese people's life\n",
      "D. illegal land use\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1765, Accumulated: 0.1765, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0814, Accumulated: 0.2579, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0541, Accumulated: 0.3120, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0456, Accumulated: 0.3576, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0306, Accumulated: 0.3882, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0410, Accumulated: 0.4292, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0509, Accumulated: 0.4801, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1088, Accumulated: 0.5889, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1516, Accumulated: 0.7406, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1162, Accumulated: 0.8568, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0722, Accumulated: 0.9290, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0433, Accumulated: 0.9723, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0140, Accumulated: 0.9863, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0055, Accumulated: 0.0055, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0278, Accumulated: 0.0333, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0082, Accumulated: 0.0415, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0773, Accumulated: 0.1188, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0210, Accumulated: 0.1398, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0189, Accumulated: 0.1587, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0206, Accumulated: 0.1793, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0172, Accumulated: 0.1965, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0189, Accumulated: 0.2154, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7631, Accumulated: 0.9785, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0213, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Tommy hated school and was always looking for excuses  not to go.If he sneezed, he asked his mother to write a note saying he had a cold.If he had a headache, he asked his mother to take him to the doctor during school hours.\n",
      "He spent more time at home than he did at school.On the days that he did go to school, he looked for excuses to come home early.One morning he came home when the lessons were only half finished.His father was surprised.\n",
      "\"You've come home early,\" he said. \"Is the school closed today?\"\n",
      "\"No, Dad, \" Tommy said - \"It's open. I came home early.\n",
      "\"How did you do that?\" his father asked him. \"What did you say to the teacher?\"\n",
      "\"I told her that I had a new baby brother and that I had to come home and help you . \"\n",
      "\"But your mother has had twins,\" his father said, \"a boy and a girl. You've got a baby brother and a baby sister.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "  1%|          | 1/100 [00:00<00:56,  1.75it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:37,  2.61it/s]\n",
      "  3%|▎         | 3/100 [00:01<00:30,  3.23it/s]\n",
      "  4%|▍         | 4/100 [00:01<00:22,  4.18it/s]\n",
      "  5%|▌         | 5/100 [00:01<00:21,  4.38it/s]\n",
      "  6%|▌         | 6/100 [00:01<00:18,  4.96it/s]\n",
      "  7%|▋         | 7/100 [00:01<00:17,  5.17it/s]\n",
      "  8%|▊         | 8/100 [00:01<00:18,  4.98it/s]\n",
      "  9%|▉         | 9/100 [00:02<00:19,  4.65it/s]\n",
      " 10%|█         | 10/100 [00:02<00:16,  5.30it/s]\n",
      " 11%|█         | 11/100 [00:02<00:17,  5.02it/s]\n",
      " 12%|█▏        | 12/100 [00:02<00:17,  4.90it/s]\n",
      " 13%|█▎        | 13/100 [00:02<00:15,  5.45it/s]\n",
      " 14%|█▍        | 14/100 [00:03<00:15,  5.54it/s]\n",
      " 15%|█▌        | 15/100 [00:03<00:16,  5.21it/s]\n",
      " 16%|█▌        | 16/100 [00:03<00:17,  4.81it/s]\n",
      " 17%|█▋        | 17/100 [00:03<00:17,  4.78it/s]\n",
      " 18%|█▊        | 18/100 [00:03<00:17,  4.76it/s]\n",
      " 19%|█▉        | 19/100 [00:04<00:17,  4.72it/s]\n",
      " 20%|██        | 20/100 [00:04<00:17,  4.56it/s]\n",
      " 21%|██        | 21/100 [00:04<00:17,  4.60it/s]\n",
      " 22%|██▏       | 22/100 [00:04<00:16,  4.60it/s]\n",
      " 23%|██▎       | 23/100 [00:04<00:15,  5.01it/s]\n",
      " 24%|██▍       | 24/100 [00:05<00:14,  5.42it/s]\n",
      " 25%|██▌       | 25/100 [00:05<00:15,  4.73it/s]\n",
      " 26%|██▌       | 26/100 [00:05<00:14,  5.21it/s]\n",
      " 27%|██▋       | 27/100 [00:05<00:14,  4.96it/s]\n",
      " 28%|██▊       | 28/100 [00:05<00:14,  4.92it/s]\n",
      " 29%|██▉       | 29/100 [00:06<00:14,  4.81it/s]\n",
      " 30%|███       | 30/100 [00:06<00:14,  4.76it/s]\n",
      " 31%|███       | 31/100 [00:06<00:13,  5.08it/s]\n",
      " 32%|███▏      | 32/100 [00:06<00:13,  4.93it/s]\n",
      " 33%|███▎      | 33/100 [00:07<00:14,  4.58it/s]\n",
      " 34%|███▍      | 34/100 [00:07<00:12,  5.29it/s]\n",
      " 35%|███▌      | 35/100 [00:07<00:11,  5.78it/s]\n",
      " 36%|███▌      | 36/100 [00:07<00:11,  5.77it/s]\n",
      " 37%|███▋      | 37/100 [00:07<00:10,  5.80it/s]\n",
      " 38%|███▊      | 38/100 [00:07<00:12,  5.00it/s]\n",
      " 39%|███▉      | 39/100 [00:08<00:11,  5.32it/s]\n",
      " 40%|████      | 40/100 [00:08<00:11,  5.18it/s]\n",
      " 41%|████      | 41/100 [00:08<00:11,  5.05it/s]\n",
      " 42%|████▏     | 42/100 [00:08<00:11,  4.98it/s]\n",
      " 43%|████▎     | 43/100 [00:08<00:11,  4.83it/s]\n",
      " 44%|████▍     | 44/100 [00:09<00:10,  5.10it/s]\n",
      " 45%|████▌     | 45/100 [00:09<00:11,  4.98it/s]\n",
      " 46%|████▌     | 46/100 [00:09<00:10,  5.18it/s]\n",
      " 47%|████▋     | 47/100 [00:09<00:10,  4.97it/s]\n",
      " 48%|████▊     | 48/100 [00:09<00:10,  4.84it/s]\n",
      " 49%|████▉     | 49/100 [00:10<00:10,  5.04it/s]\n",
      " 50%|█████     | 50/100 [00:10<00:10,  4.68it/s]\n",
      " 51%|█████     | 51/100 [00:10<00:11,  4.34it/s]\n",
      " 52%|█████▏    | 52/100 [00:10<00:10,  4.38it/s]\n",
      " 53%|█████▎    | 53/100 [00:11<00:09,  4.71it/s]\n",
      " 54%|█████▍    | 54/100 [00:11<00:09,  4.63it/s]\n",
      " 55%|█████▌    | 55/100 [00:11<00:10,  4.44it/s]\n",
      " 56%|█████▌    | 56/100 [00:11<00:09,  4.41it/s]\n",
      " 57%|█████▋    | 57/100 [00:11<00:09,  4.76it/s]\n",
      " 58%|█████▊    | 58/100 [00:12<00:07,  5.25it/s]\n",
      " 59%|█████▉    | 59/100 [00:12<00:07,  5.13it/s]\n",
      " 60%|██████    | 60/100 [00:12<00:08,  4.80it/s]\n",
      " 61%|██████    | 61/100 [00:12<00:08,  4.77it/s]\n",
      " 62%|██████▏   | 62/100 [00:12<00:08,  4.68it/s]\n",
      " 63%|██████▎   | 63/100 [00:13<00:08,  4.58it/s]\n",
      " 64%|██████▍   | 64/100 [00:13<00:07,  4.54it/s]\n",
      " 65%|██████▌   | 65/100 [00:13<00:07,  4.57it/s]\n",
      " 66%|██████▌   | 66/100 [00:13<00:07,  4.83it/s]\n",
      " 67%|██████▋   | 67/100 [00:13<00:06,  5.16it/s]\n",
      " 68%|██████▊   | 68/100 [00:14<00:05,  5.59it/s]\n",
      " 69%|██████▉   | 69/100 [00:14<00:05,  5.28it/s]\n",
      " 70%|███████   | 70/100 [00:14<00:05,  5.10it/s]\n",
      " 71%|███████   | 71/100 [00:14<00:05,  5.37it/s]\n",
      " 72%|███████▏  | 72/100 [00:14<00:05,  5.14it/s]\n",
      " 73%|███████▎  | 73/100 [00:15<00:04,  5.47it/s]\n",
      " 74%|███████▍  | 74/100 [00:15<00:05,  4.94it/s]\n",
      " 75%|███████▌  | 75/100 [00:15<00:04,  5.36it/s]\n",
      " 76%|███████▌  | 76/100 [00:15<00:04,  5.18it/s]\n",
      " 77%|███████▋  | 77/100 [00:15<00:04,  4.97it/s]\n",
      " 78%|███████▊  | 78/100 [00:16<00:04,  4.92it/s]\n",
      " 79%|███████▉  | 79/100 [00:16<00:04,  4.80it/s]\n",
      " 80%|████████  | 80/100 [00:16<00:04,  4.75it/s]\n",
      " 81%|████████  | 81/100 [00:16<00:04,  4.68it/s]\n",
      " 82%|████████▏ | 82/100 [00:16<00:03,  4.61it/s]\n",
      " 83%|████████▎ | 83/100 [00:17<00:03,  4.54it/s]\n",
      " 84%|████████▍ | 84/100 [00:17<00:03,  4.38it/s]\n",
      " 85%|████████▌ | 85/100 [00:17<00:03,  4.40it/s]\n",
      " 86%|████████▌ | 86/100 [00:17<00:03,  4.53it/s]\n",
      " 87%|████████▋ | 87/100 [00:18<00:02,  4.55it/s]\n",
      " 88%|████████▊ | 88/100 [00:18<00:02,  4.55it/s]\n",
      " 89%|████████▉ | 89/100 [00:18<00:02,  5.11it/s]\n",
      " 90%|█████████ | 90/100 [00:18<00:02,  4.95it/s]\n",
      " 91%|█████████ | 91/100 [00:18<00:01,  5.19it/s]\n",
      " 92%|█████████▏| 92/100 [00:19<00:01,  5.02it/s]\n",
      " 93%|█████████▎| 93/100 [00:19<00:01,  4.49it/s]\n",
      " 94%|█████████▍| 94/100 [00:19<00:01,  4.79it/s]\n",
      " 95%|█████████▌| 95/100 [00:19<00:00,  5.07it/s]\n",
      " 96%|█████████▌| 96/100 [00:19<00:00,  5.49it/s]\n",
      " 97%|█████████▋| 97/100 [00:20<00:00,  5.17it/s]\n",
      " 98%|█████████▊| 98/100 [00:20<00:00,  4.79it/s]\n",
      " 99%|█████████▉| 99/100 [00:20<00:00,  5.22it/s]\n",
      "100%|██████████| 100/100 [00:20<00:00,  5.25it/s]\n",
      "100%|██████████| 100/100 [00:20<00:00,  4.85it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Yes, I know, Dad, \" Tommy said. \"I'm saving up my baby sister for next week \"\n",
      "\n",
      "Question: Tommy tried to find excuses for not going to school because  _  .\n",
      "A. he didn't like it.\n",
      "B. it gave him a headache\n",
      "C. it made him sneeze\n",
      "D. it made him happy\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1663, Accumulated: 0.1663, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0783, Accumulated: 0.2446, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0465, Accumulated: 0.2911, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0328, Accumulated: 0.3239, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.3555, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0366, Accumulated: 0.3921, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0436, Accumulated: 0.4357, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0839, Accumulated: 0.5196, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1359, Accumulated: 0.6555, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1237, Accumulated: 0.7792, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0983, Accumulated: 0.8775, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0675, Accumulated: 0.9450, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0246, Accumulated: 0.9696, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0207, Accumulated: 0.0207, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0354, Accumulated: 0.0561, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0701, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0177, Accumulated: 0.0878, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0164, Accumulated: 0.1043, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0066, Accumulated: 0.1108, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0265, Accumulated: 0.1374, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0520, Accumulated: 0.1894, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0650, Accumulated: 0.2543, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7399, Accumulated: 0.9942, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Dear Sally,\n",
      "Thank you for your e-mail and the photo of New York. Here are some photos of my family trip in Wuhan. In the first photo, my sister Jane is wearing Chinese traditional clothes on the Yellow Grower. In the second picture, my father and I are swimming in a river. It's so cool! In the next picture, my parents, Jane and I are eating great noodles. Its name is hot dry noodles. It looks very nice!\n",
      "In the last picture, my family people are at my friend's home. We are having some mooncakes because it's the Mid-autumn Festival. It's an important festival in China. On this day, all the families get together and have a happy dinner.\n",
      "I think Wuhan is a nice city in China. The people there are friendly. One day I wish to go there again.\n",
      "Yours,\n",
      "David\n",
      ",.\n",
      "\n",
      "Question: The passage mainly wants to tell us   _  .\n",
      "A. Wuhan is a great city in China\n",
      "B. David likes the Mid-autumn Festival a lot\n",
      "C. David's family has a great trip in Wuhan\n",
      "D. the people in Wuhan are friendly\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1914, Accumulated: 0.1914, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0919, Accumulated: 0.2833, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0629, Accumulated: 0.3462, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0506, Accumulated: 0.3967, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0400, Accumulated: 0.4367, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0474, Accumulated: 0.4842, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0627, Accumulated: 0.5468, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1010, Accumulated: 0.6478, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1221, Accumulated: 0.7699, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0903, Accumulated: 0.8602, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0671, Accumulated: 0.9273, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0372, Accumulated: 0.9645, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0148, Accumulated: 0.9793, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0130, Accumulated: 0.0130, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0452, Accumulated: 0.0581, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0080, Accumulated: 0.0661, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0192, Accumulated: 0.0853, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0365, Accumulated: 0.1218, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0179, Accumulated: 0.1397, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0163, Accumulated: 0.1560, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0428, Accumulated: 0.1988, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0791, Accumulated: 0.2779, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7175, Accumulated: 0.9954, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Thursday, April 24th\n",
      "We got to the clean, lovely city of Yangzhou early in the morning. This is our first trip to China. All the different smells attract our attention to the local food. We are going to try something special for dinner tonight. The hotel we are staying in is not expensive but very clean. We plan to stay here for a few days, visit some places in the city, and then travel to the Great Wall in the north.\n",
      "Sunday, April 27th\n",
      "We visited the famous Slender West Lake   which was crowded with visit ors from all over the world, and bought a lot of toys for our friends outside the gate of the park. Everything is so colourful, and we have taken hundreds of photos already! Later today we will do the famous foot massage   and then leave for the Great Wall. We will take the night train north, stay in Beijing for two days, and then catch a bus to the Great Wall.\n",
      "Wednesday, April 30th\n",
      "Our trip to the Great Wall was long and boring. We visited a small village in the mountains. People in the village love the quiet life. They are the kindest people I had ever met. They always smile and say \"Hello\". Ralph and I can speak only a few words in Ch inese, so smiling is the best way to show our kindness.\n",
      "\n",
      "Question: From the passage we can see that the writer had a stay in Yangzhou.\n",
      "A. four-day\n",
      "B. five-day\n",
      "C. six-day\n",
      "D. seven-day\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1411, Accumulated: 0.1411, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0824, Accumulated: 0.2235, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0485, Accumulated: 0.2720, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0338, Accumulated: 0.3058, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0244, Accumulated: 0.3302, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0314, Accumulated: 0.3616, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0481, Accumulated: 0.4097, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1125, Accumulated: 0.5223, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1396, Accumulated: 0.6619, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1208, Accumulated: 0.7827, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1073, Accumulated: 0.8899, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0648, Accumulated: 0.9548, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0224, Accumulated: 0.9772, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0093, Accumulated: 0.0093, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0098, Accumulated: 0.0191, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0110, Accumulated: 0.0301, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0354, Accumulated: 0.0655, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0065, Accumulated: 0.0720, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0069, Accumulated: 0.0789, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0068, Accumulated: 0.0857, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0222, Accumulated: 0.1079, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0108, Accumulated: 0.1187, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8477, Accumulated: 0.9664, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0334, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: I am Wang Lin, I am twelve years old. My pen pal Tom is form the United States. He is the same age as I. He is a middle school student in Beijing. There are three people in his family. His father is a teacher, he teaches English in a high school in Beijing. His mother is an English teacher, too. But they work in different schools. Tom goes to school in his mother's car every day. They all like Chinese food. Tom's father likes Guangdong food, he thinks it is delicious. Tom's mother's favorite food is Sichuan food. But Tom doesn't like Sichuan food, he thinks it is too hot. So they often eat out on weekends.\n",
      "\n",
      "Question: Tom's father is   _  .\n",
      "A. a teacher\n",
      "B. an English teacher\n",
      "C. teaches English\n",
      "D. a doctor\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.2183, Accumulated: 0.2183, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0995, Accumulated: 0.3178, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0625, Accumulated: 0.3803, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0469, Accumulated: 0.4272, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0379, Accumulated: 0.4651, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0469, Accumulated: 0.5120, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0507, Accumulated: 0.5627, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1026, Accumulated: 0.6653, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1312, Accumulated: 0.7965, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0917, Accumulated: 0.8882, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0597, Accumulated: 0.9479, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0304, Accumulated: 0.9784, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0105, Accumulated: 0.9889, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0109, Accumulated: 0.0109, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0191, Accumulated: 0.0300, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0072, Accumulated: 0.0372, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0393, Accumulated: 0.0765, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0061, Accumulated: 0.0826, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0164, Accumulated: 0.0990, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0058, Accumulated: 0.1049, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0123, Accumulated: 0.1172, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0129, Accumulated: 0.1301, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8572, Accumulated: 0.9873, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0127, Accumulated: 1.0000, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: One thing that British and Chinese cultures share is a love for fine tea. Today, when we think of western tea culture, we often think of the English and beautiful china cups.\n",
      "Afternoon tea\n",
      "People believe that an English lady, Anna, first introduced the idea of afternoon tea. In the 18thand 19thcenturies, the English are only two main meals each day ----breakfast and a heavy dinner that would last several hours in the evening. As a result, people often got very hungry during the long wait between these two meals. To solve this problem, Anna came up with the clever idea of inviting some friends to join her for an afternoon meal between four and five o`clock. This meal included cakes and sandwiches, and tea was served to wash down the food. In order to make this afternoon meal important,  fine china cups and plates, and silver teapots, forks and spoons were used. Soon, afternoon tea parties became popular social occasions. Today, afternoon tea parties continue to play an important part in the social life in the modern Britain.\n",
      "Will you come for coffee?\n",
      "Coffee also has an important role in British culture. People often use the words \"Will you come for coffee?\" to mean \"Would you like to come to my home for a chat?\"Normally, several different drinks such as tea, hot chocolate or a soft drink like orange juice will be served as well as coffee, and you will be asked what you would like. However, you will not normally be offered wine at a \"coffee\" party.\n",
      "Coffeehouses and the London Stock Exchange \n",
      "In the 17thcentury London, coffeehouses were busy and noisy places. Businessmen and bankers went to coffeehouses to do their business, as well as to drink coffee. In fact, the London Stock Exchange is believed to have started from these coffeehouses.\n",
      ",,.\n",
      "\n",
      "Question: Which is the best title of the article?\n",
      "A. British and Chinese Cultures\n",
      "B. English Tea and Coffee Culture\n",
      "C. Coffeehouses and Business\n",
      "D. Chinese Tea and Coffee\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.2058, Accumulated: 0.2058, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0930, Accumulated: 0.2988, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0579, Accumulated: 0.3566, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0489, Accumulated: 0.4055, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0398, Accumulated: 0.4453, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0458, Accumulated: 0.4911, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0471, Accumulated: 0.5382, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0943, Accumulated: 0.6324, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1319, Accumulated: 0.7643, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1013, Accumulated: 0.8657, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0669, Accumulated: 0.9325, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0368, Accumulated: 0.9693, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0139, Accumulated: 0.9831, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0106, Accumulated: 0.0106, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0507, Accumulated: 0.0613, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0104, Accumulated: 0.0718, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0070, Accumulated: 0.0788, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0075, Accumulated: 0.0863, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0122, Accumulated: 0.0985, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0174, Accumulated: 0.1159, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0277, Accumulated: 0.1436, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0411, Accumulated: 0.1847, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7616, Accumulated: 0.9463, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0530, Accumulated: 0.9992, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Last Sunday afternoon, I was having dinner in a restaurant when my friend Poor came in. Poor is working in a bank and is quite rich, but he is always borrowing money from his friends and never pays it back. Poor saw me and came to sit at my table. He had never borrowed any money from me. When he was eating, I asked him to lend me two dollars. To my surprise, he gave me the money at once.\"I have never borrowed any money from you,\"Poor said,\"So you can pay for my dinner.\"\n",
      "Read the passage and choose the best answers.(,. )\n",
      "\n",
      "Question: Poor is the name of a man and the writer    _    .\n",
      "A. knows him well\n",
      "B. doesn't know him\n",
      "C. often lends him some money\n",
      "D. often borrows money from him\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2426, Accumulated: 0.2426, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0948, Accumulated: 0.3373, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0565, Accumulated: 0.3939, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0448, Accumulated: 0.4387, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0356, Accumulated: 0.4743, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0407, Accumulated: 0.5151, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0487, Accumulated: 0.5637, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0964, Accumulated: 0.6601, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1196, Accumulated: 0.7797, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0916, Accumulated: 0.8713, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0626, Accumulated: 0.9339, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0369, Accumulated: 0.9708, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0143, Accumulated: 0.9850, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0197, Accumulated: 0.0197, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0163, Accumulated: 0.0360, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0135, Accumulated: 0.0496, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0072, Accumulated: 0.0568, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0131, Accumulated: 0.0698, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0132, Accumulated: 0.0830, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0053, Accumulated: 0.0883, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0371, Accumulated: 0.1254, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0104, Accumulated: 0.1358, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7756, Accumulated: 0.9114, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0862, Accumulated: 0.9976, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Bush takes ice bucket challenge . Bush has joined a growing list of celebrities across the world to take the ice bucket challenge. He did it to help raise money for Lou Gehrig's disease and chose his predecessor  Bill Clinton  to do it next.\n",
      "In a video posted on Wednesday on Bush's Facebook page, the former president, wearing a navy blue coat while sitting at a table, said he was challenged by his daughter Jenna Bush Hager to take the challenge.\n",
      "As he wrote the check, Laura Bush appeared with a white bucket and poured ice water over her husband's head and then said, \"That check is for me. I don't want to ruin my hairstyle.\"\n",
      "Bush then announced his choice. \"Now it's my right to challenge my friend Bill Clinton to the ALS Challenge,\" he said. \"Yesterday was Bill's birthday and my gift to him is a bucket of cold water.\"\n",
      "The online campaign challenges people to either dump a bucket of ice water over their heads or donate to support research for Lou Gehrig's disease. When a person accepts the ice bucket challenge, he or she must challenge another person to partake in the raising money effort. Many famous people in different fields around the world took part in the activity, including Bill Gates, Stephen King, Christiano Ronaldo, and Lady Gaga, and so on.\n",
      "\n",
      "Question: Which of the following is RIGHT?\n",
      "A. Bill Clinton is Bush's friend\n",
      "B. Bill Clinton's birthday was on Wednesday\n",
      "C. Bill Clinton didn't accept it\n",
      "D. Bill Clinton only had one choice.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1798, Accumulated: 0.1798, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0755, Accumulated: 0.2554, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0423, Accumulated: 0.2977, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0376, Accumulated: 0.3353, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0296, Accumulated: 0.3649, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0400, Accumulated: 0.4048, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0449, Accumulated: 0.4497, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1108, Accumulated: 0.5605, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1714, Accumulated: 0.7320, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1245, Accumulated: 0.8564, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0826, Accumulated: 0.9391, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0377, Accumulated: 0.9768, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0117, Accumulated: 0.9885, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0070, Accumulated: 0.0070, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0348, Accumulated: 0.0418, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0094, Accumulated: 0.0512, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0604, Accumulated: 0.1116, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0155, Accumulated: 0.1271, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0253, Accumulated: 0.1524, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0245, Accumulated: 0.1769, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0077, Accumulated: 0.1846, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0072, Accumulated: 0.1918, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.3932, Accumulated: 0.5851, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.3625, Accumulated: 0.9475, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0516, Accumulated: 0.9991, Threshold: 0.9900\n",
      "Early exit at layer 15/16\n",
      "[Prompt]:\n",
      "Article: Do you obey the rules in your school? What do you think of your school rules? Are you allowed to dye   hair? A lot of school rules are similar around the world, but some are different. Some students may enjoy more freedom in some countries. But freedom doesn't mean \"no rules\". Every school has its own rules.\n",
      "There are some rules in Japanese schools. The students are not allowed to dye their hair and are supposed to keep their hair black. They are not allowed to wear earrings either. Almost all schools used to require students to wear school uniforms but now half of the schools require uniforms. The students feel happy to wear all kinds of clothes. The students must get to school on time. If they are late, they cannot get into the school because the school gate is closed. In Japan, students are not allowed to have part-time jobs.\n",
      "American schools have their own rules too. For example, at Morton High School, students are not allowed to choose their own clothes. They must get to school or leave school on time. Food, drinks or snacks shouldn't be taken into the classroom. They must wear sports shoes in PE class. They are supposed to keep quiet on the school bus. In America, the students can have part-time jobs in their free time. (<<>> )\n",
      "\n",
      "Question: Which is the same rule in Japanese schools and at Morton High School?\n",
      "A. The students can have part-time jobs.\n",
      "B. The students are allowed to wear their own clothes.\n",
      "C. The students must get to school on time.\n",
      "D. The students should keep their hair black.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2146, Accumulated: 0.2146, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0981, Accumulated: 0.3127, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0565, Accumulated: 0.3692, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0429, Accumulated: 0.4121, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0379, Accumulated: 0.4500, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0446, Accumulated: 0.4946, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0465, Accumulated: 0.5411, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0995, Accumulated: 0.6406, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1260, Accumulated: 0.7666, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1032, Accumulated: 0.8698, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0702, Accumulated: 0.9401, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0348, Accumulated: 0.9749, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0118, Accumulated: 0.9867, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0083, Accumulated: 0.0083, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0133, Accumulated: 0.0216, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0100, Accumulated: 0.0316, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0830, Accumulated: 0.1146, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0084, Accumulated: 0.1230, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0369, Accumulated: 0.1599, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0195, Accumulated: 0.1793, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0077, Accumulated: 0.1870, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0161, Accumulated: 0.2031, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7875, Accumulated: 0.9907, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: More and more people around the world are joining in dangerous sports. Some people climbed the highest mountains; some traveled into unknown parts of the world; some sailed small boats across the largest sea. Now some people begin to look for new excitement.\n",
      "Bungee jumping   and motorcycle racing   are quite dangerous sports. Bungee jumping only lasts for a few minutes or even seconds. You jump from a high place, about 200 meters above the ground, and there is a rubber band   tied to your legs. When you jump down, the rubber band pulls you up. About 2,000,000 people around the world have tried bungee jumping.\n",
      "Why do people join in these dangerous sports? Some scientists say that it is because modern life has become safe and it is not interesting. In the past, people lived in danger. They had to go out and look for food, and life was like a fight but was interesting.\n",
      "Many people think that there is little excitement in life. They live and work in safe places, buy food in shops, and there are doctors and hospitals to look after them if they become ill.\n",
      ",.\n",
      "\n",
      "Question: In the past, people lived in danger because   _  .\n",
      "A. the living condition   was poor\n",
      "B. there was no doctor or hospital\n",
      "C. there were many dangerous animals\n",
      "D. A, B and C\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2030, Accumulated: 0.2030, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0850, Accumulated: 0.2880, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0538, Accumulated: 0.3417, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0398, Accumulated: 0.3816, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0293, Accumulated: 0.4108, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0389, Accumulated: 0.4498, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0508, Accumulated: 0.5006, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1156, Accumulated: 0.6162, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1439, Accumulated: 0.7601, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1110, Accumulated: 0.8711, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0695, Accumulated: 0.9406, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0344, Accumulated: 0.9750, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0124, Accumulated: 0.9874, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0076, Accumulated: 0.0076, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0097, Accumulated: 0.0174, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0087, Accumulated: 0.0261, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0293, Accumulated: 0.0554, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0191, Accumulated: 0.0745, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0125, Accumulated: 0.0869, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0088, Accumulated: 0.0957, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0148, Accumulated: 0.1106, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0849, Accumulated: 0.1954, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7794, Accumulated: 0.9749, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0250, Accumulated: 0.9999, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Ken and Anthony were childhood friends. They went to elementary and high school together. They went to college in different states, and then they lost touch. That was twenty years ago.\n",
      "One morning Ken was reading the newspaper with his morning coffee. Inside he saw an announcement for a poetry reading at a nearby bookstore. He was surprised to find that the featured poet was none other than his friend Anthony. Ken decided to see what his old pal was up to.\n",
      "Ken sat in the last row of the area set up inside the bookstore. When Anthony was introduced and came up the podium, Ken hardly recognized him. Anthony was almost completely bald and had a little potbelly  . When Anthony was in high school, he was very handsome. What Anthony had lost in looks was made up for in talent. Anthony's poetry was quite good.\n",
      "Anthony recognized Ken sitting in the back row. When the reading was over, Ken stood in line with the others waiting for Anthony to sign a copy of his book. When it was Ken's turn, Anthony stood up and hugged his long lost friend. Anthony invited Ken to stay until he had finished signing books. Ken did, and the two men grabbed a cup of coffee at a nearby cafe.\n",
      "Even though so many years had passed since the two had seen each other, both men had a lot in common. Both graduated from college with degrees in comparative literature  . Both went to graduate school. Anthony got his Master's of Fine Art in writing. Ken went to law school. Both men married Mexican women. Both men also had sons that were only a year apart. Ken and Anthony decided not to lose touch again. They planned to meet once a month for breakfast on Saturdays.\n",
      "\n",
      "Question: How did Ken probably feel while seeing Anthony at the bookstore?\n",
      "A. Worried.\n",
      "B. Amazed.\n",
      "C. Frightened.\n",
      "D. Relaxed.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.2002, Accumulated: 0.2002, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0853, Accumulated: 0.2855, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0572, Accumulated: 0.3427, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0426, Accumulated: 0.3852, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0414, Accumulated: 0.4266, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0503, Accumulated: 0.4768, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0571, Accumulated: 0.5339, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0973, Accumulated: 0.6313, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1397, Accumulated: 0.7710, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1034, Accumulated: 0.8744, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0709, Accumulated: 0.9454, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0328, Accumulated: 0.9782, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0099, Accumulated: 0.9881, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0071, Accumulated: 0.0071, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0088, Accumulated: 0.0159, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0098, Accumulated: 0.0258, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0559, Accumulated: 0.0817, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0080, Accumulated: 0.0897, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0226, Accumulated: 0.1122, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0100, Accumulated: 0.1222, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0832, Accumulated: 0.2054, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1465, Accumulated: 0.3519, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6465, Accumulated: 0.9984, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: When you were very young, you liked to play with your friends. Did you find that playtime was always more fun when everyone shared the toys? Everyone got a turn. No one was left out.\n",
      "That's a life lesson that changes as you get older. As you grow up, you begin to understand that others have less than you do - in China and in the world. And that those of us who \"have\" things should help those who \" have less\" than we do. The idea of sharing _ \n",
      "At your age, you can \"share\" with people in need in three ways.\n",
      "1. You can give them a part of your money. Many adults do that regularly.\n",
      "2. You can share items you no longer use, such as clothing and toys. You can pass them onto others who cannot buy them.\n",
      "3. You can help people by giving your time and your energy.\n",
      "The last one is also called volunteering. Volunteering is about giving your time to take part in activities that will help others. Every year, many thousands of volunteers in the world give the most valuable gift of all. They give their time. They give their talent. They give of themselves. And they are enjoying it. Volunteering isn't just about work. It's about fun too.\n",
      ",.\n",
      "\n",
      "Question: What does volunteering mean according to the passage?\n",
      "A. Give people money.\n",
      "B. Share items one no longer uses.\n",
      "C. Help people by giving one's time and energy.\n",
      "D. People give themselves to others.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.2480, Accumulated: 0.2480, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.1144, Accumulated: 0.3624, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0681, Accumulated: 0.4305, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0505, Accumulated: 0.4810, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0387, Accumulated: 0.5197, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0442, Accumulated: 0.5639, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0480, Accumulated: 0.6120, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0934, Accumulated: 0.7054, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1136, Accumulated: 0.8190, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0809, Accumulated: 0.8999, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0526, Accumulated: 0.9525, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0262, Accumulated: 0.9787, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0090, Accumulated: 0.9877, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0135, Accumulated: 0.0214, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0154, Accumulated: 0.0369, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0349, Accumulated: 0.0718, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0152, Accumulated: 0.0870, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0237, Accumulated: 0.1107, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0678, Accumulated: 0.1786, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0127, Accumulated: 0.1913, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0148, Accumulated: 0.2061, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7645, Accumulated: 0.9705, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0291, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
      "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
      "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
      "\n",
      "Question: The writer thinks many people don't live near the north or south pole because  _  .\n",
      "A. they can't get enough food there\n",
      "B. the natural sights there don't arrract people\n",
      "C. the unpleasant weather keeps them away\n",
      "D. the length of nighttime keeps them away\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1802, Accumulated: 0.1802, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0722, Accumulated: 0.2524, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0466, Accumulated: 0.2990, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0351, Accumulated: 0.3342, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0310, Accumulated: 0.3651, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0418, Accumulated: 0.4070, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0516, Accumulated: 0.4586, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0970, Accumulated: 0.5556, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1448, Accumulated: 0.7005, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1137, Accumulated: 0.8142, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0889, Accumulated: 0.9031, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0538, Accumulated: 0.9569, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0181, Accumulated: 0.9750, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0078, Accumulated: 0.0078, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0067, Accumulated: 0.0146, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0083, Accumulated: 0.0229, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0173, Accumulated: 0.0401, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0223, Accumulated: 0.0624, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0068, Accumulated: 0.0692, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0048, Accumulated: 0.0740, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0350, Accumulated: 0.1090, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0849, Accumulated: 0.1939, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7821, Accumulated: 0.9760, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0237, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Raising pets is a popular online game among teenagers. \"More than 20 of my classmates have adopted pets online, while last year the number was just 10,\" said Wang Hui,a middle school student from Beijing, who also raises pets online.\n",
      "If you go to some websites, you can adopt virtual pets like penguins, chickens, dogs and elephants. You can feed,wash, talk to and play with your pet.\n",
      "Dai Yingshuang of Shanghai raises pets on KaixinOOl. com. The 15-year-old girl said it is great fun. She thinks that she has also learned how to take care of others.\n",
      "If one doesn't feed and care for the pet, it becomes unhappy and unhealthy. So raising an online pet means spending a lot of time online.\n",
      "This makes many parents worried. They fear there will be bad influence in the children's studies.\n",
      "Dai said that she usually asks her uncle to take care of her pet, while she is at school.\n",
      "Wang Zhaotong, from Anhui,has been raising a penguin on QQ. com since last year. The 14-year-old girl takes good care of the penguin.\n",
      "She said her parents knew about the penguin and think it's Okay. If the students can keep the balance between studying and playing, it's not bad for them to \"raise\" pets online.\n",
      ",,.\n",
      "\n",
      "Question: According to the passage, over of the students in Wang Hui's class have adopted pets online this year.\n",
      "A. 10\n",
      "B. 20\n",
      "C. half\n",
      "D. all\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.2098, Accumulated: 0.2098, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0886, Accumulated: 0.2985, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0492, Accumulated: 0.3476, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0322, Accumulated: 0.3798, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0292, Accumulated: 0.4090, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0425, Accumulated: 0.4515, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0632, Accumulated: 0.5147, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1175, Accumulated: 0.6322, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1266, Accumulated: 0.7588, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1013, Accumulated: 0.8601, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0673, Accumulated: 0.9273, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0404, Accumulated: 0.9677, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0150, Accumulated: 0.9827, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0093, Accumulated: 0.0093, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0252, Accumulated: 0.0345, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0181, Accumulated: 0.0526, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0393, Accumulated: 0.0919, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0395, Accumulated: 0.1314, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0142, Accumulated: 0.1456, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0079, Accumulated: 0.1535, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0090, Accumulated: 0.1625, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0122, Accumulated: 0.1747, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5537, Accumulated: 0.7284, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.2445, Accumulated: 0.9729, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0232, Accumulated: 0.9961, Threshold: 0.9900\n",
      "Early exit at layer 15/16\n",
      "[Prompt]:\n",
      "Article: Are you a crazy chocolate fan? Have you heard about Hershey's Kisses? Do you love the movieCharlie and the Chocolate Factory? If your answer was, \"yes\", to any of the questions, then my experience will make you jealous  . I just went to the famous Hershey Chocolate Factory!\n",
      "The other day we drove from Washington DC to the small town of Hershey, Pennsylvania. When we arrived at the factory, we realized that this was much more than just a factory. The whole town is a chocolate-themed amusement park. The sweet smell of chocolate is on every street corner. There are even road signs that say things like, \"Chocolate Ave \" and \"Cake St.\".\n",
      "As we were walking towards the park, Jason, our tour guide, began telling us about this quiet little town. Hershey chocolate has been a _ in the world over the past hundred years. It is the biggest company that makes and sells chocolate in America,\" he started. \"I guess you get the chocolate in China, don't you?\"\n",
      "I nodded  without thinking. How could I possibly not know those lovely little candies when I've been eating them all these years?\n",
      "Jason went on, \"The factory first started on a small farm. It developed very fast. So they built this town for factory workers to live in. Then they built hotels, hospitals, stadiums , theaters and even museums with the theme of chocolate. Isn't that cool?\"\n",
      "\"Yes, a hundred times yes!\" I yelled ( )with delight.\n",
      "\n",
      "Question: What was the small town of Hershey like?\n",
      "A. It was very beautiful.\n",
      "B. It was like a big city.\n",
      "C. It was very colorful.\n",
      "D. It was a theme park.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.2042, Accumulated: 0.2042, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0913, Accumulated: 0.2955, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0542, Accumulated: 0.3497, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0448, Accumulated: 0.3945, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0357, Accumulated: 0.4302, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0428, Accumulated: 0.4730, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0551, Accumulated: 0.5281, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1045, Accumulated: 0.6326, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1265, Accumulated: 0.7591, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1008, Accumulated: 0.8599, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0684, Accumulated: 0.9283, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0396, Accumulated: 0.9679, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0131, Accumulated: 0.9809, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0186, Accumulated: 0.0186, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0338, Accumulated: 0.0524, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0067, Accumulated: 0.0591, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0363, Accumulated: 0.0954, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0110, Accumulated: 0.1064, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0108, Accumulated: 0.1172, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0091, Accumulated: 0.1262, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1887, Accumulated: 0.3149, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0195, Accumulated: 0.3344, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6396, Accumulated: 0.9740, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0258, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Emily Urich 18 years old Canada\n",
      "A lot of teens aren't responsible ,and that's where I'm different. Not just about school but everyday things like being able to pay my own credit card bills on time.\n",
      "The first time I got a cartoon book was on my third birthday. From then on , I fell in deep love with it. And can you guess how many cartoon books I've read? I don't really know the exact number. But I have three full boxes of them under my bed. I also like drawing cartoons and wish to be an art teacher in a sch001.\n",
      "Joe Miller 16 year's old America\n",
      "I'm proud of doing things my own way. So whether somebody wants me to do something or whatever it is , I feel like they're all other people's thoughts , not really mine. But like others , I love reading , too. When I first took skiing lessons , I found it exciting. For ski racing,there's no question I'm better shape than most guys . I think it's fun. I mean,it is a challenge . It's where I picked up the idea of needing a challenge always in my life. In order to improve my skiing skills,I have read many books and magazines about it. No doubt it's my dream to win gold medals in the Olympic Games.\n",
      "An Oi 15 years old China\n",
      "I'm different because I prefer to drop out of the world to create my own world. I'd like to build a house on a mountain. And I choose to live without electricity, a telephone,or even indoor plumbing . I have many hobbies such as traveling,reading , writing and spending time with children. I love children because they are smart and creative. They always have many strange ideas. It makes me excited. I want to do something for Hope Project and become a country school teacher .\n",
      "\n",
      "Question: Why does An Qi want to be a country schoolteacher?\n",
      "A. Because she wants to travel.\n",
      "B. Because her parents are teachers.\n",
      "C. Because she loves children very much.\n",
      "D. Because she comes from the countryside.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1799, Accumulated: 0.1799, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0688, Accumulated: 0.2487, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0416, Accumulated: 0.2903, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0400, Accumulated: 0.3303, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0282, Accumulated: 0.3586, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0339, Accumulated: 0.3925, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0466, Accumulated: 0.4391, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0919, Accumulated: 0.5310, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1466, Accumulated: 0.6776, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1266, Accumulated: 0.8042, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0973, Accumulated: 0.9014, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0581, Accumulated: 0.9595, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0212, Accumulated: 0.9806, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0082, Accumulated: 0.0082, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0085, Accumulated: 0.0167, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0106, Accumulated: 0.0273, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0602, Accumulated: 0.0875, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0151, Accumulated: 0.1025, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0263, Accumulated: 0.1289, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0340, Accumulated: 0.1629, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0208, Accumulated: 0.1836, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0430, Accumulated: 0.2266, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7545, Accumulated: 0.9811, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0187, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: It is not easy to be a vet  .You never know when you will be called upon to take care of a sick animal. You also do not always know that kind of animal you will be asked to take care of or what you must do to help the sick animal.\n",
      "Once, when some children were playing with a dog, they threw a ball into its mouth. The ball got stuck   in the dog's throat   and the dog could not breathe. The dog would die if they did not remove the ball quickly. The dog's owner took the dog to a vet called Robert Smith. Mr. Smith put his hands on the dog's neck. He could feel the ball. He was not sure what to do. He pressed   a little harder. The dog opened its mouth and the ball came flying out! No one was more surprised than Mr. Smith.\n",
      "Another vet, peter Brown. Worked with sea animals. One day, he was called upon to take care of a dolphin. The dolphin had something in its mouth that had to be taken out, but it did not want to open its mouth. Nineteen men had to hold the strong and slippery  dolphin so that the vet could open its mouth.\n",
      "\n",
      "Question: Which of the following is the writer's opinion?\n",
      "A. No one wants to be a vet.\n",
      "B. Everyone wants to be a vet.\n",
      "C. It is difficult to be a vet.\n",
      "D. It is easy to be a vet.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1359, Accumulated: 0.1359, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0612, Accumulated: 0.1970, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0393, Accumulated: 0.2363, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0337, Accumulated: 0.2700, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0286, Accumulated: 0.2985, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0423, Accumulated: 0.3409, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0419, Accumulated: 0.3828, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0964, Accumulated: 0.4792, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1446, Accumulated: 0.6237, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1392, Accumulated: 0.7629, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.1115, Accumulated: 0.8745, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0750, Accumulated: 0.9495, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0244, Accumulated: 0.9739, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0301, Accumulated: 0.0301, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0213, Accumulated: 0.0514, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0117, Accumulated: 0.0631, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0423, Accumulated: 0.1054, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0144, Accumulated: 0.1198, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0077, Accumulated: 0.1275, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0115, Accumulated: 0.1390, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0634, Accumulated: 0.2024, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0632, Accumulated: 0.2656, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6881, Accumulated: 0.9537, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0459, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Today is the fifth day of August. It is Judy's birthday. When she comes back home from school, she sees a card on the table. It says, \"There's a present   for you, Judy. Look for it in your bedroom.\" Judy runs into her bedroom. Her parents are looking at her and _ . On the chair she sees a red box. She thinks her present must be in it. She opens it, and there is a piece of paper in it. She reads it, \"Dear Judy, I'm your present. My first letter is in the word 'bag', but not in 'age'. My second letter is in 'like', but not in 'lake'. My third letter is in \"know\", but not in 'now'. And you can find my last letter in both 'desk' and 'get'. What am I?\" Judy thinks for a while and says, \"Aha, I know. But where is it?\" Her father tells her it is in her study.\n",
      "What is it? Do you know?\n",
      ". (5)\n",
      "\n",
      "Question: When is Judy's birthday?\n",
      "A. Aug.5th.\n",
      "B. Aug.6th.\n",
      "C. Sept.5th.\n",
      "D. Sept.6th.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.1992, Accumulated: 0.1992, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0922, Accumulated: 0.2914, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0636, Accumulated: 0.3550, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0492, Accumulated: 0.4042, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0398, Accumulated: 0.4440, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0469, Accumulated: 0.4909, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0604, Accumulated: 0.5513, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0966, Accumulated: 0.6479, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1231, Accumulated: 0.7710, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0889, Accumulated: 0.8599, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0666, Accumulated: 0.9265, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0375, Accumulated: 0.9640, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0150, Accumulated: 0.9789, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0144, Accumulated: 0.0144, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0131, Accumulated: 0.0274, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0135, Accumulated: 0.0410, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0425, Accumulated: 0.0834, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0190, Accumulated: 0.1024, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0159, Accumulated: 0.1184, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0179, Accumulated: 0.1363, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0119, Accumulated: 0.1482, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0226, Accumulated: 0.1707, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.8220, Accumulated: 0.9927, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Thursday, April 24th\n",
      "We got to the clean, lovely city of Yangzhou early in the morning. This is our first trip to China. All the different smells attract our attention to the local food. We are going to try something special for dinner tonight. The hotel we are staying in is not expensive but very clean. We plan to stay here for a few days, visit some places in the city, and then travel to the Great Wall in the north.\n",
      "Sunday, April 27th\n",
      "We visited the famous Slender West Lake   which was crowded with visit ors from all over the world, and bought a lot of toys for our friends outside the gate of the park. Everything is so colourful, and we have taken hundreds of photos already! Later today we will do the famous foot massage   and then leave for the Great Wall. We will take the night train north, stay in Beijing for two days, and then catch a bus to the Great Wall.\n",
      "Wednesday, April 30th\n",
      "Our trip to the Great Wall was long and boring. We visited a small village in the mountains. People in the village love the quiet life. They are the kindest people I had ever met. They always smile and say \"Hello\". Ralph and I can speak only a few words in Ch inese, so smiling is the best way to show our kindness.\n",
      "\n",
      "Question: The writer left Beijing for the Great Wall  _  .\n",
      "A. by train\n",
      "B. by car\n",
      "C. by bus\n",
      "D. on foot\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1794, Accumulated: 0.1794, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0900, Accumulated: 0.2694, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0660, Accumulated: 0.3355, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0413, Accumulated: 0.3767, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0317, Accumulated: 0.4085, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0342, Accumulated: 0.4427, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0428, Accumulated: 0.4855, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0979, Accumulated: 0.5834, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1426, Accumulated: 0.7260, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1093, Accumulated: 0.8353, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0844, Accumulated: 0.9197, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0466, Accumulated: 0.9662, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0163, Accumulated: 0.9826, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0074, Accumulated: 0.0074, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0103, Accumulated: 0.0177, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0246, Accumulated: 0.0423, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0511, Accumulated: 0.0934, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0136, Accumulated: 0.1070, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0203, Accumulated: 0.1273, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0150, Accumulated: 0.1424, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1095, Accumulated: 0.2519, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0768, Accumulated: 0.3287, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6434, Accumulated: 0.9721, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0276, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Mr. White lives on the 20th floor in a tall building in Beijing. His office is about ten kilometers from home. His wife and his children are now in America for holidays.\n",
      "Today Mr. White leaves his home at eight in the moming. He takes the lift down to the first floor, gets out of the lift and walks to his car. Oh, dear! His car is broken. He waits for a taxi but there's not any empty one. So he has to go by bus.\n",
      "Mr. White gets to his office at nine twenty. He is very late. Today he has a lot of work to do. He does it quickly and he has only one hamburger and a cup oforange juice for his lunch. Mr. White leaves his office at half past six. When he gets to his building, he quickly gets into the lift. Oh, dear! The lift doesn't work! He has to walk up to the 20th floor. But when he gets there, he finds he forgets to take the key with him.\n",
      "What can he do now? Poor Mr. White!\n",
      "\n",
      "Question: From the passage we can see Mr. White  _  .\n",
      "A. is not healthy\n",
      "B. is now in China\n",
      "C. can't drive a car\n",
      "D. likes Chinese food\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1652, Accumulated: 0.1652, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0892, Accumulated: 0.2544, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0548, Accumulated: 0.3092, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0327, Accumulated: 0.3419, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0318, Accumulated: 0.3737, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0403, Accumulated: 0.4139, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0478, Accumulated: 0.4617, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0969, Accumulated: 0.5586, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1498, Accumulated: 0.7084, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1184, Accumulated: 0.8268, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0915, Accumulated: 0.9183, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0498, Accumulated: 0.9680, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0156, Accumulated: 0.9836, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0063, Accumulated: 0.0063, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0155, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0082, Accumulated: 0.0237, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0440, Accumulated: 0.0677, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0067, Accumulated: 0.0744, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0069, Accumulated: 0.0813, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0127, Accumulated: 0.0941, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0281, Accumulated: 0.1222, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0878, Accumulated: 0.2100, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7827, Accumulated: 0.9927, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Lin Tao and Chen Hai are good friends. They are in the same class. They are in the same team. Lin Tao sits behind Chen Hai. Now it is four o'clock. School is over. They often go to play games after school. They can't look after their things very well. So their mothers don't give them watches. They don't have watches. They don't know the time. But they can ask a man under the big tree. His watch is very nice. They can also see the clock on the wall of the classroom. Now it's about five in the afternoon. It's time to go home. They must put on their clothes and go home.\n",
      "\n",
      "Question: What do they do after school?\n",
      "A. They go home.\n",
      "B. They do their homework.\n",
      "C. They look after each other.\n",
      "D. They play games.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1604, Accumulated: 0.1604, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0765, Accumulated: 0.2369, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0482, Accumulated: 0.2851, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0384, Accumulated: 0.3235, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0331, Accumulated: 0.3566, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0394, Accumulated: 0.3960, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0506, Accumulated: 0.4466, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1027, Accumulated: 0.5493, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1412, Accumulated: 0.6905, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1184, Accumulated: 0.8089, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0925, Accumulated: 0.9014, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0582, Accumulated: 0.9597, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0207, Accumulated: 0.9804, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0196, Accumulated: 0.0196, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0102, Accumulated: 0.0298, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0419, Accumulated: 0.0717, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1147, Accumulated: 0.1864, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0049, Accumulated: 0.1913, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0096, Accumulated: 0.2009, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0073, Accumulated: 0.2083, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1081, Accumulated: 0.3164, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1343, Accumulated: 0.4508, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.5444, Accumulated: 0.9952, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Autumn is the harvest season. There must be a lot for us to eat !Yes, autumn is a great time for fruit and vegetables. Let's find out about some of the best.\n",
      "Apples: You can eat apples all the year round, but they are better and cheaper in autumn. People say \"An apple a day keeps the doctor away\". Apples have a lot of vitamin C and fiber  in them. They are good for the heart and can make your mouth fresh.\n",
      "Pears: Pears are in season from autumn to mid winter. They have minerals and vitamins C and E in them. They are good for the heart and can keep cancer   away.\n",
      "Pumpkins: Pumpkin is a nice vegetable in autumn. They are rich in beta carotene  , which is turned into vitamin A in our bodies. Pumpkins also have calcium ,iron and vitamin C in them. Eating pumpkins can make us look young.\n",
      "Sweet corn  : Sweet corn is in season near the end of the year. It has minerals in it. It's good for the heart.\n",
      "Autumn weather is cold and dry. Try to eat as much fruit and vegetables as you can. They will make you healthy.\n",
      "\n",
      "Question: _   are /is in rich beta carotene.\n",
      "A. Pumpkins\n",
      "B. Sweet corn\n",
      "C. Apples\n",
      "D. Pears\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2186, Accumulated: 0.2186, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0838, Accumulated: 0.3025, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0565, Accumulated: 0.3590, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0466, Accumulated: 0.4056, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0391, Accumulated: 0.4447, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0415, Accumulated: 0.4862, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0515, Accumulated: 0.5378, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1073, Accumulated: 0.6450, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1360, Accumulated: 0.7810, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1000, Accumulated: 0.8810, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0685, Accumulated: 0.9495, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0309, Accumulated: 0.9804, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0093, Accumulated: 0.9898, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0076, Accumulated: 0.0076, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0103, Accumulated: 0.0180, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0169, Accumulated: 0.0349, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.1201, Accumulated: 0.1550, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0075, Accumulated: 0.1625, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0314, Accumulated: 0.1939, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0081, Accumulated: 0.2021, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0987, Accumulated: 0.3007, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0912, Accumulated: 0.3920, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.6045, Accumulated: 0.9964, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: There are many kinds of food in the world. Scientists learn a lot about them. They say that there are some kinds of food people must eat every day. For example, people must eat some green and yellow vegetables. We shouldn't eat too much meat. People also need to eat some fruits, bread and rice. Of course our bodies need some water and milk.\n",
      "Scientists say people in different countries and different places eat different kinds of food. They cook food in different ways. Different people eat at different times. In one place, people eat once or twice a day. But in another place, people eat three or four times. The scientists say when to eat and how many times to eat are not important. What we eat is the most important thing.\n",
      "Nowadays, the world faces two problems. People in some places, for example, in Africa, are not full. Many people are eating junk food. It's bad for people's health. So it's our duty to make everyone full and make everyone healthy.\n",
      ",.\n",
      "\n",
      "Question: _   know about food most according to the passage.\n",
      "A. Farmers\n",
      "B. Cooks\n",
      "C. Scientists\n",
      "D. Customers\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1987, Accumulated: 0.1987, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0786, Accumulated: 0.2774, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0587, Accumulated: 0.3361, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0399, Accumulated: 0.3759, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0348, Accumulated: 0.4108, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0381, Accumulated: 0.4489, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0471, Accumulated: 0.4960, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1036, Accumulated: 0.5996, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1406, Accumulated: 0.7402, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1189, Accumulated: 0.8591, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0813, Accumulated: 0.9404, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0361, Accumulated: 0.9765, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0114, Accumulated: 0.9879, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0077, Accumulated: 0.0077, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0239, Accumulated: 0.0316, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0223, Accumulated: 0.0540, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0162, Accumulated: 0.0702, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0141, Accumulated: 0.0843, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0080, Accumulated: 0.0923, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0149, Accumulated: 0.1072, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0566, Accumulated: 0.1638, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0316, Accumulated: 0.1953, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7724, Accumulated: 0.9678, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0316, Accumulated: 0.9994, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Hi, dear boys and girls! Do you know how to be a healthy kid? Here are some rules you should follow.\n",
      "First, eat different foods, especially fruit and vegetables. You may have a favourite food, but you'd better eat something different, if you eat different foods, you will probably get more nutrients  your body needs.\n",
      "Second, drink water and milk as often as possible. When you're really thirsty, cold water is the No. 1 choice. Milk is a great drink that can give you more calcium your body needs to grow strong bones.\n",
      "Third, listen to your body. How do you feel when you are full? When you are eating, notice how your body feels and when your stomach feels comfortably full. Eating too much will not make you feel comfortable and make you fat.\n",
      "Fourth, limit  screen times. Screen time is the time you watch TV, DVDs and videos, or using computers. It is good to take more exercise, such as basketball, bike riding and swimming. You can't watch TV for more than two hours a day.\n",
      "Fifth, be active. One thing you'd like to do as a kid is to find out which activity you like best. Find ways to be active every day.\n",
      "Follow these rules and you can be a healthy kid.\n",
      ", , .\n",
      "\n",
      "Question: Which is the best title of the passage?\n",
      "A. How to be active\n",
      "B. How to make yourself important\n",
      "C. How to make your parents healthy\n",
      "D. How to be a healthy kid\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.1989, Accumulated: 0.1989, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0882, Accumulated: 0.2870, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0535, Accumulated: 0.3405, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0468, Accumulated: 0.3873, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0383, Accumulated: 0.4256, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0500, Accumulated: 0.4755, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0585, Accumulated: 0.5340, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1060, Accumulated: 0.6400, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1314, Accumulated: 0.7714, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1005, Accumulated: 0.8719, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0647, Accumulated: 0.9366, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0336, Accumulated: 0.9703, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0134, Accumulated: 0.9836, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0101, Accumulated: 0.0101, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0124, Accumulated: 0.0225, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0079, Accumulated: 0.0304, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0539, Accumulated: 0.0844, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0223, Accumulated: 0.1067, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0100, Accumulated: 0.1167, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0336, Accumulated: 0.1503, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0093, Accumulated: 0.1595, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0241, Accumulated: 0.1836, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7945, Accumulated: 0.9781, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0211, Accumulated: 0.9992, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Train-spotting\n",
      "Many people around the world have seen Danny Boyle's movie Train spotting starring Ewan McGregor, but how many of us really know what train-spotting is all about? Now this is not considered cool in town and the word \"train-spotter\" in Britain is related to \"geek\" or \"nerd\" (someone who seems very ridiculous). But is this reputation really deserved?\n",
      "First of all, let's see what train-spotting is. It is said that there are some 100,000 train spotters in the UK. Exactly as the title suggests, they spot trains, that is, they stand in train stations, look at the number of each train that leaves and arrives and write it down. The eventual aim is to have seen every train in the country.\n",
      "Being crazy about railways and trains is not modern and it dates back to 1804. As the number of trains grew and they got faster and faster, so did the interest in them grow? Is this any stranger than people who love cars?\n",
      "So, what do you need to be a train-spotter? Well, all you really need is a pen or pencil and a notebook to write down the train numbers. Other equipment  includes hot tea in a thermos, a camera and some sandwiches for those long afternoons spent on train platforms when you don't want to risk the delights of railway station food.\n",
      "It's interesting to note that despite the \"bad name\" of train-spotting, there have been famous railway lovers in history, such as Alfred Hitchcock, who filmed them regularly, especially The 39 Steps. There is evidence, too, that being a train-spotter is not necessarily a strange phenomenon in Britain.\n",
      "One glance at the US train stations should be enough to convince you that train-spotters there are alive and well. In America, they try to call rail lovers \"train-fans\" and talk of \"train-fanning\". Don't let this fool you--these people are train spotters and there are a lot of them. Each month, two million pages are visited on the website TrainWeb.org.\n",
      "340words\n",
      "\n",
      "Question: The writer writes the passage to_.\n",
      "A. introduce some famous train-spotters\n",
      "B. encourage readers to do more train-spotting\n",
      "C. try to present a true picture of train-spotting\n",
      "D. describe the necessary equipment in train-spotting\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1617, Accumulated: 0.1617, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0829, Accumulated: 0.2447, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0513, Accumulated: 0.2960, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0316, Accumulated: 0.3276, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0336, Accumulated: 0.3612, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0360, Accumulated: 0.3972, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0464, Accumulated: 0.4437, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1016, Accumulated: 0.5453, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1510, Accumulated: 0.6962, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1227, Accumulated: 0.8190, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0898, Accumulated: 0.9087, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0545, Accumulated: 0.9632, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0186, Accumulated: 0.9818, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0178, Accumulated: 0.0178, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0338, Accumulated: 0.0516, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0163, Accumulated: 0.0680, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0108, Accumulated: 0.0787, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0860, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0142, Accumulated: 0.1002, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0070, Accumulated: 0.1072, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0305, Accumulated: 0.1377, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0811, Accumulated: 0.2188, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7725, Accumulated: 0.9912, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Lin Tao and Chen Hai are good friends. They are in the same class. They are in the same team. Lin Tao sits behind Chen Hai. Now it is four o'clock. School is over. They often go to play games after school. They can't look after their things very well. So their mothers don't give them watches. They don't have watches. They don't know the time. But they can ask a man under the big tree. His watch is very nice. They can also see the clock on the wall of the classroom. Now it's about five in the afternoon. It's time to go home. They must put on their clothes and go home.\n",
      "\n",
      "Question: Where do Lin Tao and Chen Hai sit in the classroom?\n",
      "A. They sit in the same row  .\n",
      "B. Chen Hai sits behind Lin Tao.\n",
      "C. They sit in the same class.\n",
      "D. Lin Tao sits behind Chen Hai.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.2117, Accumulated: 0.2117, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0810, Accumulated: 0.2926, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0574, Accumulated: 0.3500, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0398, Accumulated: 0.3898, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.4213, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0384, Accumulated: 0.4598, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0553, Accumulated: 0.5150, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0953, Accumulated: 0.6104, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1134, Accumulated: 0.7237, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1017, Accumulated: 0.8255, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0842, Accumulated: 0.9097, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0452, Accumulated: 0.9548, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0175, Accumulated: 0.9723, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0056, Accumulated: 0.0056, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0115, Accumulated: 0.0171, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0084, Accumulated: 0.0255, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0185, Accumulated: 0.0440, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0277, Accumulated: 0.0717, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0151, Accumulated: 0.0868, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0134, Accumulated: 0.1002, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0427, Accumulated: 0.1429, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0885, Accumulated: 0.2313, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7623, Accumulated: 0.9936, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Here are some ideas for learning English well.\n",
      "You are like a new baby.\n",
      "Babies learn their language slowly, First they learn to listen .Then they learn to talk .Finally , they can read and talk.\n",
      "Listen to English every day\n",
      "Listen to English radio , watch English TV, go to see English movies or use online lessons.\n",
      "Practise the conversations\n",
      "Make up conversations and practise the conversations .You'd better use beginner textbooks.\n",
      "Reading English stories\n",
      "Start with children's storybooks .Try to read stories for ESL readers , Read ads and so on ,Try English Club.com for young learners.\n",
      "Write down new words\n",
      "Start a new word notebook.Write words in _ (A...B...C)Make some sentences.Try to use an English-English dictionary.\n",
      "Keep an English diary\n",
      "Start with one sentence.Like how do you feel? What did you do today?Write another sentence tomorrow.\n",
      "\n",
      "Question: The writer gave us   _  ideas for learning English faster.\n",
      "A. four\n",
      "B. five\n",
      "C. six\n",
      "D. seven\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "Extracted prediction: C, Extracted target: C\n",
      "Layer 4/16: Halt prob: 0.1941, Accumulated: 0.1941, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0832, Accumulated: 0.2773, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0505, Accumulated: 0.3278, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0398, Accumulated: 0.3676, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0309, Accumulated: 0.3986, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0371, Accumulated: 0.4356, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0413, Accumulated: 0.4770, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0867, Accumulated: 0.5637, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1191, Accumulated: 0.6828, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1118, Accumulated: 0.7945, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0896, Accumulated: 0.8842, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0640, Accumulated: 0.9482, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0228, Accumulated: 0.9710, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0074, Accumulated: 0.0074, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0077, Accumulated: 0.0150, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0142, Accumulated: 0.0292, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0627, Accumulated: 0.0920, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0082, Accumulated: 0.1002, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0234, Accumulated: 0.1236, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0101, Accumulated: 0.1337, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0110, Accumulated: 0.1447, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0215, Accumulated: 0.1662, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7870, Accumulated: 0.9532, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0465, Accumulated: 0.9997, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Hi,I am Jennifer.I am 13 years old.I am from Africa.My father is a teacher and my mother works in a hospital.Now they are working in Beijing.They both like their work and work very hard.My father's favorite animal is pandas.but I like dolphins best.\n",
      "I am studying at a middle school.And I like music and drawing best.I want to be a designer .I like to design my room.I like the color pink,so there are a lot of pink things in my room.\n",
      "I have three friends in my room.They are Mike.Dora and Peter.They are my toys.I love them.Every night,they sleep on my bed with me.\n",
      "\n",
      "Question: Which of the following is wrong?\n",
      "A. Jennifer's parents are from Beijing.\n",
      "B. Jennifer likes dolphins best.\n",
      "C. Jennifer wants to be a designer.\n",
      "D. Jennifer has three toy friends.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: A\n",
      "Layer 4/16: Halt prob: 0.2157, Accumulated: 0.2157, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0954, Accumulated: 0.3111, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0553, Accumulated: 0.3664, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0404, Accumulated: 0.4069, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0321, Accumulated: 0.4390, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0376, Accumulated: 0.4765, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0504, Accumulated: 0.5269, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1089, Accumulated: 0.6358, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1203, Accumulated: 0.7561, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0986, Accumulated: 0.8546, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0660, Accumulated: 0.9206, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0402, Accumulated: 0.9609, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0174, Accumulated: 0.9782, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0149, Accumulated: 0.0149, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0305, Accumulated: 0.0454, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0186, Accumulated: 0.0640, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0286, Accumulated: 0.0926, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0193, Accumulated: 0.1119, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0083, Accumulated: 0.1202, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0216, Accumulated: 0.1418, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0363, Accumulated: 0.1781, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0315, Accumulated: 0.2096, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7325, Accumulated: 0.9421, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0529, Accumulated: 0.9950, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Robots are supposed to run on batteries, right? Well not all of them.\n",
      "Scientists in England have built a kind of small robots that get their energy from dead flies, bad apples, or sugar.\n",
      "One robot, called Slugbot, was even designed to hunt  garden slugs for dinner!\n",
      "What's up with all that food?\n",
      "Well, scientists at the Bristol Robotics Laboratory want to invent robots that can operate for a long time in dark, dirty, or dangerous places.\n",
      "Many of those spots, like the seafloor or Antarctica, don't have electrical sockets .\n",
      "So inventor Chris Melhuish came up with a better idea: Build robots that get their energy just like animals do by hunting and eating food from their environment.\n",
      "One robot, called Ecobot II, could run for 12 days on a diet of eight flies! Of course, it'd still get a lot more power from one AA battery, though.\n",
      "Melhuish says his team is now working on a new and improved robot, called Ecobot III, which will have a better digestion system.\n",
      "It seems that after an eight fly dinner, Ecobot II couldn't deal with the leftover  \"waste\".\n",
      "Maybe restrooms in the future will have signs for boys, girls, and robots.\n",
      "\n",
      "Question: What does the passage mainly tell us?\n",
      "A. Robots are hard things to invent.\n",
      "B. Scientists are working to improve robots.\n",
      "C. Robots in the future need to eat food like human.\n",
      "D. Scientists at the Bristol Robotics Laboratory are good at robots.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.1925, Accumulated: 0.1925, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0803, Accumulated: 0.2728, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0498, Accumulated: 0.3227, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0338, Accumulated: 0.3565, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0279, Accumulated: 0.3844, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0370, Accumulated: 0.4215, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0522, Accumulated: 0.4736, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1273, Accumulated: 0.6010, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1497, Accumulated: 0.7507, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1153, Accumulated: 0.8660, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0775, Accumulated: 0.9435, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0346, Accumulated: 0.9782, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0099, Accumulated: 0.9880, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0163, Accumulated: 0.0163, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0547, Accumulated: 0.0711, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0206, Accumulated: 0.0916, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0171, Accumulated: 0.1087, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0147, Accumulated: 0.1234, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0120, Accumulated: 0.1354, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0200, Accumulated: 0.1555, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0994, Accumulated: 0.2549, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0224, Accumulated: 0.2772, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7143, Accumulated: 0.9915, Threshold: 0.9900\n",
      "Early exit at layer 13/16\n",
      "[Prompt]:\n",
      "Article: Most people follow others blindly mainly under the effect of peer  pressure. Some people also feel it safe to follow a large number of people. In some _ cases it might be right to follow the crowd  , but in most cases this can be one big mistake. Ninety-five percent of people never succeed because they are following the wrong group. Actually there are reasons why we shouldn't follow the crowd blindly.  According to a study, people tend to follow the crowd when they aren't sure about the direction they should take. This means a large number of people could be following others without understanding what's right and what's wrong! This attracts more people to follow them and the result is that most people move in a certain direction even if it isn't right.\n",
      "A man who wants to be successful always hopes for others' guidance and he usually follows the same path of most people, but the question this man never asks himself is: are all of those people successful? Of course not! If you want to follow a crowd, then follow a successful one. However, in real life you'll only find one successful person among hundreds of people, and that's why following the crowd makes no sense at all.\n",
      "Most people act without thinking wisely. If you always follow others because\n",
      "they're greater than you in number, then sooner or later you'll discover that you're\n",
      "making decisions you might regret later.\n",
      "However, should we never follow the crowd?No. I'm not trying to say you should never follow the crowd, but instead I'm just asking you to think wisely before you take a decision. If you find others are right, there is no problem in following them, but if you have doubts about the direction they're moving in, don't follow them blindly.\n",
      "\n",
      "Question: What is the passage mainly about?\n",
      "A. Ways of finding successful people to follow.\n",
      "B. Advantages of making a right direction.\n",
      "C. Examples of not following others blindly.\n",
      "D. Reasons of not following others balindly.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "Extracted prediction: D, Extracted target: D\n",
      "Layer 4/16: Halt prob: 0.2107, Accumulated: 0.2107, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0905, Accumulated: 0.3012, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0522, Accumulated: 0.3534, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0402, Accumulated: 0.3935, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0392, Accumulated: 0.4327, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0423, Accumulated: 0.4750, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0523, Accumulated: 0.5273, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0849, Accumulated: 0.6123, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1138, Accumulated: 0.7260, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.0943, Accumulated: 0.8204, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0774, Accumulated: 0.8978, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0516, Accumulated: 0.9493, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0191, Accumulated: 0.9685, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0141, Accumulated: 0.0141, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0098, Accumulated: 0.0239, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0160, Accumulated: 0.0399, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0649, Accumulated: 0.1047, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0068, Accumulated: 0.1116, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0053, Accumulated: 0.1169, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0041, Accumulated: 0.1210, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0078, Accumulated: 0.1288, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0238, Accumulated: 0.1526, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.7576, Accumulated: 0.9102, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0883, Accumulated: 0.9985, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: If an American is satisfied with you,he will put his thumb and forefinger into a circle.That means OK.But in Brazil,the very sign is considered to be rude.In Poland,a guest usually presents flowers to his hostess.The number must be an odd one.Besides,the hostess isn't expected to remove the cover of the bunch of flowers.And usually,the red rose is a sign of love.\n",
      "Usually we nod to express our agreement and shake our heads to show disagreement.To our surprise these body movements mean the opposite in Bulgaria.\n",
      "The differences in customs and cultures in the world are really noticeable.We should learn more about them to avoid embarrassment .Then,would you please remember:When in Rome,do as the Romans do.\n",
      "\n",
      "Question: In Bulgaria,if a man nods, it means that he  _   with you.\n",
      "A. will have a talk\n",
      "B. disagrees\n",
      "C. will shake hands\n",
      "D. agrees\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "Extracted prediction: B, Extracted target: B\n",
      "Layer 4/16: Halt prob: 0.2043, Accumulated: 0.2043, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0901, Accumulated: 0.2945, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0461, Accumulated: 0.3406, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.0362, Accumulated: 0.3768, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0336, Accumulated: 0.4104, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0421, Accumulated: 0.4525, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0563, Accumulated: 0.5088, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.1051, Accumulated: 0.6139, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.1350, Accumulated: 0.7489, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.1045, Accumulated: 0.8534, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0689, Accumulated: 0.9224, Threshold: 0.9900\n",
      "Layer 15/16: Halt prob: 0.0399, Accumulated: 0.9622, Threshold: 0.9900\n",
      "Layer 16/16: Halt prob: 0.0171, Accumulated: 0.9793, Threshold: 0.9900\n",
      "Layer 4/16: Halt prob: 0.0069, Accumulated: 0.0069, Threshold: 0.9900\n",
      "Layer 5/16: Halt prob: 0.0111, Accumulated: 0.0180, Threshold: 0.9900\n",
      "Layer 6/16: Halt prob: 0.0190, Accumulated: 0.0370, Threshold: 0.9900\n",
      "Layer 7/16: Halt prob: 0.4408, Accumulated: 0.4778, Threshold: 0.9900\n",
      "Layer 8/16: Halt prob: 0.0071, Accumulated: 0.4850, Threshold: 0.9900\n",
      "Layer 9/16: Halt prob: 0.0221, Accumulated: 0.5071, Threshold: 0.9900\n",
      "Layer 10/16: Halt prob: 0.0131, Accumulated: 0.5202, Threshold: 0.9900\n",
      "Layer 11/16: Halt prob: 0.0054, Accumulated: 0.5255, Threshold: 0.9900\n",
      "Layer 12/16: Halt prob: 0.0089, Accumulated: 0.5344, Threshold: 0.9900\n",
      "Layer 13/16: Halt prob: 0.4465, Accumulated: 0.9809, Threshold: 0.9900\n",
      "Layer 14/16: Halt prob: 0.0189, Accumulated: 0.9998, Threshold: 0.9900\n",
      "Early exit at layer 14/16\n",
      "[Prompt]:\n",
      "Article: Kinsale may be one of the smallest towns in Southern Ireland, and it's also one of the most famous towns. It is well known for its wonderful fish restaurants. Some of the best known chiefs in the world have practiced in the restaurants there. The town itself is very beautiful in Southern Ireland by the sea. Here it is cooler in summer than other island towns. A big building overlooks the town and it is one of the most beautiful in the whole country. To the north of the town there is a high mountain standing in the country. The town is very beautiful, with its many craft shops and narrow cobbled streets. Most travelers visit Kinsale for its fish restaurants, which are family owned. This means that the service is better than that in other restaurants. People are more welcoming there than those anywhere else. The food may be expensive but you'll have one of the most pleasant evenings in your life there. So go ahead and visit Kinsale.\n",
      "\n",
      "Question: Why is the weather of Kinsale nice? Because   _   .\n",
      "A. it's cool\n",
      "B. it's near the sea\n",
      "C. it's beautiful\n",
      "D. it has a big building\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "Extracted prediction: A, Extracted target: A\n",
      "{'predicted_text': {'exact_match': 0.4699999988079071, 'accuracy': 0.47}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.20488766193389893}, 'time_per_token': {'mean': 0.20488766193389893}, 'tokens_per_second': {'mean': 5.11854236125946}}\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_h \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_h \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy self_speculative \\\n",
    "       --exit_layer 8 \\\n",
    "       --num_speculations 6 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_h \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy layerdrop \\\n",
    "       --dropout_rate 0.2 \\\n",
    "       --layerdrop_seed 42 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset race_h \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy depth_adaptive_sequence \\\n",
    "       --halting_threshold 0.99 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset gsm8k \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --exit_layer 8 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for math reasoning: gsm8k\n",
      "Updated generation config: max_steps=512, temperature=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 774, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 746, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 347, in benchmark\n",
      "    evaluation_data_points = get_data(\n",
      "                             ^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 547, in get_data\n",
      "    evaluation_data_points = prepare_gsm8k_format(n_shot=n_shot, seed=seed, template=template)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 373, in prepare_gsm8k_format\n",
      "    test_dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 2132, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1853, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1717, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1643, in dataset_module_factory\n",
      "    raise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\n",
      "datasets.exceptions.DatasetNotFoundError: Dataset 'gsm8k' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for math reasoning: gsm8k\n",
      "Updated generation config: max_steps=512, temperature=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 774, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 746, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 347, in benchmark\n",
      "    evaluation_data_points = get_data(\n",
      "                             ^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 547, in get_data\n",
      "    evaluation_data_points = prepare_gsm8k_format(n_shot=n_shot, seed=seed, template=template)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 373, in prepare_gsm8k_format\n",
      "    test_dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 2132, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1853, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1717, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1643, in dataset_module_factory\n",
      "    raise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\n",
      "datasets.exceptions.DatasetNotFoundError: Dataset 'gsm8k' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for math reasoning: gsm8k\n",
      "Updated generation config: max_steps=512, temperature=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 774, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 746, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 347, in benchmark\n",
      "    evaluation_data_points = get_data(\n",
      "                             ^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 547, in get_data\n",
      "    evaluation_data_points = prepare_gsm8k_format(n_shot=n_shot, seed=seed, template=template)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 373, in prepare_gsm8k_format\n",
      "    test_dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 2132, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1853, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1717, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1643, in dataset_module_factory\n",
      "    raise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\n",
      "datasets.exceptions.DatasetNotFoundError: Dataset 'gsm8k' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for math reasoning: gsm8k\n",
      "Updated generation config: max_steps=512, temperature=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 774, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 746, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 347, in benchmark\n",
      "    evaluation_data_points = get_data(\n",
      "                             ^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 547, in get_data\n",
      "    evaluation_data_points = prepare_gsm8k_format(n_shot=n_shot, seed=seed, template=template)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 373, in prepare_gsm8k_format\n",
      "    test_dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 2132, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1853, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1717, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1643, in dataset_module_factory\n",
      "    raise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\n",
      "datasets.exceptions.DatasetNotFoundError: Dataset 'gsm8k' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset gsm8k \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset gsm8k \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy self_speculative \\\n",
    "       --exit_layer 8 \\\n",
    "       --num_speculations 6 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset gsm8k \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy layerdrop \\\n",
    "       --dropout_rate 0.2 \\\n",
    "       --layerdrop_seed 42 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset gsm8k \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy depth_adaptive_sequence \\\n",
    "       --halting_threshold 0.99 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset math \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --exit_layer 8 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for math reasoning: math\n",
      "Updated generation config: max_steps=512, temperature=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 774, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 746, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 347, in benchmark\n",
      "    evaluation_data_points = get_data(\n",
      "                             ^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 549, in get_data\n",
      "    evaluation_data_points = prepare_math_format(data_path=data_path, n_shot=n_shot, seed=seed, template=template)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 449, in prepare_math_format\n",
      "    math_dataset = load_dataset(\"HuggingFaceH4/math\", split=\"test\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 2132, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1853, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1717, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1643, in dataset_module_factory\n",
      "    raise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\n",
      "datasets.exceptions.DatasetNotFoundError: Dataset 'HuggingFaceH4/math' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for math reasoning: math\n",
      "Updated generation config: max_steps=512, temperature=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 774, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 746, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 347, in benchmark\n",
      "    evaluation_data_points = get_data(\n",
      "                             ^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 549, in get_data\n",
      "    evaluation_data_points = prepare_math_format(data_path=data_path, n_shot=n_shot, seed=seed, template=template)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 449, in prepare_math_format\n",
      "    math_dataset = load_dataset(\"HuggingFaceH4/math\", split=\"test\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 2132, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1853, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1717, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1643, in dataset_module_factory\n",
      "    raise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\n",
      "datasets.exceptions.DatasetNotFoundError: Dataset 'HuggingFaceH4/math' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for math reasoning: math\n",
      "Updated generation config: max_steps=512, temperature=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 774, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 746, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 347, in benchmark\n",
      "    evaluation_data_points = get_data(\n",
      "                             ^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 549, in get_data\n",
      "    evaluation_data_points = prepare_math_format(data_path=data_path, n_shot=n_shot, seed=seed, template=template)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 449, in prepare_math_format\n",
      "    math_dataset = load_dataset(\"HuggingFaceH4/math\", split=\"test\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 2132, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1853, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1717, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1643, in dataset_module_factory\n",
      "    raise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\n",
      "datasets.exceptions.DatasetNotFoundError: Dataset 'HuggingFaceH4/math' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for math reasoning: math"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 774, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 746, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 347, in benchmark\n",
      "    evaluation_data_points = get_data(\n",
      "                             ^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 549, in get_data\n",
      "    evaluation_data_points = prepare_math_format(data_path=data_path, n_shot=n_shot, seed=seed, template=template)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\data.py\", line 449, in prepare_math_format\n",
      "    math_dataset = load_dataset(\"HuggingFaceH4/math\", split=\"test\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 2132, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1853, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1717, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\datasets\\load.py\", line 1643, in dataset_module_factory\n",
      "    raise DatasetNotFoundError(f\"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.\") from e\n",
      "datasets.exceptions.DatasetNotFoundError: Dataset 'HuggingFaceH4/math' doesn't exist on the Hub or cannot be accessed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated generation config: max_steps=512, temperature=0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset math \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset math \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy self_speculative \\\n",
    "       --exit_layer 8 \\\n",
    "       --num_speculations 6 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset math \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy layerdrop \\\n",
    "       --dropout_rate 0.2 \\\n",
    "       --layerdrop_seed 42 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset math \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy depth_adaptive_sequence \\\n",
    "       --halting_threshold 0.99 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mbpp \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --exit_layer 8 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mbpp \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mbpp \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy self_speculative \\\n",
    "       --exit_layer 8 \\\n",
    "       --num_speculations 6 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mbpp \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy layerdrop \\\n",
    "       --dropout_rate 0.2 \\\n",
    "       --layerdrop_seed 42 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset mbpp \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy depth_adaptive_sequence \\\n",
    "       --halting_threshold 0.99 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset human_eval \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --exit_layer 8 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset human_eval \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy autoregressive \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset human_eval \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy self_speculative \\\n",
    "       --exit_layer 8 \\\n",
    "       --num_speculations 6 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset human_eval \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy layerdrop \\\n",
    "       --dropout_rate 0.2 \\\n",
    "       --layerdrop_seed 42 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n",
    "\n",
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "       --dataset human_eval \\\n",
    "       --num_samples 100 \\\n",
    "       --generation_strategy depth_adaptive_sequence \\\n",
    "       --halting_threshold 0.99 \\\n",
    "       --output_dir ./logs \\\n",
    "       --distributed False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
