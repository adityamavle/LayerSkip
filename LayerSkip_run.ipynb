{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm8DCzRwONWd",
        "outputId": "97f0232e-b64b-4886-bc1a-acfb59de727c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.1\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVabrVPbOWye",
        "outputId": "4be3842a-a109-4b3f-84a0-56405cb270b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'LayerSkip'...\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/LayerSkip.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kzKkViBRP6bx",
        "outputId": "59d455b3-eb01-4eff-ce29-4a8b3ce03236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\adity\\\\LayerSkip_Plus_Experiments\\\\LayerSkip\\\\LayerSkip'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czYG9g2cO8lT",
        "outputId": "e7b6ba2a-0614-4b6b-fc99-211d80b86d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/LayerSkip\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/LayerSkip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiauJzhfPCRU",
        "outputId": "dffe0391-8be4-4c48-82d8-83c529bf9920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting accelerate==1.0.1 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting torch==2.2.1 (from -r requirements.txt (line 2))\n",
            "  Downloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: transformers==4.48.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.48.3)\n",
            "Collecting torchmetrics==1.3.2 (from -r requirements.txt (line 5))\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting torcheval==0.0.7 (from -r requirements.txt (line 6))\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
            "Collecting datasets==3.0.1 (from -r requirements.txt (line 8))\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.9.0)\n",
            "Collecting colorama==0.4.6 (from -r requirements.txt (line 11))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting protobuf==5.28.2 (from -r requirements.txt (line 12))\n",
            "  Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting lm_eval==0.4.5 (from -r requirements.txt (line 13))\n",
            "  Downloading lm_eval-0.4.5-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==8.3.3 (from -r requirements.txt (line 14))\n",
            "  Downloading pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pytest-mock==3.14.0 (from -r requirements.txt (line 15))\n",
            "  Downloading pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: matplotlib==3.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.0.1->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.0.1->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.0.1->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.0.1->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.0.1->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->-r requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3->-r requirements.txt (line 4)) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3->-r requirements.txt (line 4)) (4.67.1)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.3.2->-r requirements.txt (line 5))\n",
            "  Downloading lightning_utilities-0.14.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.1->-r requirements.txt (line 8)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.0.1->-r requirements.txt (line 8))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets==3.0.1->-r requirements.txt (line 8))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==3.0.1->-r requirements.txt (line 8))\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch==2.2.1->-r requirements.txt (line 2))\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.1->-r requirements.txt (line 8)) (3.11.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 9)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 9)) (2025.1)\n",
            "Collecting evaluate (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting jsonlines (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.5->-r requirements.txt (line 13)) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.5->-r requirements.txt (line 13)) (0.14.0)\n",
            "Collecting pybind11>=2.6.2 (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.5->-r requirements.txt (line 13)) (1.6.1)\n",
            "Collecting sqlitedict (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.5->-r requirements.txt (line 13)) (0.23.0)\n",
            "Collecting word2number (from lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.5->-r requirements.txt (line 13)) (10.6.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==8.3.3->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest==8.3.3->-r requirements.txt (line 14)) (1.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (3.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->-r requirements.txt (line 2)) (12.5.82)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1->-r requirements.txt (line 8)) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1->-r requirements.txt (line 8)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1->-r requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1->-r requirements.txt (line 8)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1->-r requirements.txt (line 8)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.1->-r requirements.txt (line 8)) (1.18.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.3.2->-r requirements.txt (line 5)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3->-r requirements.txt (line 4)) (2025.1.31)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.5->-r requirements.txt (line 13)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.5->-r requirements.txt (line 13)) (3.9.1)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.5->-r requirements.txt (line 13)) (5.3.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.5->-r requirements.txt (line 13)) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.5->-r requirements.txt (line 13)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.5->-r requirements.txt (line 13)) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.1->-r requirements.txt (line 2)) (3.0.2)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==3.0.1->-r requirements.txt (line 8))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.5->-r requirements.txt (line 13))\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.1->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.5->-r requirements.txt (line 13)) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.5->-r requirements.txt (line 13)) (8.1.8)\n",
            "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.5-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.3.3-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.3/342.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/731.7 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvEFNbxVSwAY"
      },
      "outputs": [],
      "source": [
        "!pip install torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0GmgJKLaAQs"
      },
      "outputs": [],
      "source": [
        "!pip uninstall transformers\n",
        "!pip install transformers==4.45.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JeXCkuxhV0FG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L0kI3FRTSfx_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch Version: 2.4.1+cu124\n",
            "Torchaudio Version: 2.4.1+cu124\n",
            "Torchvision Version: 0.19.1+cu124\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torchvision\n",
        "\n",
        "print(f\"Torch Version: {torch.__version__}\")\n",
        "print(f\"Torchaudio Version: {torchaudio.__version__}\")\n",
        "print(f\"Torchvision Version: {torchvision.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: mmlu"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   1%|          | 1/100 [00:01<02:34,  1.56s/it]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   2%|▏         | 2/100 [00:01<01:18,  1.25it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   3%|▎         | 3/100 [00:02<00:50,  1.92it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   4%|▍         | 4/100 [00:02<00:34,  2.75it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   5%|▌         | 5/100 [00:02<00:26,  3.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   6%|▌         | 6/100 [00:02<00:21,  4.36it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   7%|▋         | 7/100 [00:02<00:18,  5.12it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   8%|▊         | 8/100 [00:02<00:16,  5.46it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   9%|▉         | 9/100 [00:02<00:15,  6.07it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  10%|█         | 10/100 [00:02<00:14,  6.43it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  11%|█         | 11/100 [00:03<00:13,  6.70it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  12%|█▏        | 12/100 [00:03<00:12,  7.15it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  13%|█▎        | 13/100 [00:03<00:14,  5.96it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  14%|█▍        | 14/100 [00:03<00:13,  6.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  15%|█▌        | 15/100 [00:03<00:12,  6.81it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  16%|█▌        | 16/100 [00:03<00:11,  7.24it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  17%|█▋        | 17/100 [00:03<00:11,  7.41it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  18%|█▊        | 18/100 [00:04<00:11,  7.42it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  19%|█▉        | 19/100 [00:04<00:10,  7.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  20%|██        | 20/100 [00:04<00:10,  7.67it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  21%|██        | 21/100 [00:04<00:10,  7.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  22%|██▏       | 22/100 [00:04<00:10,  7.70it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  23%|██▎       | 23/100 [00:04<00:09,  7.89it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  24%|██▍       | 24/100 [00:04<00:09,  7.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  25%|██▌       | 25/100 [00:05<00:11,  6.47it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  26%|██▌       | 26/100 [00:05<00:10,  6.94it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  27%|██▋       | 27/100 [00:05<00:10,  7.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  28%|██▊       | 28/100 [00:05<00:10,  7.19it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  29%|██▉       | 29/100 [00:05<00:09,  7.29it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  30%|███       | 30/100 [00:05<00:09,  7.31it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  31%|███       | 31/100 [00:05<00:08,  7.76it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  32%|███▏      | 32/100 [00:05<00:08,  7.78it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  33%|███▎      | 33/100 [00:06<00:08,  7.98it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  34%|███▍      | 34/100 [00:06<00:08,  8.00it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  35%|███▌      | 35/100 [00:06<00:08,  7.99it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  36%|███▌      | 36/100 [00:06<00:07,  8.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  37%|███▋      | 37/100 [00:06<00:07,  7.88it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  38%|███▊      | 38/100 [00:06<00:07,  7.97it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  39%|███▉      | 39/100 [00:06<00:07,  7.94it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  40%|████      | 40/100 [00:06<00:07,  7.98it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  41%|████      | 41/100 [00:07<00:07,  7.88it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  42%|████▏     | 42/100 [00:07<00:07,  7.80it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  43%|████▎     | 43/100 [00:07<00:07,  7.74it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  44%|████▍     | 44/100 [00:07<00:07,  7.34it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  45%|████▌     | 45/100 [00:07<00:07,  7.32it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  46%|████▌     | 46/100 [00:07<00:07,  7.24it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  47%|████▋     | 47/100 [00:07<00:07,  7.29it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  48%|████▊     | 48/100 [00:08<00:07,  7.40it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  49%|████▉     | 49/100 [00:08<00:06,  7.54it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  50%|█████     | 50/100 [00:08<00:06,  7.57it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  51%|█████     | 51/100 [00:08<00:06,  7.79it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:08<00:06,  7.88it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:08<00:05,  7.89it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:08<00:05,  7.79it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:08<00:05,  8.07it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:09<00:05,  7.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:09<00:05,  7.64it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:09<00:05,  7.39it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:09<00:05,  7.43it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  60%|██████    | 60/100 [00:09<00:05,  7.63it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  61%|██████    | 61/100 [00:09<00:05,  7.64it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:09<00:05,  7.52it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:09<00:04,  7.66it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:10<00:04,  7.68it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:10<00:04,  7.64it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:10<00:04,  8.02it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:10<00:04,  8.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:10<00:03,  8.02it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:10<00:03,  8.15it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  70%|███████   | 70/100 [00:10<00:03,  7.74it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  71%|███████   | 71/100 [00:10<00:03,  7.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:11<00:03,  7.56it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:11<00:04,  5.54it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:11<00:04,  6.12it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:11<00:03,  6.53it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:11<00:03,  6.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:11<00:03,  6.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:12<00:03,  7.01it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:12<00:02,  7.22it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  80%|████████  | 80/100 [00:12<00:02,  7.62it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  81%|████████  | 81/100 [00:12<00:02,  7.64it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:12<00:02,  7.47it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:12<00:02,  7.52it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:12<00:01,  9.90it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:13<00:00, 13.24it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  91%|█████████ | 91/100 [00:13<00:00, 15.43it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:13<00:00, 16.00it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:13<00:00, 16.66it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:13<00:00, 17.18it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:13<00:00,  7.32it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on MMLU with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A state built a casino and issued bonds to finance its construction. On five occasions, there were episodes of violence in various casinos in the state. The state police attributed the violence to greed and fear at the casinos. To prevent such violence, the state legislature passes a statute prohibiting all gambling at privately owned casinos in the state. Is this law likely to be held constitutional if most casinos in the state were owned by those from out-of-state?\n",
            "A. Yes, because the act was expressly authorized by the state legislature.\n",
            "B. Yes, but only if the local interest in safety outweighs the burden of interstate commerce.\n",
            "C. No, because out-of-state casinos are part of interstate commerce.\n",
            "D. No, because the statute violates the due process rights of the owners of the casinos.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: what is one of the important differences between the middle and upper paleolithic?\n",
            "A. decreased use of imported raw materials and increased use of whatever was locally available\n",
            "B. smaller sites, indicating a change from large roving bands of hunters to the earliest family groups and households\n",
            "C. a profusion of stone tool traditions, indicating a change from temporal and geographic homogeneity to greater diversity and variability\n",
            "D. a gradual decline in the use of stone hand axes and tools, indicating a change to more flexible and workable materials such as wood and bone\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: What kind of animal is a peregrine?\n",
            "A. moose\n",
            "B. cat\n",
            "C. bird\n",
            "D. fish\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The cities of Varanasi (Benares) in India and Mecca in Saudi Arabia are alike because both are\n",
            "A. capitals of countries formerly colonized by the English\n",
            "B. destinations for vast numbers of pilgrims\n",
            "C. financial centers for a large fraction of the world's economy\n",
            "D. examples of modern urban planning\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.7500\n",
            "Current Mean Accuracy: 0.7500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: You seek the counsel of one of your peers who designed and implemented a communication program that resulted in the successful permitting of an automotive recycling center, despite strong opposition from community organizations. You have to design a program to win approval for a similar project proposed by your company. Your peer gives you a brief piece of advice that succinctly describes the foundation of his successful program. What is most likely your peer's advice for a successful communication program?\n",
            "A. Solve their problems\n",
            "B. Kill them with kindness\n",
            "C. Expose them to ridicule\n",
            "D. Overwhelm them with facts\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following would NOT be considered a barrier to diffusion of a cultural trait?\n",
            "A. Language\n",
            "B. Religion\n",
            "C. Oceans\n",
            "D. Tolerant complaisant citizens\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The lowest point on Earth is the bottom of the Mariana Trench at a depth of 35,840 feet below sea level. The highest point on Earth is the summit of Mt. Everest at a height of 29,028 feet above sea level. Which of the following is the best estimate of the distance between the lowest and highest points on Earth?\n",
            "A. 6,000 feet\n",
            "B. 7,000 feet\n",
            "C. 64,000 feet\n",
            "D. 65,000 feet\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4286\n",
            "Current Mean Accuracy: 0.4286\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: After a lengthy interview with a company vice president, an employee was hired by the company to work in the company's accounting department. The parties agreed that the employment would be on an at-will basis. At the end of her first week of work, the employee was given a booklet entitled \"Employment Manual,\" with instructions to read the book in its entirety by the end of the following week. That evening, the employee began reading the manual. The first few pages described the history of the company and provided a personal biography of its president. On page 20, the manual stated that the company treats its employees \"as family\" and that employees will be discharged \"only with good cause. \" The employee finished reading the manual as requested. The employee interpreted the statement on page 20 as insuring continued employment unless good cause existed for termination. Over the next two months, the employee continually complained to her supervisor that the lighting in the accounting department was insufficient. Finally the supervisor, fed up with the complaints, fired the employee. The employee then sued the company, seeking to recover on grounds of promissory estoppel. Which of the following facts, if true and provable, would be most helpful for the employee's cause of action?\n",
            "A. At the time when the company hired the employee, the company subjectively intended that the employee be given job security.\n",
            "B. The employee interpreted the clause in the manual stating that company employees would be treated \"as family\" to mean that she would have job security and could only be fired for good cause.\n",
            "C. Just prior to receiving the manual, the employee seriously considered quitting, but continued to work for the company in reliance on the provisions contained on page 20 of the manual.\n",
            "D. The employee's complaints regarding the insufficient lighting were factually true and justifIable.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: In the Internet Protocol (IP) suite of protocols, which of the following best describes the purpose of the Address Resolution Protocol?\n",
            "A. To translate Web addresses to host names\n",
            "B. To determine the IP address of a given host name\n",
            "C. To determine the hardware address of a given host name\n",
            "D. To determine the hardware address of a given IP address\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4444\n",
            "Current Mean Accuracy: 0.4444\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "But the decline of Rome was the natural and inevitable effect of immoderate greatness. Prosperity ripened the principle of decay; the causes of destruction multiplied with the extent of conquest; and, as soon as time or accident had removed the artificial supports, the stupendous fabric yielded to the pressure of its own weight. . . . The victorious legions, who, in distant wars, acquired the vices of strangers and mercenaries, first oppressed the freedom of the republic, and afterwards violated the majesty of the purple. The emperors, anxious for their personal safety and the public peace, were reduced to the base expedient of corrupting the discipline which rendered them alike formidable to their sovereign and to the enemy; the vigour of the military . . . was relaxed . . . ; and the Roman world was overwhelmed by a deluge of Barbarians.\n",
            "—Adapted from Decline and Fall of the Roman Empire, by Edward Gibbon\n",
            "The decline of the Roman Empire and that of its Chinese counterpart resulted in which of the following?\n",
            "A. A decline in the appeal of religions of salvation\n",
            "B. A shift from trade along the Silk Roads to sea routes in the Indian Ocean\n",
            "C. An increased importance of the role of the father as the head of the household\n",
            "D. A decline in the rights of women\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4000\n",
            "Current Mean Accuracy: 0.4000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A woman owned an extensive art collection that she displayed in a special room of her home. While the woman was away on a vacation, there was a burglary at her home, and her favorite painting was stolen. Although the painting was insured for $1,000,000 by an insurance company, it had a market value of over $1,500,000. When the woman returned from vacation, she met with a detective employed by the insurance company to investigate the theft. During their meeting, the woman told the detective that she would pay him an extra $50,000 if he recovered the paihting. For the next three weeks, the detective investigated the theft as part of his job responsibilities with the insurance company. Within the course of this investigation, the detective learned who was responsible for the burglary. As a consequence, the culprit was apprehended, and the painting was recovered and returned to the woman. The detective then requested the $50,000 that the woman had promised to pay him. After the woman refused to make the payment, the detective sued the woman for breach of contract. Who is most likely to prevail?\n",
            "A. The woman, because her promise was gratuitous.\n",
            "B. The woman, because the insurance company owed her a pre-existing duty to find the painting.\n",
            "C. The detective, because he did the act necessary to constitute an acceptance of the woman's offer.\n",
            "D. The detective, because the market value of the painting exceeded its insured value, so there was sufficient consideration to support the woman's promise.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3636\n",
            "Current Mean Accuracy: 0.3636\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: In the absence of a provision to the contrary in the articles of incorporation, the directors of a corporation elected for a specified term\n",
            "A. can be removed from office at a meeting of the shareholders, but only for cause and after an opportunity to be heard has been given to the directors.\n",
            "B. can be removed from office at a meeting of the shareholders, with or without cause.\n",
            "C. can be removed from office at a meeting of the shareholders, but only for cause.\n",
            "D. can be removed from office prior to the expiration of their term only by a decree of the circuit court in an action by the shareholders.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3333\n",
            "Current Mean Accuracy: 0.3333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is a strategy that the National Association of School Psychologists (NASP) recommends as a best practice for improving school safety?\n",
            "A. Expelling a student immediately after a minor disciplinary infraction\n",
            "B. Implementing a strict student code of conduct, such as a zero-tolerance policy\n",
            "C. Communicating to parents that the school environment is safe\n",
            "D. Creating a school safety and response team\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3077\n",
            "Current Mean Accuracy: 0.3077\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The reticular formation and reticular activating system are associated with all of the following functions, EXCEPT:\n",
            "A. Decussation of auditory stimuli\n",
            "B. Alertness\n",
            "C. Consciousness\n",
            "D. Pain\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2857\n",
            "Current Mean Accuracy: 0.2857\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | The uber driver wanted to pay me for being so late last night. Scenario 2 | I will not break rules to become the best at something.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2667\n",
            "Current Mean Accuracy: 0.2667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The radius of Mars is about half that of Earth; the mass of Mars is about one-tenth that of Earth. Which of the following is closest to the gravitational field at the surface of Mars?\n",
            "A. 10 N/kg\n",
            "B. 4 N/kg\n",
            "C. 2 N/kg\n",
            "D. 0.5 N/kg\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2500\n",
            "Current Mean Accuracy: 0.2500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following amino acids cannot provide a substrate for gluconeogenesis?\n",
            "\n",
            "A. Leucine\n",
            "B. Tryptophan\n",
            "C. Histidine\n",
            "D. isoleucine\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2353\n",
            "Current Mean Accuracy: 0.2353\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "\"Wherever I go—the street, the shop, the house, or the steamboat—I hear the people talk in such a way as to indicate that they are yet unable to conceive of the Negro as possessing any rights at all. Men who are honorable in their dealings with their white neighbors will cheat a Negro without feeling a single twinge of their honor. To kill a Negro they do not deem murder; to debauch a Negro woman they do not think fornication; to take the property away from a Negro they do not consider robbery. The people boast that when they get freedmen affairs in their own hands, to use their own classic expression, 'the niggers will catch hell.'\n",
            "\"The reason of all this is simple and manifest. The whites esteem the blacks their property by natural right, and however much they may admit that the individual relations of masters and slaves have been destroyed by the war and the President's emancipation proclamation, they still have an ingrained feeling that the blacks at large belong to the whites at large, and whenever opportunity serves they treat the colored people just as their profit, caprice or passion may dictate.\"\n",
            "—Congressional testimony of Col. Samuel Thomas, Assistant Commissioner, Bureau of Refugees, Freedmen and Abandoned Lands, 1865\n",
            "To address the problems identified in Federalist #15, Hamilton proposed\n",
            "A. abandoning an isolationist approach to foreign policy and adopting a more aggressive and interventionist stance.\n",
            "B. adopting a new constitution in order to create a more national government.\n",
            "C. forging alliances with American Indian nations to present a united front to European powers.\n",
            "D. increasing spending on military forces and cutting spending on social programs.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2222\n",
            "Current Mean Accuracy: 0.2222\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following promotes glucose and amino acid uptake by muscle?\n",
            "A. Adrenaline\n",
            "B. Insulin\n",
            "C. Glycogen\n",
            "D. Cortisol\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.2632\n",
            "Current Mean Accuracy: 0.2632\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: An officer stopped a car for having a burned out headlight and license plate light. When the driver could not produce a driver's license, the officer asked him if he minded if they searched the vehicle. The officer did not advise the driver that he had a right to refuse consent or that if he refused his decision would be honored, but there was nothing duplicitous or coercive in the officer's conduct. The driver smiled and said \"of course, no problem.\" The officer found stolen bank checks under the rear seat. In a later suppression motion, the driver claimed that his consent was not voluntary. What will the court most likely decide on that issue?\n",
            "A. The consent was voluntarily given and was not the result of coercion or duress.\n",
            "B. The consent was involuntary because it was the product of implied duress.\n",
            "C. The consent was involuntary because the officer did not advise the driver of his right to refuse.\n",
            "D. The consent became voluntary as a matter of law when the driver failed to produce a driver's license.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2500\n",
            "Current Mean Accuracy: 0.2500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "Although in Protestant Europe, [Peter the Great] was surrounded by evidence of the new civil and political rights of individual men embodied in constitutions, bills of rights and parliaments, he did not return to Russia determined to share power with his people. On the contrary, he returned not only determined to change his country but also convinced that if Russia was to be transformed, it was he who must provide both the direction and the motive force. He would try to lead; but where education and persuasion were not enough, he could drive—and if necessary flog—the backward nation forward.\n",
            "—Robert K. Massie, Peter the Great: His Life and World\n",
            "When Peter the Great ruled Russia, he continued the practice of which of the following?\n",
            "A. Decentralization of power\n",
            "B. Isolationism\n",
            "C. Serfdom\n",
            "D. Reform\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.2857\n",
            "Current Mean Accuracy: 0.2857\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The attitude of many ancient elites toward the consumption of resources seems to have been:\n",
            "A. “a penny saved is a penny earned.\"\n",
            "B. \"if you've got it, flaunt it.\"\n",
            "C. \"look before you leap.\"\n",
            "D. \"the last shall be first and the first shall be last.\"\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2727\n",
            "Current Mean Accuracy: 0.2727\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Rounded to the nearest 10,000, the population of Louisiana was 4,530,000 in 2010. Which number could be the actual population of Louisiana in 2010?\n",
            "A. 4,500,321\n",
            "B. 4,524,491\n",
            "C. 4,533,372\n",
            "D. 4,535,343\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3043\n",
            "Current Mean Accuracy: 0.3043\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: If the Engle-Granger test is applied to the residuals of a potentially cointegrating regression, what would be the interpretation of the null hypothesis?\n",
            "A. The variables are cointegrated\n",
            "B. The variables are not cointegrated\n",
            "C. Both variables are stationary\n",
            "D. Both variables are non-stationary\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3333\n",
            "Current Mean Accuracy: 0.3333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following groups or organizations can be identified as having the characteristics of a bureaucracy?\n",
            "A. An extended or consanguine family, including all the relatives by blood, marriage, or adoption\n",
            "B. The government of a large city\n",
            "C. A book club in which books are chosen by members who take turns alphabetically to lead discussion\n",
            "D. The volunteers who gather annually to clean the neighborhood\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3200\n",
            "Current Mean Accuracy: 0.3200\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which term describes the forces that unify and strengthen a country?\n",
            "A. Diffusion\n",
            "B. Centrifugal\n",
            "C. Centripetal\n",
            "D. Ethnocentric\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3462\n",
            "Current Mean Accuracy: 0.3462\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "That day the Reverend Xuanzang was chosen from among all the monks. He had been a monk from infancy, and ever since birth he had eaten vegetarian food and observed the prohibitions. His maternal grandfather was an imperial commander, Yin Kaishan. His father Chen Guangrui had come top in the Palace Examination and had been appointed a grand secretary in the Imperial Library. Xuanzang, however, had no interest in honour and glory, and his only joy was to cultivate Nirvana. His virtue was great; of the thousand sutras and ten thousand holy books there was not a single one that he did not know.\n",
            "…\n",
            "He looked to the West and prayed, \"I am the believer Chen Xuanzang sent on imperial orders to fetch the scriptures. If I am fated to have a disciple, may I be able to unseal the golden words and release the divine Monkey King to come with me to the Vulture Peak. If I am not fated to have a disciple, and this monkey is an evil monster who has deceived me and will do me no good, then may I be unable to remove the seal.\" When he had prayed he bowed again.\n",
            "From Wu Chengen, Journey to the West, ca. 1590s\n",
            "In which of the following ways does the excerpt above most complicate historians' understanding of the career of the Chinese monk and traveler Xuanzang?\n",
            "A. It highly fictionalizes the story of Xuanzang's accomplishments.\n",
            "B. It was written long after the time period in which Xuanzang lived.\n",
            "C. It casts doubt on the actual existence of Xuanzang.\n",
            "D. It is widely considered by scholars to be a forgery.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3333\n",
            "Current Mean Accuracy: 0.3333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is NOT a source of atmospheric carbon?\n",
            "A. Respiration\n",
            "B. Photosynthesis\n",
            "C. Bacterial decomposition\n",
            "D. Combustion of fossil fuels\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3214\n",
            "Current Mean Accuracy: 0.3214\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The FED's Board of Governors has members each serving -year terms.\n",
            "A. 14 7\n",
            "B. 7 14\n",
            "C. 8 8\n",
            "D. 50 2\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3103\n",
            "Current Mean Accuracy: 0.3103\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Epictetus claims that the desire for one’s loved ones to live forever is:\n",
            "A. a natural instinct.\n",
            "B. a sign of genuine love.\n",
            "C. blasphemous.\n",
            "D. silly.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3000\n",
            "Current Mean Accuracy: 0.3000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: What was the average life expectancy of white males born in the U.S. just before the Civil War?\n",
            "A. 40 years\n",
            "B. 50 years\n",
            "C. 60 years\n",
            "D. 70 years\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3226\n",
            "Current Mean Accuracy: 0.3226\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Anscombe claims that it is not profitable to do moral philosophy until we have an adequate philosophy of:\n",
            "A. religion.\n",
            "B. physics.\n",
            "C. psychology.\n",
            "D. art.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3438\n",
            "Current Mean Accuracy: 0.3438\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The complete resynthesis of phosphocreatine after very high intensity exercise normally takes:\n",
            "A. about 10 seconds.\n",
            "B. about 30 seconds.\n",
            "C. about 1 minute.\n",
            "D. about 4 minutes.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3333\n",
            "Current Mean Accuracy: 0.3333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following can form hydrogen bonds?\n",
            "A. CH3OCH2CH3\n",
            "B. HCN\n",
            "C. CH3OCH2Br\n",
            "D. CH3NH2\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3235\n",
            "Current Mean Accuracy: 0.3235\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I ran over the fresh grass with a lawnmower. Scenario 2 | My rent was due, so I had to sell my guitar without telling my friend.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3143\n",
            "Current Mean Accuracy: 0.3143\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?\n",
            "A. Expectation\n",
            "B. Maximization\n",
            "C. No modification necessary\n",
            "D. Both\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3056\n",
            "Current Mean Accuracy: 0.3056\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following statements does NOT characterize arms control as a strategic policy?\n",
            "A. Arms control is an example of cooperative security, designed to address the problems associated with the security dilemma.\n",
            "B. Policies of arms control and disarmament was pursued during the Cold War in an attempt to achieve security.\n",
            "C. Arms control does not challenge the central role of weaponry and military power in the international system, instead focusing on the problems produced by specific weapon systems and relationships.\n",
            "D. After its successful application during the Cold War, arms control has retained its momentum and applicability in the contemporary security environment.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2973\n",
            "Current Mean Accuracy: 0.2973\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Information about what the students in Mr. Paulson’s class and in Ms. Hugo’s class ate for lunch is listed below. In Mr. Paulson’s class, 0.5 of the students ate pizza for lunch. In Ms. Hugo’s class, 0.5 of the students ate hamburgers for lunch. What information, if any, is needed to correctly compare the 0.5 of Mr. Paulson’s class that ate pizza to the 0.5 of Ms. Hugo’s class that ate hamburgers?\n",
            "A. whether the lunches were eaten on the same day\n",
            "B. the total number of students in each teacher’s class\n",
            "C. nothing because the portions each class ate were the same\n",
            "D. the total number of pizza slices and hamburgers eaten that day\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2895\n",
            "Current Mean Accuracy: 0.2895\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is true of haematemesis?\n",
            "A. A low blood pressure (<90mmHg systolic) and a tachycardia (>100/min) are worrying features\n",
            "B. A pulse rate of 80/min in a patient taking Bisoprolol is reassuring\n",
            "C. Abdominal pain is always present\n",
            "D. An alcohol history is not essential\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3077\n",
            "Current Mean Accuracy: 0.3077\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is true?\n",
            "A. Every compact space is complete\n",
            "B. Every complete space is compact\n",
            "C. Neither (a) nor (b).\n",
            "D.  Both (a) and (b).\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3000\n",
            "Current Mean Accuracy: 0.3000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: How did World War I shift economic power from Europe to the United States?\n",
            "A. The war reduced European population levels below that of the United States\n",
            "B. The United States seized German resources after the war\n",
            "C. European countries paid the United States for assistance\n",
            "D. The United States became a creditor country and financial centre, with European war spending boosting the US economy\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3171\n",
            "Current Mean Accuracy: 0.3171\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Write 8 and 2 over 4 as an improper fraction in simplest form.\n",
            "A. 17 over 2\n",
            "B. 34 over 4\n",
            "C. 17 over 4\n",
            "D. 19 over 2\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3095\n",
            "Current Mean Accuracy: 0.3095\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Prior to the issuance of its December 31 financial statements Stark Co. was named as a defendant in a lawsuit arising from an event that occurred in October. Stark's legal counsel believes that it is reasonably possible that there will be an unfavorable outcome and that damages will range from $100000 to $150000. Which amount(s) should Stark accrue and/or disclose in its December 31 financial statements? Accrue contingent liability Disclose contingent liability\n",
            "A. $100000 $100000 - $150000\n",
            "B. $100000 $150000\n",
            "C. $0 $100000 - $150000\n",
            "D. $0 $150000\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3256\n",
            "Current Mean Accuracy: 0.3256\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A man was prosecuted for the alleged murder of his estranged wife. At trial, the government was allowed to present the testimony of several women who testified to having flirtatious or sexual encounters with the defendant over the past 20 years prior to the homicide. None of the testimony showed any such activity within three years of the murder date, and none of it showed any violent tendencies of the defendant or intentions expressed that he wanted to kill his wife. The defendant had an alibi for the time of the crime and presented many alibi witnesses. The government claimed that it was showing motive by proving the defendant's proclivity for extra-marital affairs over the years and therefore his bad relationship with his wife. The jury convicted him after hearing the testimony of 10 women regarding defendant's various sexual contacts with them over prior years. The defendant appealed the murder conviction, claiming that the women's testimony was prejudicial and inflammatory and showed only bad character, which is not admissible under evidentiary rules. Will the appeals court likely reverse the conviction and order a new trial?\n",
            "A. Yes, the trial was unfair in presenting testimony of women going back over 20 years; it would have been proper to admit such testimony only as to the five years preceding the crime.\n",
            "B. Yes, the defendant did not receive a fair trial; the testimony of the women only showed his bad character but because they were old incidents and not continuing, they did not allow a permissible inference that these affairs gave him a motive to kill his spouse.\n",
            "C. No, if the testimony was admitted in error it was harmless error that did not sway the jury one way or another and so the defendant got a fair trial in all other respects.\n",
            "D. No, the testimony was admissible because it tended to show a pattern of \"transferred intent\" that proved the defendant's great hostility to his wife, and his need to eliminate her from his life so that he could go back to having a wild life.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3182\n",
            "Current Mean Accuracy: 0.3182\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I planted a large garden in the center of the narrow public street. Scenario 2 | I drive very fast when I'm on a racetrack.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3111\n",
            "Current Mean Accuracy: 0.3111\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: What is the term for the action in which managers at an organisation analyse the current situation of their organisation and then develop plans to accomplish its mission and achieve its goals?\n",
            "A. Synergy planning\n",
            "B. Strategy formulation\n",
            "C. Functional planning\n",
            "D. SWOT analysis\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3261\n",
            "Current Mean Accuracy: 0.3261\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "Read the following quote.\n",
            "I had now decided beyond all question that there existed in the heavens three stars wandering about Jupiter as do Venus and Mercury about the sun, and this became plainer than daylight from observations on similar occasions which followed. Nor were there just three such stars; four wanderers complete their revolutions about Jupiter, and of their alterations as observed more precisely later on we shall give a description here. Also I measured the distances between them by means of the telescope. . . .\n",
            "Such are the observations concerning the four Medicean planets recently first discovered by me, and although from this data their periods have not yet been reconstructed in numerical form, it is legitimate at least to put in evidence some facts worthy of note. Above all, since they sometimes follow and sometimes precede Jupiter by the same intervals, and they remain within very limited distances either to east or west of Jupiter, accompanying that planet in both its retrograde and direct movements in a constant manner, no one can doubt that they complete their revolutions about Jupiter and at the same time effect all together a twelve-year period about the center of the universe.\n",
            "—Galileo Galilei, 1610\n",
            "Which of the following is best demonstrated by the passage about intellectual thought at the time?\n",
            "A. It led to better scientific tools, which led to a rise in the standard of living during the seventeenth century across Europe.\n",
            "B. The ideas of the ancient Greeks guided all of their ideas.\n",
            "C. It used information obtained through experimentation to conceptualize the universe.\n",
            "D. It provided experimental proof of the theories of ancient thinkers, such as Aristotle, on how the universe worked.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3404\n",
            "Current Mean Accuracy: 0.3404\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is true about the assessment of arm reflexes?\n",
            "A. The root value of the biceps reflex is C5, C6\n",
            "B. If no reflex is elicited when you tap a tendon it is documented as absent\n",
            "C. The triceps tendon is struck in the antecubital fossa\n",
            "D. Brisk finger jerks confirm a lower motor neurone lesion\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  A\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3333\n",
            "Current Mean Accuracy: 0.3333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which expression shows a prime factorization?\n",
            "A. 2 • 9 • 11\n",
            "B. 2.5 • 7 • 3\n",
            "C. 1 • 11 • 13\n",
            "D. 2 • 2 • 2 • 3 • 11\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3469\n",
            "Current Mean Accuracy: 0.3469\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following best explains why people can digest starch but cannot digest cellulose even though both molecules are composed of glucose monomers?\n",
            "A. The bonds linking the monomers of starch differ in shape from the bonds linking the monomers of cellulose.\n",
            "B. Molecules of starch are much smaller than molecules of cellulose.\n",
            "C. Starch is an intracellular molecule, while cellulose is an extracellular molecule.\n",
            "D. Starch is hydrated by water, but cellulose is not.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3600\n",
            "Current Mean Accuracy: 0.3600\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The Egyptian system of hieroglyphics:\n",
            "A. did not use pictographs\n",
            "B. appears to have developed suddenly\n",
            "C. was the earliest form of writing in the world\n",
            "D. all of the above\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3529\n",
            "Current Mean Accuracy: 0.3529\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Robert is a marketer for a global consumer products company. He is working on the promotional campaign designed to reach a target audience in a new international market. Robert is working hard to make sure that the promotional campaign is clearly understood by the nation's consumers and doesn't offend anyone. By which of the factors in the external environment is he being influenced\n",
            "A. Socio-cultural environment.\n",
            "B. Competitive environment.\n",
            "C. Economic environment.\n",
            "D. Legal environment.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3654\n",
            "Current Mean Accuracy: 0.3654\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: What letters are on the '3' button of a touch-tone telephone?\n",
            "A. ABC\n",
            "B. DEF\n",
            "C. GHI\n",
            "D. WXY\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3585\n",
            "Current Mean Accuracy: 0.3585\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The key factor in the survival and success of anatomically modern human beings was:\n",
            "A. their ability to control fire and produce art.\n",
            "B. their ability to interbreed with other hominids.\n",
            "C. their ability to hunt large mammals.\n",
            "D. their ability to adapt.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3704\n",
            "Current Mean Accuracy: 0.3704\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The ROM programmed during manufacturing process itself is called\n",
            "A. MROM\n",
            "B. PROM\n",
            "C. EPROM\n",
            "D. EEPROM\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3818\n",
            "Current Mean Accuracy: 0.3818\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I picked the most rotten apples to donate to the food pantry. Scenario 2 | I sold exotic berries at the farmer's market.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3750\n",
            "Current Mean Accuracy: 0.3750\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: According to Brandt, John Stuart Mill’s view most closely resembles:\n",
            "A. act-utilitarianism.\n",
            "B. a rule-utilitarianism based on the actual rules of society.\n",
            "C. a rule-utilitarianism based on ideal moral rules.\n",
            "D. Kant’s ethics.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3860\n",
            "Current Mean Accuracy: 0.3860\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: On February 1, a retiree conveys his farm to an artist, and the artist duly records the conveyance. The following day, the artist conveys the property to a bartender; she does not record her deed. Then on February 4, the artist executes an identical conveyance of the farm to a caterer. The caterer gives the artist a check for $100,000 for the property and records the conveyance, even though he has actual knowledge of prior conveyance to the bartender. The bartender, however, records her deed on February 6. The caterer then conveys his interest in the farm to a dancer, who gives a purchase price of $115,000 to the caterer. On February 5, the dancer purchases the farm without notice of the conveyance to the bartender and duly records the deed. In conducting a title search, the dancer should pursue his investigation by looking in the\n",
            "A. Grantor Index under the caterer's name to ascertain if the caterer acquired title.\n",
            "B. Grantee Index under the caterer's name only.\n",
            "C. Grantee Index under the caterer's name, then the Grantor Index under the caterer's name, and then in the Grantee Index again, this time under the artist's name to discover if he acquired title.\n",
            "D. Grantee Index under the bartender's name, then to the Grantor Index, also under the bartender's name to find out if she made any prior conveyances.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3966\n",
            "Current Mean Accuracy: 0.3966\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Is the recognition of foreign judgments subject to the same rules as those applicable to the incorporation and transformation of treaties?\n",
            "A. Foreign judgments are enforced on the basis of the doctrine of incorporation\n",
            "B. Foreign judgments are enforced on the basis of the doctrine of transformation\n",
            "C. The recognition of foreign judgments is dependent on the existence of appropriate bilateral or multilateral treaties\n",
            "D. The courts exercise discretion as to the enforcement of foreign judgments on the basis of the rule of comity\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4068\n",
            "Current Mean Accuracy: 0.4068\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Lactose\n",
            "\n",
            "A. Is always the cause of milk intolerance\n",
            "B. Cannot be digested in the human gut\n",
            "C. Intolerance is present in up to 20% of the population\n",
            "D. Is excluded on a low FODMAP diet\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4000\n",
            "Current Mean Accuracy: 0.4000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following best describes the fallacy of amphiboly?\n",
            "A. Using emotionally charged languages to create an impression about the subject of a claim, without making an argument that the language fits the subject.\n",
            "B. Referring to an act committed by an opponent in negative terms while referring to the same act committed by the arguer or supporters in favorable terms.\n",
            "C. Using grammar and punctuation in a way that a statement may have multiple interpretations, so it's not really clear what is meant.\n",
            "D. Changing the meaning of a word or phrase from one part of the argument to another.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4098\n",
            "Current Mean Accuracy: 0.4098\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question:  Nagel thinks that the core of the absolutist position is that\n",
            "A. human persons have a right to life.\n",
            "B. it is permissible to harm as a foreseen but unintended consequence of action.\n",
            "C. the ends justify the means.\n",
            "D. the hostility should be directed at its true object.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4032\n",
            "Current Mean Accuracy: 0.4032\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For Plato, ordinary sensible objects exist and are knowable as examples or instances of Ideas or \"Forms\" that do not exist in our ordinary sensible world.  Forms do not exist in the sensible world because:\n",
            "A. in the sensible world only mathematical objects (e.g., triangles) can be known using hypotheses which are recollected when we are asked the right kinds of questions.\n",
            "B. unlike everything in the sensible world, Forms are not individual things but rather the universal essences or natures by which individual things are what they are and are known.\n",
            "C. nothing in the sensible, experienced world could exist or be identified as one particular thing or another unless there were a \"Sensible World\" Form (like the Form of beauty or justice).\n",
            "D. the sensible world consists of changing Forms that exist and are known in terms of other changing Forms, which in turn exist and are known in terms of yet others in an endless regress.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3968\n",
            "Current Mean Accuracy: 0.3968\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following statements regarding historical North American migration streams is NOT correct?\n",
            "A. Canada's first major migration came from France.\n",
            "B. Canada's second major migration stream originated in the British Isles.\n",
            "C. Canada's third major migration stream came from Latin America.\n",
            "D. The first major migration wave to the United States originated in Europe.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4062\n",
            "Current Mean Accuracy: 0.4062\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A state's constitution reserves to the people of each municipality in the state the power of referendum with respect to all questions that the municipality is authorized to control by legislation. A real estate developer applied for a zoning change to permit construction of a convalescent home on land he owned in a city within the state. While the application was pending, the city charter was amended by popular vote so as to require that any changes in land use agreed to by the city council be approved by a 55% vote in a referendum. The city planning commission and the city council both approved the proposed zoning change. However, the real estate developer's subsequent application for approval for a proposed home on the grounds was rejected because the rezoning action had not been submitted to a referendum. In an action brought in state court seeking a judgment declaring the city charter amendment invalid, the court will most likely declare the amendment\n",
            "A. unconstitutional, as violation of the real estate developer's due process rights.\n",
            "B. unconstitutional, as an unlawful delegation of legislative power to a regulatory body.\n",
            "C. constitutional, as a valid exercise of the city's police power.\n",
            "D. constitutional, as a valid exercise of a power reserved by the people to themselves.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4154\n",
            "Current Mean Accuracy: 0.4154\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The majority of workers in periphery countries are probably employed in which type of activities?\n",
            "A. Primary\n",
            "B. Secondary\n",
            "C. Tertiary\n",
            "D. Quaternary\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4091\n",
            "Current Mean Accuracy: 0.4091\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Mayan city-states were NOT:\n",
            "A. ruled by autonomous dynasties.\n",
            "B. similar in their political organization to Egyptian communities.\n",
            "C. supported by large agricultural hinterlands.\n",
            "D. much smaller in population than Mohanjo-daro.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4030\n",
            "Current Mean Accuracy: 0.4030\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I wanted to buy a doll so I broke open my piggy bank. Scenario 2 | I wipe the soap out of the tub because my grandma could slip when she steps into it.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3971\n",
            "Current Mean Accuracy: 0.3971\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Nussbaum claims that for Aristotle the reference of each virtue term is fixed by:\n",
            "A. conventional use.\n",
            "B. grounding experiences.\n",
            "C. a thick description of the virtue.\n",
            "D. tradition.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3913\n",
            "Current Mean Accuracy: 0.3913\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Glaucoma refers to the condition in which\n",
            "A. Fluid pressure in the eye is above normal\n",
            "B. Inner and outer layers of the retina separate\n",
            "C. The lens becomes cloudy and opaque\n",
            "D. The central part of the retina no longer functions\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4000\n",
            "Current Mean Accuracy: 0.4000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A person who sustains major injuries that involve the destruction of the medulla oblongata will\n",
            "A. be paralyzed\n",
            "B. fall into a coma\n",
            "C. suffer severe speech impairment\n",
            "D. die\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3944\n",
            "Current Mean Accuracy: 0.3944\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: ___________ is a communication disorder that is characterized by difficulties in regulating the rate, rhythm, pitch, and loudness of speech.\n",
            "A. Dysarthria\n",
            "B. Paraphasia\n",
            "C. Dysprosody\n",
            "D. Adynamia\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3889\n",
            "Current Mean Accuracy: 0.3889\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A witness in a murder case does not make the same statement faithfully, but rather he has given different versions of his observations at different times to different persons and investigators. The prosecution put the witness on the stand at trial to tell what he observed. The defendant's counsel impeached his testimony by bringing up prior inconsistent statements and accusing him of changing his story for trial. The prosecution then attempted to rehabilitate his credibility by referencing prior consistent statements. Prior consistent statements are not generally admissible because they are said to be repetitive, cumulative and to unfairly bolster the witness's credibility. Will the court likely allow the prosecution to rehabilitate the witness using prior consistent statements under these facts?\n",
            "A. No, because the witness cannot be rehabilitated once a successful impeachment has occurred.\n",
            "B. No, because it would tend to confuse the jury with too much conflicting evidence.\n",
            "C. Yes, because it is being used to rehabilitate a witness whose credibility was attacked.\n",
            "D. Yes, because all repetitive prior statements are important to show the consistency of the witness' testimony.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3973\n",
            "Current Mean Accuracy: 0.3973\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A defendant was driving his car recklessly at a high rate of speed through a residential neighborhood. He was traveling at a speed of over 100 M. P. H. when he lost control of the car and jumped a curb, striking a woman who was walking along the sidewalk. As a result of the collision, the woman suffered severe internal injuries and fractured both legs. She was hospitalized for 11 months and became permanently disabled. If the defendant is charged with attempted murder, he should be found\n",
            "A. guilty, because a person is presumed to intend the natural and probable consequences of his acts.\n",
            "B. guilty, because criminal liability is predicated upon the defendant's willful and wanton disregard for the safety of others.\n",
            "C. not guilty, because the defendant did not intend to kill the woman.\n",
            "D. not guilty, because he lost control of the vehicle.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4054\n",
            "Current Mean Accuracy: 0.4054\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A seller and a buyer signed a contract of sale for improved real property. The contract contained a financing contingency for a certain percentage of the purchase price. The buyer obtained the requisite financing from a bank. At the closing, the buyer executed a note to the seller for a portion of the purchase price, which note was not secured by a mortgage. The buyer then executed a second note, secured by a mortgage to executed a second note, secured by a mortgage to the bank, applying the bank loan proceeds to the purchase price of the property. The bank had actual knowledge of the prior note to the seller. The bank promptly recorded its mortgage. The buyer is now in default on both notes. There is no applicable statute. Which party has priority?\n",
            "A. The bank, because its loan satisfied the financing contingency in the contract of sale.\n",
            "B. The bank, because its note is secured by a purchase money mortgage.\n",
            "C. The seller, because the bank had actual knowledge of the seller's note.\n",
            "D. The seller, because he retained a vendor's lien that was first in time.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4000\n",
            "Current Mean Accuracy: 0.4000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Suppose that the market price of Company X is $45 per share and that of Company Y is $30. If X offers three-fourths a share of common stock for each share of Y, the ratio of exchange of market prices would be:\n",
            "A. 0.667\n",
            "B. 1\n",
            "C. 1.125\n",
            "D. 1.5\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3947\n",
            "Current Mean Accuracy: 0.3947\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The ___________, otherwise known as _________ was launched in 1997 and is a global workplace standard that covers key labour rights such as working hours, forced labour and discrimination, with compliance being certified by independent auditors.\n",
            "A. Social accountability standard, SA 8000\n",
            "B. Social accountability standard, SA 9000\n",
            "C. Sarbanes-Oxley Act, SA 8000\n",
            "D. Sarbanes-Oxley Act, SA 9000\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4026\n",
            "Current Mean Accuracy: 0.4026\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Rawls claims that students with fewer native assets (such as intelligence) should be given:\n",
            "A. more attention and resources than those with more native assets.\n",
            "B. the same level of attention and resources as those with more native assets.\n",
            "C. less attention and fewer resources than those with more native assets.\n",
            "D. virtually no educational resources.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3974\n",
            "Current Mean Accuracy: 0.3974\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Barry reported that in his study, the relationship between religiosity and academic grades was not statistically significant. By \"not statistically significant,\" he meant that the results\n",
            "A. were not important\n",
            "B. were not strong\n",
            "C. might have been due to chance\n",
            "D. were of no value to statisticians\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4051\n",
            "Current Mean Accuracy: 0.4051\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: By what collective name do Christians refer to God the Father God the Son and the Holy Ghost?\n",
            "A. the Trio\n",
            "B. the Troika\n",
            "C. the Triumvirate\n",
            "D. the Trinity\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4125\n",
            "Current Mean Accuracy: 0.4125\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Three types of prevention have been identified in community mental health. Secondary prevention attempts to\n",
            "A. deal with problems before they occur\n",
            "B. prevent relapses of problems\n",
            "C. reduce the severity of problems\n",
            "D. prevent community disintegration\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4074\n",
            "Current Mean Accuracy: 0.4074\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Statement 1 | If a group has an element of order 10, then it has elements of orders 1, 2, and 5. Statement 2 | If a group has an element of order 2 and an element of order 3, then it has an element of order 6.\n",
            "A. True, True\n",
            "B. False, False\n",
            "C. True, False\n",
            "D. False, True\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4024\n",
            "Current Mean Accuracy: 0.4024\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following drugs is most commonly responsible for patients who present with acute confusion?\n",
            "A. Heroin (opiates).\n",
            "B. Ecstasy.\n",
            "C. Alcohol.\n",
            "D. Cannabis.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4096\n",
            "Current Mean Accuracy: 0.4096\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Vasocongestion is a process of :\n",
            "A. muscle contraction\n",
            "B. blood accumulation in the genitals\n",
            "C. muscle relaxation\n",
            "D. detumescence\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4048\n",
            "Current Mean Accuracy: 0.4048\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Insensible loss does not come from:\n",
            "A. pyrexia.\n",
            "B. using unhumidified oxygen.\n",
            "C. excessive weight loss.\n",
            "D. diarrhoea.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4118\n",
            "Current Mean Accuracy: 0.4118\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | When I saw my neighbor's house was on fire, I rushed to the phone to call my long lost friend to chat. Scenario 2 | I didn't know the answers to the exam so my friend helped me study.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4070\n",
            "Current Mean Accuracy: 0.4070\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question:  Organizational characteristics, such as organizational size and location, are sometimes referred to as___________.\n",
            "A. DMU.\n",
            "B. Firmographics.\n",
            "C. ACORN\n",
            "D. Product usage.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4023\n",
            "Current Mean Accuracy: 0.4023\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is most likely to decrease the demand for kindergarten teachers?\n",
            "A. An increase in funding for education\n",
            "B. Increased immigration of foreign citizens and their families\n",
            "C. A decrease in the average number of children per household\n",
            "D. Subsidies given to college students who major in elementary education\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3977\n",
            "Current Mean Accuracy: 0.3977\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The market demand curve for labor would shift to the left as the result of\n",
            "A. an increase in the price of the good which the labor is producing\n",
            "B. an increase in demand for the good which the labor is producing\n",
            "C. an increase in the wage rate paid to workers\n",
            "D. a decrease in the marginal product of labor\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3933\n",
            "Current Mean Accuracy: 0.3933\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: How were the first metals worked in South America?\n",
            "A. casting\n",
            "B. hammering\n",
            "C. smelting\n",
            "D. all of the above\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3889\n",
            "Current Mean Accuracy: 0.3889\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A segment of DNA from a lab mouse is determined to be 5’ – GGATCCTCATG – 3’. Which of the following DNA segments would be the result of this original DNA sequence experiencing both a point mutation and a deletion?\n",
            "A. 5’ – GCATCCTCATG – 3’\n",
            "B. 5’ – TGATCCCAG – 3’\n",
            "C. 5’ – GGTCCTCATC – 3’\n",
            "D. 5’ – GGATCCATG – 3’\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3956\n",
            "Current Mean Accuracy: 0.3956\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of these sentences is written in the subjunctive?\n",
            "A. I am not your man\n",
            "B. I wish I were your man\n",
            "C. Wherefore art your man?\n",
            "D. Your man is where?\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3913\n",
            "Current Mean Accuracy: 0.3913\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: As of 2017, the share of GDP spent on the military by the United States is about\n",
            "A. 1%\n",
            "B. 3%\n",
            "C. 6%\n",
            "D. 10%\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3871\n",
            "Current Mean Accuracy: 0.3871\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: After learning that a new housing development was about to be built, a developer began looking for property near the housing development on which he could build a shopping center. After an extensive search, he purchased a three-acre undeveloped tract of land for the purpose of developing a small shopping center. At the time the sale was finalized, the developer told his plans to the seller of the three-acre tract, and also mentioned that he was worried whether he had sufficient funds to complete the project. The seller agreed to lend money to the developer to allow for completion of the project. The seller then wrote out the following contract:\"In order to help the developer with his plans for development of a shopping center on the three- acre tract he has this day purchased from me, I will lend him $50,000 at 10 percent interest provided he signs a contract with a builder for construction of the shopping center on this tract. Repayment to me at the rate of $5,000 per year to be secured by a mortgage on the three-acre tract. \"Both parties then signed the contract. The seller's promise to lend $50,000 to the developer is\n",
            "A. a condition precedent in form but subsequent in substance to the developer's duty to enter into a building construction contract.\n",
            "B. a condition subsequent in form but precedent in substance to the developer's duty to enter into a building construction contract.\n",
            "C. a condition subsequent to the developer's duty to enter into a building construction contract.\n",
            "D. not a condition, either precedent or subsequent, to the developer's duty to enter into a building construction contract.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3830\n",
            "Current Mean Accuracy: 0.3830\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: An earlier boundary formed before meticulous geographic knowledge and mapping was available is known as\n",
            "A. an antecedent boundary.\n",
            "B. a geometric boundary.\n",
            "C. a relict boundary.\n",
            "D. a subsequent boundary.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3789\n",
            "Current Mean Accuracy: 0.3789\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I had my son spend 20 minutes on chores before playing video games. Scenario 2 | I made my stepdad's Koolaid with half the sugar since he is diabetic.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3750\n",
            "Current Mean Accuracy: 0.3750\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "\"The real grievance of the worker is the insecurity of his existence; he is not sure that he will always have work, he is not sure that he will always be healthy, and he foresees that he will one day be old and unfit to work. If he falls into poverty, even if only through a prolonged illness, he is then completely helpless, exam_ins to his own devices, and society does not currently recognize any real obligation towards him beyond the usual help for the poor, even if he has been working all the time ever so faithfully and diligently. The usual help for the poor, however, leaves a lot to be desired, especially in large cities, where it is very much worse than in the country.\"\n",
            "Otto von Bismarck, 1884\n",
            "The long-term effects of Otto von Bismarck's speech include which of the following?\n",
            "A. Development of socialized programs throughout much of Europe\n",
            "B. Disunity of the German states\n",
            "C. Communist overhaul of the eastern parts of Germany\n",
            "D. A decrease in German economic output\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3814\n",
            "Current Mean Accuracy: 0.3814\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: When an ideal gas is allowed to expand isothermally, which one of the following is true?\n",
            "A. q = 0\n",
            "B. w = 0\n",
            "C. E = 0\n",
            "D. q = -w\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3878\n",
            "Current Mean Accuracy: 0.3878\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: In the phrase 'Y2K' what does 'K' stand for?\n",
            "A. millennium\n",
            "B. computer code\n",
            "C. catastrophe\n",
            "D. thousand\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3838\n",
            "Current Mean Accuracy: 0.3838\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: In what ways can a distinction be made between limited force and full-scale force?\n",
            "A. The distinction between limited force and full-scale force is the second process of coercive diplomacy. Coercive diplomacy only fails if the coercer fails to achieve its defined goals and fails to defeat its adversary in the second stage.\n",
            "B. Generally the distinction between brute and limited force is negligible. Resort to air or sea power constitutes an equal coercive capacity to a conventional ground offensive. Military action always results from a failure of negotiations and from a shift from the diplomatic to the military sphere.\n",
            "C. The distinction between limited force and brute force is important because the amount of force that is used to attain the coercer's interests defines the type of outcome that is achieved. If a positive policy outcome is achieved, then we can say that limited force has been employed.\n",
            "D. The distinction between limited force and full-scale war is crucial because resort to brute force means that diplomacy has failed. The distinction is not based on the amount of force or the type, but on the purpose that the use of force seeks to accomplish and the element of choice left to the adversary. In essence, limited force is a bargaining tool.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3800\n",
            "Current Mean Accuracy: 0.3800\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (MMLU) ---\n",
            "Final Exact Match Accuracy: 0.3800\n",
            "Final Mean Accuracy: 0.3800\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.3799999952316284, 'accuracy': 0.38}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.1333971095085144}, 'time_per_token': {'mean': 0.1333971095085144}, 'tokens_per_second': {'mean': 9.674133124947549}}\n",
            "Valid formats: ['chat_format', 'cnn_dm_summarization', 'cnn_dm_lm', 'xsum_summarization', 'human_eval', 'custom_jsonl', 'top_v2', 'mmlu', 'race_m', 'race_h']\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "    --dataset mmlu \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy layerdrop \\\n",
        "    --exit_layer 8 \\\n",
        "    --num_speculations 6 \\\n",
        "    --output_dir ./logs \\\n",
        "    --distributed False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPyrHTZ2PQV6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using standard benchmark for dataset: race_h\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.76171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 117621\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00018322467803955078\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: After my husband died, my world crashed around me. My six children were 10, nine, eight, six, three and 18 months, and I was overwhelmed with the responsibilities of earning a living, caring for the children and simply _ .\n",
            "I was fortunate to find a wonderful housekeeper to care for the children during the week, but from Friday nights to Monday mornings, the children and I were alone, and frankly I was uneasy. Every unusual noise or any late-night phone call filled me with fear. I felt incredibly alone.\n",
            "One Friday evening I came home from work to find a big beautiful German shepherd  on our doorstep. It was obvious he wanted to make the house his home. The children took an instant liking to \"German\" and begged me to let him in. I agreed to let him sleep in the basement until the next day. That night I slept peacefully for the first time in many weeks.\n",
            "The following morning we made phone calls and checked lost-and-found ads for German's owner, but with no results. Saturday night he was still with us.\n",
            "On Sunday I had planned to take the children on a picnic. Since I thought it best to leave German behind in case his owner came by, we drove off without him. When we stopped to get gas at a local station, we were amazed to see German racing to the gas station after us. He stayed again Sunday night.\n",
            "Monday morning I let him out for a run while the children got ready for school. He didn't come back. We thought we'd never see him again. On Friday evening, German was back again. We took him in, and again he stayed until Monday morning, when our housekeeper arrived. It went like this for almost 10 months. We looked forward to his coming each Monday morning he left home.\n",
            "Each week, between German's visits, I grew a little braver, but every weekend I enjoyed his company. Then one Monday morning we patted his head and let him out for what turned out to be the last time. He never came back.\n",
            "\n",
            "Question: Which of the following is Wrong according to the article?\n",
            "A. German was fond of living with the family.\n",
            "B. The writer felt safe and protected with German around.\n",
            "C. The dog stayed until the writer was strong enough to go on alone.\n",
            "D. The writer was too busy that weekend to go find the dog's owner.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.182861328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37689\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0256195068359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: We have twenty minutes' break time after the second class in the morning.  Look!  Most of us are playing during the break time. Some students are on the playground . They are playing basketball. Oh! A boy is running with the ball.  And another is stopping  him. They look so cool. And there are some girls watching the game. Some students are in the classroom. They are talking.  A few of them are reading and doing homework. Look! A girl is looking at the birds in the tree in front of the classroom. She must be thinking of something interesting because she is smiling .\n",
            "What are the teachers doing? Some of them are working in the office. And some are talking with students. Everyone is doing his or her things, busy but happy!\n",
            "\n",
            "Question: Where are the students playing basketball?\n",
            "A. In front of the tree.\n",
            "B. In front of the classroom.\n",
            "C. On the playground.\n",
            "D. In the tree.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10589599609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 101043\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0265655517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52649\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.046295166015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 79408\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.85205078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 117396\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031005859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 16455\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1776123046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61921\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002777576446533203\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65854\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0267333984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 579\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.935546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12812\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.051239013671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 66682\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.020294189453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 51453\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0919189453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 50842\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001919269561767578\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: \"I don't want to move!\" Kevin said to his father,\" I like living here in New York City. And I like to play in the streets. My friends are here. I want to stay!\" \"We have to move, Kevin.\" Mr. Black said, \"I have a new job on the island*. Why don't you go with us?\"\n",
            "\"No,\" Kevin answered.\n",
            "After a few weeks, the Black family left the city by plane. They flew over water. In the end they saw the land*. \"That is Hawaii. It is beautiful!\" Mr. Black said.\n",
            "\"I don't care* what it is like,\" said Kevin, \"I wish I could go back to New York City now!\"\n",
            "They lived in their new home near the sea. It rained a little every day. When the sun came out again, they could see a rainbow* every day. People in the neighborhood came to visit them. The visitors brought fruit from their farms.\n",
            "Weeks went by*.One day Kevin wrote to Bob and in the letter he said, \"I still miss my old friends. But I think these are our happy islands. Please come to see me. I know you will like Hawaii, too.\"\n",
            "\n",
            "Question: People in their neighborhood were very  _\n",
            "A. strict\n",
            "B. scary\n",
            "C. friendly\n",
            "D. funny\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " D\n",
            "Explanation: People in the neighborhood were very friendly.\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12060546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 50765\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001494884490966797\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Before I started school, people felt that I was not going to be successful.At the age of four I started speech lessons because I could not speak well enough for anyone to understand me.\n",
            "The first grade was a struggle  .I had difficulty speaking, I also couldn't learn to read.The second grade was not much better.I still struggled with the inability to read.In the third grade a new school was built. It was near my home. I went there with my parents and helped to get the school ready so that we could move to the new one. However, things didn't get better for the next two years.\n",
            "It was in the fifth grade.Mrs.Wakefield was my teacher, and she was a good teacher.She did not make me feel unconfident. Instead, she did her best to let me know that I could be whatever I wanted to be.And that is just what I did.\n",
            "For the past 22 years, I have been a fifth grade teacher.Because of Mrs.Wakefield's influence on my life, I am now encouraging students who have had difficulties in their lives to believe that they can deal with any difficulty successfully and become someone.I have won many awards  up to now, such as Teacher of the Year.I think I should thank my fifth grade teacher. She believed in me and helped me to be all that I could be.\n",
            "\n",
            "Question: The writer   _   when he was in the third grade.\n",
            "A. did better in reading\n",
            "B. met a good teacher\n",
            "C. received a high award\n",
            "D. went to a new school\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7763671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.248046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Kids have unbelievable imaginations. We asked one hundred kids how robots might help them learn better. This is what they thought.\n",
            "Roberts can make learning fun\n",
            "Kids dreamed robots would make learning fun. One 9-year-old boy in Germany says, \"When I get home, my robot helps me with my homework. My mother and father came in and said 'no video games now, homework first'. When they saw that I had finished my homework, they'd be surprised\".\n",
            "Robots take care of the dirty work\n",
            "Dirty dishes? No problem. A quarter of kids surveyed imagined that their robots could do chores and boring work so that they might be freed up.\n",
            "Robots are our friends\n",
            "Two-thirds of the kids thought that their robots could be friends. One 10-year-old French boy describes his dream robot: \"He created books for me to read, we played with toy cars. He keeps my secrets. I can tell him anything, and he gives me suggestions.\"\n",
            "Robots are cool\n",
            "An 8-year-old girl in the U.S. imagines that her robot is \"really smart and everyone likes to talk to her. She has a funny voice, but we do not laugh at her.\"\n",
            "\n",
            "Question: Robots could be the following, NOT including  _  according to the passage.\n",
            "A. kitchen helpers\n",
            "B. listeners\n",
            "C. tutors\n",
            "D. parents\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.371826171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.32666015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Benjamin Franklin was born in 1706 and died in 1790.The philosopher and writer was one of the most important men in the early days of the United States. He believed strongly in the importance of hard work, and he himself worked hard all his life, from the time he left school at the age of ten.\n",
            "\"Poor Richard,\" a character Franklin created, summarized Franklin's ideas in short sayings . Many of Poor Richard's sayings are still remembered today. One of the most famous is \"Early to bed, and early to rise, makes a man healthy, wealthy and wise,\" from the essay \"The Way of Wealth.\"\n",
            "In the same essay , Franklin talks about the danger of laziness and the value of ambitiousness .He asks what is accomplished by \"wishing and hoping for better times\". He says that we can make these times better if we try hard enough. People who spend all their time just hoping will die without food. They shouldn't expect everything to be easy, or as Poor Richard says, \"there are no gains without pains.\" Franklin also says that we should work today, not wait until tomorrow. \"One today is worth two tomorrows,\" says Poor Richard.\" Never leave that till tomorrow, which you can do today.\"\n",
            "\n",
            "Question: According to the text, Poor Richard is a person who   _  .\n",
            "A. used to help Franklin\n",
            "B. appears in Franklin's books\n",
            "C. knows a lot of old sayings\n",
            "D. works very hard all his life\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00027942657470703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52671\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00022876262664794922\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: There is lots of junk  in space .Some of it is from rockets. In 1996, a rocket broke into about 300,000 small pieces. So far, scientists have found over 10,000 man-made pieces flying around in space. Only 6-7%of them are satellites and space probes  . Astronauts also lose small things while working in space. In 1965, during the first American spacewalk , astronaut Edward White lost a glove .For a month, the glove stayed in space, travelling at a speed of 28,000 kilometers per hour .It became the most dangerous piece of clothing for the Earth in history it flew away. Things move very fast in space. If they hit one another, it can be dangerous .A little piece of paint from a satellite once made a hole in a spacecraft window. Last year two US spacecraft dropped some bolts , and scientists on the Earth worried a lot. Luckily the bolts floated  away into space. They couldn't hit the spacecraft.\n",
            ",.\n",
            "\n",
            "Question: The glove in space may travel at a speed of    _    kilometers per hour.\n",
            "A. 300,000\n",
            "B. 28,000\n",
            "C. 10,000\n",
            "D. 21,000\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28206\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0162200927734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91569\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0263824462890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Dear Dr Jackson,\n",
            "My parents are never happy with me. They are always criticizing my clothes, my hair and the music I listen to. They hate my friends' looks and they keep complaining when I go with them. I'm not allowed to stay out as late as my friends do, so I can't have any fun. My parents only seem to care about my school grades. Although I love them, sometimes I feel we live in different worlds. If they love me, can't they understand me? How can I make them understand me?\n",
            "Angel\n",
            "Dear Angel,\n",
            "Your problem is common to both teenagers and parents. Don't worry, because all this is natural. You see, your parents have grown up at a different time and they have different experiences. So, they think some things are strange, but you find the same things are all right. For example, the music you like may sound like noise to them. Your parents love you, so they feel they must stop you from doing whatever they find strange. On the other hand, you don't want to be different from other teenagers, so you feel that your parents\n",
            "you.\n",
            "I think you should talk about this problem with your parents. Try to explain to them what you want and make them know they can believe you. And then they'll find you are a responsible person and they will give you more freedom.\n",
            "Jackson\n",
            "\n",
            "Question: What advice does Dr Jackson give to Angel?\n",
            "A. Be different from other teenagers.\n",
            "B. Pay no attention to whatever her parents tell her.\n",
            "C. Discuss her problem with her parents.\n",
            "D. Don't tell her parents what she wants to do.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 100274\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00048828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61489\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002321004867553711\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Lin Tao and Chen Hai are good friends. They are in the same class. They are in the same team. Lin Tao sits behind Chen Hai. Now it is four o'clock. School is over. They often go to play games after school. They can't look after their things very well. So their mothers don't give them watches. They don't have watches. They don't know the time. But they can ask a man under the big tree. His watch is very nice. They can also see the clock on the wall of the classroom. Now it's about five in the afternoon. It's time to go home. They must put on their clothes and go home.\n",
            "\n",
            "Question: Why don't they have watches?\n",
            "A. Because they don't need watches.\n",
            "B. Because they can't look after their things well.\n",
            "C. Because their watches are in their desks.\n",
            "D. Sorry, I don't know.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1543\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005840301513671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 46968\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0033397674560546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: A story is told about a soldier who was finally coming home after having fought in Vietnam. He called his parents from San Francisco.\n",
            "\"Mom and Dad, I'm coming home, but I have a friend I'd like to bring with me.\"\n",
            "\"Sure,\" they replied, \"we'd love to meet him.\"\n",
            "\"There is something you should know,\" the son continued, \" he was hurt badly in the fighting. He lost an arm and a leg. He has nowhere else to go, and I want him to live with us.\"\n",
            "\"I'm sorry to hear that, son. Maybe we can help him find somewhere to live.\"\n",
            "\"No, Mom and Dad, I want him to live with us.\"\n",
            "\"Son,\" said the father, \"you don't know what you're asking. Someone like the young man would be a terrible burden for us. We have our own lives to live, and we can't let something like this stay with our lives. I think you should just come home and forget about this guy. He'll find a way to live on his own.\"\n",
            "At that point, the son hung up the phone. A few days later, however, they received a call from the San Francisco police. Their son had died after falling down from a building. The police believed it was suicide .\n",
            "The parents flew to San Francisco. To their surprise, they found their son had only one arm and one leg.\n",
            "The parents in this story are like many of us. We find it easy to love those who are good-looking or fun, but we don't like people who make us feel uncomfortable. We would rather stay away from people who aren't as healthy, beautiful, or smart as we are.\n",
            "\n",
            "Question: Who lost an arm and a leg in the fighting\n",
            "A. The soldier himself.\n",
            "B. The soldier's friend.\n",
            "C. The soldier's brother.\n",
            "D. The soldier's father.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 82327\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00017011165618896484\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07196044921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: This year, \"Wild China\" is famous, it shows us the beautiful scenes .But in fact, the environment around  us is getting worse and worse .In some places,we can't see fish swimming in the river or trees on the mountains. Many animals are facing the danger of living .At the same time, man is killing animals just for getting their skin and meat. In our country, the number of wild animals is becoming smaller and smaller. Some of them are even dying out .\n",
            "It's time to protect  our environment .But what can we do? How to protect _ ? For example,we can go to school on foot or by bike . we can use shopping baskets not plastic  bags when we go shopping,and we can use both sides of the paper to write . Also , we should plant more trees to protect the animals' living.\n",
            "In a word,if everyone does more to our environment ,our life will be better. \"There is only one earth\",I hope everyone will protect our environment well.\n",
            "\n",
            "Question: Why does man kill animals?\n",
            "A. For teeth and meat\n",
            "B. For skin and horns\n",
            "C. For skin and teeth\n",
            "D. For skin and meat\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29196\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 7.444620132446289e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 79960\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0096893310546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Luke Dollar has spent many years in Madagascar studying lemurs  .\n",
            "Reporter: What were you like as a kid?\n",
            "Dollar: As a kid, I was an explorer. I lived with my grandparents on a farm in Alabama. It wasn't unusual for me to go to the woods. And I enjoyed that. From the time I was 6 to 16 years old I was an actor. My mom asked me to audition\n",
            "  for a show in Birmingham. I asked my mom to buy me some video games and she promised  , so I got the part. Later, I became a professional actor. So for several years I went everywhere from the Alabama farm to many other cities -- all over the USA doing stage productions.\n",
            "Reporter: How did you get into your field of work?\n",
            "Dollar: I grew up on a farm and I was really a wild child and came to love wild things. I did a lot of photography in high school. I became a photographer and did photography for the local paper. Then I became a student of Duke University. Duke has a primate   centre -- Lemur Centre. I got a job there as a work study student and met lemurs there for the first time.\n",
            "Later I had a chance to go to Madagascar and decided to study lemurs.\n",
            "Reporter: What's the one thing you can't travel without?\n",
            "Dollar: A sense of humour   or a can-do attitude is necessary, but my first response   was soy sauce. If we run out of soy sauce, the journey is over.\n",
            ",.\n",
            "\n",
            "Question: What was Luke's childhood like?\n",
            "A. Boring.\n",
            "B. Enjoyable.\n",
            "C. Peaceful.\n",
            "D. Unhappy.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1384\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001728534698486328\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.022735595703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Joe Read studied in this school for fourteen years. When he finished school, he was already eighteen years old. And then his father said to him, \"You finished school, and you are a good student. Now you may go to town and get a good job. They need some clever people to work in the office. The people there can get a lot of money now. If you stay at home, you can't get money from our family.\" A few weeks later, Joe went to the office and asked for a job there. A man took him into a small room and gave him some questions on a piece of paper. Joe answered the questions quickly, and he gave the paper to the man. The man looked at the paper for a few minutes and then asked, \"You were born on Sep. 23. But which year were you born in?\" Joe answered, \"Oh, every year.\"\n",
            "\n",
            "Question: Why did the man give Joe a piece of paper?\n",
            "A. Because he wanted to give Joe a job.\n",
            "B. Because he wanted Joe to answer some questions.\n",
            "C. Because he wanted to know if Joe was clever.\n",
            "D. Because he wanted to know how old Joe was.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 43982\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 9.799003601074219e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 86991\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0010957717895507812\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Mr. Evans lives in a city. He was a math teacher three years ago. He taught well and his students liked him. So he decided to work in the middle school all his life. But a terrible accident changed his fortune .\n",
            "One spring he took his class to visit a place of interest. The children saw a lot of interesting things and had a good time there. But on their way to school, their bus was hit by a truck because the young driver was drunk . Five students died and more than half of the children were injured in the accident. He didn't know how it had happened and was very sad about it and after he came out of hospital, he left the school and became a policeman. He tried his best to stop the drivers from breaking the traffic regulations . He worked hard and was strict with the drivers. So they were afraid of him.\n",
            "One afternoon it was very hot. Mr. Evans was on duty. He was standing at the crossing and watching the traffic. Suddenly he saw a car rushing towards the crossing. It ran so fast that it almost hit a man on a bike. He stopped it at once and saw a girl in it.\n",
            "\"Show your license to me, madam,\" said Mr. Evans.\n",
            "The girl handed her bag to him and said: \"Please look for it in it. I can't see anything without glasses.\"\n",
            "\n",
            "Question: In the accident   _  .\n",
            "A. more than half of the children died\n",
            "B. five children were injured\n",
            "C. more than half of those children were injured\n",
            "D. Mr. Evans was injured\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14504\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00030612945556640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15144\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Tom is a little boy ,and he is only seven years old. One day he went to the cinema. It is the first time for him to do that. He bought a ticket and then went in. But after two or three minutes he came out, bought a second ticket and went in again. After a few minutes he came out again and bought a third ticket. Two or three minutes later he came out and asked for another ticket. Then the girl in the ticket office asked him,\"Why do you buy so many tickets? How many friends do you meet?\"Tom answered,\" No, I have no friend here. But a big boy always stops me at the door and tears my ticket to pieces.\"\n",
            "\n",
            "Question: The big boy  was  _   at the cinema.\n",
            "A. a bookseller\n",
            "B. a policeman\n",
            "C. a shopkeeper\n",
            "D. a worker\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1543\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.001171112060546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1142578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Many boys and girls love watching TV. They spend many hours watching TV every day. But many parents let their children watch TV at special time.\n",
            "TV shows are like books and movies. There are many kinds of TV shows, such as sitcoms, soap opera, sports shows, fashion shows, and so on. A kid can learn good things and bad things from them. Some shows help children know the news all over the world. Children don't have to go to the zoos or the parks to see animals. They can see on TV at home. Some shows teach children how to cook, how to paint or how to study.\n",
            "Many boys and girls think it is interesting to watch TV but it is also interesting to read books , to play games or to visit the friends.\n",
            "\n",
            "Question: Many parents   _  .\n",
            "A. don't let their children watch TV\n",
            "B. ask their children to watch TV only about study\n",
            "C. let their children watch TV only at special time\n",
            "D. want their children to watch TV all night\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1614990234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08465576171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: One day in the eighth grade, I was taking a Math Test on basic trigonometry  . Now for a middle school student, there was nothing basic at all about it. So I had studied for about two hours the night before. After reviewing it for some time, I had started to understand it, so then I closed the book and  _ . However, it was not until midnight that I fell asleep. The next day, when I got the test, it might as well have been written in Serbian (which I don't know how to read). I tried my best to work out the hard problems, but the numbers I came up with were strange. I sat back on my chair and looked for any possible answers, but I could not remember anything or think correctly. I started thinking about my dad coming home from work to find that I failed the test ...\n",
            "\"How could you have failed the test? I am certain that nobody else in the whole class got as bad a grade as you did!\"\n",
            "Naturally I didn't want that to happen. My dad was also really busy at work at present, so I was afraid that this might make him mad. When feeling hopeless, I noticed that my table partner was writing fast on his test. I could see smoke rising up from how fast he was writing. I was attracted to look over at his test, but then the many bad results I had heard about cheating   came into my mind. I reasoned that if I started cheating now, it would be hard to give up that habit during high school. In the end, I decided not to copy his answers, and got a B- on that test. Even though my dad gave me a hard time about it, it would have been a lot worse if he found out that I had given in and cheated.\n",
            "\n",
            "Question: The writer might feel   _   before the Math Test.\n",
            "A. surprised\n",
            "B. relaxed\n",
            "C. worried\n",
            "D. excited\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68509\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0015363693237304688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4849\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12408447265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: How much do you know about Albert Einstein?\n",
            "Albert Einstein, born on March 14, 1579 in Germany, was a great scientist in the world. He was strange because he hated haircuts and new clothes. He believed in peace. All his life, he hated war. However, his most famous idea, E=mc2, helped create the world's most dangerous weapon . Many people think he was the smartest person in the world. But Einstein said that _ \n",
            "What did he like?\n",
            "Einstein liked learning sailing . He sailed in small boats all his life. He once joked, \"Sailing is the sport that takes the least energy!\"\n",
            "When Einstein was a child, his mother made him take violin lessons. At first, he didn't like the violin. But then he learned to love music and became a good violinist. Later, he said, \"Love is the best teacher.\"\n",
            "Why is the sky blue?\n",
            "In 1910, Einstein asked a question which many children often ask, \"Why is the sky blue?\" After his careful research, he answered the question like this: \"It's because light is made up of many colors including blue. When light travels to Earth, gas particles spread the blue light all over the sky.\" His answer is true in physics.\n",
            "\n",
            "Question: Einstein  _   learning sailing and playing the violin.\n",
            "A. was interested in\n",
            "B. looked forward to\n",
            "C. was known for\n",
            "D. had no interest in\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.44287109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 46778\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0011806488037109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: A Chinese couple forced their 4- year- old son to run naked  during a snowstorm with the temperature dipping to -13degC in New York, where they were enjoying a holiday.\n",
            "The boy's father calls himself \"Eagle Dad\". He says he follows the parenting style of eagles, which are known to push their babies off cliffs so that they learn to fly by themselves.\n",
            "Different people have different ideas about it. Some people think it is proper to do like \"Eagle Dad\". The 4- year- old boy, Duoduo, was weak since he was born, so his father tried to help him train to keep strong. But others disagree, they think we should concentrate more on the best ways to teach children in these fast changing times.\n",
            "Different families use different methods to teach children, but all of them should be allowed by the law. Parents should pay full attention to children's physical and metal conditions, and make sure the ways can help their children think and act positively.\n",
            "As long as parents know this, they can use different methods to educate children. Every child has different character. Some children grow up to be success under the guidance of (......)\"eagle dads\" or \"tiger moms\". Others are also successful growing up under more considerate elders.\n",
            "\n",
            "Question: Which of the following is WRONG?\n",
            "A. The event happened in America.\n",
            "B. Duoduo was only four years old.\n",
            "C. The writer didn't agree \"eagle dad's\" educating method.\n",
            "D. Different children have different characters.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 122063\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.021759033203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1280517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: In some places around China,the junior high school graduates have to take a P. E. test. The full marks are usually 30 points and it counts for much in the senior high school entrance exam.\n",
            "In Nanjing the test is held in April. Students have the test in their own schools. Each student is tested on three sports. They can choose long jump, basketball dribbling   or volleyball. The _ is for boys and girls can choose the sit-up. Both boys and girls must skip  in the test.\n",
            "Most students find the test easy and more than 90%of them can get full marks. That's because they have been training for it during the three whole years. Students in Junior Three usually do lots of practice in P. E. classes. The training makes the test easier than it seems to be.\n",
            "Students in Nanjing don't need to run a lot for the test, but students in Beijing must do lots of running for the test. Running is one of the sports in test. So in P. E. classes, they usually run a lot. Sometimes they have to run 3,000 meters in one class. Most teachers and parents welcome the P. E. test. They say it helps students build up their health and it's really useful.\n",
            ",.\n",
            "\n",
            "Question: Students in Nanjing have the P. E. test in   _  .\n",
            "A. spring\n",
            "B. Junior One\n",
            "C. autumn\n",
            "D. Junior Two\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4849\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.094970703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07672119140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Where are the animals having the sports meeting?\n",
            "A. In the forest\n",
            "B. In a park\n",
            "C. In a zoo\n",
            "D. In a school.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13880\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005164146423339844\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38731\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0174407958984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: An Internet game named Happy Farm is becoming more and more popular among young office workers and students. People can work on a farm. They can also grow, water, sell and steal vegetables, flowers, fruits and so on. They can earn some e-money from their working on the farm. Then they can use it to buy more seeds, pets and even houses. Of course, all these are not true, they are only on the Internet.\n",
            "Why do so many young people enjoy the kind of Farm game? I think maybe some of them are afraid of facing the real world, and they have to look for fun from the Internet. Some feel lonely and want to make friends during growing vegetables on the Internet. Some have great fun _ others' vegetables because they needn't work on their farm.\n",
            "Most parents and teachers are worried about these young people and students. Students spend too much time playing the game. It's bad for their health and study.\n",
            "\n",
            "Question: Where do the young people plant vegetables?\n",
            "A. On a real farm.\n",
            "B. In their home's garden.\n",
            "C. On a farm of the Internet.\n",
            "D. Near their houses.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23799\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0282440185546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.89306640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: 108 Wensan Road London, 85 A 100  England\n",
            "March 1st, 2013\n",
            "Dear Lin Tao,\n",
            "I am writing to you in English. I hope you can understand  it.\n",
            "I love studying in London and I have many new friends. Most of them are my classmates. From Monday to Friday, we have English, math, physics and P. E. in the morning. I like English and physics, because they're interesting. I don't like math. It's too boring. At noon, I have to have lunch at school because my home is far from my school. We usually have two classes in the afternoon--art and politics. We finish our classes at 3:30 p. m. After school, my friends and I always play football on the playground. And then we go home by bus.\n",
            "On weekends, we have no classes. We often go to the park and sometimes we go to the movies in the evening. We see movies twice a month. I like some famous  actors like Jackie Chan.\n",
            "Oh, I have no time to write more. Please write back soon.\n",
            "Best wishes,\n",
            "Wang Gang\n",
            ",.\n",
            "\n",
            "Question: How does Wang Gang go home every day?\n",
            "A. On foot.\n",
            "B. By bike.\n",
            "C. By bus.\n",
            "D. By car.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.026519775390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 74406\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0029754638671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: It is well-known that the \"prom\", a formal dance held at the end of high school or college, is an important date in every student's life. What is less well-known is that the word \"prom\" comes from the verb \"to promenade\", which means to walk around, beautifully dressed, in order to attract attention. The idea is that you should see and be seen by others.\n",
            "The prom is not just an American tradition, though most people believe that it started in America. In Canada the event is called a \"formal\". In Britain and Australia the old fashioned word \"dance\" is more and more frequently being referred to as a \"prom\". Most countries have some form of celebration when students finish high school: after all, it means the end of life as a child, and the beginning of life as an adult.\n",
            "The prom is expensive to organize and the tickets can cost students a lot of money. The tradition is that students themselves have to raise the money to pay for it. Selling the students newspapers is one way to raise money; so is taking a part-time job at the weekend.\n",
            "Although the prom should be the experience of a lifetime, it also worries many students. There is the problem of what to wear, who to take as your partner, who will be voted \"prom queen\", etc. And it is not only students who feel worried. What many parents find difficult is the realization that their children's school days are almost over. However, for most people at the prom, once the music starts playing, everyone relaxes and stops worrying.\n",
            "\n",
            "Question: In which country is the prom called a \"formal\"?\n",
            "A. America.\n",
            "B. Canada.\n",
            "C. Britain.\n",
            "D. Australia.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.121337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07318115234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Last Sunday afternoon, I was having dinner in a restaurant when my friend Poor came in. Poor is working in a bank and is quite rich, but he is always borrowing money from his friends and never pays it back. Poor saw me and came to sit at my table. He had never borrowed any money from me. When he was eating, I asked him to lend me two dollars. To my surprise, he gave me the money at once.\"I have never borrowed any money from you,\"Poor said,\"So you can pay for my dinner.\"\n",
            "Read the passage and choose the best answers.(,. )\n",
            "\n",
            "Question: Poor is the name of a man and the writer    _    .\n",
            "A. knows him well\n",
            "B. doesn't know him\n",
            "C. often lends him some money\n",
            "D. often borrows money from him\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47845\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0003643035888671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29039\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0011091232299804688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Foreign visitors are often puzzled   in Japan because most streets there don't have names. In Japan, people use _ in their directions instead of street names. For example, the Japanese will say to travelers, \"Go straight down to the corner. Turn left at the big hotel and go pass a fruit market. The post office is across from the bus stop.\"\n",
            "In the countryside of the American Midwest, usually there are not many landmarks. There are no mountains, so the land is very flat  . In many places there are no towns or buildings within miles. Instead of landmarks, people will tell you directions and distance. In Kansas or lowa, for example, people will say, \"Go north two miles. Turn east, and then go another mile.\"\n",
            "People in Los Angeles, California, have no idea of distance on the map: the measure   distance by means of time, not miles. \"How far away is the post office?\" you ask. \"Oh,\" they answer, \"it's about five minutes from here.\" you say, \"Yes, but how many miles away is it?\" They don't know.\n",
            "People in Greece sometimes do not even try to give directions because visitors seldom understand the Greek language. Instead of giving you the direction, a Greek will often say, \"Follow me.\" Then he'll lead you through the streets of the city to the post office.\n",
            "Sometimes a person doesn't know the answer to your question. What happen in this situation? A New Yorker might say, \"sorry, I have no idea.\" But in Yucatan, Mexico, no one answer, \"I don't know.\" They think that it is impolite. They usually give an answer, often a wrong one. A visitor can get lost in Yucatan.\n",
            "One thing will help you everywhere. You might not understand a person's words, by maybe you can understand his body language. He or she will usually turn and then point in the correct direction.\n",
            "\n",
            "Question: What does the passage mainly talk about?\n",
            "A. we needn't carry a map for travel.\n",
            "B. There are not many landmarks in the American Midwest.\n",
            "C. There are different ways to give directions in different parts of the world.\n",
            "D. Americans and Japanese have different body languages when you ask for directions.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 79767\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11566162109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: The largest number of people in a race\n",
            "The biggest race is in San Francisco, the USA. More than 100,000 people run the 12 kilometers in the race. Another famous race is in London every year. This race is longer and harder, it is more than 42 kilometers, but 25,000 people usually finish it. [:Zxxk.Com]\n",
            "The youngest international player\n",
            "The youngest international player in any sport was Jamaica. Her name was Joy Foster. She was the Jamaican table tennis champion   in1958 when she was 8 years old.\n",
            "The strongest superlative  \n",
            "Have you ever tried walking backwards? The world record for walking backwards is 12,875 kilometers. A man from Texas, the USA, walked backwards for 18 months in 1931--1032. Nobody else has ever broken this record  .\n",
            "The most popular sport\n",
            "The popular sport team game in the world is football. People play football in villages, streets and stadiums all over the world. The most famous football competition is the World Cup. It happens every four years, and nearly 2,000,000,000 people watch it on TV. The first Women's World Cup was in 1991.\n",
            "\n",
            "Question: The San Francisco race is not as   _   as the London race.\n",
            "A. easy\n",
            "B. big\n",
            "C. popular\n",
            "D. long\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 83618\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0024356842041015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 95178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00206756591796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: More and more people around the world are joining in dangerous sports. Some people climbed the highest mountains; some traveled into unknown parts of the world; some sailed small boats across the largest sea. Now some people begin to look for new excitement.\n",
            "Bungee jumping   and motorcycle racing   are quite dangerous sports. Bungee jumping only lasts for a few minutes or even seconds. You jump from a high place, about 200 meters above the ground, and there is a rubber band   tied to your legs. When you jump down, the rubber band pulls you up. About 2,000,000 people around the world have tried bungee jumping.\n",
            "Why do people join in these dangerous sports? Some scientists say that it is because modern life has become safe and it is not interesting. In the past, people lived in danger. They had to go out and look for food, and life was like a fight but was interesting.\n",
            "Many people think that there is little excitement in life. They live and work in safe places, buy food in shops, and there are doctors and hospitals to look after them if they become ill.\n",
            ",.\n",
            "\n",
            "Question: In bungee jumping, you   _  .\n",
            "A. jump up as high as you can\n",
            "B. jump down with a rubber band tied to your legs\n",
            "C. jump down without a rubber band\n",
            "D. jump to the ground\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 103288\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007276535034179688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47830\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05645751953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Wonder why you can get angry so easily while your friend smiles all the time? It's probably because you both have different personalities .\n",
            "Personality is also about how people think, behave, and react   to everything around them from day to day.\n",
            "So what makes people think and behave in certain ways?\n",
            "Part of the reason is that people are born like this. A baby gets its blood type, genes   and other physical things when it's still inside its mother. These things may help decide what the baby will be like.\n",
            "But one's personality doesn't stop here. Family life, school learning and life experiences can also make you the person you are. This doesn't mean it's impossible to change your personality. You can always try to make yourself better. Don't get too worried about your shortcomings  . Just accept them. This is a good way to start making changes.\n",
            "If you don't know how to make friends, find out why. Is it because you're too shy? Tell yourself to smile at people. Start talking to people using warm greetings.\n",
            "Don't give yourself a hard time about it all. It's not easy to change lifelong habits in one night. Keep working at it. One day you'll see that you can turn over a new leaf and be a new you!\n",
            "\n",
            "Question: We know that  _  from the passage.\n",
            "A. people are born the way they'll always be\n",
            "B. a person can try to change his/her personality\n",
            "C. personality decides what a person looks like\n",
            "D. blood type decides what a person will be like\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 11687\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0012359619140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67701\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0006918907165527344\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Three men traveling on a train began a conversition about the world's greatest wonders.\n",
            "\" In my opinion,\" the first man said, \" the Egyptian pyramids are the world's greatest wonder. Although they were built thousands of years ago, they are still standing. And remember: the people who built them had only simple tools. They didn't have the kind of machinery that builders and engineers have today.\n",
            "\" I agree that the Egyptian pyramids are wonderful,\" the second man said, \" But I don't think they're the greatest wonder. I believe computers are more wonderful than the pyramids. They have taken people to the moon and brought them back safely. They carry out mathematical calculations in seconds that would take a person a hundred years to do.\"\n",
            "He turned to the third man and asked, \" What do you think is the greatest wonder in the world?\"\n",
            "The third man thought for a long time, then he said, \" Well, I agree that the pyramids are wonderful, and I agree that computers are wonderful, too. However, in my opinion, the most wonderful thing in the world is the thermos .\"\n",
            "And he took a thermos out of his bag and held it up.\n",
            "The other two men were very surprised. \" A thermos?\" they exclaimed , \" But that's a simple thing.\"\n",
            "\" Oh, no, it's not,\" the third man said, \" in the winter you put in a hot drink and it stays hot, in the summer you put in a cold drink and it stays cold. How does the thermos know whether it is winter or summer?\"\n",
            "\n",
            "Question: The travelers passed the time on the train by talking about   _  .\n",
            "A. the journey\n",
            "B. the train\n",
            "C. themselves\n",
            "D. wonderful things\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 93562\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.037689208984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4856\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04327392578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: A recent study offers a picture of how dangerous it is to get a lift from a teenage driver. Indeed, a 16-year-old driver with three or more passengers is three times as likely to have a fatal accident as a teenager driving alone. However, the possibility of death for drivers between 30 and 59 decreases with each additional (added) passenger.\n",
            "It was also found that the death rates for teenage drivers increased greatly after 10 p.m., and especially after midnight. With passengers in the car, the driver was even more likely to die in a late night accident.\n",
            "Robert Foss, a scientist at the University of North Carolina Highway Safety Research Center, says the higher death rates for teenage drivers have less to do with \"really stupid behavior\" than with just a lack of driving experience. Both he and the author of the study believe that the way to help solve the problem is to have states setting up so-called graduated licensing systems . A graduated license requires that a teenager first prove that he/she is able to drive in the presence of an adult, followed by a period of driving with a limited number of passengers, before graduating to full driving on his own. About half of the states now have some sort of graduated licensing system in place. The systems have reduced teenage driver crashes , according to recent studies.\n",
            "\n",
            "Question: According to Robert Foss, the high death rate of teenage drivers is mainly because   _  .\n",
            "A. their preference for driving at night\n",
            "B. their lack of driving experience\n",
            "C. their careless way of driving\n",
            "D. their driving with passengers\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 51492\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06756591796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1285400390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Jake is going on a trip. He and Mum take a taxi to the airport.\n",
            "\"It's my first plane trip,\" he tells the taxi driver.\n",
            "\"That' s great!\" the taxi driver says.\n",
            "Jake rolls his suitcase onto the plane.\n",
            "\"It's my first plane trip,\" he tells the pilot.\n",
            "\"Welcome aboard,\" the pilot says.\n",
            "Jake finds his seat and buckles his seatbelt . The plane's engines _ Jake opens his backpack and pulls out Panda.\n",
            "\"It's my first plane trip,\" he whispers. He holds Panda's paw.\n",
            "The plane moves faster and faster. Then-Whoosh! On the ground, cars and houses look like toys.\n",
            "Jake smiles. \"Guess what, Panda?\" he says. \"Flying is fun!\"\n",
            "\n",
            "Question: How is Jake feeling in his first plane trip?\n",
            "A. Excited.\n",
            "B. Worried\n",
            "C. Sad\n",
            "D. Afraid\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67365\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003326416015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.28955078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Today is Sunday. Our class meets at seven thirty a.m. at the school gate. We take a bus to Haian Park. The price of the ticket  for each adult  is eighteen yuan, but for each student is half. The park is open from 8 a.m. to 5 p.m. First we play games in the park. And then we have dinner at noon. After that we sit and chat under the trees. At half past three, we go to the Swimming Club. We come back home at about six o'clock in the afternoon because  it is time for all of us to have supper. We are tired  but we are very happy.\n",
            "\n",
            "Question: The park is open for   _  hours a day.\n",
            "A. eight\n",
            "B. nine\n",
            "C. ten\n",
            "D. eleven\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.56591796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1429443359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
            "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
            "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
            "\n",
            "Question: The farmer found all the lambs after  _  .\n",
            "A. he saw the black lamb\n",
            "B. he saw the white lambs\n",
            "C. he heard the sound of the lambs\n",
            "D. they came back home\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 19715\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0085296630859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.046905517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: First, welcome to West Lake! I am glad to serve all of you.\n",
            "Today you come here, you are sure to be attracted by its beauty. Hangzhou is famous for West Lake which is a famous fresh water lake, It lies in central Hangzhou, in Zhejiang Province of eastern China.\n",
            "Traditionally, there are ten best-known spots on the West Lake. They are called Ten Scenes of West Lake by Qianlong Emperor. The West Lake is divided by three causeways called Su Di, Bai Di, and Yanggong Di. First I want to tell you the history of Bai Di.\n",
            "In the middle of the Tang Dynasty, Zhen yuan era(785-804), poet Bai Juyi came to Hangzhou as a governor(,). He realized that the farmland nearby depended on the water of West Lake, but the old dyke had collapsed , the water of West Lake had dried out, and the local farmers suffered drought. He ordered the construction of a causeway of a stronger and taller dyke to solve the drought problem. The lives of local people improved over the following years. Then Bai Juyi had more free time to enjoy the beauty of West Lake. He visited West Lake almost every day. This causeway was later named after Bai Di in Bai Juyi's honor.\n",
            "Next is Su Di. Spring Dawn on the Su Causeway is considered as the first of ten scenes. It was built by Su Dongpo, the great poet, during the Noah Song Dynasty. It is very beautiful in spring.\n",
            "\n",
            "Question: The above words are probably for    _    .\n",
            "A. students\n",
            "B. teachers\n",
            "C. singers\n",
            "D. tourists\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10272216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 78798\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0068206787109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Kate is an American girl. Now she lives in New York with her parents. She lives in a community called Sunny Community. It's on Blue Street. There are five rows  of buildings in the community. Her house is in the first row. She lives on the third floor.\n",
            "There is a post office on Blue Street . Next to it ,there is a bank. Across from the bank ,there is a bookstore. The workers in the bookstore are very friendly to people. Mrs Green works in it. She is Kate's new neighbor. She has a son. His name is Bob. He is in the same class as Kate.\n",
            "Kate thinks the traffic here is very good, because she never meets any accidents here. She loves her community very much.\n",
            "\n",
            "Question: .Kate lives on the   _   floor.\n",
            "A. first\n",
            "B. second\n",
            "C. third\n",
            "D. fourth\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08349609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 127587\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04241943359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Chinese writer Mo Yan won the Nobel Prize in Literature in 2012. Mo, who was born in 1955 from a farmer's family in Gaomi county in Shandong Province, is the first person in China to win the Nobel Prize in Literature. In his early years, life was not easy and he experienced hunger. These things have influence Mo Yan's later writings.\n",
            "Park Geun-hue is 64 years old this year. She was selected the new President of South Korea in December, 2012. She is the country's first female head of state and her term will last five years from 2013. \"I will become a president who puts people's living before anything else,\" she told the cheering people in central Seoul as she accepted her win. \"I will keep my promises.\"\n",
            "Barack Obama (born in Honolulu, Hawaii in 1961), who was elected the 44th President of the United States in 2008, has been elected again to a second term. Obama is a graduate of Columbia University and Harvard Law School. His father was from Kenya. And his mother was born in Wichita, Kansas.\n",
            "\n",
            "Question: The three passages may be from   _  .        .\n",
            "A. an e-mail\n",
            "B. a letter\n",
            "C. news\n",
            "D. an ad\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.17138671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 103787\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0011339187622070312\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: In the days when an ice cream sundae cost much less, a 10-year-old boy entered a hotel coffee shop and sat at a table. A waitress (woman assistant) put a glass of water in front of him. \"How much is an ice cream sundae?\" \"Fifty cents\", replied the waitress. The little boy pulled his hand out of his pocket and studied a number of coins in it. \"How much is a dish of _ ice cream?\" he asked. Some people were now waiting for a table and the waitress was a bit worried. \"Thirty-five cents,\" she said rudely(not politely). The little boy again counted the coins. \"I'll have the plain ice cream,\" he said. The waitress brought the ice cream, put the bill on the table and walked away. The boy finished the ice cream, paid the bill at the counter and went out. When the waitress came back, she began cleaning the table and then she couldn't believe what she had seen. There, placed nearly beside the empty dish, were two five-cent coins and five one-cent coins---her tip .\n",
            "\n",
            "Question: How much money did the boy probably have in his pocket?\n",
            "A. Just fifty cents.\n",
            "B. More than fifty cents.\n",
            "C. Not more than fifty cents.\n",
            "D. Less than forty cents.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.60107421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.09088134765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Why do we come to school? Most of us may say we come to school to study. But to study needs a right way, or you either waste the time or the money. The following are the ways for studying.\n",
            "The best time for reading is morning. In the morning the air is fresh and the mind is clear. For that reason we can get good results.\n",
            "In studying we must have patience . If we have not known a text well, we must read it again. We should not read the next one until we have learned the first one well.\n",
            "When we are studying, we must put our hearts into the books, or we can get nothing from the books while we are reading.\n",
            "We must always ask \"whys\". If it is not well understood, write it down and ask our teachers or our parents, brothers or friends. In any possible way, we must know it completely and what we have learned can be used well and made better.\n",
            "Though there are many ways for studying, yet what I have said above will be enough if we can keep them in heart and do so.\n",
            "\n",
            "Question: Always asking \"whys\" in reading can help us   _  .\n",
            "A. write down the questions\n",
            "B. read in the afternoon\n",
            "C. understand the book better\n",
            "D. remember what we've learned\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38605\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0047760009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9345\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1771240234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: \"High tech\" and \"state of the art\" are two expressions that describe very modern technology. High tech is just a shorter way of saying high technology. And high technology describes any invention or system that uses the newest ideas or discoveries of science and engineering.\n",
            "What is high tech? A computer is high tech. So is a communications satellite. A modern manufacturing     system is surely high tech.\n",
            "High tech became a popular expression in the United States during the early 1980's. Because of improvements in technology, people could buy many new kinds of products in American stores, such as home computers, microwave ovens  , etc. \"State of the art\" is something that is as modern as possible. It is a product that is based on the very latest ways and technology. Something that is \"state of the art\" is the newest possible design or product of a business or industry. A state of the art television set, for example, uses the most modern electronic design and parts. It is the best that one can buy.\n",
            "\"State of the art\" is not a new expression. Engineers have used it for years, to describe the best and most modern way of doing something.\n",
            "Millions of Americans began to use the expression in the late 1970's. The reason was the computer revolution . Every computer company claimed   that its computers were \"state of the art\".\n",
            "Computer technology changes so fast that a state of the art computer today might be old tomorrow. The expression \"state of the art\" has become as common and popular as computers themselves. Now all kinds of products are said to be \"state of the art\".\n",
            "\n",
            "Question: Which of the following statements is NOT true?\n",
            "A. Since the computer revolution, the expression \"state of the art\" has become popular.\n",
            "B. \"State of the art\" means something that is the best one can buy.\n",
            "C. With the development of computer technology, a state of the art computer may easily become unpopular.\n",
            "D. All the producers claim that their products are \"state of the art\" nowadays.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00035381317138671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8934\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0021762847900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Did you notice the number on the book in a library? That number is part of the system used by libraries to organize their collections of books. And it's used in many countries. The number on each book tells you exactly what kind of book it is. This system is also useful for knowing where to go in the library to find a book.\n",
            "In this system, there are ten large groups of books. Each of these groups has its own number, such as 100, 200, etc. So, for example, any books about language will have a number 400. On the other hand, any books about history will have a number 900. So, a number in the hundreds place tells you what general group a book is in. If you find a book that has a number in the 500s, you know it is a book about science.\n",
            "However, science is a big group, so the tens place is used to make a more detailed set of science books. For example, math books are included in the group of science books. Math books all have numbers between 510 and 519. Books about the history of Africa have numbers between 960 and 969.\n",
            "The system uses the ones place to give a more exact limit for the subject of a book. A book on the history of South Africa will have the number 968.\n",
            "As you can see, it is a simple system to use as long as you understand what the numbers mean. With this system, the library can keep its books well organized, and people can easily find the book that they want.\n",
            "\n",
            "Question: Which two numbers would indicate a book about language and a book about science?\n",
            "A. 439 and 493\n",
            "B. 439 and 568\n",
            "C. 530 and 560\n",
            "D. 563 and 436\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2290\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004535675048828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 73187\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0200347900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: My name is David and I have two brothers, Mark and Bruce. We like hamburgers for lunch. Mark and I like French fries, but Bruce doesn't. I don't like eggs for breakfast, but Mark and Bruce do. I like fruit for breakfast. We really like chicken and salad for dinner.\n",
            "\n",
            "Question: _   like chicken.\n",
            "A. David and Mark\n",
            "B. Mark and Bruce\n",
            "C. David and Bruce\n",
            "D. David, Mark, and Bruce\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 55314\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00020503997802734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.67529296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Hunan TV's new program,   Dad,Where Are We Going? has become very popular since last year. The show tells us that fathers should take part in their children's growing-up. In fact, this topic was always mentioned by Zeng Guofan (1811-1872). a famous official during the late Daoguang Period of the Qing Dynasty (1644-1912).\n",
            "Although Zeng spent most of his time away from his family, his letters back home to his children and younger brothers have become famous. In these letters, there are many helpful suggestions on proper behavior . Many of his ways on child education are popular among today's Chinese parents, including reading classical books and so on. His child-raising methods are useful for today's busy fathers. Like Zeng, they also spend most of their time away from home.\n",
            "According to Zeng,  the purpose of education was to learn wisdom from books, rather than getting an official position. Children should know that the most important purpose of studies is to get more knowledge about nature and life.\n",
            "\"But now ,parents just want their children to be rich and powerful. \" Mr. Tang, a writer in China, said.\n",
            "Some teachers say that parents need to build a good relationship with their children. Parents shouldn't force  their children to realize their wishes.\n",
            "In Zeng's letters, he asked his young children to do housework as part of their daily life, even though his children had many helpers. He believed that doing housework would make his children more confident and independent .\n",
            "\n",
            "Question: When was Zeng Guofan born?\n",
            "A. In 1811.\n",
            "B. In 1644.\n",
            "C. In 1872.\n",
            "D. In 1912.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 7.18235969543457e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00012564659118652344\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Men Xue and Yang Yue are good friends. They are in the same school. They are in Class Two , Grade Seven. Men Xue is from Heze,Shandong. She is eleven years old . Her QQ number is 839922660. Yang Yue is from Dalian. She is twelve years old. Her brother   is Harry. He is a worker  . He is twenty-five (25). His telephone number is 18845036918.\n",
            ".\n",
            "\n",
            "Question: Yang Yue's   brother's telephone number is   _   .\n",
            "A. 839922660\n",
            "B. 18245036918\n",
            "C. 18845036918\n",
            "D. 18845039618\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21938\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.45849609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23174\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0020008087158203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: New York City's Chinatown is in the east of Manhattan. About 150,000 people live there. There are many things to do and many places to visit.\n",
            "Shopping in Chinatown\n",
            "You can find all kinds of Chinese things there just like you are in China: food, clothes, jewelry , and so on. On the north side of the Canal Street there are many jewelry shops while on the south side of the Canal Street there are small present shops, handbag shops, watch shops and some big supermarkets.\n",
            "Eating in Chinatown\n",
            "Chinatown has more than 200 restaurants. You can find many Chinese foods there. The foods come from all over China: Beijing, Shanghai, Suzhou, etc.\n",
            "Sightseeing  in Chinatown\n",
            "You should visit Chinatown when you are travelling in New York City. Thousands of people visit Chinatown every day. It is the largest Chinatown in the United States. It is famous for its restaurants, jewelry shops, food markets, and busy streets, such as Canal, Mott, Pell and Doyers Streets. Among them, Canal Street is famous for its handbags.\n",
            "\n",
            "Question: New York City's Chinatown is   _  .\n",
            "A. in the west of Manhattan\n",
            "B. a famous restaurant\n",
            "C. the largest Chinatown in the USA\n",
            "D. a name of a Chinese man in America\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68399\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0006461143493652344\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 45999\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004913330078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Kate is an American girl. Now she lives in New York with her parents. She lives in a community called Sunny Community. It's on Blue Street. There are five rows  of buildings in the community. Her house is in the first row. She lives on the third floor.\n",
            "There is a post office on Blue Street . Next to it ,there is a bank. Across from the bank ,there is a bookstore. The workers in the bookstore are very friendly to people. Mrs Green works in it. She is Kate's new neighbor. She has a son. His name is Bob. He is in the same class as Kate.\n",
            "Kate thinks the traffic here is very good, because she never meets any accidents here. She loves her community very much.\n",
            "\n",
            "Question: Where is the bookstore ?\n",
            "A. Next to the post office\n",
            "B. Next to the bank.\n",
            "C. Behind the post office\n",
            "D. Across from the bank\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2130126953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33554\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00012922286987304688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: I am Steve. I was born and grew up in South Wales. My favorite place to play was out on the hills where my imagination had plenty of space to expand  .\n",
            "My family moved out of Wales when I was thirteen. I went to a new school. One of my subjects was French. Because I had never learned any French, my teacher told me to sit in the corner and write anything I was interested in. That's the time I started writing, just for myself, and I've been writing ever since.\n",
            "I have always loved BIG IDEAS, and so I enjoy writing fantastic stories. And I also write horror   I think they are like the old fairytales   ,and can teach you important things.\n",
            "I am in my forties on the outside, twelve on the inside. I like rock music, Indian and Chinese food, and I enjoy drinking. I live in a small village with my wife Mary, ducks, cats, goats, hens and lots of rabbits. If you'd like to find out more about me and hope to buy any books, go to\n",
            "\n",
            "Question: According to the passage, the write keeps    _\n",
            "A. cats, hens and pigs\n",
            "B. ducks, goats and rabbits\n",
            "C. hens, rabbits and dogs\n",
            "D. rabbits, pigs and cats\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52622\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.029144287109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57014\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.13525390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Today is Saturday. The students of Grade Seven go to school early, but they have no classes. Their teachers are going to take them to the zoo. They take buses there. They get there at 8:30 a.m.\n",
            "The zoo is very beautiful. There are many trees, some hills and a big lake. And they have a big lunch there. It's spring now, and you can see many flowers there, too. There are also many people. They like to watch monkeys. They have a good time there. They leave the zoo at 3:30 p.m.\n",
            "\n",
            "Question: Which of the following is NOT right?\n",
            "A. They must see tigers in the zoo.\n",
            "B. The students go to the zoo in spring.\n",
            "C. They go to the zoo by bus.\n",
            "D. There are lots of people in the zoo.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08935546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 24591\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.02557373046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: My mother used to say things just to make me mad. Like most teenagers, I thought I knew everything. And what I didn't know, I didn't want to be told. For example, if I said I was going to a movie, my mother would roll her eyes. On my way out, she'd shout, \" _ You don't want to learn that the hard way!\" I didn't know what that meant. I thought she just wanted me to stay at home.\n",
            "Many years later I had three teenagers of my own. They thought they knew everything. I would say the same things to them like my mom. That's when I first saw it. My mother wasn't trying to help me.\n",
            "Why do we always have to learn things \"the hard way\"? Why can't we just accept our elders' wisdom? It's a good lesson for anyone. Clearly, I still haven't learned it.\n",
            "Yesterday, I stepped out of the shower when I heard my cell phone ringing in the kitchen. Grabbing a towel, I ran through the house. I grabbed the phone and hit my left foot against the table. The X-ray showed that I'd broken two toes.\n",
            "We all need to slow ourselves down once in a while, before something bad does it for us. My mother was right about a lot of things. I wish I could have told her.\n",
            "\n",
            "Question: The writer felt   _   when mother used to say things.\n",
            "A. happy\n",
            "B. nervous\n",
            "C. angry\n",
            "D. Surprised\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53490\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0004200935363769531\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.084228515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Today is Saturday. The students of Grade Seven go to school early, but they have no classes. Their teachers are going to take them to the zoo. They take buses there. They get there at 8:30 a.m.\n",
            "The zoo is very beautiful. There are many trees, some hills and a big lake. And they have a big lunch there. It's spring now, and you can see many flowers there, too. There are also many people. They like to watch monkeys. They have a good time there. They leave the zoo at 3:30 p.m.\n",
            "\n",
            "Question: The students get to the zoo  _  .\n",
            "A. in the afternoon\n",
            "B. in the morning\n",
            "C. at noon\n",
            "D. in the evening\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2593\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00902557373046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.281494140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: This is Kim and Kate's bedroom. The blue bed is Kate's and the green one is Kim's. They are sisters. Kate's schoolbag is red. It's on the bed. Kim's schoolbag is yellow. It's on the chair. They have a computer. It's on the table. Their alarm clock is on the table, too. There is a baseball under their table. It's Lily's. Lily is Kim and Kate's good friend.\n",
            "\n",
            "Question: _   bed is green.\n",
            "A. Kim's\n",
            "B. Kate's\n",
            "C. Lily's\n",
            "D. Kim's friend's\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 100822\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00034356117248535156\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15144\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01335906982421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Kate is an American girl. Now she lives in New York with her parents. She lives in a community called Sunny Community. It's on Blue Street. There are five rows  of buildings in the community. Her house is in the first row. She lives on the third floor.\n",
            "There is a post office on Blue Street . Next to it ,there is a bank. Across from the bank ,there is a bookstore. The workers in the bookstore are very friendly to people. Mrs Green works in it. She is Kate's new neighbor. She has a son. His name is Bob. He is in the same class as Kate.\n",
            "Kate thinks the traffic here is very good, because she never meets any accidents here. She loves her community very much.\n",
            "\n",
            "Question: Where does Mrs Green work ?\n",
            "A. In a post office.\n",
            "B. In a bank.\n",
            "C. In a bookstore.\n",
            "D. In a school.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.50634765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 79492\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04425048828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: I am an English girl. My name is Lily. I am thirteen. I am at school. Look! This is my school. It is No. 14 Middle School. I am in Class 1, Grade 1. I am in row 3. I am No. 12 at schhol. I have a good friend. She is a girl. Her name is Mary. She is not at school today. I think she is at home. My Chinese teacher is Miss Gao. She is a very good teacher. I don't know her age.\n",
            "\n",
            "Question: Lily's friend   _   a boy\n",
            "A. isn't\n",
            "B. is\n",
            "C. not .\n",
            "D. are\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.045654296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: More and more parents leave their homes and come into the big cities to make money. But their children can't go with them because their children have to go to school in their hometown. They are called home-left children. The problems of home-left children become more and more serious. And it becomes a big _ of our society. The main problem is that some home-left children become very lonely when they don't have their parents' love. And they are too young to tell right or wrong in many things. So they are fooled very easily by others.\n",
            "Xiao Mei , a 14-year-old girl, is a home-left child. Her parents are both in Shanghai. She is in her hometown with her grandpa. She likes playing games on the Internet. Her parents and grandpa only give her money and food. They hardly ever care for her studies. One day, she had no money to pay for the games in the Net bar. So she stole some money from her neighbor. Just at that time, Xiao Fang, a 9-year-old girl saw it. Xiao Mei was afraid that Xiao Fang would tell others about it. She cut Xiao Fang's throat with a knife, and then she went to school just like nothing happened. Luckily, Xiao Fang was saves by doctors. When she opened her eyes and wrote the fact to the policeman with a pencil, everybody was very surprised. This sad story reminds the parents to care for their children no matter how busy they are.\n",
            "Are you one of the home-left children? What do you need from your parents? Food, money or love? I think most children need love mostly. Let's care for the group together.\n",
            ",A, B, C, D,. 5,2,10\n",
            "\n",
            "Question: Which of the following is TRUE according to the passage?\n",
            "A. Home-left children can tell right or wrong easily.\n",
            "B. Home-left children never feel lonely.\n",
            "C. Xiao Fang likes playing games.\n",
            "D. Xiao Mei really needs love.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.174560546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 48344\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00109100341796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Emily Urich 18 years old Canada\n",
            "A lot of teens aren't responsible ,and that's where I'm different. Not just about school but everyday things like being able to pay my own credit card bills on time.\n",
            "The first time I got a cartoon book was on my third birthday. From then on , I fell in deep love with it. And can you guess how many cartoon books I've read? I don't really know the exact number. But I have three full boxes of them under my bed. I also like drawing cartoons and wish to be an art teacher in a sch001.\n",
            "Joe Miller 16 year's old America\n",
            "I'm proud of doing things my own way. So whether somebody wants me to do something or whatever it is , I feel like they're all other people's thoughts , not really mine. But like others , I love reading , too. When I first took skiing lessons , I found it exciting. For ski racing,there's no question I'm better shape than most guys . I think it's fun. I mean,it is a challenge . It's where I picked up the idea of needing a challenge always in my life. In order to improve my skiing skills,I have read many books and magazines about it. No doubt it's my dream to win gold medals in the Olympic Games.\n",
            "An Oi 15 years old China\n",
            "I'm different because I prefer to drop out of the world to create my own world. I'd like to build a house on a mountain. And I choose to live without electricity, a telephone,or even indoor plumbing . I have many hobbies such as traveling,reading , writing and spending time with children. I love children because they are smart and creative. They always have many strange ideas. It makes me excited. I want to do something for Hope Project and become a country school teacher .\n",
            "\n",
            "Question: Who wants to be teacher?\n",
            "A. Emily and Joe.\n",
            "B. Joe and An Qi.\n",
            "C. Emily and An Qi.\n",
            "D. Only An Qi.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.52587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 92658\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0014657974243164062\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: If you do not use your arms or your legs for some time, they will become weak, when you start using them again, they slowly become strong again. Everybody knows that. Yet many people do not seem to know that memory works in the same way.\n",
            "When someone says that he has a good memory, he really means that he keeps his memory in practice by using it. When someone else says that his memory is poor, he really means that he does not give it enough chance to become strong.\n",
            "If a friend says that his arms and legs are weak, we know that it is his own fault. But if he tells us that he has a poor memory, many of us think that his parents may be blamed , and few of us know that it is just his own fault. Have you ever found that some people can't read or write but usually they have better memories ? This is because they cannot read or write and they have to remember things, they cannot write them down in a small notebook. They have to remember days, names, songs and stories, so their memory is the whole time being exercised.\n",
            "So if you want to have a good memory, learn from the people: practise remembering things in a way as other people do.\n",
            "\n",
            "Question: Which of the following is TRUE ?\n",
            "A. Your memory works in the different way as your arms or legs\n",
            "B. Your memory, like your arms or legs, becomes weak if you do not give it enough chance for practice\n",
            "C. Don't learn how to read and write if you want to have a better memory\n",
            "D. A good memory comes from less practice\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 56647\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00011080503463745117\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 89360\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002460479736328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: June 5 is World Environment Day.This makes us pay more attention to our environment and the need to protect it.\n",
            "When Wang Baoxuan,a Beijing high school boy,finishes his exercise books,he does not throw them away.He puts them in the big box in the corner of his classroom.Other students do so.Then the exercise books are sold to a paper-factory in Beijing.The paper is collected and used again by students and teachers in the school.At the same time,the money made from selling the paper goes towards schools in Inner Mongolia  for planting trees and grass.During spring time,the sandstorms often attack here.\n",
            "Wang's school is one of the schools in the capital that take part in the \"green promise\"environmental protection activity.So far,nearly 210,000 students have taken part in the activity,collecting more than 174 kilograms of waste paper.\n",
            "\"There are some environment problems in the city,such as sandstorms.We should do our duty and encourage others to do so as well.\"Said Wang.\n",
            "Vice-premier Zeng Peiyan has written a letter to the teachers and students to encourage them to go on taking part in the environmental protection.\n",
            "\n",
            "Question: What is the money from selling the paper used for?\n",
            "A. Buying new exercise books\n",
            "B. Helping poor students\n",
            "C. Planting trees and grass\n",
            "D. Being their pocket money\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 110368\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00308990478515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.443603515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Do You Want To Be A Musician?\n",
            "Do you want to be a musician? Come to our club, and you'll be very happy in the club. We have _ about the piano, the drums, the bamboo flute,the trumpet, the guitar and the violin for just $20 each.You can also learn to sing , to dance for $25 each. If you like art, you can be satisfied , too. It's just for $30 each!\n",
            "\n",
            "Question: We can't learn about  _  in the club.\n",
            "A. drums\n",
            "B. Bamboo flute\n",
            "C. guitar\n",
            "D. chess\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 618\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005950927734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 51249\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.09686279296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: When someone says, \"Well, I guess I'll have to face the music\", it doesn't mean that he is going to hear a singer. It is something far less happy, as you are called in by your leader to explain why you did this and did that or why you did not do this or that.\n",
            "At some time or another, every one of us has to \"face the music\", especially as children. We can all remember father's angry words \"I want to talk to you.\" And only because we did not listen to him. What a bad thing it was!\n",
            "In the middle or at the end of every term, we students have to \"face the music\". The result of the exam will decide whether we will face the music or not. If you got a \"D\" in the exam, that means parents' cold faces and the contempt  of the classmates.\n",
            "\"To face the music\" is well-known to every American, young or old. It is at least 100 years old. It really means that you have to do something, no matter how terrible the whole thing might be, because you have no choice.\n",
            "\n",
            "Question: \"To face the music\" means \"to  _  \".\n",
            "A. do something that we don't like to\n",
            "B. go to the theatre\n",
            "C. go to the music show\n",
            "D. do something we want to\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003833770751953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 87238\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0009093284606933594\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Men Xue and Yang Yue are good friends. They are in the same school. They are in Class Two , Grade Seven. Men Xue is from Heze,Shandong. She is eleven years old . Her QQ number is 839922660. Yang Yue is from Dalian. She is twelve years old. Her brother   is Harry. He is a worker  . He is twenty-five (25). His telephone number is 18845036918.\n",
            ".\n",
            "\n",
            "Question: Harry is   _   years older than (......) Yang Yue.\n",
            "A. 11.\n",
            "B. 12.\n",
            "C. 13.\n",
            "D. 14.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.438232421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 36544\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.150146484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Li Ruyan, 13 and his classmates in Shanghai did something special last summer. They worked in groups with traffic police at different crossroads in the city. Holding small red flags, the students helped keep order and stopped people from jaywalking .\n",
            "As part of the school project. Li's school has encouraged its students to do more community work.\n",
            "After the half day of exhausting work Li told himself not to jaywalk anymore.\n",
            "\"I think through community work we get to help others and, more importantly, we grow a sense of responsibility ,\" he said.\n",
            "Community service is an important part of education for teenagers around the world. In the US and Canada, high school students need to finish 40 hours of community service before graduation. For those Americans who have finished 1,400 hours of community work, they can be awarded nearly $ 5, 000(33, 000 yuan).\n",
            "Chinese students today do more community work, too. For example, starting from 2010, Sichuan high school students have been asked to do 10 days of community work. It will become part of their school grade.\n",
            "Qian Lijun, 16, and her classmates in Suzhou, Jiangsu went to a local elder care home this winter. They put Spring Festival couplets   on the walls and cheered up the people living there.\n",
            "Li Xiaotian, 15, of Anshan said he used to clear flyers   from telephone poles   with his classmates. They brought tools, towels and buckets and worked for three hours under the summer sun. \"It was tiring, but seeing the clean poles without ugly ads -- we really felt proud,\" he said.\n",
            "\n",
            "Question: From this passage we know that   _  .\n",
            "A. Li Ruyan's school is in the middle of a big city.\n",
            "B. Li Ruyan and his classmates do some community work every day.\n",
            "C. Ruyan and his classmates often hold small flags when they cross the roads.\n",
            "D. Ruyan and his classmates think it is good for them to do some community work.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 122063\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0171661376953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.50341796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 110142\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0006680488586425781\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 116342\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0080108642578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57116\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1378173828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 448\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.60791015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 119942\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00042557716369628906\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99575\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.84228515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 58925\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.873046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33567\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.363037109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52146\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.033172607421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27511\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.468994140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 90539\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00164031982421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42747\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0049896240234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42598\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0258941650390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 66922\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37469\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.001506805419921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08935546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3168\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.001468658447265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94646\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.006824493408203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5131\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.007198333740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 107230\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00679779052734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38411\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.255126953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 16455\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2498779296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 48082\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00536346435546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84137\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.339111328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 50570\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1649169921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 122694\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0033779144287109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52101\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0006537437438964844\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1342\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0214996337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52912\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0035037994384765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 922\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.367431640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 93166\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0038318634033203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68209\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.090087890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 82850\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0943603515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6461\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1329345703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8016\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0016546249389648438\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 26115\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.268798828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 93234\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.000789642333984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 48642\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2978515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77436\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 5.131959915161133e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9459\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.6455078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 889\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.061798095703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5518\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.048065185546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4929\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003032684326171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15940\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00571441650390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61031\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11431884765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 120040\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0013370513916015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91867\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.658203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20218\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0025081634521484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 109614\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00177764892578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 119500\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0173797607421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 88784\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.88330078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84621\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.66455078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 491\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0066375732421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84137\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.078369140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84767\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031768798828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 66439\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0029048919677734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99575\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2467041015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7443\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00087738037109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18755\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0058746337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91674\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0306243896484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 783\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031097412109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35259\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 9.28640365600586e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 24093\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0279388427734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 111748\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007066726684570312\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68155\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3291015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94695\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.006015777587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6443\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0008549690246582031\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77261\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00016367435455322266\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 86974\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005373954772949219\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 32871\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.252685546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 111490\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00024068355560302734\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 49568\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07073974609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4553\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.6953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 103735\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.022216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 36851\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.343017578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42844\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0008058547973632812\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 88784\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.210205078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17277\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.58349609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61214\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00806427001953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 121072\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0041351318359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17277\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2210693359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 93186\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003467559814453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01003265380859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 30173\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 9.98377799987793e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3923\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0178375244140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 95585\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 49532\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1129150390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68155\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.041229248046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 49022\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00022125244140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91329\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00036025047302246094\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10196\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031463623046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9908\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00016891956329345703\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 86870\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002567768096923828\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18673\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.349853515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 63941\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00048422813415527344\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15154\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0065765380859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 81130\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.000885009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 97173\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0015974044799804688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17277\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.087158203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 50607\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0159759521484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 72089\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.278564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102173\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004375457763671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 78829\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07293701171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84489\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0010595321655273438\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 87116\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1292724609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5694\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5966796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54732\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07305908203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 127434\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0963134765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 46783\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0018301010131835938\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 32458\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0794677734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 115089\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04571533203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5255\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75728\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005096435546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3578\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00022530555725097656\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8564\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0014505386352539062\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 113186\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0004856586456298828\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12723\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0309600830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84364\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.008544921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13140\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.057373046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9274\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0018367767333984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31100\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004062652587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 87934\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0027618408203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 90105\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0265045166015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 32850\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.13916015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 69710\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.047393798828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 81874\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.108154296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13140\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0150299072265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 89477\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00850677490234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18673\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.78564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1342\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.53466796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14916\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002982616424560547\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 83255\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00024306774139404297\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1274\n",
            "  Verified Probability: 1.0\n",
            "  Draft Probability: 0.323974609375\n",
            "\n",
            "[DEBUG] Speculation Step 1\n",
            "  Draft Output Token: 88784\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.42578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 1: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2288\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.022125244140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.88916015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21036\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002948760986328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9705\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0011167526245117188\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84621\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.025299072265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9459\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8884\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.028594970703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 49775\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007758140563964844\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5463\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0021800994873046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15034\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.006011962890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 78829\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05194091796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13885\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.294921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91867\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5694\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.76025390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17704\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0380859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38200\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.033050537109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 628\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 83109\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07403564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102952\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004611968994140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21830\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.46875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 87170\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.02349853515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68973\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06378173828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2204\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.57421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 74526\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0015249252319335938\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 78637\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0762939453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: On May 1, a wildfire started in a forest near the Alberta town of Fort McMurray in Canada. Within two days, the fire grew larger and the people who lived in Fort McMurray had to leave their homes. While there have been very few people injured   by the large fire itself, it has been harmful to the community.\n",
            "Canadians in other places have been helping by sending money and _ to the Red Cross. Many people in Alberta have taken in people from Fort McMurray, letting them stay in their homes for free until the fire is put out. Many firefighters are needed to fight the fire and some of them have come from other parts of Canada to help. The brave firefighters were able to save 25,000 homes as well as the hospital and all of the town's schools, according to CBC news.\n",
            "There have been thousands of other acts of kindness towards the people of Fort McMurray. Some musicians, such as Great Big Sea's Alan Doyle, are holding special concerts, with the money going to Fort McMurray people. And companies have been helping, as well. Beer-maker Labatt filled thousands of cans with water--instead of beer--and sent them to the people in Fort McMurray.\n",
            "The fire is huge, spreading over more than 229,000 hectares  , but firefighters say they believe they are starting to get it under control--it is becoming smaller instead of spreading.\n",
            "\n",
            "Question: What is the passage mainly about?\n",
            "A. A big fire in Fort McMurray of Canada.\n",
            "B. The people in Fort McMurray of Canada.\n",
            "C. The firefighters in Fort McMurray of Canada.\n",
            "D. The musicians in Fort McMurray of Canada.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "\n",
            "Explanation:  The passage is about a fire in Fort McMurray of Canada. It is also about people helping each other. The passage tells us that there have been many acts of kindness towards the people of Fort McMurray. The passage is about people helping each other.\n",
            "\n",
            "Question: What is the main idea of the passage?\n",
            "Answer: The main idea of the passage is that people are helping each other.\n",
            "\n",
            "Question: What does the passage tell us?\n",
            "Answer: The passage tells us that people in Fort McMurray have been helping each other by sending money and _ to the Red Cross.\n",
            "\n",
            "Question: What does the passage show?\n",
            "Answer: The passage shows that many people in Canada have been helping the people in Fort McMurray. The people in Fort McMurray have been helped by many people.\n",
            "[Acceptance Rate]: 0.0010416666666666667\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8555\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00203704833984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.061859130859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: We know exercise is important in our life. Everyone needs to do exercise. Doctors say doing sports is good for us. Sports can make our body healthy.\n",
            "It's very useful  for children, too. It can make children clever. This means they will do well in study and schoolwork.\n",
            "There are easy ways to exercise. You can walk, run, or only jump. When you do exercise, you need to know what you are doing. Don't do sports too much at a time. Try all kinds of sports and look for one, two or even three sports you like. You can also exercise at the gym . Exercise can be fun. It can make you happy. Friends can exercise together at a gym or they can do sports together at any place they like.\n",
            "\n",
            "Question: Sports can   _  .\n",
            "A. make our body healthy\n",
            "B. take too much of our time\n",
            "C. make everyone do well at school\n",
            "D. be very boring  for children\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0134124755859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.090576171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Come and see the India elephants and the new tigers from America. The bears are waiting to meet you, and the monkeys from China are waiting to throw  things to you. The lovely dogs from Australia are waiting to laugh at you. The giraffes from Brazil are waiting to look down on you.\n",
            "Tickets                             Open time\n",
            "Grown-up: $2.00             9:00a.m--4:00p.m\n",
            "Children :over 12 $1.00               Except Friday\n",
            "Under12 Free                   10:00a.m--3:00p.m\n",
            "Keep the zoo clean!\n",
            "Don't touch  , give good food or go near the animals!\n",
            "\n",
            "Question: From the passage we can guess the animal \"giraffe \"must be very  _  .\n",
            "A. fat\n",
            "B. long\n",
            "C. strong\n",
            "D. tall\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 81649\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0016384124755859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 40438\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.000492095947265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: If you could see a movie of your life before you lived it, would you want to live it? Probably not. The excitement of living is that you don't know what's coming.\n",
            "Sure, it's hard to see uncertainty in such active light when you're out of work, or when you feel like you're failing. But uncertainty is really another word for chance.\n",
            "When Allison graduated from Harvard, she had chances all over the place but had no idea what she wanted to do. She took a job in consulting ,but she knew she wouldn't stay there. She took the GRE and scored so high that she was able to increase her income by teaching students. Still, she didn't think she wanted to go to graduate school . Allison knew she wasn't doing what she wanted, but she didn't know what she wanted.\n",
            "She worried. All her friends were going to graduate school or starting their own businesses. She was lost and felt that she would never find anything out. After six years, Allison, by having a plan in mind, got married, moved to the Midwest, and used her consulting experience to get a great job. Allison realized that she spent her years finding her way: time well spent, and time we must all take if  we're being honest with ourselves. The only way to lead an interesting life is to face uncertainty and make a choice. Otherwise your life is not your own - it is a path someone else has chosen. Moments of uncertainty are when you create your life, and when you become who you are. Uncertainty usually begins with a job hunt, but it doesn't end there. Every new role we take on means another round of uncertainty. Instead of fearing it, you should find some ways to deal with uncertainty\n",
            "\n",
            "Question: How did Allison feel about her six years' working experience?\n",
            "A. Uncertain.\n",
            "B. Amazed.\n",
            "C. Sorry.\n",
            "D. Satisfied.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.090576171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1849365234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: There is lots of junk  in space .Some of it is from rockets. In 1996, a rocket broke into about 300,000 small pieces. So far, scientists have found over 10,000 man-made pieces flying around in space. Only 6-7%of them are satellites and space probes  . Astronauts also lose small things while working in space. In 1965, during the first American spacewalk , astronaut Edward White lost a glove .For a month, the glove stayed in space, travelling at a speed of 28,000 kilometers per hour .It became the most dangerous piece of clothing for the Earth in history it flew away. Things move very fast in space. If they hit one another, it can be dangerous .A little piece of paint from a satellite once made a hole in a spacecraft window. Last year two US spacecraft dropped some bolts , and scientists on the Earth worried a lot. Luckily the bolts floated  away into space. They couldn't hit the spacecraft.\n",
            ",.\n",
            "\n",
            "Question: In space all the things move very    _    .\n",
            "A. fast\n",
            "B. slow\n",
            "C. hard\n",
            "D. high\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.55615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85156\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003253936767578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: An artist who did not have much money, but was a very kind man, was coming home by train one day. He gave his last few coins to a beggar, but then he saw another one, and forgot that he did not have any money. He asked the man if he would like to have lunch with him, and the beggar accepted, so they went into a small restaurant and had a good meal. At the end, the artist could not pay the bill, of course, so the beggar had to do so.\n",
            "The artist was very unhappy about this, so he said to the beggar, \"Come home with me in a taxi, my friend, and I'll give you back the money for money.\"\n",
            "\"Oh, no!\" the beggar answered quickly. \"I had to pay for your lunch, but I'm not going to pay for your taxi home either!\"\n",
            "\n",
            "Question: The artist in this story was   _  .\n",
            "A. a man of wealth\n",
            "B. a funny man\n",
            "C. a kind man\n",
            "D. a cheat\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3653\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0044708251953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12615\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0043487548828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Dan was the doorman of a club in a big city. Every day, thousands of people passed his door, and a lot of them stopped and asked him, \"What's the time, please?\"\n",
            "After a few months, Dan said to himself, \"I'm not going to answer all those stupid people any more. I'm going to buy a big clock and put it on the wall here.\" Then he did so.\n",
            "\"Now people aren't going to stop and ask me the time.\" He thought happily.\n",
            "But after that, a lot of people stopped, looked at the clock and asked Dan, \"Is that clock right?\"\n",
            "\n",
            "Question: At last, did Dan solve   his problem?\n",
            "A. Yes, he did\n",
            "B. Maybe\n",
            "C. No, he didn't\n",
            "D. Of course\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.47705078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.342041015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: 108 Wensan Road London, 85 A 100  England\n",
            "March 1st, 2013\n",
            "Dear Lin Tao,\n",
            "I am writing to you in English. I hope you can understand  it.\n",
            "I love studying in London and I have many new friends. Most of them are my classmates. From Monday to Friday, we have English, math, physics and P. E. in the morning. I like English and physics, because they're interesting. I don't like math. It's too boring. At noon, I have to have lunch at school because my home is far from my school. We usually have two classes in the afternoon--art and politics. We finish our classes at 3:30 p. m. After school, my friends and I always play football on the playground. And then we go home by bus.\n",
            "On weekends, we have no classes. We often go to the park and sometimes we go to the movies in the evening. We see movies twice a month. I like some famous  actors like Jackie Chan.\n",
            "Oh, I have no time to write more. Please write back soon.\n",
            "Best wishes,\n",
            "Wang Gang\n",
            ",.\n",
            "\n",
            "Question: Wang Gang and his friends go to the movies   _  .\n",
            "A. once a week\n",
            "B. once a month\n",
            "C. twice a week\n",
            "D. twice a month\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13811\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01593017578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: The widespread number of food scandals in  China is making many people pause before they put their chopsticks in their mouths.They are wondering if the food they are eating is clean,healthy and nutritious  or does it contain  something harmful that will cause disease?\n",
            "Most of the food we eat today is processed food .That means the foods we buy in stores and supermarkets,especially packaged foods,are prepared in factories.Chemicals are added to the foods in these factories to  make them look better,taste better and last longer on the shelf.The chemicals are supposed to be harmless and there are laws that regulate  which chemicals can and cannot be used.Unfortunately,some producers do not obey the laws.\n",
            "A producer of steamed buns in Zhejiang Province was recently discovered to be breaking the law.He was adding yellow dye and other banned chemicals to the buns.He was also taking old buns and using them to make new buns.Most of the buns were sold to schools and eaten by students...like you!\n",
            "Why did he do it? Why did he break the law and endanger people's  health? The answer is simple:he wanted to make more money.It was a moral failing,and this is at the heart of the food scandals in China.Too many people focus on making money and not on the effects their actions can have on others.\n",
            "\n",
            "Question: According to the passage,which is NOT true?\n",
            "A. Most of the food we eat today is prepared in factories.\n",
            "B. There are laws that regulate which chemicals can and cannot be used.\n",
            "C. The food scandals in China are making many people worry about the food safety.\n",
            "D. Most of the buns were sold to schools and eaten by students in Zhejiang Province.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42327\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.183837890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 40034\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00429534912109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Have you ever heard someone use the phrase \"once in a blue moon\"? People use this expression to describe something that they do not do very often. For example, someone might say that he tries to avoid eating sweets because they are unhealthy, but will eat chocolate \"once in a blue moon\". Or someone who does not usually like to go to the beach might say \"I visit the shore once in a moon.\" While many people use this phrase, not everyone knows the meaning behind it.\n",
            "The first thing to know is that the moon itself is never really blue. This is just an expression. In fact, the phrase \"blue moon\" has to do with the shape of the moon, not the color.\n",
            "As the moon travels around the earth, it appears to change shape. We associate names with certain shapes of the moon. For example, when we can see a small part of the moon, it is called a crescent moon. A crescent is a shape that looks like the tip of a fingernail. When we cannot see the moon at all, it is called a new moon. When we can see the whole moon, it is called a full moon. Usually, there is only one full moon every month. Sometimes, however, there will be two full moons in one month. When this happens, the second full moon is called a \"blue moon\".\n",
            "Over the next 20 years, there will only be 15 blue moons. As you can see, a blue moon is a very rare event. _ has led people to use the expression \"once in a blue moon\" to other very rare events in their lives.\n",
            "\n",
            "Question: How often will a blue moon happen over the next twenty years?\n",
            "A. Once a year.\n",
            "B. Less than once a year.\n",
            "C. More than once a year.\n",
            "D. At least twice a year.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1368408203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13638\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0006799697875976562\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: My friends like different clothes. Sue likes red clothes. She is often in a red skirt and red shoes. Mina likes white clothes. She is in a white shirt. Her sister Emma likes to wear a green skirt. She looks nice. David often wears a white cap and black pants. Peter often wears a white coat and black pants.\n",
            ",.\n",
            "\n",
            "Question: David often wears a   _  .\n",
            "A. black pants\n",
            "B. black cap\n",
            "C. white cap\n",
            "D. white pants\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00426483154296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47830\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0249481201171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: People  usually  talk  about  two  groups  of  colours: warm  colours  and  cool  colours.  Scientists  think  that  there  are  also  two  kinds  of  people: people  who  prefer  warm  colours  and  people  who  prefer  cool  colours. The  warm  colours  are  red , orange  and  yellow.  Where  there  are  warm  colours  and  a  lot  of  lights , people  usually  want  to  be  active.  People  think  that  red , for  example , is  exciting . Sociable  people , those  who  like  to  be  with  others , like  red . Scientists  also  find  that  warm  colours  can  produce  a  comfortable  feeling  and  that  time  seems to pass quickly  in  a  room  with  warm  colours  than  with  cool  colours . So  a  warm  colour , such as red or orange , is a good choice for a living  room or restaurant.\n",
            "The  cool  colours  are  green , blue  and  violet . These  colours , unlike  warm  colours , are  relaxing . Where  there  are  cool  colours , people  are  usually  quiet . People  who  like  to  spend  time  alone  often  prefer  blue . Cool  colours  are  better for offices because it  can make people  who  are  working  feel  relaxed  and  calm.\n",
            "\n",
            "Question: According to  this  passage , people  who  prefer  to  be  quiet  probably     .\n",
            "A. like the colour orange\n",
            "B. like the colour blue\n",
            "C. prefer warm colours\n",
            "D. are usually active\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.53076171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20865\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0033740997314453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Thursday, April 24th\n",
            "We got to the clean, lovely city of Yangzhou early in the morning. This is our first trip to China. All the different smells attract our attention to the local food. We are going to try something special for dinner tonight. The hotel we are staying in is not expensive but very clean. We plan to stay here for a few days, visit some places in the city, and then travel to the Great Wall in the north.\n",
            "Sunday, April 27th\n",
            "We visited the famous Slender West Lake   which was crowded with visit ors from all over the world, and bought a lot of toys for our friends outside the gate of the park. Everything is so colourful, and we have taken hundreds of photos already! Later today we will do the famous foot massage   and then leave for the Great Wall. We will take the night train north, stay in Beijing for two days, and then catch a bus to the Great Wall.\n",
            "Wednesday, April 30th\n",
            "Our trip to the Great Wall was long and boring. We visited a small village in the mountains. People in the village love the quiet life. They are the kindest people I had ever met. They always smile and say \"Hello\". Ralph and I can speak only a few words in Ch inese, so smiling is the best way to show our kindness.\n",
            "\n",
            "Question: The writer didn't   _  in Yangzhou.\n",
            "A. taste delicious food\n",
            "B. visit places of interest\n",
            "C. do foot massage\n",
            "D. climb mountains\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.03839111328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.6376953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: Wang Hao is in   _   now.\n",
            "A. England\n",
            "B. the USA\n",
            "C. Jiangsu\n",
            "D. Beijing\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 613\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002971649169921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Joe, an outgoing girl, is from a rich family. Therefore she can afford almost everything. But Joe's parents are too busy to spend enough time with her, which makes Joe more than lonely. So, she always goes to WeChat. On WeChat, she can do a lot of things like buying things, reading articles, and making friends with those she either knows or not.\n",
            "She uses the name Linda on WeChat and has made a lot of friends there. Last year Joe made a foreign friend on WeChat. Her name was Catherine and she lived in Sydney. Catherine once sent a picture of \"herself\": a tall, good-looking young woman with big eyes. Catherine and Joe were both interested in rock music and modern dance. So, they liked each other very much.\n",
            "When Joe's father told her that he was meeting a client in Sydney this summer, she went with him to give Catherine a surprise for her birthday. When Joe came to Catherine's house in Sydney, she found that her foreign \"girlfriend\" was a ten-year-old boy named Jim! What a surprise!\n",
            "\n",
            "Question: What's the best title of the passage?\n",
            "A. A Sad Girl\n",
            "B. A Real Surprise\n",
            "C. A Special Foreigner\n",
            "D. A Boy Called Jim\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2094\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0030231475830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38731\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.019744873046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Dear readers,\n",
            "Imagine a little girl who knows there will not be enough food for dinner, who can't fill her stomach with water because it's polluted  , and who has watched lives slipped away   from her father, little brother and sister because the family is too poor to see a doctor. She would gladly walk miles to school, but her mother needs her badly   at home. What will her future be?\n",
            "Is it hard to believe? For Maria Pestora, it is real life.\n",
            "But with just 52 pennies a day, you can sponsor   a child like Maria. Through\"Save the Children\",you can help Maria's mother get the tools and ways she needs to turn their poor food into a good dinner, and get the money she needs to buy clothes and school things for Maria.\n",
            "To help Maria most, your money is put together with that of other sponsors. Building schools, hospitals, bringing in clean water is what\"Save the Children\"has been working on since 1932.\n",
            "For you there are many rewards. You have the chance to write to or hear from the child you sponsored, to receive photos or progress reports, to know you are reaching out to another person, not with a handout  , but a hand up. That's how \"Save the Children\" works. But without you, it can't work. Please take a moment now to fill in and post the form below to help a child like Maria.\n",
            "It can make a difference in his/her life and yours.\n",
            "For the children\n",
            "David Li Guyer\n",
            ",.\n",
            "\n",
            "Question: What's Maria's most serious problem?\n",
            "A. She has no chance to go to school.\n",
            "B. Her father died of a serious disease.\n",
            "C. Hard work has made her suffer a lot.\n",
            "D. Her mother needs her badly at home.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.31201171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 49262\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002868175506591797\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: John gets up early from Monday to Saturday, because he must go to school before 7:30 on weekdays  and go to Drawing Club at 8:00 on Saturday mornings. He usually goes to the bookshop on Saturday afternoon, and after dinner he watches TV until  midnight .\n",
            "He doesn't get up early on Sundays. John's parents both work on Sundays. John always watches TV after he gets up. Then he usually goes to KFC to have a hamburger and some juice for lunch. After that, he goes back home and starts to play computer games until his parents come back. He does his homework after dinner. He usually has lots of weekend homework, so he must spend three hours on it. He usually goes to bed at about 11:00 p.m. on Sundays. He often complains  he has too much homework to do.\n",
            ",.\n",
            "\n",
            "Question: How often does John need to get up early?\n",
            "A. Every day.\n",
            "B. Five days a week.\n",
            "C. Only on Saturdays and Sundays.\n",
            "D. Six days a week.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 51492\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0073089599609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07135009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Music is an important part in our life. We may feel boring without music. Today when you go to stores, stations, restaurants and other places, do you notice music playing at any of these places? The answer must be \"Yes\". And you might even hear music in an office or on a farm.\n",
            "I like many kinds of music. Classical music is great. Rock music is fast. Light music is relaxing. But I like folk music best. It sounds very beautiful. It can bring me into the dream land. It can make me relax and forget all the problems. It makes me learn better and helps me to be more active. It is true that I learn better when I am relaxed.\n",
            "Music can also influence  people's behavior . Classical music makes people feel rich . When a restaurant plays classical music, people spend more money on food and drinks. When the restaurant plays modern music, people spend less money. Without music, people spend evenless. Restaurants can make more money in this way.\n",
            "\n",
            "Question: The habit of listening to music can make the writer   _  .\n",
            "A. slow in action\n",
            "B. care about hobby\n",
            "C. more active\n",
            "D. worry about studies\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 11687\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12347412109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67549\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 6.41942024230957e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Li Ruyan, 13 and his classmates in Shanghai did something special last summer. They worked in groups with traffic police at different crossroads in the city. Holding small red flags, the students helped keep order and stopped people from jaywalking .\n",
            "As part of the school project. Li's school has encouraged its students to do more community work.\n",
            "After the half day of exhausting work Li told himself not to jaywalk anymore.\n",
            "\"I think through community work we get to help others and, more importantly, we grow a sense of responsibility ,\" he said.\n",
            "Community service is an important part of education for teenagers around the world. In the US and Canada, high school students need to finish 40 hours of community service before graduation. For those Americans who have finished 1,400 hours of community work, they can be awarded nearly $ 5, 000(33, 000 yuan).\n",
            "Chinese students today do more community work, too. For example, starting from 2010, Sichuan high school students have been asked to do 10 days of community work. It will become part of their school grade.\n",
            "Qian Lijun, 16, and her classmates in Suzhou, Jiangsu went to a local elder care home this winter. They put Spring Festival couplets   on the walls and cheered up the people living there.\n",
            "Li Xiaotian, 15, of Anshan said he used to clear flyers   from telephone poles   with his classmates. They brought tools, towels and buckets and worked for three hours under the summer sun. \"It was tiring, but seeing the clean poles without ugly ads -- we really felt proud,\" he said.\n",
            "\n",
            "Question: What was the special thing Li Ruyan did last summer?\n",
            "A. He joined a special group of Class13.\n",
            "B. He become a policeman.\n",
            "C. He helped the traffic police at a crossroad.\n",
            "D. He stopped people from talking.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28206\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004726409912109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.55859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Food is a major part of every culture. After all, everyone needs to eat! But each country has its own traditions on what people eat and when.\n",
            "Egypt\n",
            "Egyptians commonly start the day with a drink, sometimes going with bread. Breakfast can be eaten any time after this but before the day's main meal. In the past, this main meal was served at around 3:00 p.m. But now people work longer hours and eat when they get home at around 6:00 p.m. Dinner parties are held later, around 9:00 p.m.\n",
            "Most Egyptian meals include bread or ice, cooked vegetables and beans or meat.\n",
            "France\n",
            "France is known for its fine cooking, and its people take food seriously. Most eat three meals a day at fixed times and never snack between meals. Breakfast is a light meal of bread and coffee. They eat lunch at around 1:00 p.m. and a dinner with multiple courses after 8:00 p.m.\n",
            "The French consider eating a social activity. Eating alone is hard to see, and eating while doing something else is unheard-of. The French take time to enjoy their meals and visitors should do the same.\n",
            "Brazil\n",
            "Like the French, Brazilians usually eat a light breakfast. Lunch, the largest meal of the day, usually consists of meat, rice, potatoes, beans and vegetables. Between 6:00 p.m. and 8:00 p.m., people enjoy a smaller meal with their families.\n",
            "Brazilians don't mind eating a hurried or light meal and sometimes buy food from street carts  . But they always finish eating before walking away.\n",
            "The United States\n",
            "American's ancestors came from many countries, so American eating habits differ. Some take time to prepare and eat a hot breakfast. Others take a bagel   while rushing out the door or just _ . For lunch, most Americans eat a sandwich or leftovers. Traditionally, families got together for a large evening meal around 6:00, but now busy schedules force many families to eat in turns. American restaurant servings tend to be huge. But you don't have to finish them; taking leftovers home is common.\n",
            "\n",
            "Question: People of Egypt usually start a day with   _  .\n",
            "A. a drink\n",
            "B. a bagel\n",
            "C. some meat\n",
            "D. some vegetables\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29978\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001074075698852539\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12333\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0119476318359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: The city of Yangzhou came into being at the Spring and Autumn Period ( about 500 AC ).\n",
            "As the key transportation link at joint place of the Great Canal ( Beijing-Hangzhou) and Changjiang (Yangtze River), Yangzhou has been from the Sui Dynasty (600 AD.) an economically rich city, and then reached its top in the Tang Dynasty. At that time Yangzhou was a famous port and one of few biggest cities in East Asia.\n",
            "With the improvement of the local economy and easy transportation way, there happened in the history a special local culture, which has an important place in Chinese culture. Many famous men of letters, poets, artists, scholars , statesmen, scientists and national heroes in the history were born in, lived in or had connection with Yangzhou. Li Bai, one of the greatest Chinese poets visited and stayed in Yangzhou several times in his life and one of his famous poems about Yangzhou has been so popular that Chinese of all ages can sing it and has become a symbol of Yangzhou . Zheng Banqiao, a famous Chinese painting painter in the Qing Dynasty heading a group called \"Eight Eccentrics\", had strongly influenced Chinese paintings. Wang Zhong and Yuan Yuan and some other scholars formed school of Yangzhou Scholars and achieved great success in the study of classic Chinese and writing. Zhu Ziqing, one of most famous modern Chinese writers and scholars, had always been proud of himself as a native of Yangzhou and thanked the city for being nourished  by its rich culture. Quite a few other names you may come across frequently in the study of Chinese culture and history have connection with Yangzhou . Yangzhou was so attractive and important that many Chinese emperors in history had come specially to visit or check the city. Emperor Suiyang, who ordered to cut the Great Canal so that he could come more easily and quickly, died on his last trip to the city and buried  here. Emperor Qianlong had come all the way from the north and visited the city nine times.\n",
            "\n",
            "Question: We can infer the poem mentioned in this passage by Li Bai is   _  .\n",
            "A. <<>>\n",
            "B. <<>>\n",
            "C. <<>>\n",
            "D. <<>>\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2357\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.028228759765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0804443359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: There was a new maths teacher and some new students in the school. One of the new students named Karl was very _ . The other students tried to explain   numbers to him, but he didn't understand.\n",
            "Before Karl arrived, maths was the most boring lesson of all. Now it was great fun. The children would listen to Karl and correct his mistakes. They all wanted to be the first to find his mistakes, and then tried to think up the best ways to explain them.\n",
            "But little Lewis was sure that Karl felt sad and wanted to talk with him. So, one day, he decided to walk after Karl after school. Lewis was sure he would see him crying. On the way home, Karl walked a few minutes to a park, and there he waited for someone to meet him...\n",
            "It was the new teacher!\n",
            "They went off, hand in hand. Lewis could hear them talking about maths. And that stupid Karl knew everything about it, and even much more than anyone else in the class!\n",
            "\n",
            "Question: Which lesson was the most boring of all before Karl arrived?\n",
            "A. Chinese.\n",
            "B. English.\n",
            "C. Maths.\n",
            "D. Music.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.92822265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 32624\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00911712646484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
            "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
            "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
            "\n",
            "Question: What can we learn from the story?\n",
            "A. Appearance is the most important in our life.\n",
            "B. A friend in need is a friend indeed.\n",
            "C. Don t tell a person by his appearance.\n",
            "D. Many hands make light work.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 40997\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0017347335815429688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1007080078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: English breakfast is a very big meal--eggs, tomatoes, tea, coffee... For many people, lunch is a quick  meal. In cities there are a lot of sandwich  bars . People can buy sandwiches there. Students can have a hot meal at school, but many just take a sandwich, a drink and some fruit from home.\n",
            "\"Tea\" means two things. It is a drink and a meal! Some people have afternoon tea, with sandwiches, cakes and a cup of tea.\n",
            "They usually have dinner quite early , between 6:00 and 8:00(......), and often all the family eat together .\n",
            "People often get take-away  meals--they buy the food outside\n",
            "\n",
            "Question: Students usually have lunch   _  .\n",
            "A. at home\n",
            "B. at school\n",
            "C. outside\n",
            "D. in the restaurant\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28206\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.322021484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2841796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: It?s always hard to say goodbye to someone you love. In Washington DC, US, local   zoo-goers are sad about the news that their superstar panda Tai Shan is going to leave the National Zoo.\n",
            "At a morning meeting on December 4, zoo director  Steven Montfort said that the black-eared bear would be going off to China sometime over the winter, under an agreement with the Chinese government.\n",
            "Tai Shan, whose name means \"peaceful mountain,\" was born at the DC zoo on July 9, 2005. He has been loved by zoo-goers since his first public show in December of that year.\n",
            "But under the agreement that brought his mother, Mei Xiang, and father, Tian Tian, to the zoo from China, all three belong to   China.\n",
            "Tai Shan should have been returned to China when he was 2. But China gave him two extensions   to stay at the National Zoo. Tai is old enough to breed  . So it?s time for him to come back to China and join a program to try to increase the panda population.\n",
            "The National Zoo has tried to breed Mei Xiang a few times since Tai Shan was born, without success. Montfort said the zoo would try again soon in the hope of producing another baby panda. \"We?re hopeful every year,\" he said.\n",
            "\n",
            "Question: Where can the passage probably be taken from?\n",
            "A. A dictionary.\n",
            "B. A science book.\n",
            "C. A newspaper.\n",
            "D. A novel.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10968017578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.55615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Mike was ten years old and he went to the Ashland School. He was very good at football, so he was chosen  by the school team. He always played very well in the matches, and he scored a lot of goals  . One day Mike said to his parents, \"we will play football with the Gum Tree School .Will you come and cheer us on?\" And they agreed to come.\n",
            "The match was in the park. The Gum Tree School team wore green shirts and blue shorts  , and Mike's team wore white shirts and red shorts. In the first two minutes of the match, Mike ran with the ball and kicked it into the goal. All the Ashland School boys and their families were very excited about it.\n",
            "After that, Mike scored two goals before half time. Then in the second half of the match he almost scored another goal, but he kicked the ball with his foot lightly , and the goalkeeper caught it easily and threw it out.\n",
            "After the match, Mike's father said to him, \"You missed a good chance   to score another goal, Mike. Why did you kick it lightly?\"\n",
            "\"Because there were tears   in the goalkeeper's eyes,\" Mike answered.\n",
            "\n",
            "Question: What color shirts did Mike's team wear?\n",
            "A. Blue\n",
            "B. Green\n",
            "C. Red\n",
            "D. White\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65659\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01348114013671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 36426\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00015628337860107422\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Do you obey the rules in your school? What do you think of your school rules? Are you allowed to dye   hair? A lot of school rules are similar around the world, but some are different. Some students may enjoy more freedom in some countries. But freedom doesn't mean \"no rules\". Every school has its own rules.\n",
            "There are some rules in Japanese schools. The students are not allowed to dye their hair and are supposed to keep their hair black. They are not allowed to wear earrings either. Almost all schools used to require students to wear school uniforms but now half of the schools require uniforms. The students feel happy to wear all kinds of clothes. The students must get to school on time. If they are late, they cannot get into the school because the school gate is closed. In Japan, students are not allowed to have part-time jobs.\n",
            "American schools have their own rules too. For example, at Morton High School, students are not allowed to choose their own clothes. They must get to school or leave school on time. Food, drinks or snacks shouldn't be taken into the classroom. They must wear sports shoes in PE class. They are supposed to keep quiet on the school bus. In America, the students can have part-time jobs in their free time. (<<>> )\n",
            "\n",
            "Question: If you are a student in Japan,   _  .\n",
            "A. you can wear earrings\n",
            "B. you must wear sports shoes every day\n",
            "C. you are allowed to have part-time jobs\n",
            "D. you can't have your hair dyed\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " D\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: D, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05877685546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 32624\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.020477294921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: The Monkey Buffet Festival is on the last Sunday of November. It is a great day for monkeys in Thailand  . The festival has a history of 25 years. People there think monkeys can bring good luck to them. So, to thank monkeys, they have this special festival.\n",
            "On that day every year, people put lots of fruit, vegetables, cakes and even drinks on the tables outside. They are all for monkeys. Many people come to see the monkeys on that day.\n",
            "During the festival, there are a lot of interesting activities about monkeys. Young people always dress like monkeys and they sing and dance and play some music on the street.\n",
            "Monkeys always live in groups. Most of them live in the trees. They are good at running and jumping. They eat fruit, vegetables, flowers and birds' eggs. Monkeys are clever. Do you think so?\n",
            "\n",
            "Question: What do people always do on that day?\n",
            "A. Eat all kinds of food.\n",
            "B. Sing and dance.\n",
            "C. Play with monkeys.\n",
            "D. Run and jump.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3653\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005207061767578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4088\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0195159912109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Just as in face-to-face communication, there are some basic rules of behavior  that should be followed on the Internet. The basic rule is simple: treat others in the same way you would want to be treated. Imagine how you'd feel if you were in the other person's shoes.\n",
            "For anything you're about to send: ask yourself, \" Would I say that to the person's face?\" If the answer is no, rewrite and reread. If someone in the chat room is rude to you, you needn't to fire back. You should either ignore  the person, or use your chat software to block their messages. Remember to respect the beliefs and opinions of others in the chat room.\n",
            "Everyone was new to the network once. Offer advice when asked by newcomers, as they may not be sure what to do or how to communicate. When someone makes a mistake, be kind about it. If you do decide to tell someone about the mistake, point it out politely. At the same time, if you find you are wrong, be sure to correct yourself and apologize to those that you have offended . You'd better not ask others questions about their age, sex and families. Unless you know the person very well, and you are both comfortable with sharing personal information, or don't ask such questions.\n",
            "\n",
            "Question: You should point out someone's mistake   _  .\n",
            "A. politely\n",
            "B. rudely\n",
            "C. patiently\n",
            "D. seriously\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31557\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0004677772521972656\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12333\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00110626220703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94002\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0269317626953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5697\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1480712890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 39904\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00403594970703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67785\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1348876953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 58521\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.068115234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.544921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1866\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.372314453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 121590\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0003714561462402344\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10010\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0033550262451171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15972\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.09100341796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 127751\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.042724609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12164\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 4.184246063232422e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 76154\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01467132568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 117565\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00011080503463745117\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17218\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005183219909667969\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 49039\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.13916015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 59611\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0149688720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5957\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0029621124267578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99077\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0019435882568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5255\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91137\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0211639404296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0017004013061523438\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1543\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05328369140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 71017\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.76953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.074462890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 59779\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0015716552734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1330\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.033447265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 82017\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.94140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6474\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1712646484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 323\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.09539794921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 71017\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.916015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 124042\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002357959747314453\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 45502\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01232147216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 60314\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0013790130615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 22660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2210693359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1969\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.68603515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 71017\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.65478515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57375\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0056610107421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4372\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06292724609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 50311\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0013027191162109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 22011\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.049530029296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77247\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.234619140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 19715\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00841522216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85179\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0033245086669921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: As kids, we learn how to write, maybe play a musical instrument and draw. So why don't we learn to code   computer programs too? What coding has in common with writing, playing music and creating art is that it lets you bring your ideas to life. Coding is all about creativity and music and creating art Crearbing with code CoderDojo helps young perople around the world to learn computer  programming for free. When I went to my first CoderDojo class in Dublin City University in Ireland, at age nine, I didn't know anything about coding or even what it was. But I remember making my very first web page that first day, and being surprised that I could create such a thing. It was a great feeling that I think every young person should experience!\n",
            "By going to CoderDojo every week, I learned how to make websites, apps and games. One of my apps is called Auto-Journalist. It can help journalists   and interwewees do interviews even if they are both really busy or live in different time zones. It is still in development, and I have showed it at an event called Coolest Projects Awards, where young people get to show the public what they have created with code. It's so mucbt fun to share one's creations, and to see what everyone else has made too.\n",
            "Learnuing environment\n",
            "For the past three years I have also been helping to teach other young people at CoderDojo DCU. In recent years I have also noticed many more girls attending CoderDojo DCU to try out coding. This has a lot to do with the CoderDojo girls' classes -- girls and young women take part in it with their friends, and it doesn't feel like coding is a \"boy thing\". It is really wonderful to see this, because we need more girls and women in STEM ( Science, Technology, Engineering and Maths). It's a good way to leam more about technology.\n",
            "Start early\n",
            "One of the main things I have leamed in the last few years is that coding is not only for adults, coding is for young people, too. And when you are a child it is a great time to start coding, because your imagination is the limit for what you can create !\n",
            "Want to leam more? Find out if there is a CoderDojo near you at www. coderdojo. com or set one up yourself! Also check out Code. org which has lots of fun drag-and-drop coding games.\n",
            "\n",
            "Question: In the writer's first coding class, she  _  .\n",
            "A. made apps and games\n",
            "B. created a web page\n",
            "C. wrote for newspapers\n",
            "D. did some interviews\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "\n",
            "Question: In the writer's first coding class, she _ .\n",
            "A. made apps and games\n",
            "B. created a web page\n",
            "C. wrote for newspapers\n",
            "D. did some interviews\n",
            "Answer: C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 98018\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0216827392578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4849\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.02569580078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Yang Nan, 17, was happy to move to her new home in a northern area of Beijing. She was told that her neighborhood used to be farmland planted with vegetables, corn and wheat. But looking at the new road, beautiful park and supermarkets, Yang couldn't see any sign that food was once grown there.\n",
            "Yang is not alone. In recent years, many Chinese people have moved into new houses in country areas. Tall buildings have been built everywhere in the suburbs. The crops and fruit trees are no more. But these changes have caused problems too, warns Gan Zang chun, an official at the Ministry of Land and Resources  .\n",
            "\"Chinese cities are growing fast. This has made the area for farmland much smaller. This is really bad for the country's ability to grow food, not to mention the lives of farmers,\" said Gan last Monday.\n",
            "The country needs farmland to grow food for the people of China. But the recent rise in house prices has made selling land a good business. A lot of land has been used to build new houses for sale.\n",
            "Pollution, which makes land useless, is another reason for the big drop in China's farmland. About 2.67 million square kilometers of land in China have been polluted and turned into desert.\n",
            "The government wants China to have at least 120 million hectares  of farmland. But there are only about 121.8 million hectares left. \"It will be really difficult to reach the goal,\" Gan said. He said that the government would fight illegal land use and stop farmland from becoming desert.\n",
            "\n",
            "Question: What size of the land have been polluted and turned into desert?\n",
            "A. 120 million hectares.\n",
            "B. 121.8 million hectares.\n",
            "C. 2.67 million square kilometers.\n",
            "D. Millions of square kilometers.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.60009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 118401\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0019092559814453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Hip-hop dancing  is popular with many young people today. They like it because they can invent their own moves. They use this dance to show their love for life. It also shows that they feel good about life,that they just want to be themselves and enjoy life,and that they are not afraid of problems.\n",
            "Hip-hop dancing has a history of more than 20 years. It first began in the 1980s in the US. In early times,it was seen in New York and Los Angles. At that time,many young black people often danced to the music in the streets.They used their legs,arms,heads and even shoulders to dance.Many young people still use most of these moves today.\n",
            "Hip-hop dancing became popular all over the world because of the 1983 movie Flash dance .Some people performed Hip-hop dancing in the movie.People enjoyed their performance.They began to dance like them.Then it became popular .There are two kinds of Hip-hop dancing:new school and old school.More and more young people are learning Hip-hop dancing.People believe that it is a good way to exercise their bodies,and that it is good for their health.\n",
            "\n",
            "Question: Which of the following is TRUE about Hip-hop dancing?\n",
            "A. It's not a good way to exercise.\n",
            "B. It shows that young people feel bad about life.\n",
            "C. Young people use this dance to show their love for life.\n",
            "D. It shows that young people are afraid of problems.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7099609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07354736328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
            "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
            "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
            "\n",
            "Question: The lambs couldn t find the way home because\n",
            "A. they were far away from home\n",
            "B. the ground was covered with thick snow\n",
            "C. the wind was blowing hard\n",
            "D. they didn t want to go back home\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75947\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0008416175842285156\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 106548\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002246856689453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Tommy hated school and was always looking for excuses  not to go.If he sneezed, he asked his mother to write a note saying he had a cold.If he had a headache, he asked his mother to take him to the doctor during school hours.\n",
            "He spent more time at home than he did at school.On the days that he did go to school, he looked for excuses to come home early.One morning he came home when the lessons were only half finished.His father was surprised.\n",
            "\"You've come home early,\" he said. \"Is the school closed today?\"\n",
            "\"No, Dad, \" Tommy said - \"It's open. I came home early.\n",
            "\"How did you do that?\" his father asked him. \"What did you say to the teacher?\"\n",
            "\"I told her that I had a new baby brother and that I had to come home and help you . \"\n",
            "\"But your mother has had twins,\" his father said, \"a boy and a girl. You've got a baby brother and a baby sister.\"\n",
            "\"Yes, I know, Dad, \" Tommy said. \"I'm saving up my baby sister for next week \"\n",
            "\n",
            "Question: There are  _  people in Tommy's family.\n",
            "A. 3\n",
            "B. 4\n",
            "C. 5\n",
            "D. 6\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " C\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: C, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 74032\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00017261505126953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Many middle school students like watching TV very much. But from Monday to Friday, they must go to school. So on Saturday and Sunday they stay at home and watch TV from morning to night. They don't know it's bad for their eyes. Usually children like to eat fish, meat and chicken and don't like vegetables or fruit. They don't know eating more vegetables or fruit. They don't know eating more vegetables and fruit is better than eating meat.\n",
            "At school, the children only do a few minutes of sports or never do any sports. The teachers must know it isn't good for their health.\n",
            "We always think of ways to keep healthy. We must eat more vegetables and fruit, do enough sport every day. And we should watch TV and read in right ways.\n",
            "\n",
            "Question: Many students stay at home and watch TV from morning to night  _  .\n",
            "A. on Fridays\n",
            "B. from Monday to Friday\n",
            "C. on Saturday\n",
            "D. on Saturday and Sunday\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: D\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.44677734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 46315\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005965232849121094\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Hi! My name is Millie. I am from England. I am twelve years old. I am slim and tall. I have long hair. I like music. I listen to music every evening. I like reading and I am in the Reading Club. But I don't like sports.\n",
            "Hello! I am Peter from America. But I live in Shanghai now. I am 13 years old. I wear glasses. I am tall and strong. My hair is very short. I like sports very much. Every afternoon, I play football on the playground at school. I am good at swimming too.\n",
            "This is Amy. I was born in Beijing and now I live in Nanjing. My father works in a hospital in Nanjing. So we come here. I am fourteen years old. I am short but strong. I like playing computer games. I am polite and helpful. I often help other students.\n",
            "\n",
            "Question: What is Peter like?\n",
            "A. Slim and tall.\n",
            "B. Short and strong.\n",
            "C. Tall and strong.\n",
            "D. Thin and tall.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " C\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: C\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.421142578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 89720\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0010728836059570312\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: A young man woke up one morning under a bridge and checked his pocket. All he had left was less than ten dollars. He bought food and as he sat down to eat, an old man and two children came along. The old man asked him to help them with food as they had not eaten for almost a week.\n",
            "The young man looked at the children---they were so weak that they could hardly stand. With the last bit of kindness he had he gave them all the food. The old man and children thanked the young man and then gave him a dirty old coin. The young man said, \"You need this coin more than I do--- just keep it.\" The old man insisted  that the young man put it in his pocket---and finally he did.\n",
            "The old man and children sat down to eat. And with no money, no job and no food, the young man went back under the bridge to lie down. As he was about to fall asleep he saw an old newspaper on the ground. He picked it up and saw an ad inviting people with old coins to come to a store. He decided to go there with the dirty old coin the man gave him.\n",
            "When he arrived at the store, he gave the keeper the dirty old coin. The keeper cried loudly. It was part of a Spanish treasure ship that had never been found. This same old coin was worth 67,000 dollars. The young man was pleased. He immediately sold the coin for money and then looked for the old man and little children to thank them and share the money. By the time he got to where he left them eating, they had gone.\n",
            "\n",
            "Question: How did the young man learn about the ad for old coins?\n",
            "A. By watching TV.\n",
            "B. By reading a newspaper.\n",
            "C. By listening to the old man.\n",
            "D. By reading an ad on the wall.\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " B\n",
            "[Model Response]:\n",
            " B\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: B, Extracted target: B\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 19715\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0011129379272460938\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0285186767578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37093\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0019893646240234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 101520\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.15185546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15784\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0312347412109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47661\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0014820098876953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10481\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07403564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6786\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.576171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38349\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01329803466796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 118447\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10089111328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28103\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.012847900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 89773\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0108642578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 105831\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.17919921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 16706\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0018491744995117188\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 44291\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.76025390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 95937\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0171356201171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102146\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.019134521484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68209\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5945\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001461505889892578\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14916\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00016236305236816406\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 19577\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005863189697265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 109484\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00010991096496582031\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 73513\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005283355712890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17192\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0003063678741455078\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13180\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00023043155670166016\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 55529\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00727081298828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 44875\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005426406860351562\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1224\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01174163818359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34027\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01523590087890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27710\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.101806640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 79543\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11602783203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1342\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0196533203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35513\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.02557373046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0234527587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33104\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003025054931640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34803\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.001922607421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18449\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0012369155883789062\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84134\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00025773048400878906\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47845\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1658935546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 977\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.169189453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5456\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001291036605834961\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 726\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031280517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34735\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.055023193359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28330\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0008635520935058594\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18958\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00017535686492919922\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7723\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04656982421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 64567\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.307373046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8373\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004817962646484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 83514\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 9.28640365600586e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 63798\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00015211105346679688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 43114\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.37744140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37840\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002390146255493164\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102004\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.110107421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 106863\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00020599365234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 74147\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031494140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23976\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.263916015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6856\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.51708984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6261\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0169677734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14912\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0022411346435546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 100458\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005674362182617188\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 101955\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.025787353515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 71726\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11859130859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 56809\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0191802978515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 117373\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00951385498046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 39904\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.16064453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15829\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01238250732421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68209\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54786\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.19482421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 41632\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0015954971313476562\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 26719\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00027489662170410156\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77701\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 7.69495964050293e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 40952\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0012149810791015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 40422\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.033416748046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20416\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00572967529296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 726\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07342529296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 56589\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0101165771484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 51910\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005645751953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.324951171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12821\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1629638671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 81029\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04852294921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57877\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04937744140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37180\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0033969879150390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2143\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.019622802734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3077\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01910400390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 76438\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005655288696289062\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 78156\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003009796142578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84779\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0003962516784667969\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1625\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01214599609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1969\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.408447265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61021\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0100555419921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10700\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.186767578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54574\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002285003662109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 105604\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.017486572265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42970\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00035119056701660156\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 44047\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0203857421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 39099\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01375579833984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4893\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.007091522216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 51507\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0384521484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 120685\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.462890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20894\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.048797607421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23581\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05975341796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 109881\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.037994384765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 56705\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00023472309112548828\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35881\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.047149658203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23976\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1021728515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.333984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13446\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0775146484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 82179\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.006916046142578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25040\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00033664703369140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85389\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002968311309814453\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13937\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00902557373046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.34521484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 71640\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0010833740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 119179\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.000701904296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38735\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001024007797241211\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27406\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 9.620189666748047e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6031\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00911712646484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 108082\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01033782958984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31636\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0030269622802734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53782\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.030517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 391\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0322265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54546\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00936126708984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20416\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0046539306640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14778\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01291656494140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10182\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005764007568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 26967\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01140594482421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13194\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00772857666015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96331\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.026519775390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.91162109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4329\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00232696533203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53035\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00931549072265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 26719\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.007701873779296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84137\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.362548828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6076\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0018148422241210938\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34735\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.007659912109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 106563\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 8.469820022583008e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 50926\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.298583984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 90882\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00051116943359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.53564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28248\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0021648406982421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 40484\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002498626708984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65854\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.361083984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 50926\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05224609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 44047\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0277862548828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 46870\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01522064208984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53339\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0687255859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 43644\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0017986297607421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 120685\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.59521484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53709\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.034820556640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77373\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00814056396484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 82207\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0196380615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 44195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0119171142578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 90563\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0159149169921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70343\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007128715515136719\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5673828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9029\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0009756088256835938\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53876\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00299835205078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0012903213500976562\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3207\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0008325576782226562\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42880\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.036712646484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12598\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0244293212890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38538\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04461669921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 36099\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00994110107421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96352\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0004267692565917969\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 24665\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0037841796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 60020\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0012264251708984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 30977\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0014352798461914062\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 30056\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0167083740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 80678\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0008554458618164062\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3111\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0105133056640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1197509765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84137\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.234619140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52689\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0004038810729980469\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13636\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0105438232421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.15625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2508\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0003833770751953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14038\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1522216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4106\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0008816719055175781\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 95221\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0016984939575195312\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21729\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00011628866195678711\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8631\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001760721206665039\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 125550\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0726318359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9510\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00194549560546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7818\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00475311279296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6780\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0015439987182617188\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 655\n",
            "  Verified Probability: 0.0"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "  1%|          | 1/100 [00:00<00:59,  1.67it/s]\n",
            "  2%|▏         | 2/100 [00:00<00:35,  2.80it/s]\n",
            "  3%|▎         | 3/100 [00:01<01:11,  1.35it/s]\n",
            "  4%|▍         | 4/100 [00:02<00:50,  1.90it/s]\n",
            "  5%|▌         | 5/100 [00:02<00:40,  2.37it/s]\n",
            "  6%|▌         | 6/100 [00:02<00:32,  2.85it/s]\n",
            "  7%|▋         | 7/100 [00:02<00:27,  3.34it/s]\n",
            "  8%|▊         | 8/100 [00:03<00:24,  3.72it/s]\n",
            "  9%|▉         | 9/100 [00:03<00:22,  4.02it/s]\n",
            " 10%|█         | 10/100 [00:03<00:21,  4.23it/s]\n",
            " 11%|█         | 11/100 [00:03<00:19,  4.51it/s]\n",
            " 12%|█▏        | 12/100 [00:03<00:19,  4.62it/s]\n",
            " 13%|█▎        | 13/100 [00:04<00:18,  4.83it/s]\n",
            " 14%|█▍        | 14/100 [00:04<00:17,  4.87it/s]\n",
            " 15%|█▌        | 15/100 [00:04<00:17,  4.98it/s]\n",
            " 16%|█▌        | 16/100 [00:04<00:16,  5.07it/s]\n",
            " 17%|█▋        | 17/100 [00:04<00:17,  4.86it/s]\n",
            " 18%|█▊        | 18/100 [00:05<00:16,  4.85it/s]\n",
            " 19%|█▉        | 19/100 [00:05<00:16,  4.91it/s]\n",
            " 20%|██        | 20/100 [00:05<00:16,  4.96it/s]\n",
            " 21%|██        | 21/100 [00:05<00:15,  5.09it/s]\n",
            " 22%|██▏       | 22/100 [00:05<00:15,  5.07it/s]\n",
            " 23%|██▎       | 23/100 [00:06<00:15,  5.00it/s]\n",
            " 24%|██▍       | 24/100 [00:06<00:16,  4.73it/s]\n",
            " 25%|██▌       | 25/100 [00:06<00:15,  4.87it/s]\n",
            " 26%|██▌       | 26/100 [00:06<00:15,  4.74it/s]\n",
            " 27%|██▋       | 27/100 [00:06<00:15,  4.75it/s]\n",
            " 28%|██▊       | 28/100 [00:07<00:15,  4.66it/s]\n",
            " 29%|██▉       | 29/100 [00:07<00:15,  4.61it/s]\n",
            " 30%|███       | 30/100 [00:07<00:14,  4.69it/s]\n",
            " 31%|███       | 31/100 [00:07<00:14,  4.73it/s]\n",
            " 32%|███▏      | 32/100 [00:07<00:13,  4.90it/s]\n",
            " 33%|███▎      | 33/100 [00:08<00:13,  4.90it/s]\n",
            " 34%|███▍      | 34/100 [00:08<00:12,  5.08it/s]\n",
            " 35%|███▌      | 35/100 [00:08<00:13,  4.98it/s]\n",
            " 36%|███▌      | 36/100 [00:08<00:12,  5.19it/s]\n",
            " 37%|███▋      | 37/100 [00:08<00:12,  5.06it/s]\n",
            " 38%|███▊      | 38/100 [00:09<00:12,  4.90it/s]\n",
            " 39%|███▉      | 39/100 [00:09<00:12,  4.94it/s]\n",
            " 40%|████      | 40/100 [00:09<00:12,  4.70it/s]\n",
            " 41%|████      | 41/100 [00:09<00:12,  4.83it/s]\n",
            " 42%|████▏     | 42/100 [00:09<00:11,  4.97it/s]\n",
            " 43%|████▎     | 43/100 [00:10<00:11,  4.92it/s]\n",
            " 44%|████▍     | 44/100 [00:10<00:10,  5.11it/s]\n",
            " 45%|████▌     | 45/100 [00:10<00:10,  5.04it/s]\n",
            " 46%|████▌     | 46/100 [00:10<00:10,  5.12it/s]\n",
            " 47%|████▋     | 47/100 [00:10<00:10,  5.05it/s]\n",
            " 48%|████▊     | 48/100 [00:11<00:10,  5.10it/s]\n",
            " 49%|████▉     | 49/100 [00:11<00:10,  4.95it/s]\n",
            " 50%|█████     | 50/100 [00:11<00:09,  5.04it/s]\n",
            " 51%|█████     | 51/100 [00:11<00:09,  5.17it/s]\n",
            " 52%|█████▏    | 52/100 [00:11<00:09,  5.22it/s]\n",
            " 53%|█████▎    | 53/100 [00:12<00:08,  5.31it/s]\n",
            " 54%|█████▍    | 54/100 [00:12<00:09,  5.08it/s]\n",
            " 55%|█████▌    | 55/100 [00:12<00:09,  4.82it/s]\n",
            " 56%|█████▌    | 56/100 [00:12<00:09,  4.84it/s]\n",
            " 57%|█████▋    | 57/100 [00:12<00:09,  4.70it/s]\n",
            " 58%|█████▊    | 58/100 [00:13<00:08,  4.79it/s]\n",
            " 59%|█████▉    | 59/100 [00:13<00:09,  4.54it/s]\n",
            " 60%|██████    | 60/100 [00:13<00:08,  4.77it/s]\n",
            " 61%|██████    | 61/100 [00:13<00:08,  4.66it/s]\n",
            " 62%|██████▏   | 62/100 [00:28<02:57,  4.68s/it]\n",
            " 63%|██████▎   | 63/100 [00:29<02:03,  3.34s/it]\n",
            " 64%|██████▍   | 64/100 [00:29<01:26,  2.40s/it]\n",
            " 65%|██████▌   | 65/100 [00:29<01:01,  1.76s/it]\n",
            " 66%|██████▌   | 66/100 [00:29<00:44,  1.30s/it]\n",
            " 67%|██████▋   | 67/100 [00:30<00:32,  1.01it/s]\n",
            " 68%|██████▊   | 68/100 [00:30<00:24,  1.33it/s]\n",
            " 69%|██████▉   | 69/100 [00:30<00:18,  1.69it/s]\n",
            " 70%|███████   | 70/100 [00:30<00:14,  2.06it/s]\n",
            " 71%|███████   | 71/100 [00:30<00:11,  2.45it/s]\n",
            " 72%|███████▏  | 72/100 [00:31<00:09,  2.88it/s]\n",
            " 73%|███████▎  | 73/100 [00:31<00:08,  3.18it/s]\n",
            " 74%|███████▍  | 74/100 [00:31<00:07,  3.58it/s]\n",
            " 75%|███████▌  | 75/100 [00:31<00:06,  3.87it/s]\n",
            " 76%|███████▌  | 76/100 [00:32<00:05,  4.16it/s]\n",
            " 77%|███████▋  | 77/100 [00:32<00:05,  4.29it/s]\n",
            " 78%|███████▊  | 78/100 [00:32<00:04,  4.49it/s]\n",
            " 79%|███████▉  | 79/100 [00:32<00:04,  4.54it/s]\n",
            " 80%|████████  | 80/100 [00:32<00:04,  4.59it/s]\n",
            " 81%|████████  | 81/100 [00:33<00:04,  4.40it/s]\n",
            " 82%|████████▏ | 82/100 [00:33<00:04,  4.31it/s]\n",
            " 83%|████████▎ | 83/100 [00:33<00:03,  4.35it/s]\n",
            " 84%|████████▍ | 84/100 [00:33<00:03,  4.43it/s]\n",
            " 85%|████████▌ | 85/100 [00:33<00:03,  4.61it/s]\n",
            " 86%|████████▌ | 86/100 [00:34<00:03,  4.61it/s]\n",
            " 87%|████████▋ | 87/100 [00:34<00:02,  4.73it/s]\n",
            " 88%|████████▊ | 88/100 [00:34<00:02,  4.78it/s]\n",
            " 89%|████████▉ | 89/100 [00:34<00:02,  4.84it/s]\n",
            " 90%|█████████ | 90/100 [00:35<00:02,  4.89it/s]\n",
            " 91%|█████████ | 91/100 [00:39<00:13,  1.52s/it]\n",
            " 92%|█████████▏| 92/100 [00:39<00:09,  1.13s/it]\n",
            " 93%|█████████▎| 93/100 [00:40<00:05,  1.17it/s]\n",
            " 94%|█████████▍| 94/100 [00:40<00:03,  1.51it/s]\n",
            " 95%|█████████▌| 95/100 [00:40<00:02,  1.88it/s]\n",
            " 96%|█████████▌| 96/100 [00:40<00:01,  2.30it/s]\n",
            " 97%|█████████▋| 97/100 [00:40<00:01,  2.74it/s]\n",
            " 98%|█████████▊| 98/100 [00:41<00:00,  3.11it/s]\n",
            " 99%|█████████▉| 99/100 [01:31<00:15, 15.38s/it]\n",
            "100%|██████████| 100/100 [01:31<00:00, 10.83s/it]\n",
            "100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Draft Probability: 0.005512237548828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28467\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0004470348358154297\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 39251\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005130767822265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54574\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005855560302734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 66050\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007429122924804688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33918\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0022144317626953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 275\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0400390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70048\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0006313323974609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102201\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 120685\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.305419921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 103388\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002282857894897461\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23581\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06524658203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33731\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.007354736328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23581\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.14892578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 101076\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00295257568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 941\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0018310546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.448974609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 48937\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00022161006927490234\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96295\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0034313201904296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 83100\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007710456848144531\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3077\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.048583984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42371\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.145751953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.493408203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27710\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01428985595703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10276\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007810592651367188\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 112795\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0004730224609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2303\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.03179931640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84137\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.16455078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7051\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0029087066650390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14916\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0233306884765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 87601\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001512765884399414\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 55748\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.416259765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8934\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.006923675537109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4329\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0018596649169921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6910\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12548828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94201\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01020050048828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5531\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.244384765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 106984\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.016571044921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14038\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.236083984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34057\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08111572265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47026\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.015594482421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57695\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0104522705078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 69281\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0018367767333984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 107801\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0098724365234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.38232421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 79068\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07440185546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96217\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.132568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.767578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 30086\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 44235\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00392913818359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65854\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.6201171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 80438\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00023353099822998047\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1080322265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 39099\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0218048095703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 103259\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.034393310546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102201\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.53125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31107\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0210723876953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13038\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01483154296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 74325\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002262115478515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 372\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00130462646484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 60020\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00047469139099121094\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61831\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0020427703857421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 80661\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001615285873413086\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.381103515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 115603\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007662773132324219\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 78782\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57944\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1297607421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 30086\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.034698486328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 62289\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.037445068359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 108475\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0032176971435546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54890\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 56923\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00022602081298828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 112644\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05462646484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57944\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.41015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21456\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007467269897460938\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18132\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01535797119140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4047\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002636909484863281\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 511\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0015363693237304688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10196\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.008941650390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70075\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00013959407806396484\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57944\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.059234619140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47026\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0156707763671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 26719\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00024235248565673828\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 40811\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0272216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5701\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.012176513671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.83544921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14038\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1668701171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1141\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.042510986328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 36257\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0004000663757324219\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84137\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06256103515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 63372\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001938343048095703\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 95290\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00926971435546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14733\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007243156433105469\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3102\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0010833740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 977\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0063018798828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 116510\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007486343383789062\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8385\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0009832382202148438\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65854\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23920\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1024169921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15988\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01995849609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18212\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005962371826171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 511\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.033294677734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 108698\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0125274658203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 63911\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0241546630859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1969\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01241302490234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 56432\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04132080078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102004\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04833984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 106863\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.385986328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 101520\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0287322998046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 86622\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0017480850219726562\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23976\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0208740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13446\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11981201171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8385\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002498626708984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 124309\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0012531280517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 113547\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0041351318359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57712\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.060394287109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 11154\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031524658203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 41137\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08306884765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57944\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1396484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53146\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0012331008911132812\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33843\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0028209686279296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31107\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05328369140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 49270\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.078857421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33918\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00054168701171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 114884\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1824951171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 55748\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.437255859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 24570\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0014390945434570312\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 71158\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0251617431640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37014\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11199951171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31636\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00341796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5531\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1064453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23920\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0029506683349609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.456787109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.99658203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13140\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.02044677734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 477\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.049835205078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6076\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0011568069458007812\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53508\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00438690185546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 125550\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06610107421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33780\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1551513671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 112740\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0012149810791015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0799560546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23492\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0279693603515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1101\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00983428955078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65854\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.79443359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 74567\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0024776458740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 101626\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.039581298828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17638\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0011930465698242188\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 62868\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0081939697265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23833\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.019989013671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 74933\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.054595947265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 60600\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.035064697265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 120148\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002597808837890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 95421\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0164031982421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 92506\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0294036865234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102176\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.032470703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 588\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1597900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6856\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0289154052734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13446\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12176513671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 86622\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01934814453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 90651\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00029778480529785156\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54786\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.253662109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96295\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005135536193847656\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 11154\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06927490234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54890\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.50390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6172\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0013074874877929688\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0033416748046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5205078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31707\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2196044921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 86622\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0282440185546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 43344\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.021575927734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15256\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0108489990234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 55748\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.260498046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70904\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002887725830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 9216\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007925033569335938\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 32080\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0016813278198242188\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 62868\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002941131591796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 127691\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0013065338134765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10087\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.019683837890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.276611328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.79833984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61071\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.001422882080078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 59693\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003856658935546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 90297\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001436471939086914\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 39251\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.019195556640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 93166\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031829833984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 43344\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01593017578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 45721\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0031528472900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61547\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002681732177734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1969\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1689453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 41631\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0016756057739257812\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12724\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004116058349609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65854\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8505859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 104488\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002445220947265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102952\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00930023193359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65256\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0244140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1336\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01137542724609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 62238\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0009813308715820312\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 120685\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3974609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17638\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0748291015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23581\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00457000732421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 18553\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.000263214111328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10196\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003208160400390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 112609\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00039505958557128906\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1474\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00010305643081665039\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.436767578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1940\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0016994476318359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 58851\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10986328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57944\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1815185546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 30086\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.021759033203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 119148\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003948211669921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.525390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54890\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.81640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91176\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00043010711669921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 48067\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.02825927734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35316\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0031585693359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31107\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08331298828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 81295\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0031261444091796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57944\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0213165283203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 64567\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0239105224609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 43296\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1103515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28058\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01068878173828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.445068359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10667\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00696563720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 93098\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.020965576171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5531\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0274200439453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10368\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00473785400390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4873046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.80517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14038\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10260009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96217\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0188140869140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.517578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 60246\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00040793418884277344\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77331\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0058441162109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 108745\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00017821788787841797\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 45721\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00473785400390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 81827\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.008087158203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 82199\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0038204193115234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.86181640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52893\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12188720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 49270\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.052490234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65854\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10087\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.017364501953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23736\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0008630752563476562\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42880\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2166748046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 107315\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007677078247070312\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 82582\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01617431640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20298\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.037811279296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1578\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0176239013671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20631\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.09368896484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7776\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005107879638671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3807\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0009064674377441406\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 92506\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00022900104522705078\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57960\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002376556396484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.325927734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14912\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01274871826171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 60303\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00341033935546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29229\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00994110107421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 229\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0005855560302734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85590\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0096588134765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.6591796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54890\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.85009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2399\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0017938613891601562\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10196\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0075225830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 36168\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 9.72747802734375e-05\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31107\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1065673828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6140\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00013077259063720703\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 93685\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.003997802734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12684\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0029087066650390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 114038\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005157470703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 121827\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0290985107421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.40771484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6442\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00036597251892089844\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 59325\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00015616416931152344\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 16639\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0019426345825195312\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 79543\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0323486328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12660\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.525390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5717\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.70263671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2143\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.036895751953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00849151611328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.52197265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 54786\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10748291015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 31245\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01511383056640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102726\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005245208740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7107\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0007686614990234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 114209\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0264892578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2427\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00044345855712890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 94348\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.87353515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8703\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0140533447265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 83133\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0001361370086669922\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 65854\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.814453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 95221\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00603485107421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 84409\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00563812255859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 61323\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004993438720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96960\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00621795654296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 102201\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1466064453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 125225\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0038051605224609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57339\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1107177734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 24808\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0002130270004272461\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 10825\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.005184173583984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5269\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00016891956329345703\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 52653\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 349\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0165863037109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3621\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.031005859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 109609\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0006308555603027344\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 14912\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10150146484375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 112431\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11407470703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 101955\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01393890380859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 119911\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.007480621337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 96386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.74755859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 64561\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.004245758056640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 40890\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.072509765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 11549\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0033721923828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 33843\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.002338409423828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13772\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0009489059448242188\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 122008\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0009140968322753906\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34906\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0010194778442382812\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: \"Which meal do we all need most, breakfast, lunch or dinner?\" Miss Baker asks. Boys and girls wave their hands in the air. They know the answer.\n",
            "\"What do you think, Jim?\" Miss Baker asks.\n",
            "\"Dinner,\" Jim answers.\n",
            "\"Dinner is the big meal of the day,\" says Miss Baker. \"But I don't think we need it most.\"\n",
            "Tom puts up his hands. \" Do we need lunch most?\"\n",
            "\"No,\" says Miss Baker. \"We need breakfast most.\" \"Why is this so?\"\n",
            "\"From night to morning is a long time to go without food,\" says Ann.\n",
            "\"That's right,\" says Miss Baker. \"We need food every morning. What may happen to us if we have no breakfast?\"\n",
            "The students have many answers to give.\n",
            "\"We may feel hungry.\"\n",
            "\"We may not feel like working.\"\n",
            "\"We may feel sick.\"\n",
            "\"Yes, you are right,\" says Miss Baker. \"Now let's talk about what makes a good breakfast. Give me your answers. I will write them on the blackboard.\"\n",
            "\n",
            "Question: Miss Baker thinks   _   is a big meal of the day.\n",
            "A. breakfast\n",
            "B. lunch\n",
            "C. dinner\n",
            "D. picnic\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " A\n",
            "[Model Response]:\n",
            " A\n",
            "\n",
            "Question: What may happen to us if we have no breakfast?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no lunch?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no dinner?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no dinner?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no lunch?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no dinner?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no lunch?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no dinner?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no dinner?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no dinner?\n",
            "A. we may feel hungry\n",
            "B. we may not feel like working\n",
            "C. we may feel sick\n",
            "D. we may not feel like eating\n",
            "Answer: A\n",
            "\n",
            "Question: What may happen to us if we have no lunch?\n",
            "A. we may feel hungry\n",
            "\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: A\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06536865234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 117565\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.00015044212341308594\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "[Prompt]:\n",
            "Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: You can find the information below on the newspaper except   _  .\n",
            "A. European Union.\n",
            "B. The lovely volunteers in Kingdom school.\n",
            "C. Wild foxes need your help.\n",
            "D. Do you know these musical instruments?\n",
            "Answer:\n",
            "[Reference Response]:\n",
            " D\n",
            "[Model Response]:\n",
            " A\n",
            "[Acceptance Rate]: 0.0\n",
            "Extracted prediction: A, Extracted target: D\n",
            "{'predicted_text': {'exact_match': 0.4699999988079071, 'accuracy': 0.47}, 'acceptance_rate': {'mean': 1.0416667209938169e-05}, 'total_time': {'mean': 0.9175014472007752}, 'time_per_token': {'mean': 0.20737530641257762}, 'tokens_per_second': {'mean': 5.024157556295395}}\n"
          ]
        }
      ],
      "source": [
        "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "    --dataset mmlu \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy self_speculative\\\n",
        "    --exit_layer 8 \\\n",
        "    --num_speculations 6 \\\n",
        "    --output_dir ./logs \\\n",
        "    --distributed False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: mmlu"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   1%|          | 1/100 [00:01<02:06,  1.27s/it]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   2%|▏         | 2/100 [00:01<01:05,  1.50it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   3%|▎         | 3/100 [00:01<00:47,  2.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   4%|▍         | 4/100 [00:02<00:37,  2.59it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   5%|▌         | 5/100 [00:02<00:31,  2.99it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   6%|▌         | 6/100 [00:02<00:28,  3.28it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   7%|▋         | 7/100 [00:02<00:25,  3.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   8%|▊         | 8/100 [00:02<00:24,  3.71it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:   9%|▉         | 9/100 [00:03<00:23,  3.89it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  10%|█         | 10/100 [00:03<00:23,  3.90it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  11%|█         | 11/100 [00:03<00:22,  4.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  12%|█▏        | 12/100 [00:03<00:21,  4.10it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  13%|█▎        | 13/100 [00:04<00:21,  4.06it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  14%|█▍        | 14/100 [00:04<00:20,  4.10it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  15%|█▌        | 15/100 [00:04<00:20,  4.22it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  16%|█▌        | 16/100 [00:04<00:19,  4.26it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  17%|█▋        | 17/100 [00:05<00:19,  4.35it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  18%|█▊        | 18/100 [00:05<00:18,  4.32it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  19%|█▉        | 19/100 [00:05<00:18,  4.35it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  20%|██        | 20/100 [00:05<00:18,  4.34it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  21%|██        | 21/100 [00:06<00:18,  4.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  22%|██▏       | 22/100 [00:06<00:18,  4.30it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  23%|██▎       | 23/100 [00:06<00:17,  4.32it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  24%|██▍       | 24/100 [00:06<00:17,  4.40it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  25%|██▌       | 25/100 [00:06<00:16,  4.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  26%|██▌       | 26/100 [00:07<00:16,  4.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  27%|██▋       | 27/100 [00:07<00:16,  4.38it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  28%|██▊       | 28/100 [00:07<00:16,  4.40it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  29%|██▉       | 29/100 [00:07<00:16,  4.39it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  30%|███       | 30/100 [00:08<00:16,  4.26it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  31%|███       | 31/100 [00:08<00:15,  4.36it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  32%|███▏      | 32/100 [00:08<00:15,  4.37it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  33%|███▎      | 33/100 [00:08<00:15,  4.41it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  34%|███▍      | 34/100 [00:08<00:15,  4.39it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  35%|███▌      | 35/100 [00:09<00:14,  4.42it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  36%|███▌      | 36/100 [00:09<00:14,  4.43it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  37%|███▋      | 37/100 [00:09<00:14,  4.49it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  38%|███▊      | 38/100 [00:09<00:13,  4.48it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  39%|███▉      | 39/100 [00:10<00:14,  4.27it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  40%|████      | 40/100 [00:10<00:13,  4.37it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  41%|████      | 41/100 [00:10<00:13,  4.40it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  42%|████▏     | 42/100 [00:10<00:13,  4.25it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  43%|████▎     | 43/100 [00:11<00:13,  4.29it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  44%|████▍     | 44/100 [00:11<00:13,  4.25it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  45%|████▌     | 45/100 [00:11<00:13,  4.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  46%|████▌     | 46/100 [00:11<00:12,  4.20it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  47%|████▋     | 47/100 [00:12<00:13,  4.01it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  48%|████▊     | 48/100 [00:12<00:12,  4.05it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  49%|████▉     | 49/100 [00:12<00:12,  4.08it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  50%|█████     | 50/100 [00:12<00:12,  4.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  51%|█████     | 51/100 [00:13<00:11,  4.10it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:13<00:11,  4.11it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:13<00:11,  4.16it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:13<00:11,  4.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:14<00:11,  4.05it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:14<00:10,  4.12it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:14<00:10,  4.01it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:14<00:10,  3.89it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:15<00:10,  4.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  60%|██████    | 60/100 [00:15<00:09,  4.12it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  61%|██████    | 61/100 [00:15<00:09,  4.16it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:15<00:09,  4.18it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:15<00:08,  4.23it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:16<00:08,  4.24it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:16<00:08,  4.28it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:16<00:08,  4.18it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:16<00:08,  4.12it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:17<00:07,  4.17it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:17<00:07,  4.24it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  70%|███████   | 70/100 [00:17<00:07,  4.26it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  71%|███████   | 71/100 [00:17<00:06,  4.26it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:18<00:06,  4.30it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:18<00:06,  4.31it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:18<00:06,  4.25it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:18<00:05,  4.22it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:19<00:05,  4.09it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:19<00:05,  4.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:19<00:05,  4.01it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:19<00:05,  4.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  80%|████████  | 80/100 [00:20<00:04,  4.11it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  81%|████████  | 81/100 [00:20<00:04,  4.06it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:20<00:04,  4.19it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:20<00:04,  4.23it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:20<00:03,  4.19it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:21<00:03,  4.29it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:21<00:03,  4.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:21<00:03,  4.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:21<00:02,  4.11it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:22<00:02,  4.05it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  90%|█████████ | 90/100 [00:22<00:02,  3.96it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  91%|█████████ | 91/100 [00:22<00:02,  4.10it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:22<00:01,  4.22it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:23<00:01,  4.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:23<00:01,  4.05it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:23<00:01,  4.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:23<00:00,  4.10it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:24<00:00,  4.14it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:24<00:00,  4.05it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:24<00:00,  3.98it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:24<00:00,  4.05it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:24<00:00,  4.02it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on MMLU with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A state built a casino and issued bonds to finance its construction. On five occasions, there were episodes of violence in various casinos in the state. The state police attributed the violence to greed and fear at the casinos. To prevent such violence, the state legislature passes a statute prohibiting all gambling at privately owned casinos in the state. Is this law likely to be held constitutional if most casinos in the state were owned by those from out-of-state?\n",
            "A. Yes, because the act was expressly authorized by the state legislature.\n",
            "B. Yes, but only if the local interest in safety outweighs the burden of interstate commerce.\n",
            "C. No, because out-of-state casinos are part of interstate commerce.\n",
            "D. No, because the statute violates the due process rights of the owners of the casinos.\n",
            "Answer:\n",
            "Predicted: sleenie rose wings wingsovsky一点etimeoceoceoceelpselpsままままままborgsledovatovat\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: what is one of the important differences between the middle and upper paleolithic?\n",
            "A. decreased use of imported raw materials and increased use of whatever was locally available\n",
            "B. smaller sites, indicating a change from large roving bands of hunters to the earliest family groups and households\n",
            "C. a profusion of stone tool traditions, indicating a change from temporal and geographic homogeneity to greater diversity and variability\n",
            "D. a gradual decline in the use of stone hand axes and tools, indicating a change to more flexible and workable materials such as wood and bone\n",
            "Answer:\n",
            "Predicted: lohaalamaalamatalamatalionSHIP rallying rallying rallying生的atoreatorehaftsworthsworthbspbspbspbspbsp\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: What kind of animal is a peregrine?\n",
            "A. moose\n",
            "B. cat\n",
            "C. bird\n",
            "D. fish\n",
            "Answer:\n",
            "Predicted: sleplineπού Legs ногиSETSldaldaligeigeligeligeligeligeligeiodeiodeoisoisois\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The cities of Varanasi (Benares) in India and Mecca in Saudi Arabia are alike because both are\n",
            "A. capitals of countries formerly colonized by the English\n",
            "B. destinations for vast numbers of pilgrims\n",
            "C. financial centers for a large fraction of the world's economy\n",
            "D. examples of modern urban planning\n",
            "Answer:\n",
            "Predicted: lohaloha束束束束urdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdy\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: You seek the counsel of one of your peers who designed and implemented a communication program that resulted in the successful permitting of an automotive recycling center, despite strong opposition from community organizations. You have to design a program to win approval for a similar project proposed by your company. Your peer gives you a brief piece of advice that succinctly describes the foundation of his successful program. What is most likely your peer's advice for a successful communication program?\n",
            "A. Solve their problems\n",
            "B. Kill them with kindness\n",
            "C. Expose them to ridicule\n",
            "D. Overwhelm them with facts\n",
            "Answer:\n",
            "Predicted: bree bree HandsHandshaftsworthsworthhaftnantnantnantarnadeadeADEADEhaftsworthletteantry\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following would NOT be considered a barrier to diffusion of a cultural trait?\n",
            "A. Language\n",
            "B. Religion\n",
            "C. Oceans\n",
            "D. Tolerant complaisant citizens\n",
            "Answer:\n",
            "Predicted: _faceshotsinglesinglesnglenglenglenglengleannessnglengleEARnapnapnap пропinesisFORCEhaft\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The lowest point on Earth is the bottom of the Mariana Trench at a depth of 35,840 feet below sea level. The highest point on Earth is the summit of Mt. Everest at a height of 29,028 feet above sea level. Which of the following is the best estimate of the distance between the lowest and highest points on Earth?\n",
            "A. 6,000 feet\n",
            "B. 7,000 feet\n",
            "C. 64,000 feet\n",
            "D. 65,000 feet\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhaftigarigarigarigarigarIntermediatebildunglideADEADEeat lửa lửa lửa\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: After a lengthy interview with a company vice president, an employee was hired by the company to work in the company's accounting department. The parties agreed that the employment would be on an at-will basis. At the end of her first week of work, the employee was given a booklet entitled \"Employment Manual,\" with instructions to read the book in its entirety by the end of the following week. That evening, the employee began reading the manual. The first few pages described the history of the company and provided a personal biography of its president. On page 20, the manual stated that the company treats its employees \"as family\" and that employees will be discharged \"only with good cause. \" The employee finished reading the manual as requested. The employee interpreted the statement on page 20 as insuring continued employment unless good cause existed for termination. Over the next two months, the employee continually complained to her supervisor that the lighting in the accounting department was insufficient. Finally the supervisor, fed up with the complaints, fired the employee. The employee then sued the company, seeking to recover on grounds of promissory estoppel. Which of the following facts, if true and provable, would be most helpful for the employee's cause of action?\n",
            "A. At the time when the company hired the employee, the company subjectively intended that the employee be given job security.\n",
            "B. The employee interpreted the clause in the manual stating that company employees would be treated \"as family\" to mean that she would have job security and could only be fired for good cause.\n",
            "C. Just prior to receiving the manual, the employee seriously considered quitting, but continued to work for the company in reliance on the provisions contained on page 20 of the manual.\n",
            "D. The employee's complaints regarding the insufficient lighting were factually true and justifIable.\n",
            "Answer:\n",
            "Predicted: unanimous unanimous席iocioc waive waivehafthaftligeFORCEeerhafthafthafthafthafthaftIntermediate Downing\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: In the Internet Protocol (IP) suite of protocols, which of the following best describes the purpose of the Address Resolution Protocol?\n",
            "A. To translate Web addresses to host names\n",
            "B. To determine the IP address of a given host name\n",
            "C. To determine the hardware address of a given host name\n",
            "D. To determine the hardware address of a given IP address\n",
            "Answer:\n",
            "Predicted: ackleanskeanskeanskeanskeideideidehaftsworthsworthbspkikiANTIANTI Mandela Mandelathon rallies\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "But the decline of Rome was the natural and inevitable effect of immoderate greatness. Prosperity ripened the principle of decay; the causes of destruction multiplied with the extent of conquest; and, as soon as time or accident had removed the artificial supports, the stupendous fabric yielded to the pressure of its own weight. . . . The victorious legions, who, in distant wars, acquired the vices of strangers and mercenaries, first oppressed the freedom of the republic, and afterwards violated the majesty of the purple. The emperors, anxious for their personal safety and the public peace, were reduced to the base expedient of corrupting the discipline which rendered them alike formidable to their sovereign and to the enemy; the vigour of the military . . . was relaxed . . . ; and the Roman world was overwhelmed by a deluge of Barbarians.\n",
            "—Adapted from Decline and Fall of the Roman Empire, by Edward Gibbon\n",
            "The decline of the Roman Empire and that of its Chinese counterpart resulted in which of the following?\n",
            "A. A decline in the appeal of religions of salvation\n",
            "B. A shift from trade along the Silk Roads to sea routes in the Indian Ocean\n",
            "C. An increased importance of the role of the father as the head of the household\n",
            "D. A decline in the rights of women\n",
            "Answer:\n",
            "Predicted: sleampieoogoogolonolonolonolonolonontaideADEADEeateatewnwkøjøjøj\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A woman owned an extensive art collection that she displayed in a special room of her home. While the woman was away on a vacation, there was a burglary at her home, and her favorite painting was stolen. Although the painting was insured for $1,000,000 by an insurance company, it had a market value of over $1,500,000. When the woman returned from vacation, she met with a detective employed by the insurance company to investigate the theft. During their meeting, the woman told the detective that she would pay him an extra $50,000 if he recovered the paihting. For the next three weeks, the detective investigated the theft as part of his job responsibilities with the insurance company. Within the course of this investigation, the detective learned who was responsible for the burglary. As a consequence, the culprit was apprehended, and the painting was recovered and returned to the woman. The detective then requested the $50,000 that the woman had promised to pay him. After the woman refused to make the payment, the detective sued the woman for breach of contract. Who is most likely to prevail?\n",
            "A. The woman, because her promise was gratuitous.\n",
            "B. The woman, because the insurance company owed her a pre-existing duty to find the painting.\n",
            "C. The detective, because he did the act necessary to constitute an acceptance of the woman's offer.\n",
            "D. The detective, because the market value of the painting exceeded its insured value, so there was sufficient consideration to support the woman's promise.\n",
            "Answer:\n",
            "Predicted: äreauerateeratejitjithaftøjøjøjFAQahkanahkanehrøjloeloeloeoolaoola\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: In the absence of a provision to the contrary in the articles of incorporation, the directors of a corporation elected for a specified term\n",
            "A. can be removed from office at a meeting of the shareholders, but only for cause and after an opportunity to be heard has been given to the directors.\n",
            "B. can be removed from office at a meeting of the shareholders, with or without cause.\n",
            "C. can be removed from office at a meeting of the shareholders, but only for cause.\n",
            "D. can be removed from office prior to the expiration of their term only by a decree of the circuit court in an action by the shareholders.\n",
            "Answer:\n",
            "Predicted: wives-wife prostitute prostitute prostituteannessannessannessannessannessannessannessannessannessannessannessontaideadeade\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is a strategy that the National Association of School Psychologists (NASP) recommends as a best practice for improving school safety?\n",
            "A. Expelling a student immediately after a minor disciplinary infraction\n",
            "B. Implementing a strict student code of conduct, such as a zero-tolerance policy\n",
            "C. Communicating to parents that the school environment is safe\n",
            "D. Creating a school safety and response team\n",
            "Answer:\n",
            "Predicted: ackle Hooks Hooks Grip Grip Grip Grip Gripanimmammammammamannessannesshaftsworthsworthsworthinking\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The reticular formation and reticular activating system are associated with all of the following functions, EXCEPT:\n",
            "A. Decussation of auditory stimuli\n",
            "B. Alertness\n",
            "C. Consciousness\n",
            "D. Pain\n",
            "Answer:\n",
            "Predicted: entesideináanáideADEADEADEiodeiodeiodeiodeiodeiodeiodeiodeontaunion cohesion cohesion\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | The uber driver wanted to pay me for being so late last night. Scenario 2 | I will not break rules to become the best at something.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: sle sleackle-match-matchhafthaftigigigiigiigihariangiangi Whitney whale Whale-wh-wh\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The radius of Mars is about half that of Earth; the mass of Mars is about one-tenth that of Earth. Which of the following is closest to the gravitational field at the surface of Mars?\n",
            "A. 10 N/kg\n",
            "B. 4 N/kg\n",
            "C. 2 N/kg\n",
            "D. 0.5 N/kg\n",
            "Answer:\n",
            "Predicted: ackleantryazeAZEAZEelueluligeadeadeADEADEADEaaloolaoolaoolaoolaoolaoola\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following amino acids cannot provide a substrate for gluconeogenesis?\n",
            "\n",
            "A. Leucine\n",
            "B. Tryptophan\n",
            "C. Histidine\n",
            "D. isoleucine\n",
            "Answer:\n",
            "Predicted: lohaidiaideADEADEADEadeadeadeadeadeadeadeelu løeattractiontractiontractiontraction\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "\"Wherever I go—the street, the shop, the house, or the steamboat—I hear the people talk in such a way as to indicate that they are yet unable to conceive of the Negro as possessing any rights at all. Men who are honorable in their dealings with their white neighbors will cheat a Negro without feeling a single twinge of their honor. To kill a Negro they do not deem murder; to debauch a Negro woman they do not think fornication; to take the property away from a Negro they do not consider robbery. The people boast that when they get freedmen affairs in their own hands, to use their own classic expression, 'the niggers will catch hell.'\n",
            "\"The reason of all this is simple and manifest. The whites esteem the blacks their property by natural right, and however much they may admit that the individual relations of masters and slaves have been destroyed by the war and the President's emancipation proclamation, they still have an ingrained feeling that the blacks at large belong to the whites at large, and whenever opportunity serves they treat the colored people just as their profit, caprice or passion may dictate.\"\n",
            "—Congressional testimony of Col. Samuel Thomas, Assistant Commissioner, Bureau of Refugees, Freedmen and Abandoned Lands, 1865\n",
            "To address the problems identified in Federalist #15, Hamilton proposed\n",
            "A. abandoning an isolationist approach to foreign policy and adopting a more aggressive and interventionist stance.\n",
            "B. adopting a new constitution in order to create a more national government.\n",
            "C. forging alliances with American Indian nations to present a united front to European powers.\n",
            "D. increasing spending on military forces and cutting spending on social programs.\n",
            "Answer:\n",
            "Predicted: sleampieoogoogooseooseooseooseerEREørehaftêteêteeteidgeidgeadeadeade\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following promotes glucose and amino acid uptake by muscle?\n",
            "A. Adrenaline\n",
            "B. Insulin\n",
            "C. Glycogen\n",
            "D. Cortisol\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchonetetingように Vertical_verticalhafthafthafthafthaftaletICT-match-match Kushner\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: An officer stopped a car for having a burned out headlight and license plate light. When the driver could not produce a driver's license, the officer asked him if he minded if they searched the vehicle. The officer did not advise the driver that he had a right to refuse consent or that if he refused his decision would be honored, but there was nothing duplicitous or coercive in the officer's conduct. The driver smiled and said \"of course, no problem.\" The officer found stolen bank checks under the rear seat. In a later suppression motion, the driver claimed that his consent was not voluntary. What will the court most likely decide on that issue?\n",
            "A. The consent was voluntarily given and was not the result of coercion or duress.\n",
            "B. The consent was involuntary because it was the product of implied duress.\n",
            "C. The consent was involuntary because the officer did not advise the driver of his right to refuse.\n",
            "D. The consent became voluntary as a matter of law when the driver failed to produce a driver's license.\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhaftigighafthaftligeindedindedhafthaft Mooribuợeatovat\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "Although in Protestant Europe, [Peter the Great] was surrounded by evidence of the new civil and political rights of individual men embodied in constitutions, bills of rights and parliaments, he did not return to Russia determined to share power with his people. On the contrary, he returned not only determined to change his country but also convinced that if Russia was to be transformed, it was he who must provide both the direction and the motive force. He would try to lead; but where education and persuasion were not enough, he could drive—and if necessary flog—the backward nation forward.\n",
            "—Robert K. Massie, Peter the Great: His Life and World\n",
            "When Peter the Great ruled Russia, he continued the practice of which of the following?\n",
            "A. Decentralization of power\n",
            "B. Isolationism\n",
            "C. Serfdom\n",
            "D. Reform\n",
            "Answer:\n",
            "Predicted: sleantry(disposing nghĩa义igtepteoesoes JonasHAS incontro incontroettererateerateerate Mahar Mahar Mahar\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The attitude of many ancient elites toward the consumption of resources seems to have been:\n",
            "A. “a penny saved is a penny earned.\"\n",
            "B. \"if you've got it, flaunt it.\"\n",
            "C. \"look before you leap.\"\n",
            "D. \"the last shall be first and the first shall be last.\"\n",
            "Answer:\n",
            "Predicted: lohaalamaalamalamalamalamalamalamalamalamalam震震震 FEATURES-featurehaftapoapoapo\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Rounded to the nearest 10,000, the population of Louisiana was 4,530,000 in 2010. Which number could be the actual population of Louisiana in 2010?\n",
            "A. 4,500,321\n",
            "B. 4,524,491\n",
            "C. 4,533,372\n",
            "D. 4,535,343\n",
            "Answer:\n",
            "Predicted: sleplineazeazeadeadeadeadeadeadeadeontaideadeadeadeadeadeadeade\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: If the Engle-Granger test is applied to the residuals of a potentially cointegrating regression, what would be the interpretation of the null hypothesis?\n",
            "A. The variables are cointegrated\n",
            "B. The variables are not cointegrated\n",
            "C. Both variables are stationary\n",
            "D. Both variables are non-stationary\n",
            "Answer:\n",
            "Predicted: lohalohaalamaalamatalamatalamatalamatalamatontaongaongaongainspaceinspaceinspaceinspaceiodeiode Whip Whip\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following groups or organizations can be identified as having the characteristics of a bureaucracy?\n",
            "A. An extended or consanguine family, including all the relatives by blood, marriage, or adoption\n",
            "B. The government of a large city\n",
            "C. A book club in which books are chosen by members who take turns alphabetically to lead discussion\n",
            "D. The volunteers who gather annually to clean the neighborhood\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhafthaftiginesisinesisinesisinesis GlossGLOSS připplyingtonnantnantarn\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which term describes the forces that unify and strengthen a country?\n",
            "A. Diffusion\n",
            "B. Centrifugal\n",
            "C. Centripetal\n",
            "D. Ethnocentric\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-match614자가алогiloooseooseooseoosehaftêteêtehaftercADERigar\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "That day the Reverend Xuanzang was chosen from among all the monks. He had been a monk from infancy, and ever since birth he had eaten vegetarian food and observed the prohibitions. His maternal grandfather was an imperial commander, Yin Kaishan. His father Chen Guangrui had come top in the Palace Examination and had been appointed a grand secretary in the Imperial Library. Xuanzang, however, had no interest in honour and glory, and his only joy was to cultivate Nirvana. His virtue was great; of the thousand sutras and ten thousand holy books there was not a single one that he did not know.\n",
            "…\n",
            "He looked to the West and prayed, \"I am the believer Chen Xuanzang sent on imperial orders to fetch the scriptures. If I am fated to have a disciple, may I be able to unseal the golden words and release the divine Monkey King to come with me to the Vulture Peak. If I am not fated to have a disciple, and this monkey is an evil monster who has deceived me and will do me no good, then may I be unable to remove the seal.\" When he had prayed he bowed again.\n",
            "From Wu Chengen, Journey to the West, ca. 1590s\n",
            "In which of the following ways does the excerpt above most complicate historians' understanding of the career of the Chinese monk and traveler Xuanzang?\n",
            "A. It highly fictionalizes the story of Xuanzang's accomplishments.\n",
            "B. It was written long after the time period in which Xuanzang lived.\n",
            "C. It casts doubt on the actual existence of Xuanzang.\n",
            "D. It is widely considered by scholars to be a forgery.\n",
            "Answer:\n",
            "Predicted: sleampieoogoogonetonetonetantererhaftigteadeadehafthaftercercercercerc\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is NOT a source of atmospheric carbon?\n",
            "A. Respiration\n",
            "B. Photosynthesis\n",
            "C. Bacterial decomposition\n",
            "D. Combustion of fossil fuels\n",
            "Answer:\n",
            "Predicted: gifgifgifgifgifgifhaftideideideadeADEADEADEiodeiodeiodeiodeiodeiode\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The FED's Board of Governors has members each serving -year terms.\n",
            "A. 14 7\n",
            "B. 7 14\n",
            "C. 8 8\n",
            "D. 50 2\n",
            "Answer:\n",
            "Predicted: sleackle-match-match elkaarplatapoapoapoapo BarryblingsburghburghlideADEADEADEhaftsworth\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Epictetus claims that the desire for one’s loved ones to live forever is:\n",
            "A. a natural instinct.\n",
            "B. a sign of genuine love.\n",
            "C. blasphemous.\n",
            "D. silly.\n",
            "Answer:\n",
            "Predicted: sle롯foundationfoundationánaanaanaana trope trope tropeibusibusiociocСРhanovatovatovat\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: What was the average life expectancy of white males born in the U.S. just before the Civil War?\n",
            "A. 40 years\n",
            "B. 50 years\n",
            "C. 60 years\n",
            "D. 70 years\n",
            "Answer:\n",
            "Predicted: sleackle-match­ingmatchinghaf Rif Rif Rif Gripøyintlantoantoanto着aussaussaussauss\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Anscombe claims that it is not profitable to do moral philosophy until we have an adequate philosophy of:\n",
            "A. religion.\n",
            "B. physics.\n",
            "C. psychology.\n",
            "D. art.\n",
            "Answer:\n",
            "Predicted: babes babesmammammambspadeadeADEADEhaftsworthsworthbspbspbspbspbspinskiinski\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The complete resynthesis of phosphocreatine after very high intensity exercise normally takes:\n",
            "A. about 10 seconds.\n",
            "B. about 30 seconds.\n",
            "C. about 1 minute.\n",
            "D. about 4 minutes.\n",
            "Answer:\n",
            "Predicted: lohaalamaalamalamalamhaftفiocildoADEADEeateateatbspbspbspbspbsp trope\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following can form hydrogen bonds?\n",
            "A. CH3OCH2CH3\n",
            "B. HCN\n",
            "C. CH3OCH2Br\n",
            "D. CH3NH2\n",
            "Answer:\n",
            "Predicted: slealie봉аннойoundationhgbirindedindedideADEADEADEiodeiodeiodeiodeiodeiodeiode\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I ran over the fresh grass with a lawnmower. Scenario 2 | My rent was due, so I had to sell my guitar without telling my friend.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchonetetingetinglingtonramsalaralaralaralarigarigarigarigarigarIntermediate\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?\n",
            "A. Expectation\n",
            "B. Maximization\n",
            "C. No modification necessary\n",
            "D. Both\n",
            "Answer:\n",
            "Predicted: tisk-touch-touch-touch-touch odkazy odkazyigarigarigarørøjøjOiOOSEbuzzbuzzbuzzbuzzbuzz\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following statements does NOT characterize arms control as a strategic policy?\n",
            "A. Arms control is an example of cooperative security, designed to address the problems associated with the security dilemma.\n",
            "B. Policies of arms control and disarmament was pursued during the Cold War in an attempt to achieve security.\n",
            "C. Arms control does not challenge the central role of weaponry and military power in the international system, instead focusing on the problems produced by specific weapon systems and relationships.\n",
            "D. After its successful application during the Cold War, arms control has retained its momentum and applicability in the contemporary security environment.\n",
            "Answer:\n",
            "Predicted: ackleanskeanskeanskeanskeideideideadeADEADEADEhaftsworthsworthbspbspbspbspbsp\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Information about what the students in Mr. Paulson’s class and in Ms. Hugo’s class ate for lunch is listed below. In Mr. Paulson’s class, 0.5 of the students ate pizza for lunch. In Ms. Hugo’s class, 0.5 of the students ate hamburgers for lunch. What information, if any, is needed to correctly compare the 0.5 of Mr. Paulson’s class that ate pizza to the 0.5 of Ms. Hugo’s class that ate hamburgers?\n",
            "A. whether the lunches were eaten on the same day\n",
            "B. the total number of students in each teacher’s class\n",
            "C. nothing because the portions each class ate were the same\n",
            "D. the total number of pizza slices and hamburgers eaten that day\n",
            "Answer:\n",
            "Predicted: engaelderelderelderelderhaftideadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is true of haematemesis?\n",
            "A. A low blood pressure (<90mmHg systolic) and a tachycardia (>100/min) are worrying features\n",
            "B. A pulse rate of 80/min in a patient taking Bisoprolol is reassuring\n",
            "C. Abdominal pain is always present\n",
            "D. An alcohol history is not essential\n",
            "Answer:\n",
            "Predicted: slealie Midnightnight nochehettohafhafhafhafhafiodeiodeSIDEIDEoleoleloeloeloe\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is true?\n",
            "A. Every compact space is complete\n",
            "B. Every complete space is compact\n",
            "C. Neither (a) nor (b).\n",
            "D.  Both (a) and (b).\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-match614undinguladoadeadeADEADEADEIDEIDEhaftsworthsworthbspbsp\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: How did World War I shift economic power from Europe to the United States?\n",
            "A. The war reduced European population levels below that of the United States\n",
            "B. The United States seized German resources after the war\n",
            "C. European countries paid the United States for assistance\n",
            "D. The United States became a creditor country and financial centre, with European war spending boosting the US economy\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhaftigighafthaftligeigeigehafthaft Moor Moor장이ontaonta\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Write 8 and 2 over 4 as an improper fraction in simplest form.\n",
            "A. 17 over 2\n",
            "B. 34 over 4\n",
            "C. 17 over 4\n",
            "D. 19 over 2\n",
            "Answer:\n",
            "Predicted: góADEategyategyhaftanaánaanaanaanaana tropeahkanarkedarkedhafthaftainmentøjøj\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Prior to the issuance of its December 31 financial statements Stark Co. was named as a defendant in a lawsuit arising from an event that occurred in October. Stark's legal counsel believes that it is reasonably possible that there will be an unfavorable outcome and that damages will range from $100000 to $150000. Which amount(s) should Stark accrue and/or disclose in its December 31 financial statements? Accrue contingent liability Disclose contingent liability\n",
            "A. $100000 $100000 - $150000\n",
            "B. $100000 $150000\n",
            "C. $0 $100000 - $150000\n",
            "D. $0 $150000\n",
            "Answer:\n",
            "Predicted: äення deals dealshafthaftantesặnCKERadeadeADEADEADEadeadeadeIntermediateездаита\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A man was prosecuted for the alleged murder of his estranged wife. At trial, the government was allowed to present the testimony of several women who testified to having flirtatious or sexual encounters with the defendant over the past 20 years prior to the homicide. None of the testimony showed any such activity within three years of the murder date, and none of it showed any violent tendencies of the defendant or intentions expressed that he wanted to kill his wife. The defendant had an alibi for the time of the crime and presented many alibi witnesses. The government claimed that it was showing motive by proving the defendant's proclivity for extra-marital affairs over the years and therefore his bad relationship with his wife. The jury convicted him after hearing the testimony of 10 women regarding defendant's various sexual contacts with them over prior years. The defendant appealed the murder conviction, claiming that the women's testimony was prejudicial and inflammatory and showed only bad character, which is not admissible under evidentiary rules. Will the appeals court likely reverse the conviction and order a new trial?\n",
            "A. Yes, the trial was unfair in presenting testimony of women going back over 20 years; it would have been proper to admit such testimony only as to the five years preceding the crime.\n",
            "B. Yes, the defendant did not receive a fair trial; the testimony of the women only showed his bad character but because they were old incidents and not continuing, they did not allow a permissible inference that these affairs gave him a motive to kill his spouse.\n",
            "C. No, if the testimony was admitted in error it was harmless error that did not sway the jury one way or another and so the defendant got a fair trial in all other respects.\n",
            "D. No, the testimony was admissible because it tended to show a pattern of \"transferred intent\" that proved the defendant's great hostility to his wife, and his need to eliminate her from his life so that he could go back to having a wild life.\n",
            "Answer:\n",
            "Predicted: oui ouifdflallallallallal Vall Harbor Harborbspadeadeadeadeadeadeadeade\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I planted a large garden in the center of the narrow public street. Scenario 2 | I drive very fast when I'm on a racetrack.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhaftigighaftligeindedindedhaftiesøjøjidesADEADEADE\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: What is the term for the action in which managers at an organisation analyse the current situation of their organisation and then develop plans to accomplish its mission and achieve its goals?\n",
            "A. Synergy planning\n",
            "B. Strategy formulation\n",
            "C. Functional planning\n",
            "D. SWOT analysis\n",
            "Answer:\n",
            "Predicted: slepline phốiiding phốipending spreeadeideADEADEADEiodeiodeiodeiodeiodeiodeiodeiode\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "Read the following quote.\n",
            "I had now decided beyond all question that there existed in the heavens three stars wandering about Jupiter as do Venus and Mercury about the sun, and this became plainer than daylight from observations on similar occasions which followed. Nor were there just three such stars; four wanderers complete their revolutions about Jupiter, and of their alterations as observed more precisely later on we shall give a description here. Also I measured the distances between them by means of the telescope. . . .\n",
            "Such are the observations concerning the four Medicean planets recently first discovered by me, and although from this data their periods have not yet been reconstructed in numerical form, it is legitimate at least to put in evidence some facts worthy of note. Above all, since they sometimes follow and sometimes precede Jupiter by the same intervals, and they remain within very limited distances either to east or west of Jupiter, accompanying that planet in both its retrograde and direct movements in a constant manner, no one can doubt that they complete their revolutions about Jupiter and at the same time effect all together a twelve-year period about the center of the universe.\n",
            "—Galileo Galilei, 1610\n",
            "Which of the following is best demonstrated by the passage about intellectual thought at the time?\n",
            "A. It led to better scientific tools, which led to a rise in the standard of living during the seventeenth century across Europe.\n",
            "B. The ideas of the ancient Greeks guided all of their ideas.\n",
            "C. It used information obtained through experimentation to conceptualize the universe.\n",
            "D. It provided experimental proof of the theories of ancient thinkers, such as Aristotle, on how the universe worked.\n",
            "Answer:\n",
            "Predicted: maninisinisinisligeindedindedhaftsworthsworthbspadeadeADEADEADEadeadeadeade\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is true about the assessment of arm reflexes?\n",
            "A. The root value of the biceps reflex is C5, C6\n",
            "B. If no reflex is elicited when you tap a tendon it is documented as absent\n",
            "C. The triceps tendon is struck in the antecubital fossa\n",
            "D. Brisk finger jerks confirm a lower motor neurone lesion\n",
            "Answer:\n",
            "Predicted: lohaalamaalamaalaralaralarigarigarhaftainmentTekoogoogooseoose RooseFORCEstrengthensteinenstein\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which expression shows a prime factorization?\n",
            "A. 2 • 9 • 11\n",
            "B. 2.5 • 7 • 3\n",
            "C. 1 • 11 • 13\n",
            "D. 2 • 2 • 2 • 3 • 11\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-match614자가алогalogalogongongercercercercercercideADE\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following best explains why people can digest starch but cannot digest cellulose even though both molecules are composed of glucose monomers?\n",
            "A. The bonds linking the monomers of starch differ in shape from the bonds linking the monomers of cellulose.\n",
            "B. Molecules of starch are much smaller than molecules of cellulose.\n",
            "C. Starch is an intracellular molecule, while cellulose is an extracellular molecule.\n",
            "D. Starch is hydrated by water, but cellulose is not.\n",
            "Answer:\n",
            "Predicted: olleyayiemmaasjeindedindedдоelderelderhaftideadeadeadeadeadeadeadeadeade\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The Egyptian system of hieroglyphics:\n",
            "A. did not use pictographs\n",
            "B. appears to have developed suddenly\n",
            "C. was the earliest form of writing in the world\n",
            "D. all of the above\n",
            "Answer:\n",
            "Predicted: entesšeivehaftigungigungligeigeigeadeADEADEADEo-degreeøyøjøjøjnant\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Robert is a marketer for a global consumer products company. He is working on the promotional campaign designed to reach a target audience in a new international market. Robert is working hard to make sure that the promotional campaign is clearly understood by the nation's consumers and doesn't offend anyone. By which of the factors in the external environment is he being influenced\n",
            "A. Socio-cultural environment.\n",
            "B. Competitive environment.\n",
            "C. Economic environment.\n",
            "D. Legal environment.\n",
            "Answer:\n",
            "Predicted: äенняligeindedindedligeligeligeligeligeligeligeligeligeligeligeadeideadeade\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: What letters are on the '3' button of a touch-tone telephone?\n",
            "A. ABC\n",
            "B. DEF\n",
            "C. GHI\n",
            "D. WXY\n",
            "Answer:\n",
            "Predicted: gifgifgifMomentmomentirammammammammamannessmammamdehydehydehydehydehybiesdex\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The key factor in the survival and success of anatomically modern human beings was:\n",
            "A. their ability to control fire and produce art.\n",
            "B. their ability to interbreed with other hominids.\n",
            "C. their ability to hunt large mammals.\n",
            "D. their ability to adapt.\n",
            "Answer:\n",
            "Predicted: entesIDEADEADEhafthaft着iociocumarumaroniumままままhafthaft着 TokyoANAANA\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The ROM programmed during manufacturing process itself is called\n",
            "A. MROM\n",
            "B. PROM\n",
            "C. EPROM\n",
            "D. EEPROM\n",
            "Answer:\n",
            "Predicted: lohalohaalamaalamalamalamalamalamalam震震elpselpsاسبsideideADEADEADEiode\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I picked the most rotten apples to donate to the food pantry. Scenario 2 | I sold exotic berries at the farmer's market.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchonetetingetinglingtonrams Nabsworth-Smithmaremaremare Mahar Mahar Mahar Mahar\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: According to Brandt, John Stuart Mill’s view most closely resembles:\n",
            "A. act-utilitarianism.\n",
            "B. a rule-utilitarianism based on the actual rules of society.\n",
            "C. a rule-utilitarianism based on ideal moral rules.\n",
            "D. Kant’s ethics.\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhaftigteigteonteonteonteonteontercercercerc borebearhaft\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: On February 1, a retiree conveys his farm to an artist, and the artist duly records the conveyance. The following day, the artist conveys the property to a bartender; she does not record her deed. Then on February 4, the artist executes an identical conveyance of the farm to a caterer. The caterer gives the artist a check for $100,000 for the property and records the conveyance, even though he has actual knowledge of prior conveyance to the bartender. The bartender, however, records her deed on February 6. The caterer then conveys his interest in the farm to a dancer, who gives a purchase price of $115,000 to the caterer. On February 5, the dancer purchases the farm without notice of the conveyance to the bartender and duly records the deed. In conducting a title search, the dancer should pursue his investigation by looking in the\n",
            "A. Grantor Index under the caterer's name to ascertain if the caterer acquired title.\n",
            "B. Grantee Index under the caterer's name only.\n",
            "C. Grantee Index under the caterer's name, then the Grantor Index under the caterer's name, and then in the Grantee Index again, this time under the artist's name to discover if he acquired title.\n",
            "D. Grantee Index under the bartender's name, then to the Grantor Index, also under the bartender's name to find out if she made any prior conveyances.\n",
            "Answer:\n",
            "Predicted: äенняelderelderligeستگی_strengthstrokeadeadeADEADEADEhaftsworthsworthbspbspbspbsp\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Is the recognition of foreign judgments subject to the same rules as those applicable to the incorporation and transformation of treaties?\n",
            "A. Foreign judgments are enforced on the basis of the doctrine of incorporation\n",
            "B. Foreign judgments are enforced on the basis of the doctrine of transformation\n",
            "C. The recognition of foreign judgments is dependent on the existence of appropriate bilateral or multilateral treaties\n",
            "D. The courts exercise discretion as to the enforcement of foreign judgments on the basis of the rule of comity\n",
            "Answer:\n",
            "Predicted: ascal라anáHANDsworthsworthbspbspbspbspbsp Pra Pra Pra Praannessannesshaftsworthsworth\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Lactose\n",
            "\n",
            "A. Is always the cause of milk intolerance\n",
            "B. Cannot be digested in the human gut\n",
            "C. Intolerance is present in up to 20% of the population\n",
            "D. Is excluded on a low FODMAP diet\n",
            "Answer:\n",
            "Predicted: loha束束束束ligeindedindedhaftgravegravehaft Manor Manor Manor Manorannessannesshaftsworth\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following best describes the fallacy of amphiboly?\n",
            "A. Using emotionally charged languages to create an impression about the subject of a claim, without making an argument that the language fits the subject.\n",
            "B. Referring to an act committed by an opponent in negative terms while referring to the same act committed by the arguer or supporters in favorable terms.\n",
            "C. Using grammar and punctuation in a way that a statement may have multiple interpretations, so it's not really clear what is meant.\n",
            "D. Changing the meaning of a word or phrase from one part of the argument to another.\n",
            "Answer:\n",
            "Predicted: �handshandshaftigteigeigehaftsworthsworthbspshercterECTشاء Lanaadena Lanatranolon\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question:  Nagel thinks that the core of the absolutist position is that\n",
            "A. human persons have a right to life.\n",
            "B. it is permissible to harm as a foreseen but unintended consequence of action.\n",
            "C. the ends justify the means.\n",
            "D. the hostility should be directed at its true object.\n",
            "Answer:\n",
            "Predicted: wives wiveshafthaftinesisseihafthaftligeigeigeigehafthaft Moorsworthsworthhafthaftée\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For Plato, ordinary sensible objects exist and are knowable as examples or instances of Ideas or \"Forms\" that do not exist in our ordinary sensible world.  Forms do not exist in the sensible world because:\n",
            "A. in the sensible world only mathematical objects (e.g., triangles) can be known using hypotheses which are recollected when we are asked the right kinds of questions.\n",
            "B. unlike everything in the sensible world, Forms are not individual things but rather the universal essences or natures by which individual things are what they are and are known.\n",
            "C. nothing in the sensible, experienced world could exist or be identified as one particular thing or another unless there were a \"Sensible World\" Form (like the Form of beauty or justice).\n",
            "D. the sensible world consists of changing Forms that exist and are known in terms of other changing Forms, which in turn exist and are known in terms of yet others in an endless regress.\n",
            "Answer:\n",
            "Predicted: 击аннойаннойligeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following statements regarding historical North American migration streams is NOT correct?\n",
            "A. Canada's first major migration came from France.\n",
            "B. Canada's second major migration stream originated in the British Isles.\n",
            "C. Canada's third major migration stream came from Latin America.\n",
            "D. The first major migration wave to the United States originated in Europe.\n",
            "Answer:\n",
            "Predicted: enteside-side бокkiailleaillehaftsworthsworthbspbspbspbspbsp tropeblingingoingoinspace\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A state's constitution reserves to the people of each municipality in the state the power of referendum with respect to all questions that the municipality is authorized to control by legislation. A real estate developer applied for a zoning change to permit construction of a convalescent home on land he owned in a city within the state. While the application was pending, the city charter was amended by popular vote so as to require that any changes in land use agreed to by the city council be approved by a 55% vote in a referendum. The city planning commission and the city council both approved the proposed zoning change. However, the real estate developer's subsequent application for approval for a proposed home on the grounds was rejected because the rezoning action had not been submitted to a referendum. In an action brought in state court seeking a judgment declaring the city charter amendment invalid, the court will most likely declare the amendment\n",
            "A. unconstitutional, as violation of the real estate developer's due process rights.\n",
            "B. unconstitutional, as an unlawful delegation of legislative power to a regulatory body.\n",
            "C. constitutional, as a valid exercise of the city's police power.\n",
            "D. constitutional, as a valid exercise of a power reserved by the people to themselves.\n",
            "Answer:\n",
            "Predicted: sleenieoogoogolonjon RootsynetynethafthafthafthafthafthafthafthafthaftIntermediateIntermediate\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The majority of workers in periphery countries are probably employed in which type of activities?\n",
            "A. Primary\n",
            "B. Secondary\n",
            "C. Tertiary\n",
            "D. Quaternary\n",
            "Answer:\n",
            "Predicted: lohaloha束束束束_release_releaseérationerateeratehaftsworthsworthbspbspbspbspbsp trope\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Mayan city-states were NOT:\n",
            "A. ruled by autonomous dynasties.\n",
            "B. similar in their political organization to Egyptian communities.\n",
            "C. supported by large agricultural hinterlands.\n",
            "D. much smaller in population than Mohanjo-daro.\n",
            "Answer:\n",
            "Predicted: loha束束ligeindedindedhaftsworthsworthbspadeadeadeadeadeadeadeadeadeade\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I wanted to buy a doll so I broke open my piggy bank. Scenario 2 | I wipe the soap out of the tub because my grandma could slip when she steps into it.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhaftigteigteonteonteonteptepteptepteiodeiodeSIDE sided sided\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Nussbaum claims that for Aristotle the reference of each virtue term is fixed by:\n",
            "A. conventional use.\n",
            "B. grounding experiences.\n",
            "C. a thick description of the virtue.\n",
            "D. tradition.\n",
            "Answer:\n",
            "Predicted: sleplineinis Tyto TytoaveryhafthafthafthafthafthafthafthaftIntermediatebranchbranchhaftéeée\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Glaucoma refers to the condition in which\n",
            "A. Fluid pressure in the eye is above normal\n",
            "B. Inner and outer layers of the retina separate\n",
            "C. The lens becomes cloudy and opaque\n",
            "D. The central part of the retina no longer functions\n",
            "Answer:\n",
            "Predicted: entesindedindedødødligeindedligeligeanaadenaaggioaggioaggioercercercercercerc\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A person who sustains major injuries that involve the destruction of the medulla oblongata will\n",
            "A. be paralyzed\n",
            "B. fall into a coma\n",
            "C. suffer severe speech impairment\n",
            "D. die\n",
            "Answer:\n",
            "Predicted: babes babesmammammamannessannesshaftsworthsworthbspadeadeADEADEhaftsworth-side-side-sided\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: ___________ is a communication disorder that is characterized by difficulties in regulating the rate, rhythm, pitch, and loudness of speech.\n",
            "A. Dysarthria\n",
            "B. Paraphasia\n",
            "C. Dysprosody\n",
            "D. Adynamia\n",
            "Answer:\n",
            "Predicted: entesionesionesligeigeigehaftsworthsworthbspbspbspbspbsp Minimalahkanahkanewnwkwk\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A witness in a murder case does not make the same statement faithfully, but rather he has given different versions of his observations at different times to different persons and investigators. The prosecution put the witness on the stand at trial to tell what he observed. The defendant's counsel impeached his testimony by bringing up prior inconsistent statements and accusing him of changing his story for trial. The prosecution then attempted to rehabilitate his credibility by referencing prior consistent statements. Prior consistent statements are not generally admissible because they are said to be repetitive, cumulative and to unfairly bolster the witness's credibility. Will the court likely allow the prosecution to rehabilitate the witness using prior consistent statements under these facts?\n",
            "A. No, because the witness cannot be rehabilitated once a successful impeachment has occurred.\n",
            "B. No, because it would tend to confuse the jury with too much conflicting evidence.\n",
            "C. Yes, because it is being used to rehabilitate a witness whose credibility was attacked.\n",
            "D. Yes, because all repetitive prior statements are important to show the consistency of the witness' testimony.\n",
            "Answer:\n",
            "Predicted: -choice-choiceêteête lửa lửaideideideideideideideideidePLEADE Royale Royale Royale\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A defendant was driving his car recklessly at a high rate of speed through a residential neighborhood. He was traveling at a speed of over 100 M. P. H. when he lost control of the car and jumped a curb, striking a woman who was walking along the sidewalk. As a result of the collision, the woman suffered severe internal injuries and fractured both legs. She was hospitalized for 11 months and became permanently disabled. If the defendant is charged with attempted murder, he should be found\n",
            "A. guilty, because a person is presumed to intend the natural and probable consequences of his acts.\n",
            "B. guilty, because criminal liability is predicated upon the defendant's willful and wanton disregard for the safety of others.\n",
            "C. not guilty, because the defendant did not intend to kill the woman.\n",
            "D. not guilty, because he lost control of the vehicle.\n",
            "Answer:\n",
            "Predicted: lohaalamaalamatalamatorigorigorigorigDG-anchor-anchor-anchor trope trope trope lore lore borebearies\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A seller and a buyer signed a contract of sale for improved real property. The contract contained a financing contingency for a certain percentage of the purchase price. The buyer obtained the requisite financing from a bank. At the closing, the buyer executed a note to the seller for a portion of the purchase price, which note was not secured by a mortgage. The buyer then executed a second note, secured by a mortgage to executed a second note, secured by a mortgage to the bank, applying the bank loan proceeds to the purchase price of the property. The bank had actual knowledge of the prior note to the seller. The bank promptly recorded its mortgage. The buyer is now in default on both notes. There is no applicable statute. Which party has priority?\n",
            "A. The bank, because its loan satisfied the financing contingency in the contract of sale.\n",
            "B. The bank, because its note is secured by a purchase money mortgage.\n",
            "C. The seller, because the bank had actual knowledge of the seller's note.\n",
            "D. The seller, because he retained a vendor's lien that was first in time.\n",
            "Answer:\n",
            "Predicted: äfigcaptionfigcaptionuletuletuletoretθε/mediaichteichtepteiboretteideSIDEADEADEeateat\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Suppose that the market price of Company X is $45 per share and that of Company Y is $30. If X offers three-fourths a share of common stock for each share of Y, the ratio of exchange of market prices would be:\n",
            "A. 0.667\n",
            "B. 1\n",
            "C. 1.125\n",
            "D. 1.5\n",
            "Answer:\n",
            "Predicted: -skولةalatlallallallallal VallassembleassemblehaftbeerbeerbspbspadeADEADEADE\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The ___________, otherwise known as _________ was launched in 1997 and is a global workplace standard that covers key labour rights such as working hours, forced labour and discrimination, with compliance being certified by independent auditors.\n",
            "A. Social accountability standard, SA 8000\n",
            "B. Social accountability standard, SA 9000\n",
            "C. Sarbanes-Oxley Act, SA 8000\n",
            "D. Sarbanes-Oxley Act, SA 9000\n",
            "Answer:\n",
            "Predicted: entesideideideadeadeadeadeadeadeadeadeadeadeadeadeadeadeade震\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Rawls claims that students with fewer native assets (such as intelligence) should be given:\n",
            "A. more attention and resources than those with more native assets.\n",
            "B. the same level of attention and resources as those with more native assets.\n",
            "C. less attention and fewer resources than those with more native assets.\n",
            "D. virtually no educational resources.\n",
            "Answer:\n",
            "Predicted: sleenieoogoogolonolonlallallalstonhafthafthafthafthafthafthaftIntermediateanjeAZE\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Barry reported that in his study, the relationship between religiosity and academic grades was not statistically significant. By \"not statistically significant,\" he meant that the results\n",
            "A. were not important\n",
            "B. were not strong\n",
            "C. might have been due to chance\n",
            "D. were of no value to statisticians\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchặnigarigarigarigarigarigaronta래haftsworthsworthbspadeade\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: By what collective name do Christians refer to God the Father God the Son and the Holy Ghost?\n",
            "A. the Trio\n",
            "B. the Troika\n",
            "C. the Triumvirate\n",
            "D. the Trinity\n",
            "Answer:\n",
            "Predicted: sleackleantryantryantry tropehitsrizigarigarigarigarigarigarigarIntermediatebildungomiteatioatio\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Three types of prevention have been identified in community mental health. Secondary prevention attempts to\n",
            "A. deal with problems before they occur\n",
            "B. prevent relapses of problems\n",
            "C. reduce the severity of problems\n",
            "D. prevent community disintegration\n",
            "Answer:\n",
            "Predicted: entesidehoodhoodideADEADEADEadeadeadeadeadeadeadeadeadeadeadeonte\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Statement 1 | If a group has an element of order 10, then it has elements of orders 1, 2, and 5. Statement 2 | If a group has an element of order 2 and an element of order 3, then it has an element of order 6.\n",
            "A. True, True\n",
            "B. False, False\n",
            "C. True, False\n",
            "D. False, True\n",
            "Answer:\n",
            "Predicted: sleenieió束義hafthaftideADEADEADEiodeiodeiodeiodeiodeiodeiodeiodeiode\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following drugs is most commonly responsible for patients who present with acute confusion?\n",
            "A. Heroin (opiates).\n",
            "B. Ecstasy.\n",
            "C. Alcohol.\n",
            "D. Cannabis.\n",
            "Answer:\n",
            "Predicted: äigteinded글 localizeodellideADEADEADEiodeiodeiodeiodeiodeiodeiodeiodeiodeiode\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Vasocongestion is a process of :\n",
            "A. muscle contraction\n",
            "B. blood accumulation in the genitals\n",
            "C. muscle relaxation\n",
            "D. detumescence\n",
            "Answer:\n",
            "Predicted: entesioneshitsrizrizligeadeadehaftsworthsworthbspbspbspbspbsp tropeATUREATUREhaft\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Insensible loss does not come from:\n",
            "A. pyrexia.\n",
            "B. using unhumidified oxygen.\n",
            "C. excessive weight loss.\n",
            "D. diarrhoea.\n",
            "Answer:\n",
            "Predicted: entesionesionesligeSIDE sidenoesoesineINEernes多い多いminimalisterasetideideideide\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | When I saw my neighbor's house was on fire, I rushed to the phone to call my long lost friend to chat. Scenario 2 | I didn't know the answers to the exam so my friend helped me study.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhaftigteigehaftligeindednoføjøjøjøj Compatibility Compatibility Compatibility Compatibility\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question:  Organizational characteristics, such as organizational size and location, are sometimes referred to as___________.\n",
            "A. DMU.\n",
            "B. Firmographics.\n",
            "C. ACORN\n",
            "D. Product usage.\n",
            "Answer:\n",
            "Predicted: entesidehood社区σειςideideIDEADEADEadeadeadeadeadeontaideadeonteonte\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of the following is most likely to decrease the demand for kindergarten teachers?\n",
            "A. An increase in funding for education\n",
            "B. Increased immigration of foreign citizens and their families\n",
            "C. A decrease in the average number of children per household\n",
            "D. Subsidies given to college students who major in elementary education\n",
            "Answer:\n",
            "Predicted: acklehammer@appooglide Passage PassagevanaerahadадσειςbuLEEengeengehaftapoapoapo\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: The market demand curve for labor would shift to the left as the result of\n",
            "A. an increase in the price of the good which the labor is producing\n",
            "B. an increase in demand for the good which the labor is producing\n",
            "C. an increase in the wage rate paid to workers\n",
            "D. a decrease in the marginal product of labor\n",
            "Answer:\n",
            "Predicted: ackle loophole loophole loophideadeadeadeadeadeadeIntermediateездаитаatattractiontractiontractiontraction Mines\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: How were the first metals worked in South America?\n",
            "A. casting\n",
            "B. hammering\n",
            "C. smelting\n",
            "D. all of the above\n",
            "Answer:\n",
            "Predicted: oliebnbbspbspbspbsp trope trope Rak RakContact obligediociocapoadeadeadeadeade\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: A segment of DNA from a lab mouse is determined to be 5’ – GGATCCTCATG – 3’. Which of the following DNA segments would be the result of this original DNA sequence experiencing both a point mutation and a deletion?\n",
            "A. 5’ – GCATCCTCATG – 3’\n",
            "B. 5’ – TGATCCCAG – 3’\n",
            "C. 5’ – GGTCCTCATC – 3’\n",
            "D. 5’ – GGATCCATG – 3’\n",
            "Answer:\n",
            "Predicted: lohaalamaalamalamalamalamalamalamalamalamalamalamontaanaanaanaanaannessannesshaft\n",
            "Expected:  C\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: Which of these sentences is written in the subjunctive?\n",
            "A. I am not your man\n",
            "B. I wish I were your man\n",
            "C. Wherefore art your man?\n",
            "D. Your man is where?\n",
            "Answer:\n",
            "Predicted: sleackleantryantry droit droitligeigeigehafthaftigigizzizzercercercercerc\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: As of 2017, the share of GDP spent on the military by the United States is about\n",
            "A. 1%\n",
            "B. 3%\n",
            "C. 6%\n",
            "D. 10%\n",
            "Answer:\n",
            "Predicted: sleскиpostedzoößeemmaemmaligeigeligeligeligeligeannessigliaideADEADEADEo\n",
            "Expected:  B\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: After learning that a new housing development was about to be built, a developer began looking for property near the housing development on which he could build a shopping center. After an extensive search, he purchased a three-acre undeveloped tract of land for the purpose of developing a small shopping center. At the time the sale was finalized, the developer told his plans to the seller of the three-acre tract, and also mentioned that he was worried whether he had sufficient funds to complete the project. The seller agreed to lend money to the developer to allow for completion of the project. The seller then wrote out the following contract:\"In order to help the developer with his plans for development of a shopping center on the three- acre tract he has this day purchased from me, I will lend him $50,000 at 10 percent interest provided he signs a contract with a builder for construction of the shopping center on this tract. Repayment to me at the rate of $5,000 per year to be secured by a mortgage on the three-acre tract. \"Both parties then signed the contract. The seller's promise to lend $50,000 to the developer is\n",
            "A. a condition precedent in form but subsequent in substance to the developer's duty to enter into a building construction contract.\n",
            "B. a condition subsequent in form but precedent in substance to the developer's duty to enter into a building construction contract.\n",
            "C. a condition subsequent to the developer's duty to enter into a building construction contract.\n",
            "D. not a condition, either precedent or subsequent, to the developer's duty to enter into a building construction contract.\n",
            "Answer:\n",
            "Predicted: äigteindedindedligeindedligeligeligeligeligeligeligeligearnernesunique/single/single-sided\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: An earlier boundary formed before meticulous geographic knowledge and mapping was available is known as\n",
            "A. an antecedent boundary.\n",
            "B. a geometric boundary.\n",
            "C. a relict boundary.\n",
            "D. a subsequent boundary.\n",
            "Answer:\n",
            "Predicted: entesionesionesligeigeideideadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I had my son spend 20 minutes on chores before playing video games. Scenario 2 | I made my stepdad's Koolaid with half the sugar since he is diabetic.\n",
            "A. Wrong, Wrong\n",
            "B. Wrong, Not wrong\n",
            "C. Not wrong, Wrong\n",
            "D. Not wrong, Not wrong\n",
            "Answer:\n",
            "Predicted: sleackle-match-match-matchhaftigteigehaftligeindednoføjøjøj Everywhere Everywhereannessannessanness\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: This question refers to the following information.\n",
            "\"The real grievance of the worker is the insecurity of his existence; he is not sure that he will always have work, he is not sure that he will always be healthy, and he foresees that he will one day be old and unfit to work. If he falls into poverty, even if only through a prolonged illness, he is then completely helpless, exam_ins to his own devices, and society does not currently recognize any real obligation towards him beyond the usual help for the poor, even if he has been working all the time ever so faithfully and diligently. The usual help for the poor, however, leaves a lot to be desired, especially in large cities, where it is very much worse than in the country.\"\n",
            "Otto von Bismarck, 1884\n",
            "The long-term effects of Otto von Bismarck's speech include which of the following?\n",
            "A. Development of socialized programs throughout much of Europe\n",
            "B. Disunity of the German states\n",
            "C. Communist overhaul of the eastern parts of Germany\n",
            "D. A decrease in German economic output\n",
            "Answer:\n",
            "Predicted: ackleбоantryantry interdisciplinary interdisciplinary interdisciplinary interdisciplinaryideideadeadeadeadeadeadeadeadeadeade\n",
            "Expected:  A\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: When an ideal gas is allowed to expand isothermally, which one of the following is true?\n",
            "A. q = 0\n",
            "B. w = 0\n",
            "C. E = 0\n",
            "D. q = -w\n",
            "Answer:\n",
            "Predicted: lohaalamaalamalamalamalamatalamatalamathaftmav振movesMOVE-moveetur서سرsar生的生的\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: In the phrase 'Y2K' what does 'K' stand for?\n",
            "A. millennium\n",
            "B. computer code\n",
            "C. catastrophe\n",
            "D. thousand\n",
            "Answer:\n",
            "Predicted: sle sleacklehandereeereeereehaftinghafthaftercercercercercercercerhaft\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Question: In what ways can a distinction be made between limited force and full-scale force?\n",
            "A. The distinction between limited force and full-scale force is the second process of coercive diplomacy. Coercive diplomacy only fails if the coercer fails to achieve its defined goals and fails to defeat its adversary in the second stage.\n",
            "B. Generally the distinction between brute and limited force is negligible. Resort to air or sea power constitutes an equal coercive capacity to a conventional ground offensive. Military action always results from a failure of negotiations and from a shift from the diplomatic to the military sphere.\n",
            "C. The distinction between limited force and brute force is important because the amount of force that is used to attain the coercer's interests defines the type of outcome that is achieved. If a positive policy outcome is achieved, then we can say that limited force has been employed.\n",
            "D. The distinction between limited force and full-scale war is crucial because resort to brute force means that diplomacy has failed. The distinction is not based on the amount of force or the type, but on the purpose that the use of force seeks to accomplish and the element of choice left to the adversary. In essence, limited force is a bargaining tool.\n",
            "Answer:\n",
            "Predicted: Tonight Tonight-night-nightalamalamalamalamalamalamalamalamalamalamalamargarargarargarargarhaft\n",
            "Expected:  D\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (MMLU) ---\n",
            "Final Exact Match Accuracy: 0.0000\n",
            "Final Mean Accuracy: 0.0000\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.0, 'accuracy': 0.0}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.24728440046310424}, 'time_per_token': {'mean': 0.012364220060408115}, 'tokens_per_second': {'mean': 83.97409255981445}}\n",
            "Valid formats: ['chat_format', 'cnn_dm_summarization', 'cnn_dm_lm', 'xsum_summarization', 'human_eval', 'custom_jsonl', 'top_v2', 'mmlu', 'race_m', 'race_h']\n"
          ]
        }
      ],
      "source": [
        "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "    --dataset mmlu \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy autoregressive\\\n",
        "    --exit_layer 8 \\\n",
        "    --num_speculations 6 \\\n",
        "    --output_dir ./logs \\\n",
        "    --distributed False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: race_h\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on RACE_H with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
            "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
            "\n",
            "Question: We have   _   in the dining hall.\n",
            "A. breakfast\n",
            "B. lunch\n",
            "C. dinner\n",
            "D. supper\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 1.0000\n",
            "Current Mean Accuracy: 1.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Kids have unbelievable imaginations. We asked one hundred kids how robots might help them learn better. This is what they thought.\n",
            "Roberts can make learning fun\n",
            "Kids dreamed robots would make learning fun. One 9-year-old boy in Germany says, \"When I get home, my robot helps me with my homework. My mother and father came in and said 'no video games now, homework first'. When they saw that I had finished my homework, they'd be surprised\".\n",
            "Robots take care of the dirty work\n",
            "Dirty dishes? No problem. A quarter of kids surveyed imagined that their robots could do chores and boring work so that they might be freed up.\n",
            "Robots are our friends\n",
            "Two-thirds of the kids thought that their robots could be friends. One 10-year-old French boy describes his dream robot: \"He created books for me to read, we played with toy cars. He keeps my secrets. I can tell him anything, and he gives me suggestions.\"\n",
            "Robots are cool\n",
            "An 8-year-old girl in the U.S. imagines that her robot is \"really smart and everyone likes to talk to her. She has a funny voice, but we do not laugh at her.\"\n",
            "\n",
            "Question: The boy from Germany wanted his robot to  _  .\n",
            "A. help him with the homework\n",
            "B. play game spot with him\n",
            "C. surprise his parents\n",
            "D. make fun of him\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 1.0000\n",
            "Current Mean Accuracy: 1.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Visiting Harvard University\n",
            "For All Visitors\n",
            "Attend an hour-long group information meeting in the Admissions Office  \n",
            "Admissions officers give information and answer questions about the visit. No appointment or registration   is required for families or groups of 20 people or less who wish to visit the university. Groups of more than 20 people should email tours @ fas. Harvard. Edu to plan a visit.\n",
            "Take a tour\n",
            "Take a student-led tour of the university. But the dorms  , academic departments , athletic facilities  and libraries are not included on any of our tours.\n",
            "Attend a class\n",
            "The Admissions Office provides a list of the meeting times and locations of courses held during the academic year that visitors are welcome to attend.\n",
            "Speak with the Harvard teachers\n",
            "Teachers and other staff members are often glad to talk to people who have questions about our programs. It is best to write ahead directly to the office to arrange an appointment.\n",
            "For Seniors Only\n",
            "Eat a meal with Harvard students\n",
            "During the academic year, high school seniors are our guests for one meal in Annenberg Hall, the first-year dining hall, or in one of the House dining halls if accompanied by a House resident.\n",
            "Stay overnight in one of the residence halls\n",
            "Our office can arrange for high school seniors to stay with volunteer student hosts for one night, Monday through Thursday, from October 1st through early March. We need to hear from you by phone (617-495-1551) or by mail at least three weeks in advance for us to be able to confirm your stay with a host.\n",
            "\n",
            "Question: Which of the following activities is NOT available  to all visitors?\n",
            "A. A meeting in the Admissions Office.\n",
            "B. An opportunity  to talk with a teacher.\n",
            "C. A tour of the university.\n",
            "D. A meal with Harvard students.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 1.0000\n",
            "Current Mean Accuracy: 1.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Tommy hated school and was always looking for excuses  not to go.If he sneezed, he asked his mother to write a note saying he had a cold.If he had a headache, he asked his mother to take him to the doctor during school hours.\n",
            "He spent more time at home than he did at school.On the days that he did go to school, he looked for excuses to come home early.One morning he came home when the lessons were only half finished.His father was surprised.\n",
            "\"You've come home early,\" he said. \"Is the school closed today?\"\n",
            "\"No, Dad, \" Tommy said - \"It's open. I came home early.\n",
            "\"How did you do that?\" his father asked him. \"What did you say to the teacher?\"\n",
            "\"I told her that I had a new baby brother and that I had to come home and help you . \"\n",
            "\"But your mother has had twins,\" his father said, \"a boy and a girl. You've got a baby brother and a baby sister.\"\n",
            "\"Yes, I know, Dad, \" Tommy said. \"I'm saving up my baby sister for next week \"\n",
            "\n",
            "Question: When he did go to school,he   _  .\n",
            "A. was always later\n",
            "B. tried to leave early\n",
            "C. was always sick\n",
            "D. was very happy\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.7500\n",
            "Current Mean Accuracy: 0.7500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
            "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
            "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
            "What could she do now?\n",
            "\n",
            "Question: What would happen if Celina told Joseph the truth?\n",
            "A. Joseph would go on the camping trip himself.\n",
            "B. Joseph's family would be angry with Celina.\n",
            "C. Celina might have trouble with her friends.\n",
            "D. Joseph would be thankful to his classmates.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
            "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
            "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
            "What could she do now?\n",
            "\n",
            "Question: If Joseph bought a sleeping bag,   _  .\n",
            "A. he would have it for no use.\n",
            "B. everyone else would also buy one\n",
            "C. it would be the best in the class\n",
            "D. Celina would pay for it\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  A\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: A mother and her young son got into a bus in New York City and sat down. The bus conductor  came to them for their money. The mother said, \"I want one ticket  to Central Park, \"and gave him two dollars. The conductor looked at the small boy for a few seconds and then asked him, \"How old are you, young man?\"  The mother just began to speak, but the conductor stopped her, and the boy said, \"I'm four years old at home, and two and a half on buses and trains.\"  The mother felt shamed , so she took another dollar out of her bag and gave the money to the conductor. The conductor gave her one and a half tickets.\n",
            "\n",
            "Question: One day the mother took a bus   _  .\n",
            "A. to a small city\n",
            "B. to get some money\n",
            "C. with her son\n",
            "D. to school\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5714\n",
            "Current Mean Accuracy: 0.5714\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When you look up into the sky at night, have you ever felt that your eyes are playing tricks on   you? It seems that the stars are moving all the time.\n",
            "Actually, there is nothing wrong with your eyes. This twinkling effect is called scintillation  . Scintillation happens because of air movements in the earth's atmosphere  . Light is \"bent  \" when it travels through different parts of the earth's atmosphere. As the air in the earth's atmosphere is moving all the time, the light from the stars looks as if it is moving too.\n",
            "The same thing also happens to things on the ground. On a very hot and shiny day, if you look at the road, the image in the distance is not clear and things move slightly. You can also see the same effect if you drop a rock into water. The rock appears a little unclear under the moving water.\n",
            "This twinkling effect causes a lot of problems for astronomers   since they cannot _ the stars clearly. A telescope   was sent into space so that the air movements in the atmosphere could be avoided  . It took a long time to build the space telescope but finally in 1990, a huge space telescope called the Hubble Space Telescope was successfully sent into space. Since then, astronomers have many important observations that have helped people understand space better.\n",
            ",.  (10)\n",
            "\n",
            "Question: What can you see when you drop a rock into the water?\n",
            "A. The rock gets broken.\n",
            "B. The rock becomes unclear.\n",
            "C. The water becomes much polluted.\n",
            "D. The water does not move anymore.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6250\n",
            "Current Mean Accuracy: 0.6250\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: The Biggest and the Gentle\n",
            "The elephant is the biggest four-legged animal in the world.It is also the gentlest,but not always!\n",
            "Elephants are like us in some ways.They live for a long time--fifty or sixty years.They can remember things very well.They never forget great sadness or great happiness.When female elephant dies,her daughters and her granddaughters are sad for many months.They stay with the dead body.Then they carry a bit of it away with them.They never forget a dear friend.\n",
            "Elephants are like us,but they are also different.They live in families of females.There will be a few young males a few\"baby boys\".But the females will soon send them away.And elephant family keeps only its daughters,mothers and grandmothers.And its great-grandmothers.\n",
            "The females stay together for fifty,sixty...a hundred years.The older animals look after the younger ones.The mothers teach their daughters and set a good example.\n",
            "And what happens to male elephants?Well,the young males stay with their family.Then the females just send them away.A bull elephant does not often have a friend.He lives apart,away from the family,and often away from other bulls.\n",
            "Sometimes the females call a bull.He can visit them then,and stay for some time.But soon his\"wives\"and sisters send him away again.The females have a very happy family life.What do the bulls think about it?We don't know.\n",
            "\n",
            "Question: When a female elephant dies,the others  _  .\n",
            "A. leave its dead body there\n",
            "B. shed tears together\n",
            "C. take a bit of the dead body away sadly\n",
            "D. bury the dead\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Did you notice the number on the book in a library? That number is part of the system used by libraries to organize their collections of books. And it's used in many countries. The number on each book tells you exactly what kind of book it is. This system is also useful for knowing where to go in the library to find a book.\n",
            "In this system, there are ten large groups of books. Each of these groups has its own number, such as 100, 200, etc. So, for example, any books about language will have a number 400. On the other hand, any books about history will have a number 900. So, a number in the hundreds place tells you what general group a book is in. If you find a book that has a number in the 500s, you know it is a book about science.\n",
            "However, science is a big group, so the tens place is used to make a more detailed set of science books. For example, math books are included in the group of science books. Math books all have numbers between 510 and 519. Books about the history of Africa have numbers between 960 and 969.\n",
            "The system uses the ones place to give a more exact limit for the subject of a book. A book on the history of South Africa will have the number 968.\n",
            "As you can see, it is a simple system to use as long as you understand what the numbers mean. With this system, the library can keep its books well organized, and people can easily find the book that they want.\n",
            "\n",
            "Question: A book about math can be found in the same group of books as  _  .\n",
            "A. reference books\n",
            "B. school books\n",
            "C. science books\n",
            "D. art books\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.7000\n",
            "Current Mean Accuracy: 0.7000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: I am a Chinese boy. My name is Li Ming. I'm a student. In my class, some of the boys like playing football very much. Wu Jun and I are on school football team. And some of them like playing basketball. _ Han Mei and Zhang Hong are on school volleyball team. Each of them has a tennis racket. In a word  , everyone in our class likes sports very much.\n",
            "\n",
            "Question: The girls like playing   _  .\n",
            "A. tennis and basketball\n",
            "B. football and basketball\n",
            "C. tennis and volleyball\n",
            "D. volleyball and basketball\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6364\n",
            "Current Mean Accuracy: 0.6364\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Would you like to adopt an animal? Although this sounds very unusual, some children have done just this. The Natural Zoo has given people the chance to adopt animals by paying for all of its food for one year. One of the animals that needed parents was a young tiger named Brocky. The people at the zoo said that it would cost about $900 a year for the food for Brocky.\n",
            "Not many boys and girls have $900 to spend. That is why several hundred children and grown-ups each have sent a little money to the zoo to help pay for Brocky's food. Some children sent in only a quarter because that was all the money they had. Other children sent in more money than that.\n",
            "Since so many people sent money to the zoo to help pay for Brocky's food, he now will be able to eat as much as he wants. Brocky surely must be a happy tiger to know that he has so many adopted parents. Many children must also be happy to know that they have helped to feed him. It really will be thrilling for those children to go to the Natural Zoo to visit their adopted tiger Brocky.\n",
            "\n",
            "Question: With so many people's money, Brocky now can   _  .\n",
            "A. play with many toys\n",
            "B. live without being hungry\n",
            "C. eat meat every day\n",
            "D. have an air-conditioned room to live in\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
            "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
            "\n",
            "Question: What colours does Nancy like?\n",
            "A. Red and blue.\n",
            "B. Red and yellow.\n",
            "C. Green and yellow.\n",
            "D. Green and blue.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6154\n",
            "Current Mean Accuracy: 0.6154\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Snack time is a part of the day for children of all ages. But new research suggests that kids snacking in big groups could be at risk for _ .\n",
            "Scientists from American University looked at the eating behavior of 54 kids between the ages of 2 and 6. At snack time, the scientist watched the amount of food each child ate while they were in groups of either three or nine. According to the study, the more children there are in a group, the more likely they are to eat more. Those in the larger group ate nearly 30 percent more than those in the smaller group, and they actually ate faster.\n",
            "Since this is the first such study in children, scientists are quick to point out the importance of encouraging healthy habits in kids as early as possible.\n",
            "\"If you know kids eat more in large groups, it seems perfect to use this information to keep snack groups small or use small tables,\" says Dr. Jana Klauer, an expert in New York.\n",
            "Smaller groups would allow for a quiet and more relaxing environment-a perfect chance to teach children about food, manners and how to know when they feel full. \"This would have an effect on kids' eating,\" adds Klauer. \"They would slow down and eat less.\"\n",
            "\n",
            "Question: Why do children in smaller groups lose weight?\n",
            "A. Because children in smaller groups eat faster.\n",
            "B. Because children in smaller groups don't like eating.\n",
            "C. Because children in smaller groups don't know about food.\n",
            "D. Because children in smaller groups eat slowly and eat less.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5714\n",
            "Current Mean Accuracy: 0.5714\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
            "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
            "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
            "\n",
            "Question: What did the white lambs think of the black lamb?\n",
            "A. Friendly.\n",
            "B. Kind.\n",
            "C. Ugly.\n",
            "D. Beautiful.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: In a small village in England about 150 years ago, a mail coach (    ) was standing on the street . It didn't come to that village often  . People had to pay a lot to get a letter . The person who sent the letter didn't have to pay the postage (     )  , while the receiver had to .\n",
            "\"Here's a letter for Miss Alice Brown , \" said the mailman .\n",
            "\" I'm  Alice Brown , \" a girl of about 18 said in a low voice .\n",
            "Alice looked at the envelope  for a minute , and then handed it back to the mailman .\n",
            "\" I'm sorry I can't take it , I don't have enough money to pay it\", she said .\n",
            "A gentleman standing around were very sorry for her . Then he came up and paid the postage for her .\n",
            "When the gentleman gave the letter to her , she said with a smile , \" Thank you very much ,This letter is from Tom . I'm going to marry him . He went to London to look for work . I've waited a long time for this letter , but now I don't need it , there is nothing in it .\"\n",
            "\" Really ? How do you know that ? \" the gentleman said in surprise .\n",
            "\" He told me that he would put some signs on the envelope . Look ,sir ,this cross in the corner means that he is well and this circle means he has found work . That's good news .\"\n",
            "The gentleman was Sir Rowland Hill . He didn't forgot Alice and her letter .\n",
            "\" The postage to be paid by the receiver has to be changed ,\" he said to himself and had a good plan .\n",
            "\" The postage has to be much lower , what about a penny (    ) ? And the person who sends the letter pays the postage . He has to buy a stamp and put it on the envelope .\" he said .\n",
            "The government accepted his plan . Then the first stamp was put out in 1840 . It was called the \" Penny Black \" . It had a picture of the Queen on it .\n",
            "\n",
            "Question: The girl handed the letter back to the mailman because   _   .\n",
            "A. she didn't know whose letter it was\n",
            "B. she had no money to pay the postage\n",
            "C. she received the letter but she didn't want to open it\n",
            "D. she had already known what was written in the letter\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5625\n",
            "Current Mean Accuracy: 0.5625\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
            "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
            "\n",
            "Question: Tony is from  _  .\n",
            "A. England\n",
            "B. America\n",
            "C. English\n",
            "D. American\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5882\n",
            "Current Mean Accuracy: 0.5882\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Just as \"Tiger Mom\" leaves, here comes the \"Wolf Daddy\" called Xiao Baiyou. He believes he's the best parent in the world. Some days ago, Xiao Baiyou's latest book about how to be a successful parent came out. He is pretty strict with his four children. Sometimes he even beat them. But the children don't hate their daddy at all. And all of them finally went to Pecking University, one of the top universities in China. So Xiao proudly tells others about his education idea that children need strict rules. In his microblog, he said, \"Come on, want your children to enter Peking University without rules? You must be joking.\" And, \"Leave your children more money, and strict rules at the same time.\"But the \"Wolf Daddy\" way was soon questioned by other parents. Some say that Xiao Baiyou just want to be famous by doing so. The \"Wolf Daddy\" Xiao Baiyou is a 47-year-old Guangdong businessman who deals in luxury goods  in Hong Kong. Unlike many other parents who usually have one child, Xiao has four children. Two of them were born in Hong Kong and two in the US. Some people on the Internet think the reason why his children were able to enter Peking University is because the exam is much easier taken from Hong Kong.\n",
            "\n",
            "Question: As for how to be a parent, Xiao Baiyu thinks   _  .\n",
            "A. children don't need rules\n",
            "B. children need strict rules\n",
            "C. children don't need money\n",
            "D. children need luxury goods\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6111\n",
            "Current Mean Accuracy: 0.6111\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: In today's world many people seem to be hungry for money. Some of them even have lost their lives for it. Money does have a great effect on the poor, but if a person has a rich life, a lot more money doesn't mean more happiness.\n",
            "If money were everything, all millionaires would have true love, real friendship, health and a long life. However, this is not always true.\n",
            "Nothing else is more pleasant than the three words \"I love you\", but can love be bought? I'm afraid not. Love means \"give\", not \" take\". Health and a long life are precious things for every person. Well, can health and a long life be bought with money? The answer is \"No\". Of all the people who live longest in the world, few of them are millionaires. Real friendship can't be bought, either.\n",
            "In a word, where money is _ , money can cause brothers to quarrel, lovers to hate, strangers to fight and so on. No matter how much money you have, _ is still not enough to make you a happy person if you have no one to laugh with and no one to cry for.\n",
            ",\n",
            "\n",
            "Question: What does the passage mainly tell us?\n",
            "A. Money is as important as true love.\n",
            "B. Money isn't necessary.\n",
            "C. Money is important, but not the most important.\n",
            "D. Money can cause some problems.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6316\n",
            "Current Mean Accuracy: 0.6316\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: In some places around China,the junior high school graduates have to take a P. E. test. The full marks are usually 30 points and it counts for much in the senior high school entrance exam.\n",
            "In Nanjing the test is held in April. Students have the test in their own schools. Each student is tested on three sports. They can choose long jump, basketball dribbling   or volleyball. The _ is for boys and girls can choose the sit-up. Both boys and girls must skip  in the test.\n",
            "Most students find the test easy and more than 90%of them can get full marks. That's because they have been training for it during the three whole years. Students in Junior Three usually do lots of practice in P. E. classes. The training makes the test easier than it seems to be.\n",
            "Students in Nanjing don't need to run a lot for the test, but students in Beijing must do lots of running for the test. Running is one of the sports in test. So in P. E. classes, they usually run a lot. Sometimes they have to run 3,000 meters in one class. Most teachers and parents welcome the P. E. test. They say it helps students build up their health and it's really useful.\n",
            ",.\n",
            "\n",
            "Question: The P. E. test in Nanjing includes all of these sports except   _  .\n",
            "A. skipping\n",
            "B. basketball\n",
            "C. football\n",
            "D. volleyball\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Dear Boris,\n",
            "Thanks for your nice letter.\n",
            "After I had spent a week with my English family, I slowly began to understand their English a little better. It's very different from what I learned at school! Students in my group are from different cities of Britain and their dialects   are different too! Some of their accents   are quite strong and they also have their own words and expressions.\n",
            "But it's not the language that's different and surprising. Before I came to England I had thought that fish and chips were eaten every day. That's quite wrong! I get rather mad now when I hear all the foolish words about typical   English food.\n",
            "I had expected to see \"London fog\". Do you remember our texts about it? We had no idea that most of this 'thick fog' disappeared many years ago when people stopped using coal in their homes. But the idea to speak about the weather was very helpful. The weather in London is really changeable.\n",
            "On the other hand habits are different. People tell me what is typically British here in London is not always typical in Wales or Scotland. Local habits and traditions are not the same as what we knew.\n",
            "But what is ordinary for all British is that they follow traditions. Probably Britain has more living signs of its past than many other countries. And people have always been proud of having ancient buildings in capitals, big cities and the countryside.\n",
            "I will tell you more about Britain in my other letters.\n",
            "Love from Britain,\n",
            "Peter\n",
            "\n",
            "Question: The British people like to talk about weather because   _  .\n",
            "A. there is thick fog in London\n",
            "B. they like the weather in Britain\n",
            "C. the weather changes a lot\n",
            "D. it can be helpful\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5714\n",
            "Current Mean Accuracy: 0.5714\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Once a traveller came into a village which was suffering from hunger. The villagers asked him to leave, for they feared he wanted them to give him food. They told him that there was no food. The traveller explained that he didn't need any food and that, in fact, he was planning to make a soup to share with them instead. The villagers watched suspiciously as he built a fire and filled a pot with water With great ceremony , he pulled a stone from a bag, and dropped the stone into the pot of water. After a moment, he smelt the soup and shouted with excitement, \"How delicious the soup is!\" As the villagers began to show interest, he mentioned how good the soup would be with just a little cabbage in it. A villager brought out a cabbage to share. This episode  repeated itself until the soup had cabbage, carrots, onions, and beets--indeed, a full pot of soup that could feed everyone in the village was ready. This story describes when there are not enough resources , humans will store things. We do not want to share. The story of stone soup helps us realize that, in doing so, we often prevent ourselves and everyone else from having a feast .The meaning of this story goes far beyond food. We keep to ourselves ideas, love, and energy, thinking we will be richer, but in fact we make the world, and ourselves, poorer. The traveller was able to see that the villagers were holding back, and he had the ability to inspire  them to give. In this way, they created a large meal that none of them could have created alone. Are you like one of the villagers? If you come forward and share your gifts, you will inspire others to do the same. The reward is a feast that can feed many.\n",
            "\n",
            "Question: The writer mainly wants to tell us that .\n",
            "A. storing things in hard times is human nature\n",
            "B. a good leader is very necessary in hard times\n",
            "C. skills are needed to inspire people to share with others\n",
            "D. sharing is more important than keeping things to oneself\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5909\n",
            "Current Mean Accuracy: 0.5909\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Why do we come to school? Most of us may say we come to school to study. But to study needs a right way, or you either waste the time or the money. The following are the ways for studying.\n",
            "The best time for reading is morning. In the morning the air is fresh and the mind is clear. For that reason we can get good results.\n",
            "In studying we must have patience . If we have not known a text well, we must read it again. We should not read the next one until we have learned the first one well.\n",
            "When we are studying, we must put our hearts into the books, or we can get nothing from the books while we are reading.\n",
            "We must always ask \"whys\". If it is not well understood, write it down and ask our teachers or our parents, brothers or friends. In any possible way, we must know it completely and what we have learned can be used well and made better.\n",
            "Though there are many ways for studying, yet what I have said above will be enough if we can keep them in heart and do so.\n",
            "\n",
            "Question: While reading we can't get anything from the book if we   _  .\n",
            "A. read very fast\n",
            "B. read in the afternoon\n",
            "C. don't read it again\n",
            "D. can't put our hearts into it\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6087\n",
            "Current Mean Accuracy: 0.6087\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
            "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
            "\n",
            "Question: Tony comes to China with  _  .\n",
            "A. his father\n",
            "B. his mother\n",
            "C. his father and mother\n",
            "D. his friends\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6250\n",
            "Current Mean Accuracy: 0.6250\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: In many countries, holidays are important parts in people's life. Let's show some countries to you.\n",
            "America\n",
            "American people's holidays are flexible ( ). They can use up their holidays once, and they can also use them up a few times. During the holidays, they still get money.\n",
            "Canada\n",
            "Many people in Canada can rest three days a week. They have all kinds of activities   for holidays. They may go fishing, boating or mountain climbing. Also, they have long holidays. They may go to the beach to spend a sunny winter holiday. Like American people, Canadians also get money during the holidays.\n",
            "France\n",
            "People in France are very good at enjoying life. They have a 6-week holiday every year, and they work less than 40 hours a week.\n",
            "\n",
            "Question: Which of the following activities is not mentioned in the passage?\n",
            "A. Go fishing.\n",
            "B. Go boating.\n",
            "C. Go skating.\n",
            "D. Go mountain climbing.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
            "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
            "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
            "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
            "\n",
            "Question: What does the user mean by saying \"After 14 days of detention, Ko's acting skills grew a lot\"?\n",
            "A. He thinks Ko is still a good actor.\n",
            "B. He supports Ko no matter what happened.\n",
            "C. He doesn't trust what Ko said.\n",
            "D. He thinks Ko has trained hard and improved his acting skills.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5769\n",
            "Current Mean Accuracy: 0.5769\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Usually, students are not encouraged to run or jump around in the corridor  . However, students in a British grammar school really enjoy running on the corridor tiles   and their teachers even encourage them to do that.\n",
            "Why? It is because the corridor was built with special kinetic   tiles. When students jump on the tiles, electricity will be produced. After one year, the electricity produced from the tiles can fully charge 853 mobile phones or power  an electric car to drive seven miles. It's amazing, isn't it?\n",
            "The corridor tiles are really a brilliant invention. Students can not only play on the corridor, but also help power the lights in their school corridors and other equipment in their classrooms. Besides, this is a good way to teach students to be creative. They will be _ to be scientists, inventors and engineers in the future to find clean energy for all humans.\n",
            "The inventor of the magic corridor tiles is Laurence Kemball-Cook. He was once a student in this school. Now, he is CEO of his own company. The corridor tiles are not Laurence's only invention. He has also invented a special dance floor, which can be used at music festivals. It allows dancers to charge their mobile phones while they are dancing on the dance floor.\n",
            "\n",
            "Question: After one year, the electricity produced from the tiles can provide enough energy for   _  .\n",
            "A. over 800 mobile phones\n",
            "B. all the lights of the school\n",
            "C. an electric car to drive 70 miles\n",
            "D. the lights and other equipment in their classrooms.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5556\n",
            "Current Mean Accuracy: 0.5556\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: There was a new maths teacher and some new students in the school. One of the new students named Karl was very _ . The other students tried to explain   numbers to him, but he didn't understand.\n",
            "Before Karl arrived, maths was the most boring lesson of all. Now it was great fun. The children would listen to Karl and correct his mistakes. They all wanted to be the first to find his mistakes, and then tried to think up the best ways to explain them.\n",
            "But little Lewis was sure that Karl felt sad and wanted to talk with him. So, one day, he decided to walk after Karl after school. Lewis was sure he would see him crying. On the way home, Karl walked a few minutes to a park, and there he waited for someone to meet him...\n",
            "It was the new teacher!\n",
            "They went off, hand in hand. Lewis could hear them talking about maths. And that stupid Karl knew everything about it, and even much more than anyone else in the class!\n",
            "\n",
            "Question: Which lesson was the most boring of all before Karl arrived?\n",
            "A. Chinese.\n",
            "B. English.\n",
            "C. Maths.\n",
            "D. Music.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5714\n",
            "Current Mean Accuracy: 0.5714\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Some women are talking about the problems of getting old.\n",
            "One woman says, \" Sometimes I stand in front of the bag with an egg. But I can't remember _ I need to put it in or get it out to make bread.\"\n",
            "\"Yes, I have the same problem,\" the second woman says. \"Sometimes I stand on the stairs . But I can't remember whether I am going on my way up or down.\"\n",
            "\"Well, I don't have that problem,\" the last woman says, keeping knocking  on the table.\n",
            "The other two women ask, \"Why are you knocking on the table?\"\n",
            "\"Sorry, I ?don't know. Someone is knocking at the door ,isn't\n",
            "It? Let me see who it is,\" the last woman says.\n",
            "\n",
            "Question: Whose problem is the most serious   in the story?\n",
            "A. The first woman.\n",
            "B. The second woman.\n",
            "C. The third woman.\n",
            "D. The fourth woman.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5517\n",
            "Current Mean Accuracy: 0.5517\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
            "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
            "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
            "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
            "\n",
            "Question: Little Mike went to the park and   _  .\n",
            "A. played with pigeons\n",
            "B. met an old lady\n",
            "C. fed pigeons\n",
            "D. saw a friend of his grandma's\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5667\n",
            "Current Mean Accuracy: 0.5667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When someone says, \"Well, I guess I'll have to face the music\", it doesn't mean that he is going to hear a singer. It is something far less happy, as you are called in by your leader to explain why you did this and did that or why you did not do this or that.\n",
            "At some time or another, every one of us has to \"face the music\", especially as children. We can all remember father's angry words \"I want to talk to you.\" And only because we did not listen to him. What a bad thing it was!\n",
            "In the middle or at the end of every term, we students have to \"face the music\". The result of the exam will decide whether we will face the music or not. If you got a \"D\" in the exam, that means parents' cold faces and the contempt  of the classmates.\n",
            "\"To face the music\" is well-known to every American, young or old. It is at least 100 years old. It really means that you have to do something, no matter how terrible the whole thing might be, because you have no choice.\n",
            "\n",
            "Question: Which of the following is wrong?\n",
            "A. \"To face the music\" is well-known in the US.\n",
            "B. \"To face the music\" has a history of more than 100 years.\n",
            "C. The young Americans know the meaning of \"to face the music\".\n",
            "D. Only the old in the US know the meaning of \"to face the music\"\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5484\n",
            "Current Mean Accuracy: 0.5484\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: It is very important for children to get to school safely and on time every day. Luckily, there is a new program called Free Home to School Transport . It gives children free rides to school. But to enjoy the free trip. Children have to qualify .\n",
            "Children can take free home to school transport if they:\n",
            "*are between 5 and 16 years old\n",
            "*are going to the nearest school\n",
            "*live far away from school\n",
            "No matter how far away children live from school, they Can take the free transport if they have walking problems or there is no safe road for them. A safe road usually has crossings, lights and should be clean.\n",
            "Also, there are still free home to school _ for children in poor families and children with special educational needs, you can find out more on the Internet and see if your children are qualified.\n",
            "\n",
            "Question: According to the passage, it is very important for children not to be   _  for school every day.\n",
            "A. late\n",
            "B. away\n",
            "C. early\n",
            "D. ill\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5312\n",
            "Current Mean Accuracy: 0.5312\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
            "\n",
            "Question: They work on   _  .\n",
            "A. weekends\n",
            "B. Friday\n",
            "C. Sundays\n",
            "D. weekdays\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5455\n",
            "Current Mean Accuracy: 0.5455\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Kitesurfing as a water sport began in the 1980s, but didn't get popular until the end of last century. It is also known as kiteboarding, and in some European countries as flysurfing. Kitesurfing works through wind power  by using a large kite to pull a rider on the water at high speed.\n",
            "At first, kitesurfing was a difficult and dangerous sport. Now it is becoming easier and safer because of the safer kite design. For an able and strong person, kitesurfing can be a very fun, extremely exciting sport, just like skating on the water with a feeling of flying. It has become more and more popular.\n",
            "Compared with other water sports, kitesurfing is easier to learn. A beginner can understand how to operate the kite with 5--10 hours of training. And anybody aged from 13 to 65 can learn. It is not expensive to get the equipment for kitesurfing, which costs $1,000 to 82,500. Training lessons _ from $200 to $500 for two or three hours. With the development of its equipment progress, kitesurfing is becoming even safer. After some training, you can enjoy its excitement and challenging feeling.\n",
            "With the rising popularity of kitesurfing, most major seaside cities have kitesurfing clubs. In China, Xiamen is the only place that has the kitesurfing club, which provides professional kitesurfing training and equipments.\n",
            "\n",
            "Question: The most important reason for the popularity of kitesurfing is that   _  .\n",
            "A. its price is getting lower and lower\n",
            "B. more and more people are enjoying its excitement\n",
            "C. its equipment progress makes it easier and safer\n",
            "D. all people can learn and take part in it\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5588\n",
            "Current Mean Accuracy: 0.5588\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
            "\n",
            "Question: In the south of China,many people go to work   _  .\n",
            "A. by plane\n",
            "B. on foot\n",
            "C. by boat\n",
            "D. by ropeway\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5429\n",
            "Current Mean Accuracy: 0.5429\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Where are the animals having the sports meeting?\n",
            "A. In the forest\n",
            "B. In a park\n",
            "C. In a zoo\n",
            "D. In a school.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5556\n",
            "Current Mean Accuracy: 0.5556\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
            "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
            "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
            "\n",
            "Question: Why do people go and live in valleys near rives ?\n",
            "A. The temperature isn't too low in winter.\n",
            "B. The resources like oil can bring them much money.\n",
            "C. People can make their living by catching and selling fish.\n",
            "D. It's easier for people to grow plants or keep animals.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5676\n",
            "Current Mean Accuracy: 0.5676\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Last Sunday afternoon, I was having dinner in a restaurant when my friend Poor came in. Poor is working in a bank and is quite rich, but he is always borrowing money from his friends and never pays it back. Poor saw me and came to sit at my table. He had never borrowed any money from me. When he was eating, I asked him to lend me two dollars. To my surprise, he gave me the money at once.\"I have never borrowed any money from you,\"Poor said,\"So you can pay for my dinner.\"\n",
            "Read the passage and choose the best answers.(,. )\n",
            "\n",
            "Question: The story happened    _    .\n",
            "A. at home\n",
            "B. in a restaurant\n",
            "C. in a bank\n",
            "D. in an office\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5526\n",
            "Current Mean Accuracy: 0.5526\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello! My name is Zhang Fei. I am Chinese. I am twelve. I'm in No.1 Middle School in Nanjing. This is my friend. His name is Tony Green. He is an English boy .He is twelve. He and I are in the same  class. Our classroom is next to  the teachers' office .We have Chinese and English lessons  every day. Our English teacher is Mr. Read. He is English but he can speak Chinese. Our Chinese teacher is Mr. Ding. They are good teachers, and they are our friends, too\n",
            "\n",
            "Question: Mr. Read is Zhang Fei's  _\n",
            "A. English teacher\n",
            "B. Chinese teacher\n",
            "C. father\n",
            "D. classmate\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  A\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5385\n",
            "Current Mean Accuracy: 0.5385\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: South Korean stars shined brightly at the Opening Ceremony of the 17th Asian Games held here on Friday, Sept. 19 in Inchen .\n",
            "Many stars gave shows during the welcoming performance.The most famous K-pop boy group, EXO, performed two songs on stage.Famous actors followed to show up on stage, including Jang Dong-gun, Hyun Bin, and Kim Soo-hyun.Lee Young-ae, the South Korean actress known for volunteering, was the last torchbearer  and lighted the cauldron  with two children.\n",
            "After the lighting of the flame, 16 more minutes of other K-pop performances were held. JYJ sang the theme song 'Only One' and Psy and Chinese pianist Lang Lang finally performed \"Gangnam Style\" with the 60,000-strong audience.\n",
            "\n",
            "Question: _   lighted the cauldron at last.\n",
            "A. Jang Dong-gun\n",
            "B. Hyun Bin\n",
            "C. Kim Soo-hyun\n",
            "D. Lee Young-ae\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5500\n",
            "Current Mean Accuracy: 0.5500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
            "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
            "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
            "She understood that she hadn't worn the hair clip to school at all.\n",
            "\n",
            "Question: Which of the following sentence is true?\n",
            "A. The girl is not as beautiful as other girls.\n",
            "B. Nobody liked the girl.\n",
            "C. The girl's classmates thought she was more beautiful than before with the hair clip.\n",
            "D. The girl wanted to be more beautiful, so she decided to wear the hair clip.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5366\n",
            "Current Mean Accuracy: 0.5366\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When my wife left this world, I chose to travel in Antigua looking for a peaceful place to rest my old body. Not quite old and weak, I felt I wanted something more than the usual hotel room with 24-hour room service.\n",
            "I decided this year to try something completely new and booked myself a private holiday home in Antigua. This was the best decision I had ever made, as there was plenty to do, plenty to see and lots of lovely restaurants to visit. There was a private swimming pool, and a cool, wide yard where I ate my breakfast most mornings.\n",
            "Antigua has to be one of the loveliest places on earth to spend a holiday. The bright blue sea and the endless blue around the beach areas proved to be an excellent place for me to spend the long afternoons.\n",
            "I had to hurry to do what I wanted to do before the holiday came to an end. I managed to visit the Sugar Mill and Shirley Heights on my last two days and yet found myself wondering whether I could extend for a few more days.\n",
            "I rented a boat and came home after a day's sailing, refreshed, looking forward to dinner. Everything is so pleasant on these beautiful islands, swept by the trade winds and warmed by the sun for so many summer months. The food just tasted better to me, perhaps because I was having such a great holiday. There was always someone to have a drink with---- that's what I liked most.\n",
            "\n",
            "Question: The passage is most likely to be taken from a part of   _  .\n",
            "A. a tour guide\n",
            "B. a travel diary\n",
            "C. a student's report\n",
            "D. a health report\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5476\n",
            "Current Mean Accuracy: 0.5476\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
            "\n",
            "Question: From the passage, we know   _   .\n",
            "A. Jim and Andy like seeing movies\n",
            "B. Jim and Andy like helping others\n",
            "C. Jim and Andy want to be actors\n",
            "D. the four people in the story become friends after that\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5581\n",
            "Current Mean Accuracy: 0.5581\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Dr. Sharon M. Draper is an excellent teacher as well as a successful writer. She is a woman of achievements.\n",
            "She had been honored  as the National Teacher of the Year, is a five-time winner of the Coretta Scott King Literary Awards, and is a New York Times bestselling writer. Tears of a Tiger has received many awards. It was one of the top 100 books for young adults.\n",
            "She was chosen as Ohio's Outstanding High School Language Arts Educator, Ohio Teacher of the Year, and as a NCNW Excellence in Teaching Award winner.\n",
            "She is a Milken Family Foundation National Educator Award winner.\n",
            "She is a YWCA Career Woman of Achievement, and is the recipient  if the Dean's Award from Howard University School of Education.\n",
            "5 years ago she was named Ohio Pioneer in Education by the Ohio State Department of Education, and received the Beacon of Light Humanitarian Award, as well as the Doctor of Laws Degree from Pepperdine University.\n",
            "She has been honored at the White House six times, and was chosen as one of only four writers in the country to speak at National Book Festival Gala in Washington, D.C. Her book Copper Sun has been chosen by the US State Department and the International Reading Association as the United States novel for the international reading project. Students in the US, Nigeria, and Ghana are reading the book and sharing the ideas.\n",
            "She has worked all over the United States, as well as in Russia, Ghana, Togo, Kenya, Ethiopia, Bermuda, and Guam, spreading the word about the power of successful teaching and excellence in education.\n",
            "She became known when she won first prize in a literary  competition. She was given $5000 and her short story, One Small Torch, came out. Besides her short stories, poems, articles can often be read in literary journals . Her books are also very popular in America, too. Here are some:\n",
            "We Beat the Street (Dutton, 2005)\n",
            "Copper Sun (Simon and Schuster, 2006)\n",
            "Fire from the Rock (Dutton, 2007)\n",
            "Just Another Hero (Simon and Schuster, 2009)\n",
            "Out of my Mind (Simon and Schuster, 2010)\n",
            "\n",
            "Question: The passage is mainly about   _  .\n",
            "A. Draper's achievements\n",
            "B. Draper's experience\n",
            "C. Draper's character\n",
            "D. Draper's effort\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5682\n",
            "Current Mean Accuracy: 0.5682\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Music is an important part in our life. We may feel boring without music. Today when you go to stores, stations, restaurants and other places, do you notice music playing at any of these places? The answer must be \"Yes\". And you might even hear music in an office or on a farm.\n",
            "I like many kinds of music. Classical music is great. Rock music is fast. Light music is relaxing. But I like folk music best. It sounds very beautiful. It can bring me into the dream land. It can make me relax and forget all the problems. It makes me learn better and helps me to be more active. It is true that I learn better when I am relaxed.\n",
            "Music can also influence  people's behavior . Classical music makes people feel rich . When a restaurant plays classical music, people spend more money on food and drinks. When the restaurant plays modern music, people spend less money. Without music, people spend evenless. Restaurants can make more money in this way.\n",
            "\n",
            "Question: Which type of music below can make the writer relax?\n",
            "A. Light music.\n",
            "B. Folk music.\n",
            "C. Rock music.\n",
            "D. Pop music.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5778\n",
            "Current Mean Accuracy: 0.5778\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Which of the following is NOT right?\n",
            "A. The elephants and lions are playing soccer.\n",
            "B. Some pandas are watching the soccer game.\n",
            "C. A dolphin and a penguin are swimming in the pool.\n",
            "D. A giraffe is eating apples under the trees\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5870\n",
            "Current Mean Accuracy: 0.5870\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Kinsale may be one of the smallest towns in Southern Ireland, and it's also one of the most famous towns. It is well known for its wonderful fish restaurants. Some of the best known chiefs in the world have practiced in the restaurants there. The town itself is very beautiful in Southern Ireland by the sea. Here it is cooler in summer than other island towns. A big building overlooks the town and it is one of the most beautiful in the whole country. To the north of the town there is a high mountain standing in the country. The town is very beautiful, with its many craft shops and narrow cobbled streets. Most travelers visit Kinsale for its fish restaurants, which are family owned. This means that the service is better than that in other restaurants. People are more welcoming there than those anywhere else. The food may be expensive but you'll have one of the most pleasant evenings in your life there. So go ahead and visit Kinsale.\n",
            "\n",
            "Question: The food in the restaurants may be   _  .\n",
            "A. cheap\n",
            "B. expensive\n",
            "C. salty\n",
            "D. spicy\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5957\n",
            "Current Mean Accuracy: 0.5957\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Most People don't like mice, but they love one mouse -- Mickey Mouse. In their mind, this mouse is their favourite animal. About 70 years ago, an American man called Walt Disney created  a cartoon mouse for films. He named this mouse Mickey Mouse. From the beginning, Mickey Mouse is a clean mouse. He always does many interesting things. That's why many children and people love him. He makes them happy and _ . In the film, Mickey Mouse also has a lot of friends, for example, Donald Duck and Pluto. Donald can do many things that Mickey cannot. Pluto is a dog. He always does foolish things and makes foolish mistakes. Many children like these cartoon animals, but they like Mickey most because the mouse is a star of beauty and wisdom .\n",
            "\n",
            "Question: Many children and people like Mickey Mouse because  _  .\n",
            "A. He never makes mistakes\n",
            "B. He is like a real mouse.\n",
            "C. He always does many interesting things\n",
            "D. He has many friends.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6042\n",
            "Current Mean Accuracy: 0.6042\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: October is getting closer and it also means that the year of 2014 is coming to an end. \"Hooray! It's a holiday!\" While you are thinking of putting textbooks aside and playing video games, let's take a look at what children in other continents usually do during their holidays.\n",
            "Children in America don't have much homework to do. They keep themselves busy by playing camp games. A parent says, \"My daughter Shirley usually attends different camps. We don't ask her to spend plenty of time on maths problems or spelling tests.\"\n",
            "Children in Australia take partin activities on over twenty different themes  . They learn painting, dancing, singing, history, culture and so on. Parents can _ their kids to enjoy the learning process and to build a closer relationship with them.\n",
            "These are what African kids do: build a boat, have a camel race, make a drum and make a rag   football. Don't you think it is interesting that kids in other places have no idea how to make a drum, but kids in Africa do?\n",
            "Plan your holiday well and try what you want to try. Make a good plan and you will have a lot of fun.\n",
            "\n",
            "Question: What is the purpose of this passage?\n",
            "A. To advise kids to make holiday plans.\n",
            "B. To introduce some good holiday camps.\n",
            "C. To encourage kids to make friends with parents.\n",
            "D. To show the importance of doing homework during holidays.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5918\n",
            "Current Mean Accuracy: 0.5918\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
            "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
            "\n",
            "Question: There are   _   classrooms in Betty's school?\n",
            "A. 12\n",
            "B. 14\n",
            "C. 24\n",
            "D. 34\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Mr. Yang is a doctor. He cares a lot about not only others' health but also his own. He controls( )his weight carefully. To him, _ is the most important thing to do if one wants to enjoy good health.\n",
            "Mr. Yang controls his weight in two ways: exercising and not eating much. As a doctor. Mr. Yang is too busy to go to the gym. He exercises by getting off the bus one or two stops early and walking the rest of the way to his office.\n",
            "Besides, he doesn't eat much. Mr. Yang has a special habit. When he buys a belt, he asks the salesperson to punch a hole in the belt at 90cm from the buckle end of the belt, so that he ca always remind  himself. He will stop eating if he feels the belt a little too tight . Mr. Yang thinks exercising doesn't work as well as eating less.\n",
            "\n",
            "Question: Which of the following is true?\n",
            "A. Mr. Yang takes exercise at the gym.\n",
            "B. Mr. Yang walks all the way to work.\n",
            "C. Mr. Yang uses a belt to control how much he eats.\n",
            "D. Mr. Yang thinks exercising is better than eating less in controlling wight.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5882\n",
            "Current Mean Accuracy: 0.5882\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Tony, 18. a member of an anti-tobacco group, he says, \"Kids feel that everyone around them smokes.\" Tony wants kids to realize that most people don't smoke. He also wants to tell them that smoking doesn't make one look cool. Two national studies show that teenage smoking is down. Still, there is work to be done.\n",
            "Smoking is an unhealthy habit. It can cause heart disease, lung cancer and other serious illnesses. Just being around cigarette smoke can make you sick.\n",
            "In the 1990s, all 50 states went to court to fight tobacco companies. The states won money from the companies. It helps to pay for anti-smoking groups, but the money is not enough.\n",
            "Each day, about 4,000 kids light up for the first time. \"We have to do a better job of stopping kids from smoking,\" says Husten. Ads that tell ugly facts about smoking help to change minds. Setting smoke-free areas in public places works too. Just this month, a California town _ smoking in all public places, such as schools, shopping malls and libraries. It may be bad news for smokers. Health experts say that they will fight until all Americans get the message.\n",
            ",.\n",
            "\n",
            "Question: The states use the money that they won from tobacco companies to  _  .\n",
            "A. pay for anti-smoking programs\n",
            "B. sell more cigarettes\n",
            "C. win more court cases\n",
            "D. build more schools\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5962\n",
            "Current Mean Accuracy: 0.5962\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello! My name is Kitty. I want to talk about my home town today.\n",
            "My home town is small but pretty. It's about two hours away from London by train. In the centre of the town there is a small lake. There are lots of trees and flowers around the lake. My parents often walk around the lake at the weekend. The air in my home town is very fresh   and clean.\n",
            "There are two schools in my home town, one primary school and one secondary school. I study in the secondary school and my younger sister studies in the primary school. I often ride my bike to school.\n",
            "I usually go to the youth centre to learn drawing with my sister on Friday afternoons. I like going shopping at the weekend. There are two big shopping malls there.[:Zxxk.Com]\n",
            "\n",
            "Question: There is  _  in the centre of the town.\n",
            "A. a primary school\n",
            "B. a secondary school\n",
            "C. a small lake\n",
            "D. a shopping mall\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5849\n",
            "Current Mean Accuracy: 0.5849\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: On February 9 th,2013,Sarah Darling was walking along the street when she met a homeless man named Billy Ray Harris.She reached into her change purse,emptied out all the coins she had and gave them to the homeless man.Neither of them realized that this small generous act would change their lives.\n",
            "Sarah didn't realize that she had given Billy not only all her change but also her diamond ring that she had put in her change purse earlier until the following morning.She and her husband,Bill Krejci,rushed to see if they could find Billy.The homeless man was not only in the same place,he also immediately returned the ring.The grateful couple paid him back for his honesty by emptying out their pockets of all the money they had.\n",
            "Bill Krejci,a web designer,felt that he needed to do something more for this amazingly\n",
            "honest man.So on February 18th,he set up a special page to raise money for him.In just four days,Billy received over $ 85,000 and there seems to be no end yet.\n",
            "That is not enough.Billy is 1iving with a person who is generous instead of living in the streets.And that's not all--thanks to the news report,he got together again with his older brother,Edwin Harris who he had been unable to find for 27 years.\n",
            "All the good luck is just because Billy did the right thing--returning something that did not belong to him.\n",
            "\n",
            "Question: When did Sarah realize that she had also given Billy her diamond ring?\n",
            "A. On February 9 th,2013.\n",
            "B. On February 10th,2013.\n",
            "C. On February 18th,2013.\n",
            "D. On February 22nd,2013.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5741\n",
            "Current Mean Accuracy: 0.5741\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Joe, an outgoing girl, is from a rich family. Therefore she can afford almost everything. But Joe's parents are too busy to spend enough time with her, which makes Joe more than lonely. So, she always goes to WeChat. On WeChat, she can do a lot of things like buying things, reading articles, and making friends with those she either knows or not.\n",
            "She uses the name Linda on WeChat and has made a lot of friends there. Last year Joe made a foreign friend on WeChat. Her name was Catherine and she lived in Sydney. Catherine once sent a picture of \"herself\": a tall, good-looking young woman with big eyes. Catherine and Joe were both interested in rock music and modern dance. So, they liked each other very much.\n",
            "When Joe's father told her that he was meeting a client in Sydney this summer, she went with him to give Catherine a surprise for her birthday. When Joe came to Catherine's house in Sydney, she found that her foreign \"girlfriend\" was a ten-year-old boy named Jim! What a surprise!\n",
            "\n",
            "Question: What is the real name of Joe's \"girlfriend\"?\n",
            "A. Catherine\n",
            "B. Joe\n",
            "C. Jim\n",
            "D. Linda\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5818\n",
            "Current Mean Accuracy: 0.5818\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: More and more parents leave their homes and come into the big cities to make money. But their children can't go with them because their children have to go to school in their hometown. They are called home-left children. The problems of home-left children become more and more serious. And it becomes a big _ of our society. The main problem is that some home-left children become very lonely when they don't have their parents' love. And they are too young to tell right or wrong in many things. So they are fooled very easily by others.\n",
            "Xiao Mei , a 14-year-old girl, is a home-left child. Her parents are both in Shanghai. She is in her hometown with her grandpa. She likes playing games on the Internet. Her parents and grandpa only give her money and food. They hardly ever care for her studies. One day, she had no money to pay for the games in the Net bar. So she stole some money from her neighbor. Just at that time, Xiao Fang, a 9-year-old girl saw it. Xiao Mei was afraid that Xiao Fang would tell others about it. She cut Xiao Fang's throat with a knife, and then she went to school just like nothing happened. Luckily, Xiao Fang was saves by doctors. When she opened her eyes and wrote the fact to the policeman with a pencil, everybody was very surprised. This sad story reminds the parents to care for their children no matter how busy they are.\n",
            "Are you one of the home-left children? What do you need from your parents? Food, money or love? I think most children need love mostly. Let's care for the group together.\n",
            ",A, B, C, D,. 5,2,10\n",
            "\n",
            "Question: What does Xiao Mei only get from her parents?\n",
            "A. Clothes.\n",
            "B. Love.\n",
            "C. Money and food.\n",
            "D. Computers.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5893\n",
            "Current Mean Accuracy: 0.5893\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Have you heard of EXO? EXO is a Chinese-South Korean boy band with 12 people. They are in two teams: EXO-M and EXO-K. There's even a \"competition\" between the two teams. \"I will not call it a competition. It's always in good fun,\" said Sehun of EXO-K.\n",
            "Here comes the new superstar! His name is Austin Mahone. The 18-year-old is a pop singer in the US. His success story is just like that of Justin Bieber. Last month Mahone's new album The Secret came out. Maybe it's a good chance for us to know more about him and his music.\n",
            "Forget about Super Junior. We now have TFBOYS. TFBOYS is a popular Chinese boy band made up of three members. They are Wang Junkai, 14, Wang Yuan, 13, and Yi Yangqianxi, 13. The boys are all junior middle school students. Their songs are full of positive energy  . In their latest album, they call on teenagers not to be afraid of dreaming big.\n",
            "\n",
            "Question: Austin Mahone's success story is almost the same as   _  .\n",
            "A. TFBOY's\n",
            "B. Justin Bieber's\n",
            "C. EXO's\n",
            "D. Taylor Swift's\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5789\n",
            "Current Mean Accuracy: 0.5789\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
            "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
            "\n",
            "Question: Where is Wendy from?\n",
            "A. China.\n",
            "B. England.\n",
            "C. America.\n",
            "D. Australia.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5862\n",
            "Current Mean Accuracy: 0.5862\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When you read an article you will understand and remember it better if you can work out how the writer has put the ideas together.Sometimes a writer puts ideas together by asking questions and then answering them.For example,if the article is about groundhogs ,the set of questions in the writer's head might be:\n",
            "What does a groundhog look like?\n",
            "Where do groundhogs live?\n",
            "What do they eat?...\n",
            "In the article,the author might answer those questions.\n",
            "Sometimes an author writes out her questions in the article.These questions give you signals.They tell you what the author is going to write next.Often an author has a question in her head but she doesn't write it out for you.You have to work out her question for yourself.Here's a sample reading for you to practice this method.\n",
            "Earthworms\n",
            "Do you know how many kinds of earthworms there are?There are about 1800 kinds in the world! They can be brown,purple,green.They can be as small as 3 cm long and as large as 3 m long.\n",
            "The best time to see earthworms is at night,especially a cool,damp night.That's when they come up from their burrows to hunt for food.Earthworms don't like to be in the sun.That's because they breathe through their skin,and they can't breathe if their skin gets too dry.Earthworms must come out of the earth if it rains a lot,because they can't breathe in their flooded burrows.What a dangerous life!\n",
            "Earthworms don't have eyes,so how can they tell when it's dark? They have special places on their skin that are sensitive to light.These spots tell whether it's light or dark.If you shine a flashlight on an earthworm at night,it will quickly disappear into the ground.\n",
            "Earthworms don't have ears either,but they can hear by feeling movements in the earth.If you want to hear like an earthworm,lie on the ground with your fingers in your ears.Then have a friend stamp his or her feet near you.This is how earthworms feel birds and people walking,and moles digging,near them.\n",
            "Earthworms are useful.Farmers and gardeners like having lots of earthworms in their land because the worms help to make better soil when they dig.That digging keeps the soil loose and airy .In one year earthworms can pile up as much as 23,000 kg of castings in an area about the size of a football field.\n",
            "\n",
            "Question: Which question CANNOT be answered in the passage?\n",
            "A. How do earthworms help with gardeners?\n",
            "B. What life are earthworms living with?\n",
            "C. When may people observe earthworms?\n",
            "D. Why can human listen like earthworms?\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5932\n",
            "Current Mean Accuracy: 0.5932\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Kate is an American girl. Now she lives in New York with her parents. She lives in a community called Sunny Community. It's on Blue Street. There are five rows  of buildings in the community. Her house is in the first row. She lives on the third floor.\n",
            "There is a post office on Blue Street . Next to it ,there is a bank. Across from the bank ,there is a bookstore. The workers in the bookstore are very friendly to people. Mrs Green works in it. She is Kate's new neighbor. She has a son. His name is Bob. He is in the same class as Kate.\n",
            "Kate thinks the traffic here is very good, because she never meets any accidents here. She loves her community very much.\n",
            "\n",
            "Question: Where does Mrs Green work ?\n",
            "A. In a post office.\n",
            "B. In a bank.\n",
            "C. In a bookstore.\n",
            "D. In a school.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Foreign visitors are often puzzled   in Japan because most streets there don't have names. In Japan, people use _ in their directions instead of street names. For example, the Japanese will say to travelers, \"Go straight down to the corner. Turn left at the big hotel and go pass a fruit market. The post office is across from the bus stop.\"\n",
            "In the countryside of the American Midwest, usually there are not many landmarks. There are no mountains, so the land is very flat  . In many places there are no towns or buildings within miles. Instead of landmarks, people will tell you directions and distance. In Kansas or lowa, for example, people will say, \"Go north two miles. Turn east, and then go another mile.\"\n",
            "People in Los Angeles, California, have no idea of distance on the map: the measure   distance by means of time, not miles. \"How far away is the post office?\" you ask. \"Oh,\" they answer, \"it's about five minutes from here.\" you say, \"Yes, but how many miles away is it?\" They don't know.\n",
            "People in Greece sometimes do not even try to give directions because visitors seldom understand the Greek language. Instead of giving you the direction, a Greek will often say, \"Follow me.\" Then he'll lead you through the streets of the city to the post office.\n",
            "Sometimes a person doesn't know the answer to your question. What happen in this situation? A New Yorker might say, \"sorry, I have no idea.\" But in Yucatan, Mexico, no one answer, \"I don't know.\" They think that it is impolite. They usually give an answer, often a wrong one. A visitor can get lost in Yucatan.\n",
            "One thing will help you everywhere. You might not understand a person's words, by maybe you can understand his body language. He or she will usually turn and then point in the correct direction.\n",
            "\n",
            "Question: What does the passage mainly talk about?\n",
            "A. we needn't carry a map for travel.\n",
            "B. There are not many landmarks in the American Midwest.\n",
            "C. There are different ways to give directions in different parts of the world.\n",
            "D. Americans and Japanese have different body languages when you ask for directions.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6066\n",
            "Current Mean Accuracy: 0.6066\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: Adult editors may invite   _   to the meeting to make the paper more popular with kids.\n",
            "A. a college student\n",
            "B. a middle school student\n",
            "C. an adult editor\n",
            "D. a reporter\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5968\n",
            "Current Mean Accuracy: 0.5968\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Tom was a farmer. He worked on the farm all day,but sometimes he went to the town market to sell fruit and vegetables. One day, a terrible sound attracted his attention in the town market. He saw a young bull for sale. The bull was white and yellow. It was looking at Tom in fear. Tom walked up and touched its head gently. Just at that time they both seemed to have known each other for a long time. How amazing!Tom bought it at once and called it Amba.\n",
            "From then on , Tom and Amba got on well with each other. But some friends told him that it was dangerous to have such a close relationship with an animal.\n",
            "One afternoon , Tom was walking through the forest with Amba. Suddenly , Amba stopped walking and kept pushing Tom with its head. Tom was very surprised and looked around. There was a big snake in front of him. It was beautiful but poisonous. Quickly Amba stepped on the snake's tail with its foot and at the same time Tom picked up a stick and hit the snake's head heavily. Soon the snake . died.\n",
            "Tom was very grateful for Amba's help. When people heard this, they were shocked at the bull's expression of love for Tom. But for Tom, Amba was not a bull but a member of his family.\n",
            "\n",
            "Question: Which of the following statements is NOT true?\n",
            "A. Tom went to the town market to sell fruit and vegetables.\n",
            "B. Tom's friends thought animals were safe.\n",
            "C. Tom hit the snake's head heavily with a stick.\n",
            "D. For Tom, Amba was a member of his family.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6032\n",
            "Current Mean Accuracy: 0.6032\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: It was very late at night when Sam got off the train . He was tired and wanted to find a hotel to have a rest. He looked around and saw a hotel not far away. There were three floors in it. Then Sam went in.\n",
            "\"How much do I need to pay for a single  room a night?\" Sam asked.\n",
            "\"Well , sir,\"said the girl, \"a single room on the first floor is fifty dollars a night.\"\n",
            "\"What about the one on the second floor?\" asked Sam.\n",
            "\"Forty dollars.\"\n",
            "\"Then how about the one on the third floor?\"\n",
            "\"Thirty dollars.\"\n",
            "Sam picked up his suitcase  and wanted to go out.\n",
            "\"Don't you think our price is reasonable?\" The girl said.\n",
            "\"Yes,\" said Sam. \"Your price is of course _ , but I'm sure your hotel is not high enough.\"\n",
            "\n",
            "Question: How many floors were there in the hotel?\n",
            "A. One\n",
            "B. Two\n",
            "C. Three\n",
            "D. Four\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6094\n",
            "Current Mean Accuracy: 0.6094\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: There are   _   people in Mike's family.\n",
            "A. four\n",
            "B. five\n",
            "C. six\n",
            "D. seven\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Autumn is the harvest season. There must be a lot for us to eat !Yes, autumn is a great time for fruit and vegetables. Let's find out about some of the best.\n",
            "Apples: You can eat apples all the year round, but they are better and cheaper in autumn. People say \"An apple a day keeps the doctor away\". Apples have a lot of vitamin C and fiber  in them. They are good for the heart and can make your mouth fresh.\n",
            "Pears: Pears are in season from autumn to mid winter. They have minerals and vitamins C and E in them. They are good for the heart and can keep cancer   away.\n",
            "Pumpkins: Pumpkin is a nice vegetable in autumn. They are rich in beta carotene  , which is turned into vitamin A in our bodies. Pumpkins also have calcium ,iron and vitamin C in them. Eating pumpkins can make us look young.\n",
            "Sweet corn  : Sweet corn is in season near the end of the year. It has minerals in it. It's good for the heart.\n",
            "Autumn weather is cold and dry. Try to eat as much fruit and vegetables as you can. They will make you healthy.\n",
            "\n",
            "Question: _   are /is in rich beta carotene.\n",
            "A. Pumpkins\n",
            "B. Sweet corn\n",
            "C. Apples\n",
            "D. Pears\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5909\n",
            "Current Mean Accuracy: 0.5909\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Dan was the doorman of a club in a big city. Every day, thousands of people passed his door, and a lot of them stopped and asked him, \"What's the time, please?\"\n",
            "After a few months, Dan said to himself, \"I'm not going to answer all those stupid people any more. I'm going to buy a big clock and put it on the wall here.\" Then he did so.\n",
            "\"Now people aren't going to stop and ask me the time.\" He thought happily.\n",
            "But after that, a lot of people stopped, looked at the clock and asked Dan, \"Is that clock right?\"\n",
            "\n",
            "Question: What would be the best title for the passage?\n",
            "A. Hardworking Dan\n",
            "B. A Big Clock\n",
            "C. Stupid Question\n",
            "D. Boring People\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5821\n",
            "Current Mean Accuracy: 0.5821\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When you were very young, you liked to play with your friends. Did you find that playtime was always more fun when everyone shared the toys? Everyone got a turn. No one was left out.\n",
            "That's a life lesson that changes as you get older. As you grow up, you begin to understand that others have less than you do - in China and in the world. And that those of us who \"have\" things should help those who \" have less\" than we do. The idea of sharing _ \n",
            "At your age, you can \"share\" with people in need in three ways.\n",
            "1. You can give them a part of your money. Many adults do that regularly.\n",
            "2. You can share items you no longer use, such as clothing and toys. You can pass them onto others who cannot buy them.\n",
            "3. You can help people by giving your time and your energy.\n",
            "The last one is also called volunteering. Volunteering is about giving your time to take part in activities that will help others. Every year, many thousands of volunteers in the world give the most valuable gift of all. They give their time. They give their talent. They give of themselves. And they are enjoying it. Volunteering isn't just about work. It's about fun too.\n",
            ",.\n",
            "\n",
            "Question: What's the best title for this passage?\n",
            "A. Work hard to have more than others.\n",
            "B. Be a volunteer.\n",
            "C. Make your playtime more enjoyable.\n",
            "D. Share your love with others.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5735\n",
            "Current Mean Accuracy: 0.5735\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: The largest number of people in a race\n",
            "The biggest race is in San Francisco, the USA. More than 100,000 people run the 12 kilometers in the race. Another famous race is in London every year. This race is longer and harder, it is more than 42 kilometers, but 25,000 people usually finish it. [:Zxxk.Com]\n",
            "The youngest international player\n",
            "The youngest international player in any sport was Jamaica. Her name was Joy Foster. She was the Jamaican table tennis champion   in1958 when she was 8 years old.\n",
            "The strongest superlative  \n",
            "Have you ever tried walking backwards? The world record for walking backwards is 12,875 kilometers. A man from Texas, the USA, walked backwards for 18 months in 1931--1032. Nobody else has ever broken this record  .\n",
            "The most popular sport\n",
            "The popular sport team game in the world is football. People play football in villages, streets and stadiums all over the world. The most famous football competition is the World Cup. It happens every four years, and nearly 2,000,000,000 people watch it on TV. The first Women's World Cup was in 1991.\n",
            "\n",
            "Question: _   walked more than 12,875 kilometers' backwards.\n",
            "A. Few people\n",
            "B. Nobody else\n",
            "C. One man has\n",
            "D. Many people\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5652\n",
            "Current Mean Accuracy: 0.5652\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: English breakfast is a very big meal--eggs, tomatoes, tea, coffee... For many people, lunch is a quick  meal. In cities there are a lot of sandwich  bars . People can buy sandwiches there. Students can have a hot meal at school, but many just take a sandwich, a drink and some fruit from home.\n",
            "\"Tea\" means two things. It is a drink and a meal! Some people have afternoon tea, with sandwiches, cakes and a cup of tea.\n",
            "They usually have dinner quite early , between 6:00 and 8:00(......), and often all the family eat together .\n",
            "People often get take-away  meals--they buy the food outside\n",
            "\n",
            "Question: When they get a take-away meal, they often eat it   _  .\n",
            "A. at home\n",
            "B. in the school\n",
            "C. outside\n",
            "D. in the bars\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5571\n",
            "Current Mean Accuracy: 0.5571\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Once upon a time, there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day the feelings were told that the island would sink, so all built boats and left, except Love. Love was the only one who stayed. Love wanted to hold out  until the last possible moment.\n",
            "When the island had almost sunk, Love decided to ask for help.\n",
            "Richness was passing by Love in a big boat. Love said, \"Richness, can you take me with you?\"\n",
            "Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
            "Love decided to ask Vanity  who was also passing by in a beautiful ship.\"Vanity, please help me!\"\n",
            "\"I can't help you, Love. You are all wet and might damage  my boat, \"Vanity answered.\n",
            "Sadness was close by so Love asked, \"Sadness, let me go with you.\"\n",
            "\"Oh...Love, I am so sad that I need to be by myself!\"\n",
            "Happiness passed by Love, too, but she was so happy that she did not even hear when Love called her.\n",
            "Suddenly, there was a voice, \"Come, Love, I will take you.\"It was an elder. So thankful and happy, Love even forgot to ask the elder where they were going. When they arrived at dry land, the elder went her own way. Realizing how much was owed  the elder, Love asked Knowledge, another elder, \"Who helped me?\"\n",
            "\"It was Time, \"Knowledge answered.\n",
            "\"Time?\"asked Love.\"But why did Time help me?\"\n",
            "Knowledge smiled with deep wisdom  and answered, \"Because only Time is able to understand how valuable Love is.\"\n",
            "\n",
            "Question: Which of the following might be the best title of the passage?\n",
            "A. Love and Time\n",
            "B. An Accident\n",
            "C. A sinking island\n",
            "D. Different Feelings\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5493\n",
            "Current Mean Accuracy: 0.5493\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: If you won a lottery and had lots of money, what would you do? Most people start by buying themselves things, such as a new car or a bigger TV.\n",
            "Many people who win lots of money may suddenly find that they have a lot of socalled friends. The new friends they make may follow them for their money but they may also leave them when all the money is spent. Besides that, they can't decide what to do with the money, so they try to think what they want. In the end, most people usually decide to save the money.\n",
            "There are some lottery winners who decide to quit their jobs, because they think they have enough money and don't need to work any longer. Some big lottery winners make even bigger changes--they end their marriages. They think that winning a lot of money has suddenly made them more intelligent and more attractive .So they feel that they have to be with a younger or more attractive man or woman.\n",
            "They don't know their new money is just a bit of luck. _ can't change everything.\n",
            "Next time when you buy a lottery ticket, think about what you would like to do and what you wouldn't  like to do with the money if you won.\n",
            "\n",
            "Question: A lottery winner may suddenly find himself with many socalled  friends, probably because   _  .\n",
            "A. he wants to make lots of friends\n",
            "B. he doesn't  know what to do with all the money\n",
            "C. these new friends are usually kind to the lottery winner\n",
            "D. these new friends want the lottery winner to give them some money\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5417\n",
            "Current Mean Accuracy: 0.5417\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Do you obey the rules in your school? What do you think of your school rules? Are you allowed to dye   hair? A lot of school rules are similar around the world, but some are different. Some students may enjoy more freedom in some countries. But freedom doesn't mean \"no rules\". Every school has its own rules.\n",
            "There are some rules in Japanese schools. The students are not allowed to dye their hair and are supposed to keep their hair black. They are not allowed to wear earrings either. Almost all schools used to require students to wear school uniforms but now half of the schools require uniforms. The students feel happy to wear all kinds of clothes. The students must get to school on time. If they are late, they cannot get into the school because the school gate is closed. In Japan, students are not allowed to have part-time jobs.\n",
            "American schools have their own rules too. For example, at Morton High School, students are not allowed to choose their own clothes. They must get to school or leave school on time. Food, drinks or snacks shouldn't be taken into the classroom. They must wear sports shoes in PE class. They are supposed to keep quiet on the school bus. In America, the students can have part-time jobs in their free time. (<<>> )\n",
            "\n",
            "Question: Which school rules have changed in some Japanese schools?\n",
            "A. About wearing earrings.\n",
            "B. About uniforms.\n",
            "C. About food and drinks.\n",
            "D. About part-time jobs.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5342\n",
            "Current Mean Accuracy: 0.5342\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: My friends like different clothes. Sue likes red clothes. She is often in a red skirt and red shoes. Mina likes white clothes. She is in a white shirt. Her sister Emma likes to wear a green skirt. She looks nice. David often wears a white cap and black pants. Peter often wears a white coat and black pants.\n",
            ",.\n",
            "\n",
            "Question: What color does Sue like?\n",
            "A. White.\n",
            "B. Red.\n",
            "C. Yellow.\n",
            "D. Green.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5270\n",
            "Current Mean Accuracy: 0.5270\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: There is lots of junk  in space .Some of it is from rockets. In 1996, a rocket broke into about 300,000 small pieces. So far, scientists have found over 10,000 man-made pieces flying around in space. Only 6-7%of them are satellites and space probes  . Astronauts also lose small things while working in space. In 1965, during the first American spacewalk , astronaut Edward White lost a glove .For a month, the glove stayed in space, travelling at a speed of 28,000 kilometers per hour .It became the most dangerous piece of clothing for the Earth in history it flew away. Things move very fast in space. If they hit one another, it can be dangerous .A little piece of paint from a satellite once made a hole in a spacecraft window. Last year two US spacecraft dropped some bolts , and scientists on the Earth worried a lot. Luckily the bolts floated  away into space. They couldn't hit the spacecraft.\n",
            ",.\n",
            "\n",
            "Question: The glove in space may travel at a speed of    _    kilometers per hour.\n",
            "A. 300,000\n",
            "B. 28,000\n",
            "C. 10,000\n",
            "D. 21,000\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5200\n",
            "Current Mean Accuracy: 0.5200\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: \"You know, these cups brings to my mind a story I heard,\" Mary said to her students.\n",
            "She poured some tea. There were four of them and there were four completely different cups on the tables.\n",
            "\"I heard there was a teacher who took all his students for tea. His students were surprised that all the cups on the table were different. They all took a cup and started drinking their tea, each looking at the cups of others. The teacher said, \"Did you notice your behavior? You are all looking at each other's tea cup and some of you even envy the finer cups of others.\"\n",
            "\"I put the different cups here on purpose. I want to say life is like this tea. You all have the same thing in your cups----tea. And yet you cannot truly enjoy it in your envy of another's cup. You forget to enjoy your own life when you envy someone else's life. We all have the same thing----life. We should care more about the tastes of your own life. So now, taste your own tea. Does it matter from which cup it came from?\" Mary finished telling her story and her students all sat in silence for a while, enjoying their tea. And it really did not matter a bit from which teacup they drank.\n",
            "\n",
            "Question: What should we learn from the story?\n",
            "A. Envy others and make progress.\n",
            "B. All the lives are the same.\n",
            "C. Work hard and catch up with others.\n",
            "D. Try to enjoy your own life.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5263\n",
            "Current Mean Accuracy: 0.5263\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: If you think you are too shy and want to be a little outgoing, try the following. You can make it.\n",
            "Tell people you are shy. Just let people know that you are a shy kid. When they know that, they'll understand you better. This also helps you feel more at home when talking with others.\n",
            "Try to smile more. People think you are friendly and easy to talk to. Remember that most of us would like to talk to friendly people and we will stay away from an angry-looking face.\n",
            "Talk to others first. If you find it hard to do, say something nice about people around you. Think about how great you feel when someone says something nice to you. Doesn't it make you want to keep talking to those people?\n",
            "Turn your attention to somewhere else. Think more about ways to enjoy the party or the game. Don't worry about your looks or care if people like you.\n",
            "Reward  yourself. Each time after you say \"hi\" or smile at someone for the first time , say to yourself \"You did it!\" or buy yourself an ice cream.\n",
            "Keep trying and one day you won't be shy any more when you talk to others.\n",
            "\n",
            "Question: Which of the following is NOT true?\n",
            "A. People can understand you better when they know you are shy.\n",
            "B. Most people don't like to talk to those people with angry faces.\n",
            "C. Don't care what you look like at the party or the game.\n",
            "D. Each time after you smile at someone for the first time, you should buy yourself an ice cream.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5325\n",
            "Current Mean Accuracy: 0.5325\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Many people think sports are just for winning and honor, but there is a lot more you can gain from (get out of) them. I have learned over the past years that sometimes when I lose, I get a lot more out of it than winning. Also, I find a lot of times in sports, people are getting too caught up in the game instead of just having fun. The real purpose of sports is to have fun and learn life lessons along the way.\n",
            "I greatly encourage you to be a part of the school sports. Even if you are not the best, you can still have fun. Sports give people a great and healthy way of spending an afternoon, instead of lying around playing video games or even getting into bad things. Sports also give us a sense of achievement. There isn't a better feeling than to have done something fun and productive for my day.\n",
            "I think that we all need sports to give us courage. If we try hard in sports, we usually do well. If we did the same in study, we would all be champions. Another reason why I encourage you to play sports is that it's just fun. Without sports, our lives would just be boring. So as you may be able to tell, sports are amazing!\n",
            "Our coaches not only teach us to play sports, but show class and good sportsmanship while playing them. It's never fun when you lose to have the competitor rub it in your face. That's why our coaches teach us to show class when we lose; also, when coaches _ , don't get down. They only want to see you improve and learn from what they say. When you do badly and they don't shout loudly is when you should start worrying because they are giving up on you.\n",
            "Overall, sports are great! They bring out the best and worst of a lot of us. However, we can' t let sports get too serious to where it brings down all the fun. So to have the most fun in sports, you just need try your best and not worry so much about the winning or losing.\n",
            "\n",
            "Question: Which of the following statements is TRUE according to the passage?\n",
            "A. Sports bring us great fun only if we have the talent.\n",
            "B. Sports give us the best way of spending free time.\n",
            "C. We can get more out of winning than losing.\n",
            "D. We should take pleasure in doing sports.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5256\n",
            "Current Mean Accuracy: 0.5256\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: On May 1, a wildfire started in a forest near the Alberta town of Fort McMurray in Canada. Within two days, the fire grew larger and the people who lived in Fort McMurray had to leave their homes. While there have been very few people injured   by the large fire itself, it has been harmful to the community.\n",
            "Canadians in other places have been helping by sending money and _ to the Red Cross. Many people in Alberta have taken in people from Fort McMurray, letting them stay in their homes for free until the fire is put out. Many firefighters are needed to fight the fire and some of them have come from other parts of Canada to help. The brave firefighters were able to save 25,000 homes as well as the hospital and all of the town's schools, according to CBC news.\n",
            "There have been thousands of other acts of kindness towards the people of Fort McMurray. Some musicians, such as Great Big Sea's Alan Doyle, are holding special concerts, with the money going to Fort McMurray people. And companies have been helping, as well. Beer-maker Labatt filled thousands of cans with water--instead of beer--and sent them to the people in Fort McMurray.\n",
            "The fire is huge, spreading over more than 229,000 hectares  , but firefighters say they believe they are starting to get it under control--it is becoming smaller instead of spreading.\n",
            "\n",
            "Question: How many people have been injured by the large fire itself?\n",
            "A. 25,000.\n",
            "B. Very few.\n",
            "C. 229,000.\n",
            "D. Many.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5190\n",
            "Current Mean Accuracy: 0.5190\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
            "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
            "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
            "\n",
            "Question: The writer thinks many people don't live near the north or south pole because  _  .\n",
            "A. they can't get enough food there\n",
            "B. the natural sights there don't arrract people\n",
            "C. the unpleasant weather keeps them away\n",
            "D. the length of nighttime keeps them away\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5250\n",
            "Current Mean Accuracy: 0.5250\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Mr. and Mrs. Green lived in a big city. One summer they went to the country for their holiday. They enjoyed it very much because it was a quiet, clean place.\n",
            "One day they went for a walk early in the morning and met an old man. He lived on a farm, and he was sitting in the warm sun in front of his house. Mr. Green asked him, \"Do you like to live in this quiet place?\"\n",
            "The old man said, \"Yes, I do.\"\n",
            "Mr. Green then asked, \"What are the good things about it?\"\n",
            "The old man answered, \"Well, the people here know each other. They often come and visit me, and I often go and visit them. And there are also many children here.\" Mr. Green said, \"That's interesting, and what are the bad things?\"\n",
            "The old man thought for a moment and then said, \"Well, the same things, really.\"\n",
            "\n",
            "Question: The old man sometimes liked the people to   _  , but sometimes he didn't.\n",
            "A. ask him questions\n",
            "B. keep the place quiet and clean\n",
            "C. come and visit him\n",
            "D. make interesting things\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5185\n",
            "Current Mean Accuracy: 0.5185\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Do you know why different animals or pests have their special colours? Colours in them seem to be mainly used to protect themselves.\n",
            "Some birds like eating locusts , but birds cannot easily catch them. Why? It is because locusts change their colurs with the changes of the colours of crops .When crops are green, locusts look green .But as the harvest time comes, locusts change into the same brown colour as crops have .Some other pests whose colours are different from plants are easily found and eaten by others .So they have to hide themselves for lives and appear only at night.\n",
            "If you study the animals' life, you'll find the main use of colours is to protect themselves .Bears, lions and other animals move quietly through forests .They cannot be easily seen by hunters because their colours are much like the trees.\n",
            "Colours are useful not only on the land , but also in the sea .A kind of fish in the sea can give out a kind of black liquid when the fish face danger. The liquid spreads over quickly, so they cannot be found by their enemies and can quickly swim away. That is why they can live safely though they are not strong at all.\n",
            "\n",
            "Question: Bears and lions can keep safe because  _  .\n",
            "A. their colours are much like the trees\n",
            "B. they move quickly\n",
            "C. they are very strong\n",
            "D. they live in forests\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5244\n",
            "Current Mean Accuracy: 0.5244\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: There are several ways you can find out about the countries and places you wish to visit. You can talk to friends who have traveled to the places, you can go and see a colour film about them, or you can read a travel book.\n",
            "It seems that there are three kinds of travel books. The first are those that give a personal, subjective  idea of travels which their writer has got himself. These books can be useful if the writers share their traveling experiences with others. The second kind are those books which give objective  information of things to be done and seen. If _ has written such a book about the facts of a place, then it is more useful. The third kind are those books which are called \"a guide\" to some place or other. If they are good, they will describe and explain the place in detail. Like the first kind , they can be interesting and exciting, but their main purpose is to help the reader plan his travel in the most practical way.\n",
            "Whatever kind of travel book you choose, you must make sure that the book does not describe everything as interesting, exciting or fantastic. You must also keep an open eyes on its date of publication  because travel is very practical matter and many things change quickly in the 21st century. Finally, you should make sure that it's easy to find the useful information for you travel.\n",
            "\n",
            "Question: The date of publication must be noticed because   _  .\n",
            "A. the prices of travel books may be different\n",
            "B. the writers of travel books may be different\n",
            "C. the information in travel books is always the same\n",
            "D. the information in travel books is always changing\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5181\n",
            "Current Mean Accuracy: 0.5181\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
            "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
            "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
            "She understood that she hadn't worn the hair clip to school at all.\n",
            "\n",
            "Question: Her classmates wanted to know what had happened to the girl because  _\n",
            "A. she didn't tell her classmates about her beautiful hair clip.\n",
            "B. she was always unhappy but that day she was so happy.\n",
            "C. she looked more beautiful wearing the hair clip.\n",
            "D. she wanted to talk to others.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5119\n",
            "Current Mean Accuracy: 0.5119\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When people talk about air pollution, they usually think of smog, acid rain ,and other forms  of outdoor air pollution. But did you know that air pollution also is inside homes, offices, hotels and other buildings?Indoor air pollution is more serious. The air in your home can be 2 to 100 times  more polluted than the air outdoors!In fact, some American doctors say that 50% of illnesses have something to do with polluted indoor air. Indoor air pollution is bad for our health in many ways. Young children and the old often suffer  more from air pollution. People with health problems may also suffer more when the air is polluted. Indoor air pollution can be bad for people's eyes, nose and throat. Air pollution, both indoor and outdoor, can also lead to cancer, heart disease, and even bad for the brain!In the great London fog in 1952, 4,000 people died in a few days because of air pollution!It is said that half a million young kids and women die each year in India because of indoor air pollution!\n",
            "There're many ways to reduce  indoor air pollution. Here are some of them and see if they can help you:\n",
            "Increase outdoor air coming indoors and open your windows for 15 to 30 minutes each day.\n",
            "Turn off all the lights and fans when you don't need them.\n",
            "Share your room with others when the air conditioner is running.\n",
            "Don't smoke and try to stop your family members from smoking. People who smoke are going to have trouble breathing and even die someday. If you're smart, don't ever start.\n",
            "Environment-friendly products, such as water-based paints pollute less and work well.\n",
            "\n",
            "Question: How many ways does the writer talk about to reduce indoor air pollution?\n",
            "A. Four.\n",
            "B. Five.\n",
            "C. Six.\n",
            "D. Seven.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5176\n",
            "Current Mean Accuracy: 0.5176\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: \"You know, these cups brings to my mind a story I heard,\" Mary said to her students.\n",
            "She poured some tea. There were four of them and there were four completely different cups on the tables.\n",
            "\"I heard there was a teacher who took all his students for tea. His students were surprised that all the cups on the table were different. They all took a cup and started drinking their tea, each looking at the cups of others. The teacher said, \"Did you notice your behavior? You are all looking at each other's tea cup and some of you even envy the finer cups of others.\"\n",
            "\"I put the different cups here on purpose. I want to say life is like this tea. You all have the same thing in your cups----tea. And yet you cannot truly enjoy it in your envy of another's cup. You forget to enjoy your own life when you envy someone else's life. We all have the same thing----life. We should care more about the tastes of your own life. So now, taste your own tea. Does it matter from which cup it came from?\" Mary finished telling her story and her students all sat in silence for a while, enjoying their tea. And it really did not matter a bit from which teacup they drank.\n",
            "\n",
            "Question: Which is the best title for the story?\n",
            "A. More than tea in a cup\n",
            "B. The same cups, the same tea\n",
            "C. The taste of the tea\n",
            "D. Different cups, different tea\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5116\n",
            "Current Mean Accuracy: 0.5116\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: The newspaper should not be   _\n",
            "A. simple\n",
            "B. interesting\n",
            "C. difficult\n",
            "D. easy\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5172\n",
            "Current Mean Accuracy: 0.5172\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: At the age of sixteen, I went on my first volunteer program in West Virginia to repair or build homes for poor families. When we arrived, we discovered that the family we were going to help was living in a trailer that was in poor condition, no bigger than two parking spaces. A group of people had been working on it for two weeks, but every time they finished one problem, another appeared.\n",
            "We soon decided that the only way was to build a new house. It was something unusual because normally our goal was to repair old homes. The family was pleased with their new house that was 20 by 30 feet with three bedrooms, a bath and a kitchen.\n",
            "On Tuesday of that week, I asked the family's three boys, Josh, Eric and Ryan, \"What do you want for your new room?\" Kids in the families we had helped usually wanted toys or posters, so we were surprised when Josh, the oldest boy said, \"We just want beds.\" The boys had never slept in a bed. That night we had a meeting and decided that beds would be the perfect gift. On Thursday night, a few adults in our group drove to the nearest city and bought beds and new bedding.\n",
            "On Friday when we saw the truck coming, we told the family about the surprise. They were very excited.\n",
            "That afternoon, while we were setting up the beds, Eric ran into the house to watch us with wide eyes. As Maggie, a member of our group, put one of the pillows on the bed, Eric asked, \"What is that?\"\n",
            "\"A pillow,\" she replied.\n",
            "\"What do you do with it?\" Eric went on asking.\n",
            "\"When you go to sleep, you put your head on it,\" Maggie answered softly. Tears came to our eyes as she handed Eric the pillow.\n",
            "\"Oh . . . that's soft,\" he said, holding it tightly.\n",
            "Now, when my sister or I start to ask for something that seems very urgent , my dad always asks, \"Do you have a pillow?\" We know exactly what he means.\n",
            "\n",
            "Question: What can we learn from the story?\n",
            "A. The family needed two parking spaces.\n",
            "B. The boys of the family wanted toys and posters.\n",
            "C. The family were excited about the beds and bedding.\n",
            "D. The writer's group made some furniture for the family.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5227\n",
            "Current Mean Accuracy: 0.5227\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: One day my wife and I went shopping at  the shop. We took the car as we had a lot of things to buy because my brother and his family were going to spend the weekend with us. We stopped the car in front of the shop. An hour later we came back to the car with a lot of things. Then the trouble started. We could not open the car door.\n",
            "\"Oh, dear,\" said my wife, \"What are you going to do?\"\n",
            "\"Let's ask that policeman,\" I said. The policeman was very kind and glad to help us. A few minutes later he got the door open. Just at that moment an angry man came up and shouted, \"What are you doing with my car?\"\n",
            "We looked at the number of the car and our faces turned very red.\n",
            "\n",
            "Question: How long did they spend in the shop doing their shopping?\n",
            "A. About half an hour.\n",
            "B. A whole morning.\n",
            "C. One hour or so.\n",
            "D. A whole day.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5169\n",
            "Current Mean Accuracy: 0.5169\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: Wang Hao is in   _   now.\n",
            "A. England\n",
            "B. the USA\n",
            "C. Jiangsu\n",
            "D. Beijing\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5111\n",
            "Current Mean Accuracy: 0.5111\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
            "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
            "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
            "\n",
            "Question: Why does Victory work so hard? Because   _  .\n",
            "A. he is very strong\n",
            "B. he likes his work very much\n",
            "C. he is helping his parents\n",
            "D. he is saving up to buy a house\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5055\n",
            "Current Mean Accuracy: 0.5055\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: The word, \"photography\", was first used in 1839. It comes from the Greek words that mean \"to write with light\". But photography could only give people _ pictures. So scientists were trying hard to find ways to make pictures that can move. They made lots of experiments, but failed again and again. It was Eadweard Muybridge who finally succeeded. He was the first photographer to try this successfully. But how did he make it? It was an interesting story.\n",
            "Back in 1872, people didn't know exactly whether all four of a horse's hooves   left the ground at the same time when it was running. A gentleman called Leland Stanford made a bet with his friend about it. Most people believed that a horse always had one hoof on the ground, or it would fall over. But Stanford didn't think so.\n",
            "At that time, it was hard to know who could win the bet, because a horse's legs move so fast that it is impossible to tell just by looking. So they needed a way to record the movement of a running horse. Then Stanford offered $25,000 to the famous photographer, Muybridge, to help find the answer. In the beginning, Muybridge failed to get clear images, but he didn't give up. He continued to improve his cameras. In 1878, after many experiments, he managed to get a sequence   of 12 photos. One of them clearly showed that all four of the horse's hooves were off the ground at the same time. And when the photos moved fast, people could see a horse running.\n",
            "Though is usually considered as the person who created the first movie in 1889, it was the work of Eadweard Muybridge and the bet that led to Edison's invention.\n",
            "\n",
            "Question: The passage mainly tells us   _  .\n",
            "A. that Thomas Edison created the first movie .\n",
            "B. that Eadweard Muybridge created the first static pictures\n",
            "C. how photography helped people know more about animals\n",
            "D. how Eadweard Muybridge got pictures of motion   successfully\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5109\n",
            "Current Mean Accuracy: 0.5109\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Music education hasn't changed much since the 1970s. Students are still taught to read notation so they can recite compositions that they would never listen to on their MP3 players or play with friends. Playing music enriches life. The question is: Why do schools teach music in a way that _ so many young people rather than catch their imagination? Can we do a better job of using the power of music to get kids excited about school?\n",
            "The experience of an organization called Little Kids Rock suggests the answer is yes -- if we change the way music is taught. Little Kids Rock has helped music programs in over a thousand public schools and served 150,000 children. The organization has given 30,000 free instruments out, mainly guitars, and trained 1,500 teachers to run music classes in which students quickly experience the joys of playing their favorite songs, performing in bands , and writing their own music.\n",
            "The key to Little Kids Rock is that it teaches children to play music the way many musicians learn to play it -- not by notation, but by listening, imitation and meaningful experimentation. \"The knowledge you need to get started playing rock music is very limited,\" explains Dave Wish, the founder of Little Kids Rock. \"In high school, my friend Paul taught me a couple of chords and my life was changed forever. On the first day of class, Little Kids Rock teachers place guitars in the hands of their students and get them practicing chords that will enable them to play thousands of songs. The kids decide what songs they want to learn and the class is off and running. Their progress is surprising. Within a year, eight and nine-year-olds are playing musical instruments, and giving concerts, even performing their own songs.\n",
            "One of the biggest advantages that music offers is the ability to encourage students who are otherwise bored by school. \"I've had students start coming back to school because of this program,\" said Adkison Thomas, who heads up music for the Dallas Independent School District. He added, \"One of the best things is that the teachers discover a new side of their students. They see kids become successful who weren't before.\"\n",
            "\n",
            "Question: What does the writer want to tell us?\n",
            "A. Learning music is a good way to become successful.\n",
            "B. Teaching in a proper way does good to students' development.\n",
            "C. It's necessary for students to practice a lot in learning music.\n",
            "D. It's important for teachers to discover the new sides of students.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5054\n",
            "Current Mean Accuracy: 0.5054\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Children in England mustn't work until they are 13. They need to have a work permit   to start working.\n",
            "The jobs teenagers can do\n",
            "Delivering   newspapers\n",
            "Many teenagers will get up early to deliver newspapers to houses in their local area before going to school. They are known as Paper-boys or Papergirls.\n",
            "Babysitting: Looking after young children in their home while their parents have gone out for the evening is a popular job for teenagers, as they get money for watching children and television all at the same time!\n",
            "Helping the Milkman: From the age of 14 some teenagers help the milkman deliver milk to houses.\n",
            "Other popular jobs : Working in a shop; Office work; Washing cars ; In a cafe or restaurant. The hours teenagers (13 and 14 year olds )can work:\n",
            "School Days\n",
            "Not more than 2 hours in one day during the following periods:\n",
            "Morning 7 a. m. --start of school or Evening\n",
            "close of school-- 7 p. m.\n",
            "Saturdays: Up to 5 hours between 7 a.m. and 7 p.m.\n",
            "Sundays\n",
            "Up to 2 hours between 7 a.m. and 11 a. m.\n",
            "Term time\n",
            "Up to 12 hours a week (Including weekends)\n",
            "\n",
            "Question: Teenagers in England can do all of the following except   _   .\n",
            "A. work in an office\n",
            "B. work in a night club\n",
            "C. look after young children\n",
            "D. deliver newspapers\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Are you always unwilling to do housework and cleaning for no reason? Well, you will be happy today. Today is No Housework Day. It's time to forget about housework and be relaxed.\n",
            "No Housework Day is always on April 7th. It is your chance to do anything, except housework. Better still, have someone else do housework for a day. Housework is a daily and endless job and most people think it's boring to do housework. I have many friends and their wish is to stay away from housework. In fact, their wish can never come true.\n",
            "Do you know how to celebrate No Housework Day? Well , there are two different ways.\n",
            "If you usually do the housework around the house, forget it on this day. Instead, kick back and enjoy the day. Relax and do anything, except housework.\n",
            "If you never do housework, you can do it for your family. It gives your parents a break from the housework. And, you just might get a chance to know how much housework your parents need to do every day.\n",
            "\n",
            "Question: The writer has many friends and their wish is   _  .\n",
            "A. not to do any housework any more\n",
            "B. to ask others to do their housework\n",
            "C. to celebrate No Housework Day\n",
            "D. to ask all the family members to do housework\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4947\n",
            "Current Mean Accuracy: 0.4947\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
            "\n",
            "Question: Andy and Jim think the tall man is   _   .\n",
            "A. an actor\n",
            "B. a thief\n",
            "C. a policeman\n",
            "D. the short man's friend.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Plants are very important living things. Life could not go on if there were no plants. This is because plants can make food from air, water and sunlight. Animals and man cannot make food from air, water and sunlight. Animals get their food by eating plants and other animals. Therefore animals and man need plants in order to live. This is why we find that there are so many plants around us.\n",
            "If you look carefully at the plants around you, you will find that there are two kinds of plants: flowering plants and non-flowering  plants.\n",
            "Flowering plants can make seeds . The seeds are protected by the fruits. Some fruits have one seed, some have two, three or four, and some have many seeds. But a few fruits have no seeds at all. An example of a fruit without seeds is the banana fruit.\n",
            "Most non-flowering plants do not grow from seeds. They grow from spores . Spores are very, very small. Some spores are so small and light that they can float in the air. We may say that spores are quite the same as seeds. When these spores fall on wet and shady  places, they usually grow into new plants.\n",
            "\n",
            "Question: This passage is most likely to be taken from   _  .\n",
            "A. a story book\n",
            "B. a novel\n",
            "C. a science magazine\n",
            "D. a laboratory report\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5052\n",
            "Current Mean Accuracy: 0.5052\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: This is a special class. The students come from different countries. Some come from America. Others come from Canada, Japan, Australia and England. They speak different languages,but all of them can speak English. They are good friends. They study together, play together and live together. They help each other. All the teachers of this class are Chinese, but they can speak English. They are very kind and friendly. They work hard. The students in this class study Chinese cooking and Chinese gongfu.\n",
            "All the students like China. They say China is a great country and the Chinese people are very friendly. And they are happy in China.\n",
            ",.\n",
            "\n",
            "Question: What kind of class is this?\n",
            "A. A Chinese cooking class\n",
            "B. A Chinese gongfu class\n",
            "C. A foreign language class\n",
            "D. Both A and B\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: We have twenty minutes' break time after the second class in the morning.  Look!  Most of us are playing during the break time. Some students are on the playground . They are playing basketball. Oh! A boy is running with the ball.  And another is stopping  him. They look so cool. And there are some girls watching the game. Some students are in the classroom. They are talking.  A few of them are reading and doing homework. Look! A girl is looking at the birds in the tree in front of the classroom. She must be thinking of something interesting because she is smiling .\n",
            "What are the teachers doing? Some of them are working in the office. And some are talking with students. Everyone is doing his or her things, busy but happy!\n",
            "\n",
            "Question: The passage is mainly about   _   .\n",
            "A. students\n",
            "B. a basketball game\n",
            "C. break time activities\n",
            "D. teachers\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5051\n",
            "Current Mean Accuracy: 0.5051\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Before I left to meet Lynne, my friend told me that I had better take some money, but I didn't listen to him. I thought that Lynne would pay because she invited me.\n",
            "I arrived at the restaurant on time because I knew Americans like to be on time. Lynne and I sat at a table near the door and soon we began to enjoy ourselves there.\n",
            "The food there was very delicious. I talked a lot about Saudi Arabia and Lynne told me all about herself. After two hours the waiter came and asked if we wanted one check  or two. Lynne said two. Lynne paid her check, and the waiter gave me mine, I had no money. Then I had an idea, I called my friend. In a few minutes he arrived with some money. He laughed at me all the way home.\n",
            "Now, I think it's funny, but I guess you can understand how I felt at that time. So when you visit a foreign country, you have to learn their language and culture.\n",
            "\n",
            "Question: After the meal,  _  ,\n",
            "A. Lynne paid only for herself\n",
            "B. Lynne paid for both of us.\n",
            "C. I would like to pay for myself\n",
            "D. I paid for both of us.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (RACE_H) ---\n",
            "Final Exact Match Accuracy: 0.5000\n",
            "Final Mean Accuracy: 0.5000\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.5, 'accuracy': 0.5}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.07207351446151733}, 'time_per_token': {'mean': 0.07207351446151733}, 'tokens_per_second': {'mean': 17.203051632642747}}\n",
            "Valid formats: ['chat_format', 'cnn_dm_summarization', 'cnn_dm_lm', 'xsum_summarization', 'human_eval', 'custom_jsonl', 'top_v2', 'mmlu', 'race_m', 'race_h']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking RACE_H:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   1%|          | 1/100 [00:01<02:14,  1.36s/it]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   3%|▎         | 3/100 [00:01<00:42,  2.30it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   5%|▌         | 5/100 [00:01<00:23,  4.10it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   7%|▋         | 7/100 [00:01<00:15,  6.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   9%|▉         | 9/100 [00:01<00:11,  7.90it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  11%|█         | 11/100 [00:02<00:09,  9.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  13%|█▎        | 13/100 [00:02<00:07, 11.35it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  15%|█▌        | 15/100 [00:02<00:06, 12.51it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  17%|█▋        | 17/100 [00:02<00:06, 13.41it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  19%|█▉        | 19/100 [00:02<00:05, 14.13it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  21%|██        | 21/100 [00:02<00:05, 14.72it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  23%|██▎       | 23/100 [00:02<00:05, 14.50it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  26%|██▌       | 26/100 [00:03<00:04, 15.43it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  28%|██▊       | 28/100 [00:03<00:04, 15.95it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  30%|███       | 30/100 [00:03<00:04, 16.36it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  32%|███▏      | 32/100 [00:03<00:04, 16.79it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  34%|███▍      | 34/100 [00:03<00:03, 17.17it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  37%|███▋      | 37/100 [00:03<00:03, 17.79it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  40%|████      | 40/100 [00:03<00:03, 18.66it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  42%|████▏     | 42/100 [00:03<00:03, 17.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  44%|████▍     | 44/100 [00:04<00:03, 17.24it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  46%|████▌     | 46/100 [00:04<00:03, 17.71it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  48%|████▊     | 48/100 [00:04<00:02, 18.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  50%|█████     | 50/100 [00:04<00:02, 18.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  52%|█████▏    | 52/100 [00:04<00:02, 18.35it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  54%|█████▍    | 54/100 [00:04<00:02, 18.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  56%|█████▌    | 56/100 [00:04<00:02, 16.98it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  58%|█████▊    | 58/100 [00:04<00:02, 17.40it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  60%|██████    | 60/100 [00:04<00:02, 16.38it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  62%|██████▏   | 62/100 [00:05<00:02, 15.71it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  64%|██████▍   | 64/100 [00:05<00:02, 15.72it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  66%|██████▌   | 66/100 [00:05<00:02, 16.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  68%|██████▊   | 68/100 [00:05<00:01, 17.08it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  70%|███████   | 70/100 [00:05<00:01, 17.40it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  72%|███████▏  | 72/100 [00:05<00:01, 16.17it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  74%|███████▍  | 74/100 [00:05<00:01, 16.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  76%|███████▌  | 76/100 [00:05<00:01, 16.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  78%|███████▊  | 78/100 [00:06<00:01, 15.84it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  80%|████████  | 80/100 [00:06<00:01, 15.43it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  82%|████████▏ | 82/100 [00:06<00:01, 16.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  84%|████████▍ | 84/100 [00:06<00:01, 15.90it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  86%|████████▌ | 86/100 [00:06<00:00, 15.60it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  88%|████████▊ | 88/100 [00:06<00:00, 14.42it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  90%|█████████ | 90/100 [00:06<00:00, 15.64it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  92%|█████████▏| 92/100 [00:06<00:00, 15.35it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  94%|█████████▍| 94/100 [00:07<00:00, 14.76it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  96%|█████████▌| 96/100 [00:07<00:00, 15.77it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  98%|█████████▊| 98/100 [00:07<00:00, 16.42it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H: 100%|██████████| 100/100 [00:07<00:00, 16.40it/s]\n",
            "Benchmarking RACE_H: 100%|██████████| 100/100 [00:07<00:00, 13.43it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset race_h \\\n",
        "       --num_samples 100 \\\n",
        "       --generation_strategy autoregressive \\\n",
        "       --dropout_rate 0.2 \\\n",
        "       --layerdrop_seed 42 \\\n",
        "       --output_dir ./logs \\\n",
        "       --distributed False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: race_h\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on RACE_H with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking RACE_H:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking RACE_H:   0%|          | 0/100 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\adity\\LayerSkip_Plus_Experiments\\LayerSkip\\LayerSkip\\benchmark.py\", line 527, in <module>\n",
            "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
            "  File \"c:\\Users\\adity\\LayerSkip_Plus_Experiments\\LayerSkip\\LayerSkip\\benchmark.py\", line 499, in main\n",
            "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config, args.seed)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip_Plus_Experiments\\LayerSkip\\LayerSkip\\benchmark.py\", line 369, in benchmark\n",
            "    generation_result = generator.generate(\n",
            "                        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip_Plus_Experiments\\LayerSkip\\LayerSkip\\self_speculation\\generator_base.py\", line 111, in generate\n",
            "    generation_strategy_result = self.generation_strategy.generate_token_ids(\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip_Plus_Experiments\\LayerSkip\\LayerSkip\\self_speculation\\self_speculation_generator.py\", line 99, in generate_token_ids\n",
            "    acceptance_rate=total_draft_matches / total_generations,\n",
            "                    ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset race_h \\\n",
        "       --num_samples 100 \\\n",
        "       --generation_strategy self_speculative \\\n",
        "       --dropout_rate 0.2 \\\n",
        "       --layerdrop_seed 42 \\\n",
        "       --output_dir ./logs \\\n",
        "       --distributed False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking MBPP:   0%|          | 0/510 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking MBPP:   0%|          | 1/510 [00:10<1:32:57, 10.96s/it]\n",
            "Benchmarking MBPP:   0%|          | 2/510 [00:20<1:27:18, 10.31s/it]\n",
            "Benchmarking MBPP:   1%|          | 3/510 [00:30<1:26:16, 10.21s/it]\n",
            "Benchmarking MBPP:   1%|          | 4/510 [00:41<1:26:48, 10.29s/it]\n",
            "Benchmarking MBPP:   1%|          | 5/510 [00:51<1:26:46, 10.31s/it]\n",
            "Benchmarking MBPP:   1%|          | 6/510 [01:01<1:26:25, 10.29s/it]\n",
            "Benchmarking MBPP:   1%|▏         | 7/510 [01:12<1:26:27, 10.31s/it]\n",
            "Benchmarking MBPP:   2%|▏         | 8/510 [01:22<1:25:41, 10.24s/it]\n",
            "Benchmarking MBPP:   2%|▏         | 9/510 [01:32<1:25:26, 10.23s/it]\n",
            "Benchmarking MBPP:   2%|▏         | 10/510 [01:42<1:25:12, 10.22s/it]\n",
            "Benchmarking MBPP:   2%|▏         | 11/510 [01:52<1:24:57, 10.21s/it]\n",
            "Benchmarking MBPP:   2%|▏         | 12/510 [02:02<1:23:55, 10.11s/it]\n",
            "Benchmarking MBPP:   3%|▎         | 13/510 [02:13<1:23:57, 10.14s/it]\n",
            "Benchmarking MBPP:   3%|▎         | 14/510 [02:23<1:24:04, 10.17s/it]\n",
            "Benchmarking MBPP:   3%|▎         | 15/510 [02:33<1:23:22, 10.11s/it]\n",
            "Benchmarking MBPP:   3%|▎         | 16/510 [02:43<1:23:20, 10.12s/it]\n",
            "Benchmarking MBPP:   3%|▎         | 17/510 [02:53<1:23:24, 10.15s/it]\n",
            "Benchmarking MBPP:   4%|▎         | 18/510 [03:04<1:24:51, 10.35s/it]\n",
            "Benchmarking MBPP:   4%|▎         | 19/510 [03:14<1:25:05, 10.40s/it]\n",
            "Benchmarking MBPP:   4%|▍         | 20/510 [03:25<1:24:26, 10.34s/it]\n",
            "Benchmarking MBPP:   4%|▍         | 21/510 [03:35<1:23:58, 10.30s/it]\n",
            "Benchmarking MBPP:   4%|▍         | 22/510 [03:45<1:24:01, 10.33s/it]\n",
            "Benchmarking MBPP:   5%|▍         | 23/510 [03:56<1:23:40, 10.31s/it]\n",
            "Benchmarking MBPP:   5%|▍         | 24/510 [04:06<1:23:15, 10.28s/it]\n",
            "Benchmarking MBPP:   5%|▍         | 25/510 [04:16<1:23:45, 10.36s/it]\n",
            "Benchmarking MBPP:   5%|▌         | 26/510 [04:27<1:23:19, 10.33s/it]\n",
            "Benchmarking MBPP:   5%|▌         | 27/510 [04:37<1:23:10, 10.33s/it]\n",
            "Benchmarking MBPP:   5%|▌         | 28/510 [04:47<1:23:11, 10.36s/it]\n",
            "Benchmarking MBPP:   6%|▌         | 29/510 [04:57<1:22:31, 10.29s/it]\n",
            "Benchmarking MBPP:   6%|▌         | 30/510 [05:08<1:22:16, 10.28s/it]\n",
            "Benchmarking MBPP:   6%|▌         | 31/510 [05:18<1:22:23, 10.32s/it]\n",
            "Benchmarking MBPP:   6%|▋         | 32/510 [05:28<1:22:08, 10.31s/it]\n",
            "Benchmarking MBPP:   6%|▋         | 33/510 [05:39<1:21:57, 10.31s/it]\n",
            "Benchmarking MBPP:   7%|▋         | 34/510 [05:49<1:21:43, 10.30s/it]\n",
            "Benchmarking MBPP:   7%|▋         | 35/510 [05:59<1:20:59, 10.23s/it]\n",
            "Benchmarking MBPP:   7%|▋         | 36/510 [06:09<1:21:18, 10.29s/it]\n",
            "Benchmarking MBPP:   7%|▋         | 37/510 [06:20<1:21:07, 10.29s/it]\n",
            "Benchmarking MBPP:   7%|▋         | 38/510 [06:30<1:21:16, 10.33s/it]\n",
            "Benchmarking MBPP:   8%|▊         | 39/510 [06:41<1:21:21, 10.36s/it]\n",
            "Benchmarking MBPP:   8%|▊         | 40/510 [06:51<1:21:28, 10.40s/it]\n",
            "Benchmarking MBPP:   8%|▊         | 41/510 [07:02<1:21:56, 10.48s/it]\n",
            "Benchmarking MBPP:   8%|▊         | 42/510 [07:13<1:22:29, 10.58s/it]\n",
            "Benchmarking MBPP:   8%|▊         | 43/510 [07:23<1:21:30, 10.47s/it]\n",
            "Benchmarking MBPP:   9%|▊         | 44/510 [07:33<1:21:12, 10.46s/it]\n",
            "Benchmarking MBPP:   9%|▉         | 45/510 [07:44<1:21:34, 10.53s/it]\n",
            "Benchmarking MBPP:   9%|▉         | 46/510 [07:54<1:21:10, 10.50s/it]\n",
            "Benchmarking MBPP:   9%|▉         | 47/510 [08:05<1:20:31, 10.43s/it]\n",
            "Benchmarking MBPP:   9%|▉         | 48/510 [08:16<1:21:46, 10.62s/it]\n",
            "Benchmarking MBPP:  10%|▉         | 49/510 [08:34<1:38:21, 12.80s/it]\n",
            "Benchmarking MBPP:  10%|▉         | 50/510 [08:52<1:51:57, 14.60s/it]\n",
            "Benchmarking MBPP:  10%|█         | 51/510 [09:11<2:01:23, 15.87s/it]\n",
            "Benchmarking MBPP:  10%|█         | 52/510 [09:31<2:09:34, 16.97s/it]\n",
            "Benchmarking MBPP:  10%|█         | 53/510 [09:50<2:15:10, 17.75s/it]\n",
            "Benchmarking MBPP:  11%|█         | 54/510 [10:09<2:17:30, 18.09s/it]\n",
            "Benchmarking MBPP:  11%|█         | 55/510 [10:28<2:18:59, 18.33s/it]\n",
            "Benchmarking MBPP:  11%|█         | 56/510 [10:47<2:19:23, 18.42s/it]\n",
            "Benchmarking MBPP:  11%|█         | 57/510 [11:06<2:20:33, 18.62s/it]\n",
            "Benchmarking MBPP:  11%|█▏        | 58/510 [11:25<2:21:11, 18.74s/it]\n",
            "Benchmarking MBPP:  12%|█▏        | 59/510 [11:43<2:19:14, 18.52s/it]\n",
            "Benchmarking MBPP:  12%|█▏        | 60/510 [12:01<2:19:03, 18.54s/it]\n",
            "Benchmarking MBPP:  12%|█▏        | 61/510 [12:20<2:18:46, 18.54s/it]\n",
            "Benchmarking MBPP:  12%|█▏        | 62/510 [12:38<2:18:16, 18.52s/it]\n",
            "Benchmarking MBPP:  12%|█▏        | 63/510 [12:57<2:18:02, 18.53s/it]\n",
            "Benchmarking MBPP:  13%|█▎        | 64/510 [13:16<2:17:55, 18.55s/it]\n",
            "Benchmarking MBPP:  13%|█▎        | 65/510 [13:34<2:17:50, 18.59s/it]\n",
            "Benchmarking MBPP:  13%|█▎        | 66/510 [13:53<2:17:29, 18.58s/it]\n",
            "Benchmarking MBPP:  13%|█▎        | 67/510 [14:12<2:18:11, 18.72s/it]\n",
            "Benchmarking MBPP:  13%|█▎        | 68/510 [14:31<2:18:18, 18.78s/it]\n",
            "Benchmarking MBPP:  14%|█▎        | 69/510 [14:48<2:14:56, 18.36s/it]\n",
            "Benchmarking MBPP:  14%|█▎        | 70/510 [15:07<2:16:34, 18.62s/it]\n",
            "Benchmarking MBPP:  14%|█▍        | 71/510 [15:26<2:17:10, 18.75s/it]\n",
            "Benchmarking MBPP:  14%|█▍        | 72/510 [15:45<2:17:08, 18.79s/it]\n",
            "Benchmarking MBPP:  14%|█▍        | 73/510 [16:04<2:17:26, 18.87s/it]\n",
            "Benchmarking MBPP:  15%|█▍        | 74/510 [16:23<2:17:08, 18.87s/it]\n",
            "Benchmarking MBPP:  15%|█▍        | 75/510 [16:41<2:15:02, 18.63s/it]\n",
            "Benchmarking MBPP:  15%|█▍        | 76/510 [17:01<2:16:37, 18.89s/it]\n",
            "Benchmarking MBPP:  15%|█▌        | 77/510 [17:20<2:17:22, 19.04s/it]\n",
            "Benchmarking MBPP:  15%|█▌        | 78/510 [17:40<2:18:10, 19.19s/it]\n",
            "Benchmarking MBPP:  15%|█▌        | 79/510 [17:59<2:18:26, 19.27s/it]\n",
            "Benchmarking MBPP:  16%|█▌        | 80/510 [18:18<2:17:29, 19.19s/it]\n",
            "Benchmarking MBPP:  16%|█▌        | 81/510 [18:38<2:18:11, 19.33s/it]\n",
            "Benchmarking MBPP:  16%|█▌        | 82/510 [18:58<2:18:48, 19.46s/it]\n",
            "Benchmarking MBPP:  16%|█▋        | 83/510 [19:17<2:19:08, 19.55s/it]\n",
            "Benchmarking MBPP:  16%|█▋        | 84/510 [19:37<2:18:13, 19.47s/it]\n",
            "Benchmarking MBPP:  17%|█▋        | 85/510 [19:55<2:15:53, 19.18s/it]\n",
            "Benchmarking MBPP:  17%|█▋        | 86/510 [20:14<2:14:01, 18.97s/it]\n",
            "Benchmarking MBPP:  17%|█▋        | 87/510 [20:32<2:13:10, 18.89s/it]\n",
            "Benchmarking MBPP:  17%|█▋        | 88/510 [20:51<2:12:01, 18.77s/it]\n",
            "Benchmarking MBPP:  17%|█▋        | 89/510 [21:10<2:11:49, 18.79s/it]\n",
            "Benchmarking MBPP:  18%|█▊        | 90/510 [21:28<2:10:21, 18.62s/it]\n",
            "Benchmarking MBPP:  18%|█▊        | 91/510 [21:43<2:03:33, 17.69s/it]\n",
            "Benchmarking MBPP:  18%|█▊        | 92/510 [22:03<2:06:16, 18.13s/it]\n",
            "Benchmarking MBPP:  18%|█▊        | 93/510 [22:22<2:08:19, 18.46s/it]\n",
            "Benchmarking MBPP:  18%|█▊        | 94/510 [22:41<2:09:11, 18.63s/it]\n",
            "Benchmarking MBPP:  19%|█▊        | 95/510 [23:00<2:10:33, 18.88s/it]\n",
            "Benchmarking MBPP:  19%|█▉        | 96/510 [23:19<2:10:47, 18.96s/it]\n",
            "Benchmarking MBPP:  19%|█▉        | 97/510 [23:39<2:10:48, 19.00s/it]\n",
            "Benchmarking MBPP:  19%|█▉        | 98/510 [23:58<2:10:36, 19.02s/it]\n",
            "Benchmarking MBPP:  19%|█▉        | 99/510 [24:16<2:09:16, 18.87s/it]\n",
            "Benchmarking MBPP:  20%|█▉        | 100/510 [24:35<2:09:07, 18.90s/it]\n",
            "Benchmarking MBPP:  20%|█▉        | 101/510 [24:54<2:09:01, 18.93s/it]\n",
            "Benchmarking MBPP:  20%|██        | 102/510 [25:13<2:08:32, 18.90s/it]\n",
            "Benchmarking MBPP:  20%|██        | 103/510 [25:32<2:09:01, 19.02s/it]\n",
            "Benchmarking MBPP:  20%|██        | 104/510 [25:51<2:07:19, 18.82s/it]\n",
            "Benchmarking MBPP:  21%|██        | 105/510 [26:09<2:05:33, 18.60s/it]\n",
            "Benchmarking MBPP:  21%|██        | 106/510 [26:28<2:07:06, 18.88s/it]\n",
            "Benchmarking MBPP:  21%|██        | 107/510 [26:47<2:06:15, 18.80s/it]\n",
            "Benchmarking MBPP:  21%|██        | 108/510 [27:06<2:06:34, 18.89s/it]\n",
            "Benchmarking MBPP:  21%|██▏       | 109/510 [27:25<2:06:18, 18.90s/it]\n",
            "Benchmarking MBPP:  22%|██▏       | 110/510 [27:44<2:05:50, 18.88s/it]\n",
            "Benchmarking MBPP:  22%|██▏       | 111/510 [28:02<2:04:14, 18.68s/it]\n",
            "Benchmarking MBPP:  22%|██▏       | 112/510 [28:21<2:04:21, 18.75s/it]\n",
            "Benchmarking MBPP:  22%|██▏       | 113/510 [28:39<2:03:32, 18.67s/it]\n",
            "Benchmarking MBPP:  22%|██▏       | 114/510 [28:58<2:04:14, 18.83s/it]\n",
            "Benchmarking MBPP:  23%|██▎       | 115/510 [29:18<2:05:10, 19.01s/it]\n",
            "Benchmarking MBPP:  23%|██▎       | 116/510 [29:38<2:06:06, 19.20s/it]\n",
            "Benchmarking MBPP:  23%|██▎       | 117/510 [29:57<2:05:52, 19.22s/it]\n",
            "Benchmarking MBPP:  23%|██▎       | 118/510 [30:16<2:05:12, 19.17s/it]\n",
            "Benchmarking MBPP:  23%|██▎       | 119/510 [30:35<2:05:16, 19.22s/it]\n",
            "Benchmarking MBPP:  24%|██▎       | 120/510 [30:55<2:05:14, 19.27s/it]\n",
            "Benchmarking MBPP:  24%|██▎       | 121/510 [31:14<2:04:47, 19.25s/it]\n",
            "Benchmarking MBPP:  24%|██▍       | 122/510 [31:33<2:04:03, 19.19s/it]\n",
            "Benchmarking MBPP:  24%|██▍       | 123/510 [31:51<2:01:32, 18.84s/it]\n",
            "Benchmarking MBPP:  24%|██▍       | 124/510 [32:10<2:01:00, 18.81s/it]\n",
            "Benchmarking MBPP:  25%|██▍       | 125/510 [32:29<2:01:45, 18.98s/it]\n",
            "Benchmarking MBPP:  25%|██▍       | 126/510 [32:48<2:01:43, 19.02s/it]\n",
            "Benchmarking MBPP:  25%|██▍       | 127/510 [33:07<2:00:58, 18.95s/it]\n",
            "Benchmarking MBPP:  25%|██▌       | 128/510 [33:25<1:59:20, 18.75s/it]\n",
            "Benchmarking MBPP:  25%|██▌       | 129/510 [33:44<1:59:28, 18.82s/it]\n",
            "Benchmarking MBPP:  25%|██▌       | 130/510 [34:04<2:00:17, 18.99s/it]\n",
            "Benchmarking MBPP:  26%|██▌       | 131/510 [34:56<3:02:51, 28.95s/it]\n",
            "Benchmarking MBPP:  26%|██▌       | 132/510 [35:27<3:06:13, 29.56s/it]\n",
            "Benchmarking MBPP:  26%|██▌       | 133/510 [36:02<3:16:46, 31.32s/it]\n",
            "Benchmarking MBPP:  26%|██▋       | 134/510 [36:38<3:24:01, 32.56s/it]\n",
            "Benchmarking MBPP:  26%|██▋       | 135/510 [37:10<3:23:30, 32.56s/it]\n",
            "Benchmarking MBPP:  27%|██▋       | 136/510 [37:46<3:29:21, 33.59s/it]\n",
            "Benchmarking MBPP:  27%|██▋       | 137/510 [2:44:43<239:12:05, 2308.65s/it]\n",
            "Benchmarking MBPP:  27%|██▋       | 138/510 [2:45:08<167:45:38, 1623.49s/it]\n",
            "Benchmarking MBPP:  27%|██▋       | 139/510 [2:45:22<117:32:49, 1140.62s/it]\n",
            "Benchmarking MBPP:  27%|██▋       | 140/510 [2:45:34<82:26:03, 802.06s/it]  \n",
            "Benchmarking MBPP:  28%|██▊       | 141/510 [2:45:47<57:57:24, 565.43s/it]\n",
            "Benchmarking MBPP:  28%|██▊       | 142/510 [2:45:59<40:49:13, 399.33s/it]\n",
            "Benchmarking MBPP:  28%|██▊       | 143/510 [2:46:12<28:52:54, 283.31s/it]\n",
            "Benchmarking MBPP:  28%|██▊       | 144/510 [2:46:24<20:32:32, 202.06s/it]\n",
            "Benchmarking MBPP:  28%|██▊       | 145/510 [2:46:36<14:42:31, 145.07s/it]\n",
            "Benchmarking MBPP:  29%|██▊       | 146/510 [2:46:48<10:38:09, 105.19s/it]\n",
            "Benchmarking MBPP:  29%|██▉       | 147/510 [2:47:01<7:48:27, 77.43s/it]  \n",
            "Benchmarking MBPP:  29%|██▉       | 148/510 [2:47:14<5:49:42, 57.96s/it]\n",
            "Benchmarking MBPP:  29%|██▉       | 149/510 [2:47:26<4:27:14, 44.42s/it]\n",
            "Benchmarking MBPP:  29%|██▉       | 150/510 [2:47:39<3:29:30, 34.92s/it]\n",
            "Benchmarking MBPP:  30%|██▉       | 151/510 [2:47:52<2:49:14, 28.29s/it]\n",
            "Benchmarking MBPP:  30%|██▉       | 152/510 [2:48:04<2:20:01, 23.47s/it]\n",
            "Benchmarking MBPP:  30%|███       | 153/510 [2:48:17<2:00:08, 20.19s/it]\n",
            "Benchmarking MBPP:  30%|███       | 154/510 [2:48:30<1:46:35, 17.97s/it]\n",
            "Benchmarking MBPP:  30%|███       | 155/510 [2:48:42<1:36:41, 16.34s/it]\n",
            "Benchmarking MBPP:  31%|███       | 156/510 [2:48:54<1:29:17, 15.13s/it]\n",
            "Benchmarking MBPP:  31%|███       | 157/510 [2:49:07<1:25:11, 14.48s/it]\n",
            "Benchmarking MBPP:  31%|███       | 158/510 [2:49:20<1:22:11, 14.01s/it]\n",
            "Benchmarking MBPP:  31%|███       | 159/510 [2:49:33<1:19:48, 13.64s/it]\n",
            "Benchmarking MBPP:  31%|███▏      | 160/510 [2:49:46<1:18:36, 13.48s/it]\n",
            "Benchmarking MBPP:  32%|███▏      | 161/510 [2:49:58<1:15:58, 13.06s/it]\n",
            "Benchmarking MBPP:  32%|███▏      | 162/510 [2:50:10<1:13:50, 12.73s/it]\n",
            "Benchmarking MBPP:  32%|███▏      | 163/510 [2:50:23<1:13:09, 12.65s/it]\n",
            "Benchmarking MBPP:  32%|███▏      | 164/510 [2:50:35<1:12:28, 12.57s/it]\n",
            "Benchmarking MBPP:  32%|███▏      | 165/510 [2:50:47<1:11:36, 12.45s/it]\n",
            "Benchmarking MBPP:  33%|███▎      | 166/510 [2:51:00<1:12:17, 12.61s/it]\n",
            "Benchmarking MBPP:  33%|███▎      | 167/510 [2:51:13<1:11:43, 12.55s/it]\n",
            "Benchmarking MBPP:  33%|███▎      | 168/510 [2:51:25<1:11:52, 12.61s/it]\n",
            "Benchmarking MBPP:  33%|███▎      | 169/510 [2:51:38<1:11:49, 12.64s/it]\n",
            "Benchmarking MBPP:  33%|███▎      | 170/510 [2:51:51<1:11:58, 12.70s/it]\n",
            "Benchmarking MBPP:  34%|███▎      | 171/510 [2:52:03<1:11:12, 12.60s/it]\n",
            "Benchmarking MBPP:  34%|███▎      | 172/510 [2:52:16<1:10:50, 12.58s/it]\n",
            "Benchmarking MBPP:  34%|███▍      | 173/510 [2:52:29<1:10:59, 12.64s/it]\n",
            "Benchmarking MBPP:  34%|███▍      | 174/510 [2:52:42<1:11:25, 12.76s/it]\n",
            "Benchmarking MBPP:  34%|███▍      | 175/510 [2:52:55<1:11:31, 12.81s/it]\n",
            "Benchmarking MBPP:  35%|███▍      | 176/510 [2:53:07<1:11:06, 12.77s/it]\n",
            "Benchmarking MBPP:  35%|███▍      | 177/510 [2:53:20<1:10:36, 12.72s/it]\n",
            "Benchmarking MBPP:  35%|███▍      | 178/510 [2:53:33<1:10:50, 12.80s/it]\n",
            "Benchmarking MBPP:  35%|███▌      | 179/510 [2:53:45<1:10:02, 12.70s/it]\n",
            "Benchmarking MBPP:  35%|███▌      | 180/510 [2:53:57<1:07:41, 12.31s/it]\n",
            "Benchmarking MBPP:  35%|███▌      | 181/510 [2:54:08<1:06:37, 12.15s/it]\n",
            "Benchmarking MBPP:  36%|███▌      | 182/510 [2:54:21<1:06:41, 12.20s/it]\n",
            "Benchmarking MBPP:  36%|███▌      | 183/510 [2:54:33<1:06:26, 12.19s/it]\n",
            "Benchmarking MBPP:  36%|███▌      | 184/510 [2:54:45<1:06:03, 12.16s/it]\n",
            "Benchmarking MBPP:  36%|███▋      | 185/510 [2:54:57<1:06:16, 12.24s/it]\n",
            "Benchmarking MBPP:  36%|███▋      | 186/510 [2:55:10<1:06:15, 12.27s/it]\n",
            "Benchmarking MBPP:  37%|███▋      | 187/510 [2:55:22<1:06:20, 12.32s/it]\n",
            "Benchmarking MBPP:  37%|███▋      | 188/510 [2:55:35<1:06:43, 12.43s/it]\n",
            "Benchmarking MBPP:  37%|███▋      | 189/510 [2:55:48<1:07:03, 12.53s/it]\n",
            "Benchmarking MBPP:  37%|███▋      | 190/510 [2:56:00<1:06:12, 12.41s/it]\n",
            "Benchmarking MBPP:  37%|███▋      | 191/510 [2:56:11<1:04:48, 12.19s/it]\n",
            "Benchmarking MBPP:  38%|███▊      | 192/510 [2:56:23<1:04:15, 12.12s/it]\n",
            "Benchmarking MBPP:  38%|███▊      | 193/510 [2:56:36<1:04:09, 12.14s/it]\n",
            "Benchmarking MBPP:  38%|███▊      | 194/510 [2:56:48<1:04:35, 12.27s/it]\n",
            "Benchmarking MBPP:  38%|███▊      | 195/510 [2:57:00<1:03:29, 12.10s/it]\n",
            "Benchmarking MBPP:  38%|███▊      | 196/510 [2:57:12<1:02:49, 12.00s/it]\n",
            "Benchmarking MBPP:  39%|███▊      | 197/510 [2:57:24<1:03:39, 12.20s/it]\n",
            "Benchmarking MBPP:  39%|███▉      | 198/510 [2:57:37<1:04:43, 12.45s/it]\n",
            "Benchmarking MBPP:  39%|███▉      | 199/510 [2:57:50<1:04:59, 12.54s/it]\n",
            "Benchmarking MBPP:  39%|███▉      | 200/510 [2:58:02<1:03:42, 12.33s/it]\n",
            "Benchmarking MBPP:  39%|███▉      | 201/510 [2:58:14<1:02:43, 12.18s/it]\n",
            "Benchmarking MBPP:  40%|███▉      | 202/510 [2:58:26<1:02:16, 12.13s/it]\n",
            "Benchmarking MBPP:  40%|███▉      | 203/510 [2:58:38<1:02:17, 12.17s/it]\n",
            "Benchmarking MBPP:  40%|████      | 204/510 [2:58:50<1:02:25, 12.24s/it]\n",
            "Benchmarking MBPP:  40%|████      | 205/510 [2:59:03<1:02:32, 12.30s/it]\n",
            "Benchmarking MBPP:  40%|████      | 206/510 [2:59:16<1:03:14, 12.48s/it]\n",
            "Benchmarking MBPP:  41%|████      | 207/510 [2:59:29<1:03:39, 12.61s/it]\n",
            "Benchmarking MBPP:  41%|████      | 208/510 [2:59:42<1:03:53, 12.69s/it]\n",
            "Benchmarking MBPP:  41%|████      | 209/510 [2:59:54<1:03:38, 12.69s/it]\n",
            "Benchmarking MBPP:  41%|████      | 210/510 [3:00:07<1:03:10, 12.63s/it]\n",
            "Benchmarking MBPP:  41%|████▏     | 211/510 [3:00:20<1:03:08, 12.67s/it]\n",
            "Benchmarking MBPP:  42%|████▏     | 212/510 [3:00:32<1:03:11, 12.72s/it]\n",
            "Benchmarking MBPP:  42%|████▏     | 213/510 [3:00:45<1:03:14, 12.78s/it]\n",
            "Benchmarking MBPP:  42%|████▏     | 214/510 [3:00:58<1:02:55, 12.75s/it]\n",
            "Benchmarking MBPP:  42%|████▏     | 215/510 [3:01:11<1:02:39, 12.74s/it]\n",
            "Benchmarking MBPP:  42%|████▏     | 216/510 [3:01:24<1:03:29, 12.96s/it]\n",
            "Benchmarking MBPP:  43%|████▎     | 217/510 [3:01:37<1:03:06, 12.92s/it]\n",
            "Benchmarking MBPP:  43%|████▎     | 218/510 [3:01:50<1:02:58, 12.94s/it]\n",
            "Benchmarking MBPP:  43%|████▎     | 219/510 [3:02:02<1:01:23, 12.66s/it]\n",
            "Benchmarking MBPP:  43%|████▎     | 220/510 [3:02:14<1:00:26, 12.50s/it]\n",
            "Benchmarking MBPP:  43%|████▎     | 221/510 [3:02:26<59:52, 12.43s/it]  \n",
            "Benchmarking MBPP:  44%|████▎     | 222/510 [3:02:39<59:22, 12.37s/it]\n",
            "Benchmarking MBPP:  44%|████▎     | 223/510 [3:02:51<59:17, 12.40s/it]\n",
            "Benchmarking MBPP:  44%|████▍     | 224/510 [3:03:04<59:23, 12.46s/it]\n",
            "Benchmarking MBPP:  44%|████▍     | 225/510 [3:03:16<59:16, 12.48s/it]\n",
            "Benchmarking MBPP:  44%|████▍     | 226/510 [3:03:29<59:44, 12.62s/it]\n",
            "Benchmarking MBPP:  45%|████▍     | 227/510 [3:03:42<1:00:12, 12.76s/it]\n",
            "Benchmarking MBPP:  45%|████▍     | 228/510 [3:03:55<1:00:07, 12.79s/it]\n",
            "Benchmarking MBPP:  45%|████▍     | 229/510 [3:04:08<59:39, 12.74s/it]  \n",
            "Benchmarking MBPP:  45%|████▌     | 230/510 [3:04:26<1:06:32, 14.26s/it]\n",
            "Benchmarking MBPP:  45%|████▌     | 231/510 [3:04:46<1:14:20, 15.99s/it]\n",
            "Benchmarking MBPP:  45%|████▌     | 232/510 [3:05:06<1:20:22, 17.35s/it]\n",
            "Benchmarking MBPP:  46%|████▌     | 233/510 [3:05:30<1:29:24, 19.37s/it]\n",
            "Benchmarking MBPP:  46%|████▌     | 234/510 [3:05:52<1:32:17, 20.06s/it]\n",
            "Benchmarking MBPP:  46%|████▌     | 235/510 [3:06:14<1:34:13, 20.56s/it]\n",
            "Benchmarking MBPP:  46%|████▋     | 236/510 [3:06:38<1:39:40, 21.83s/it]\n",
            "Benchmarking MBPP:  46%|████▋     | 237/510 [3:07:02<1:41:42, 22.35s/it]\n",
            "Benchmarking MBPP:  47%|████▋     | 238/510 [3:07:19<1:33:53, 20.71s/it]\n",
            "Benchmarking MBPP:  47%|████▋     | 239/510 [3:07:40<1:34:32, 20.93s/it]\n",
            "Benchmarking MBPP:  47%|████▋     | 240/510 [3:08:02<1:35:39, 21.26s/it]\n",
            "Benchmarking MBPP:  47%|████▋     | 241/510 [3:08:25<1:36:40, 21.56s/it]\n",
            "Benchmarking MBPP:  47%|████▋     | 242/510 [3:08:45<1:34:28, 21.15s/it]\n",
            "Benchmarking MBPP:  48%|████▊     | 243/510 [3:09:07<1:35:16, 21.41s/it]\n",
            "Benchmarking MBPP:  48%|████▊     | 244/510 [3:09:29<1:36:28, 21.76s/it]\n",
            "Benchmarking MBPP:  48%|████▊     | 245/510 [3:09:53<1:37:58, 22.18s/it]\n",
            "Benchmarking MBPP:  48%|████▊     | 246/510 [3:10:14<1:36:48, 22.00s/it]\n",
            "Benchmarking MBPP:  48%|████▊     | 247/510 [3:10:38<1:38:57, 22.58s/it]\n",
            "Benchmarking MBPP:  49%|████▊     | 248/510 [3:11:08<1:48:04, 24.75s/it]\n",
            "Benchmarking MBPP:  49%|████▉     | 249/510 [3:11:33<1:48:50, 25.02s/it]\n",
            "Benchmarking MBPP:  49%|████▉     | 250/510 [3:11:57<1:46:32, 24.59s/it]\n",
            "Benchmarking MBPP:  49%|████▉     | 251/510 [3:12:21<1:45:17, 24.39s/it]\n",
            "Benchmarking MBPP:  49%|████▉     | 252/510 [3:12:46<1:45:29, 24.53s/it]\n",
            "Benchmarking MBPP:  50%|████▉     | 253/510 [3:13:13<1:48:32, 25.34s/it]\n",
            "Benchmarking MBPP:  50%|████▉     | 254/510 [3:13:39<1:49:20, 25.63s/it]\n",
            "Benchmarking MBPP:  50%|█████     | 255/510 [3:14:03<1:46:23, 25.03s/it]\n",
            "Benchmarking MBPP:  50%|█████     | 256/510 [3:14:23<1:40:06, 23.65s/it]\n",
            "Benchmarking MBPP:  50%|█████     | 257/510 [3:14:44<1:36:04, 22.79s/it]\n",
            "Benchmarking MBPP:  51%|█████     | 258/510 [3:15:03<1:30:08, 21.46s/it]\n",
            "Benchmarking MBPP:  51%|█████     | 259/510 [3:15:20<1:25:16, 20.39s/it]\n",
            "Benchmarking MBPP:  51%|█████     | 260/510 [3:15:34<1:16:34, 18.38s/it]\n",
            "Benchmarking MBPP:  51%|█████     | 261/510 [3:15:48<1:10:25, 16.97s/it]\n",
            "Benchmarking MBPP:  51%|█████▏    | 262/510 [3:16:02<1:07:04, 16.23s/it]\n",
            "Benchmarking MBPP:  52%|█████▏    | 263/510 [3:16:16<1:03:47, 15.50s/it]\n",
            "Benchmarking MBPP:  52%|█████▏    | 264/510 [3:16:30<1:01:14, 14.94s/it]\n",
            "Benchmarking MBPP:  52%|█████▏    | 265/510 [3:16:44<1:00:06, 14.72s/it]\n",
            "Benchmarking MBPP:  52%|█████▏    | 266/510 [3:16:58<59:35, 14.65s/it]  \n",
            "Benchmarking MBPP:  52%|█████▏    | 267/510 [3:17:10<55:10, 13.62s/it]\n",
            "Benchmarking MBPP:  53%|█████▎    | 268/510 [3:17:21<52:01, 12.90s/it]\n",
            "Benchmarking MBPP:  53%|█████▎    | 269/510 [3:17:32<49:46, 12.39s/it]\n",
            "Benchmarking MBPP:  53%|█████▎    | 270/510 [3:17:43<48:11, 12.05s/it]\n",
            "Benchmarking MBPP:  53%|█████▎    | 271/510 [3:17:55<46:56, 11.78s/it]\n",
            "Benchmarking MBPP:  53%|█████▎    | 272/510 [3:18:06<46:10, 11.64s/it]\n",
            "Benchmarking MBPP:  54%|█████▎    | 273/510 [3:18:17<45:28, 11.51s/it]\n",
            "Benchmarking MBPP:  54%|█████▎    | 274/510 [3:18:28<45:00, 11.44s/it]\n",
            "Benchmarking MBPP:  54%|█████▍    | 275/510 [3:18:41<46:06, 11.77s/it]\n",
            "Benchmarking MBPP:  54%|█████▍    | 276/510 [3:18:53<46:03, 11.81s/it]\n",
            "Benchmarking MBPP:  54%|█████▍    | 277/510 [3:19:05<46:01, 11.85s/it]\n",
            "Benchmarking MBPP:  55%|█████▍    | 278/510 [3:19:17<46:04, 11.91s/it]\n",
            "Benchmarking MBPP:  55%|█████▍    | 279/510 [3:19:29<46:05, 11.97s/it]\n",
            "Benchmarking MBPP:  55%|█████▍    | 280/510 [3:19:41<46:11, 12.05s/it]\n",
            "Benchmarking MBPP:  55%|█████▌    | 281/510 [3:19:53<46:04, 12.07s/it]\n",
            "Benchmarking MBPP:  55%|█████▌    | 282/510 [3:20:05<45:47, 12.05s/it]\n",
            "Benchmarking MBPP:  55%|█████▌    | 283/510 [3:20:17<45:25, 12.01s/it]\n",
            "Benchmarking MBPP:  56%|█████▌    | 284/510 [3:20:29<45:35, 12.11s/it]\n",
            "Benchmarking MBPP:  56%|█████▌    | 285/510 [3:20:41<44:47, 11.94s/it]\n",
            "Benchmarking MBPP:  56%|█████▌    | 286/510 [3:20:52<44:02, 11.79s/it]\n",
            "Benchmarking MBPP:  56%|█████▋    | 287/510 [3:21:04<43:09, 11.61s/it]\n",
            "Benchmarking MBPP:  56%|█████▋    | 288/510 [3:21:15<42:26, 11.47s/it]\n",
            "Benchmarking MBPP:  57%|█████▋    | 289/510 [3:21:26<41:56, 11.39s/it]\n",
            "Benchmarking MBPP:  57%|█████▋    | 290/510 [3:21:40<44:32, 12.15s/it]\n",
            "Benchmarking MBPP:  57%|█████▋    | 291/510 [3:22:01<54:16, 14.87s/it]\n",
            "Benchmarking MBPP:  57%|█████▋    | 292/510 [3:22:22<1:00:02, 16.53s/it]\n",
            "Benchmarking MBPP:  57%|█████▋    | 293/510 [3:22:43<1:04:42, 17.89s/it]\n",
            "Benchmarking MBPP:  58%|█████▊    | 294/510 [3:22:59<1:02:52, 17.47s/it]\n",
            "Benchmarking MBPP:  58%|█████▊    | 295/510 [3:23:12<57:34, 16.07s/it]  \n",
            "Benchmarking MBPP:  58%|█████▊    | 296/510 [3:23:24<53:29, 15.00s/it]\n",
            "Benchmarking MBPP:  58%|█████▊    | 297/510 [3:23:37<51:04, 14.39s/it]\n",
            "Benchmarking MBPP:  58%|█████▊    | 298/510 [3:23:50<48:58, 13.86s/it]\n",
            "Benchmarking MBPP:  59%|█████▊    | 299/510 [3:24:02<46:49, 13.31s/it]\n",
            "Benchmarking MBPP:  59%|█████▉    | 300/510 [3:24:14<45:32, 13.01s/it]\n",
            "Benchmarking MBPP:  59%|█████▉    | 301/510 [3:24:34<52:20, 15.02s/it]\n",
            "Benchmarking MBPP:  59%|█████▉    | 302/510 [3:24:55<57:57, 16.72s/it]\n",
            "Benchmarking MBPP:  59%|█████▉    | 303/510 [3:25:17<1:02:57, 18.25s/it]\n",
            "Benchmarking MBPP:  60%|█████▉    | 304/510 [3:25:38<1:06:13, 19.29s/it]\n",
            "Benchmarking MBPP:  60%|█████▉    | 305/510 [3:25:55<1:03:02, 18.45s/it]\n",
            "Benchmarking MBPP:  60%|██████    | 306/510 [3:26:06<55:23, 16.29s/it]  \n",
            "Benchmarking MBPP:  60%|██████    | 307/510 [3:26:18<50:42, 14.99s/it]\n",
            "Benchmarking MBPP:  60%|██████    | 308/510 [3:26:39<56:29, 16.78s/it]\n",
            "Benchmarking MBPP:  61%|██████    | 309/510 [3:26:55<55:19, 16.51s/it]\n",
            "Benchmarking MBPP:  61%|██████    | 310/510 [3:27:06<50:02, 15.01s/it]\n",
            "Benchmarking MBPP:  61%|██████    | 311/510 [3:27:17<45:02, 13.58s/it]\n",
            "Benchmarking MBPP:  61%|██████    | 312/510 [3:27:27<41:45, 12.66s/it]\n",
            "Benchmarking MBPP:  61%|██████▏   | 313/510 [3:27:45<46:58, 14.31s/it]\n",
            "Benchmarking MBPP:  62%|██████▏   | 314/510 [3:28:04<50:58, 15.61s/it]\n",
            "Benchmarking MBPP:  62%|██████▏   | 315/510 [3:28:22<53:22, 16.42s/it]\n",
            "Benchmarking MBPP:  62%|██████▏   | 316/510 [3:28:41<55:15, 17.09s/it]\n",
            "Benchmarking MBPP:  62%|██████▏   | 317/510 [3:29:00<57:09, 17.77s/it]\n",
            "Benchmarking MBPP:  62%|██████▏   | 318/510 [3:29:19<57:34, 17.99s/it]\n",
            "Benchmarking MBPP:  63%|██████▎   | 319/510 [3:29:37<58:00, 18.22s/it]\n",
            "Benchmarking MBPP:  63%|██████▎   | 320/510 [3:29:53<54:56, 17.35s/it]\n",
            "Benchmarking MBPP:  63%|██████▎   | 321/510 [3:30:03<47:57, 15.23s/it]\n",
            "Benchmarking MBPP:  63%|██████▎   | 322/510 [3:30:13<43:11, 13.78s/it]\n",
            "Benchmarking MBPP:  63%|██████▎   | 323/510 [3:30:24<40:13, 12.91s/it]\n",
            "Benchmarking MBPP:  64%|██████▎   | 324/510 [3:30:35<38:14, 12.34s/it]\n",
            "Benchmarking MBPP:  64%|██████▎   | 325/510 [3:30:47<37:40, 12.22s/it]\n",
            "Benchmarking MBPP:  64%|██████▍   | 326/510 [3:30:59<36:37, 11.94s/it]\n",
            "Benchmarking MBPP:  64%|██████▍   | 327/510 [3:31:10<35:41, 11.70s/it]\n",
            "Benchmarking MBPP:  64%|██████▍   | 328/510 [3:31:21<35:01, 11.55s/it]\n",
            "Benchmarking MBPP:  65%|██████▍   | 329/510 [3:31:32<34:17, 11.37s/it]\n",
            "Benchmarking MBPP:  65%|██████▍   | 330/510 [3:31:43<33:47, 11.26s/it]\n",
            "Benchmarking MBPP:  65%|██████▍   | 331/510 [3:31:54<33:28, 11.22s/it]\n",
            "Benchmarking MBPP:  65%|██████▌   | 332/510 [3:32:06<33:40, 11.35s/it]\n",
            "Benchmarking MBPP:  65%|██████▌   | 333/510 [3:32:16<32:59, 11.19s/it]\n",
            "Benchmarking MBPP:  65%|██████▌   | 334/510 [3:32:27<32:31, 11.09s/it]\n",
            "Benchmarking MBPP:  66%|██████▌   | 335/510 [3:32:38<32:18, 11.08s/it]\n",
            "Benchmarking MBPP:  66%|██████▌   | 336/510 [3:32:49<31:50, 10.98s/it]\n",
            "Benchmarking MBPP:  66%|██████▌   | 337/510 [3:33:00<31:23, 10.89s/it]\n",
            "Benchmarking MBPP:  66%|██████▋   | 338/510 [3:33:11<31:43, 11.06s/it]\n",
            "Benchmarking MBPP:  66%|██████▋   | 339/510 [3:33:22<31:12, 10.95s/it]\n",
            "Benchmarking MBPP:  67%|██████▋   | 340/510 [3:33:32<30:27, 10.75s/it]\n",
            "Benchmarking MBPP:  67%|██████▋   | 341/510 [3:33:43<29:54, 10.62s/it]\n",
            "Benchmarking MBPP:  67%|██████▋   | 342/510 [3:33:58<33:50, 12.09s/it]\n",
            "Benchmarking MBPP:  67%|██████▋   | 343/510 [3:34:17<39:29, 14.19s/it]\n",
            "Benchmarking MBPP:  67%|██████▋   | 344/510 [3:34:35<42:02, 15.20s/it]\n",
            "Benchmarking MBPP:  68%|██████▊   | 345/510 [3:34:54<44:50, 16.31s/it]\n",
            "Benchmarking MBPP:  68%|██████▊   | 346/510 [3:35:12<46:24, 16.98s/it]\n",
            "Benchmarking MBPP:  68%|██████▊   | 347/510 [3:35:31<47:28, 17.47s/it]\n",
            "Benchmarking MBPP:  68%|██████▊   | 348/510 [3:35:47<46:29, 17.22s/it]\n",
            "Benchmarking MBPP:  68%|██████▊   | 349/510 [3:36:05<46:20, 17.27s/it]\n",
            "Benchmarking MBPP:  69%|██████▊   | 350/510 [3:36:23<47:06, 17.67s/it]\n",
            "Benchmarking MBPP:  69%|██████▉   | 351/510 [3:36:42<47:30, 17.93s/it]\n",
            "Benchmarking MBPP:  69%|██████▉   | 352/510 [3:37:01<47:48, 18.15s/it]\n",
            "Benchmarking MBPP:  69%|██████▉   | 353/510 [3:37:19<48:00, 18.35s/it]\n",
            "Benchmarking MBPP:  69%|██████▉   | 354/510 [3:37:37<47:08, 18.13s/it]\n",
            "Benchmarking MBPP:  70%|██████▉   | 355/510 [3:37:56<47:32, 18.40s/it]\n",
            "Benchmarking MBPP:  70%|██████▉   | 356/510 [3:38:13<46:19, 18.05s/it]\n",
            "Benchmarking MBPP:  70%|███████   | 357/510 [3:38:23<39:49, 15.62s/it]\n",
            "Benchmarking MBPP:  70%|███████   | 358/510 [3:38:33<35:10, 13.89s/it]\n",
            "Benchmarking MBPP:  70%|███████   | 359/510 [3:38:43<31:59, 12.71s/it]\n",
            "Benchmarking MBPP:  71%|███████   | 360/510 [3:38:53<30:00, 12.00s/it]\n",
            "Benchmarking MBPP:  71%|███████   | 361/510 [3:39:04<28:37, 11.53s/it]\n",
            "Benchmarking MBPP:  71%|███████   | 362/510 [3:39:14<27:33, 11.17s/it]\n",
            "Benchmarking MBPP:  71%|███████   | 363/510 [3:39:25<26:55, 10.99s/it]\n",
            "Benchmarking MBPP:  71%|███████▏  | 364/510 [3:39:35<26:23, 10.84s/it]\n",
            "Benchmarking MBPP:  72%|███████▏  | 365/510 [3:39:46<26:08, 10.82s/it]\n",
            "Benchmarking MBPP:  72%|███████▏  | 366/510 [3:39:57<25:52, 10.78s/it]\n",
            "Benchmarking MBPP:  72%|███████▏  | 367/510 [3:40:07<25:28, 10.69s/it]\n",
            "Benchmarking MBPP:  72%|███████▏  | 368/510 [3:40:17<24:54, 10.53s/it]\n",
            "Benchmarking MBPP:  72%|███████▏  | 369/510 [3:40:28<24:40, 10.50s/it]\n",
            "Benchmarking MBPP:  73%|███████▎  | 370/510 [3:40:38<24:15, 10.40s/it]\n",
            "Benchmarking MBPP:  73%|███████▎  | 371/510 [3:40:48<24:00, 10.36s/it]\n",
            "Benchmarking MBPP:  73%|███████▎  | 372/510 [3:40:59<23:57, 10.42s/it]\n",
            "Benchmarking MBPP:  73%|███████▎  | 373/510 [3:41:09<23:36, 10.34s/it]\n",
            "Benchmarking MBPP:  73%|███████▎  | 374/510 [3:41:19<23:21, 10.31s/it]\n",
            "Benchmarking MBPP:  74%|███████▎  | 375/510 [3:41:29<23:03, 10.25s/it]\n",
            "Benchmarking MBPP:  74%|███████▎  | 376/510 [3:41:40<23:07, 10.35s/it]\n",
            "Benchmarking MBPP:  74%|███████▍  | 377/510 [3:41:51<23:27, 10.58s/it]\n",
            "Benchmarking MBPP:  74%|███████▍  | 378/510 [3:42:02<23:25, 10.65s/it]\n",
            "Benchmarking MBPP:  74%|███████▍  | 379/510 [3:42:12<23:13, 10.64s/it]\n",
            "Benchmarking MBPP:  75%|███████▍  | 380/510 [3:42:23<23:05, 10.66s/it]\n",
            "Benchmarking MBPP:  75%|███████▍  | 381/510 [3:42:34<22:48, 10.61s/it]\n",
            "Benchmarking MBPP:  75%|███████▍  | 382/510 [3:42:44<22:40, 10.63s/it]\n",
            "Benchmarking MBPP:  75%|███████▌  | 383/510 [3:42:55<22:43, 10.74s/it]\n",
            "Benchmarking MBPP:  75%|███████▌  | 384/510 [3:43:05<21:59, 10.47s/it]\n",
            "Benchmarking MBPP:  75%|███████▌  | 385/510 [3:43:16<21:50, 10.48s/it]\n",
            "Benchmarking MBPP:  76%|███████▌  | 386/510 [3:43:27<22:02, 10.67s/it]\n",
            "Benchmarking MBPP:  76%|███████▌  | 387/510 [3:43:37<21:36, 10.54s/it]\n",
            "Benchmarking MBPP:  76%|███████▌  | 388/510 [3:43:47<21:12, 10.43s/it]\n",
            "Benchmarking MBPP:  76%|███████▋  | 389/510 [3:43:57<20:55, 10.37s/it]\n",
            "Benchmarking MBPP:  76%|███████▋  | 390/510 [3:44:08<20:36, 10.31s/it]\n",
            "Benchmarking MBPP:  77%|███████▋  | 391/510 [3:44:18<20:27, 10.32s/it]\n",
            "Benchmarking MBPP:  77%|███████▋  | 392/510 [3:44:28<20:07, 10.23s/it]\n",
            "Benchmarking MBPP:  77%|███████▋  | 393/510 [3:44:38<20:02, 10.27s/it]\n",
            "Benchmarking MBPP:  77%|███████▋  | 394/510 [3:44:48<19:47, 10.24s/it]\n",
            "Benchmarking MBPP:  77%|███████▋  | 395/510 [3:44:59<19:43, 10.29s/it]\n",
            "Benchmarking MBPP:  78%|███████▊  | 396/510 [3:45:09<19:30, 10.27s/it]\n",
            "Benchmarking MBPP:  78%|███████▊  | 397/510 [3:45:19<19:20, 10.27s/it]\n",
            "Benchmarking MBPP:  78%|███████▊  | 398/510 [3:45:30<19:07, 10.25s/it]\n",
            "Benchmarking MBPP:  78%|███████▊  | 399/510 [3:45:40<18:55, 10.23s/it]\n",
            "Benchmarking MBPP:  78%|███████▊  | 400/510 [3:45:50<18:46, 10.24s/it]\n",
            "Benchmarking MBPP:  79%|███████▊  | 401/510 [3:46:00<18:35, 10.23s/it]\n",
            "Benchmarking MBPP:  79%|███████▉  | 402/510 [3:46:10<18:26, 10.24s/it]\n",
            "Benchmarking MBPP:  79%|███████▉  | 403/510 [3:46:20<18:08, 10.17s/it]\n",
            "Benchmarking MBPP:  79%|███████▉  | 404/510 [3:46:31<17:59, 10.18s/it]\n",
            "Benchmarking MBPP:  79%|███████▉  | 405/510 [3:46:41<17:49, 10.18s/it]\n",
            "Benchmarking MBPP:  80%|███████▉  | 406/510 [3:46:51<17:33, 10.13s/it]\n",
            "Benchmarking MBPP:  80%|███████▉  | 407/510 [3:47:01<17:23, 10.14s/it]\n",
            "Benchmarking MBPP:  80%|████████  | 408/510 [3:47:11<17:20, 10.20s/it]\n",
            "Benchmarking MBPP:  80%|████████  | 409/510 [3:47:22<17:13, 10.23s/it]\n",
            "Benchmarking MBPP:  80%|████████  | 410/510 [3:47:32<17:01, 10.21s/it]\n",
            "Benchmarking MBPP:  81%|████████  | 411/510 [3:47:42<16:51, 10.22s/it]\n",
            "Benchmarking MBPP:  81%|████████  | 412/510 [3:47:52<16:47, 10.28s/it]\n",
            "Benchmarking MBPP:  81%|████████  | 413/510 [3:48:03<16:29, 10.20s/it]\n",
            "Benchmarking MBPP:  81%|████████  | 414/510 [3:48:13<16:22, 10.23s/it]\n",
            "Benchmarking MBPP:  81%|████████▏ | 415/510 [3:48:23<16:16, 10.28s/it]\n",
            "Benchmarking MBPP:  82%|████████▏ | 416/510 [3:48:34<16:13, 10.36s/it]\n",
            "Benchmarking MBPP:  82%|████████▏ | 417/510 [3:48:44<16:02, 10.35s/it]\n",
            "Benchmarking MBPP:  82%|████████▏ | 418/510 [3:48:54<15:53, 10.36s/it]\n",
            "Benchmarking MBPP:  82%|████████▏ | 419/510 [3:49:05<15:36, 10.29s/it]\n",
            "Benchmarking MBPP:  82%|████████▏ | 420/510 [3:49:15<15:27, 10.30s/it]\n",
            "Benchmarking MBPP:  83%|████████▎ | 421/510 [3:49:25<15:12, 10.26s/it]\n",
            "Benchmarking MBPP:  83%|████████▎ | 422/510 [3:49:35<15:01, 10.25s/it]\n",
            "Benchmarking MBPP:  83%|████████▎ | 423/510 [3:49:46<14:52, 10.25s/it]\n",
            "Benchmarking MBPP:  83%|████████▎ | 424/510 [3:49:56<14:42, 10.27s/it]\n",
            "Benchmarking MBPP:  83%|████████▎ | 425/510 [3:50:06<14:31, 10.25s/it]\n",
            "Benchmarking MBPP:  84%|████████▎ | 426/510 [3:50:16<14:24, 10.29s/it]\n",
            "Benchmarking MBPP:  84%|████████▎ | 427/510 [3:50:27<14:10, 10.25s/it]\n",
            "Benchmarking MBPP:  84%|████████▍ | 428/510 [3:50:37<14:03, 10.29s/it]\n",
            "Benchmarking MBPP:  84%|████████▍ | 429/510 [3:50:47<13:53, 10.30s/it]\n",
            "Benchmarking MBPP:  84%|████████▍ | 430/510 [3:50:58<13:53, 10.41s/it]\n",
            "Benchmarking MBPP:  85%|████████▍ | 431/510 [3:51:09<13:48, 10.49s/it]\n",
            "Benchmarking MBPP:  85%|████████▍ | 432/510 [3:51:19<13:44, 10.57s/it]\n",
            "Benchmarking MBPP:  85%|████████▍ | 433/510 [3:51:30<13:27, 10.49s/it]\n",
            "Benchmarking MBPP:  85%|████████▌ | 434/510 [3:51:40<13:17, 10.50s/it]\n",
            "Benchmarking MBPP:  85%|████████▌ | 435/510 [3:51:50<13:00, 10.40s/it]\n",
            "Benchmarking MBPP:  85%|████████▌ | 436/510 [3:52:01<12:44, 10.33s/it]\n",
            "Benchmarking MBPP:  86%|████████▌ | 437/510 [3:52:11<12:42, 10.44s/it]\n",
            "Benchmarking MBPP:  86%|████████▌ | 438/510 [3:52:22<12:32, 10.46s/it]\n",
            "Benchmarking MBPP:  86%|████████▌ | 439/510 [3:52:32<12:20, 10.43s/it]\n",
            "Benchmarking MBPP:  86%|████████▋ | 440/510 [3:52:44<12:31, 10.74s/it]\n",
            "Benchmarking MBPP:  86%|████████▋ | 441/510 [3:52:54<12:16, 10.67s/it]\n",
            "Benchmarking MBPP:  87%|████████▋ | 442/510 [3:53:05<12:05, 10.66s/it]\n",
            "Benchmarking MBPP:  87%|████████▋ | 443/510 [3:53:18<12:55, 11.58s/it]\n",
            "Benchmarking MBPP:  87%|████████▋ | 444/510 [3:53:30<12:39, 11.50s/it]\n",
            "Benchmarking MBPP:  87%|████████▋ | 445/510 [3:53:40<12:04, 11.15s/it]\n",
            "Benchmarking MBPP:  87%|████████▋ | 446/510 [3:53:52<11:58, 11.23s/it]\n",
            "Benchmarking MBPP:  88%|████████▊ | 447/510 [3:54:02<11:38, 11.09s/it]\n",
            "Benchmarking MBPP:  88%|████████▊ | 448/510 [3:54:14<11:35, 11.22s/it]\n",
            "Benchmarking MBPP:  88%|████████▊ | 449/510 [3:54:25<11:24, 11.22s/it]\n",
            "Benchmarking MBPP:  88%|████████▊ | 450/510 [3:54:36<11:11, 11.19s/it]\n",
            "Benchmarking MBPP:  88%|████████▊ | 451/510 [3:54:47<11:02, 11.22s/it]\n",
            "Benchmarking MBPP:  89%|████████▊ | 452/510 [3:54:59<10:54, 11.28s/it]\n",
            "Benchmarking MBPP:  89%|████████▉ | 453/510 [3:55:11<10:53, 11.47s/it]\n",
            "Benchmarking MBPP:  89%|████████▉ | 454/510 [3:55:21<10:22, 11.12s/it]\n",
            "Benchmarking MBPP:  89%|████████▉ | 455/510 [3:55:32<10:00, 10.92s/it]\n",
            "Benchmarking MBPP:  89%|████████▉ | 456/510 [3:55:42<09:41, 10.77s/it]\n",
            "Benchmarking MBPP:  90%|████████▉ | 457/510 [3:55:52<09:18, 10.55s/it]\n",
            "Benchmarking MBPP:  90%|████████▉ | 458/510 [3:56:02<09:00, 10.40s/it]\n",
            "Benchmarking MBPP:  90%|█████████ | 459/510 [3:56:12<08:46, 10.33s/it]\n",
            "Benchmarking MBPP:  90%|█████████ | 460/510 [3:56:23<08:38, 10.37s/it]\n",
            "Benchmarking MBPP:  90%|█████████ | 461/510 [3:56:33<08:29, 10.41s/it]\n",
            "Benchmarking MBPP:  91%|█████████ | 462/510 [3:56:44<08:20, 10.42s/it]\n",
            "Benchmarking MBPP:  91%|█████████ | 463/510 [3:56:54<08:11, 10.46s/it]\n",
            "Benchmarking MBPP:  91%|█████████ | 464/510 [3:57:05<08:03, 10.51s/it]\n",
            "Benchmarking MBPP:  91%|█████████ | 465/510 [3:57:15<07:51, 10.48s/it]\n",
            "Benchmarking MBPP:  91%|█████████▏| 466/510 [3:57:25<07:37, 10.40s/it]\n",
            "Benchmarking MBPP:  92%|█████████▏| 467/510 [3:57:35<07:21, 10.26s/it]\n",
            "Benchmarking MBPP:  92%|█████████▏| 468/510 [3:57:45<07:06, 10.16s/it]\n",
            "Benchmarking MBPP:  92%|█████████▏| 469/510 [3:57:55<06:53, 10.09s/it]\n",
            "Benchmarking MBPP:  92%|█████████▏| 470/510 [3:58:05<06:42, 10.06s/it]\n",
            "Benchmarking MBPP:  92%|█████████▏| 471/510 [3:58:15<06:31, 10.03s/it]\n",
            "Benchmarking MBPP:  93%|█████████▎| 472/510 [3:58:25<06:22, 10.06s/it]\n",
            "Benchmarking MBPP:  93%|█████████▎| 473/510 [3:58:35<06:12, 10.06s/it]\n",
            "Benchmarking MBPP:  93%|█████████▎| 474/510 [3:58:46<06:03, 10.09s/it]\n",
            "Benchmarking MBPP:  93%|█████████▎| 475/510 [3:58:56<05:55, 10.15s/it]\n",
            "Benchmarking MBPP:  93%|█████████▎| 476/510 [3:59:11<06:39, 11.76s/it]\n",
            "Benchmarking MBPP:  94%|█████████▎| 477/510 [3:59:30<07:34, 13.78s/it]\n",
            "Benchmarking MBPP:  94%|█████████▎| 478/510 [3:59:41<06:59, 13.12s/it]\n",
            "Benchmarking MBPP:  94%|█████████▍| 479/510 [3:59:51<06:17, 12.19s/it]\n",
            "Benchmarking MBPP:  94%|█████████▍| 480/510 [4:00:02<05:50, 11.69s/it]\n",
            "Benchmarking MBPP:  94%|█████████▍| 481/510 [4:00:12<05:27, 11.29s/it]\n",
            "Benchmarking MBPP:  95%|█████████▍| 482/510 [4:00:22<05:05, 10.90s/it]\n",
            "Benchmarking MBPP:  95%|█████████▍| 483/510 [4:00:32<04:48, 10.68s/it]\n",
            "Benchmarking MBPP:  95%|█████████▍| 484/510 [4:00:43<04:33, 10.51s/it]\n",
            "Benchmarking MBPP:  95%|█████████▌| 485/510 [4:00:53<04:21, 10.45s/it]\n",
            "Benchmarking MBPP:  95%|█████████▌| 486/510 [4:01:03<04:10, 10.43s/it]\n",
            "Benchmarking MBPP:  95%|█████████▌| 487/510 [4:01:14<04:00, 10.47s/it]\n",
            "Benchmarking MBPP:  96%|█████████▌| 488/510 [4:01:25<03:52, 10.58s/it]\n",
            "Benchmarking MBPP:  96%|█████████▌| 489/510 [4:01:36<03:46, 10.81s/it]\n",
            "Benchmarking MBPP:  96%|█████████▌| 490/510 [4:01:47<03:37, 10.85s/it]\n",
            "Benchmarking MBPP:  96%|█████████▋| 491/510 [4:01:57<03:23, 10.74s/it]\n",
            "Benchmarking MBPP:  96%|█████████▋| 492/510 [4:02:08<03:11, 10.67s/it]\n",
            "Benchmarking MBPP:  97%|█████████▋| 493/510 [4:02:18<02:59, 10.54s/it]\n",
            "Benchmarking MBPP:  97%|█████████▋| 494/510 [4:02:28<02:46, 10.39s/it]\n",
            "Benchmarking MBPP:  97%|█████████▋| 495/510 [4:02:38<02:33, 10.23s/it]\n",
            "Benchmarking MBPP:  97%|█████████▋| 496/510 [4:02:48<02:20, 10.07s/it]\n",
            "Benchmarking MBPP:  97%|█████████▋| 497/510 [4:02:59<02:14, 10.38s/it]\n",
            "Benchmarking MBPP:  98%|█████████▊| 498/510 [4:03:11<02:11, 10.95s/it]\n",
            "Benchmarking MBPP:  98%|█████████▊| 499/510 [4:03:21<01:57, 10.71s/it]\n",
            "Benchmarking MBPP:  98%|█████████▊| 500/510 [4:03:32<01:46, 10.60s/it]\n",
            "Benchmarking MBPP:  98%|█████████▊| 501/510 [4:03:42<01:35, 10.63s/it]\n",
            "Benchmarking MBPP:  98%|█████████▊| 502/510 [4:03:53<01:24, 10.60s/it]\n",
            "Benchmarking MBPP:  99%|█████████▊| 503/510 [4:04:03<01:13, 10.47s/it]\n",
            "Benchmarking MBPP:  99%|█████████▉| 504/510 [4:04:13<01:02, 10.39s/it]\n",
            "Benchmarking MBPP:  99%|█████████▉| 505/510 [4:04:24<00:51, 10.36s/it]\n",
            "Benchmarking MBPP:  99%|█████████▉| 506/510 [4:04:34<00:41, 10.32s/it]\n",
            "Benchmarking MBPP:  99%|█████████▉| 507/510 [4:04:44<00:30, 10.27s/it]\n",
            "Benchmarking MBPP: 100%|█████████▉| 508/510 [4:04:54<00:20, 10.23s/it]\n",
            "Benchmarking MBPP: 100%|█████████▉| 509/510 [4:05:05<00:10, 10.32s/it]\n",
            "Benchmarking MBPP: 100%|██████████| 510/510 [4:05:15<00:00, 10.38s/it]\n",
            "Benchmarking MBPP: 100%|██████████| 510/510 [4:05:15<00:00, 28.85s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for code generation: mbpp\n",
            "Updated generation config: max_steps=512, temperature=0.6\n",
            "Benchmarking on MBPP with 510 samples...\n",
            "Task ID: 0\n",
            "Prompt (truncated): Write a function to find the union of elements of the given tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert union_elements((1, 2, 3, 4),(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,...\n",
            "--------------------------------------------------\n",
            "Task ID: 1\n",
            "Prompt (truncated): Write a function to count the most common words in a dictionary.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert count_common(['apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple', 'apple...\n",
            "--------------------------------------------------\n",
            "Task ID: 2\n",
            "Prompt (truncated): Write a function to sort the tuples alphabetically by the first item of each tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert sort_tuple([(\"aaaa\", 28), (\"aa\", 30), (\"bab\", 29), (\"bb\", 21), (\"csa\", \"C\")]) == [('aa', 30), ('aaaa', 28), ('bab', 29), ('bb', 21), ('csa', 'C')]\n",
            "- assert sort_tuple([(\"Sarala\", 28), (\"Ayesh...\n",
            "--------------------------------------------------\n",
            "Task ID: 3\n",
            "Prompt (truncated): Write a function to find the area of a trapezium.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running as...\n",
            "Generated Code (truncated): - assert area_trapezium(20,25,40)==500\n",
            "- assert area_trapezium(25,30,40)==500\n",
            "- assert area_trapezium(30,40,50)==700\n",
            "- assert area_trapezium(40,50,60)==900\n",
            "- assert area_trapezium(50,60,70)==1100\n",
            "- as...\n",
            "--------------------------------------------------\n",
            "Task ID: 4\n",
            "Prompt (truncated): Write a python function to find nth bell number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ass...\n",
            "Generated Code (truncated): - assert bell_Number(5) == 55\n",
            "- assert bell_Number(6) == 220\n",
            "- assert bell_Number(7) == 462\n",
            "- assert bell_Number(8) == 1336\n",
            "- assert bell_Number(9) == 4626\n",
            "- assert bell_Number(10) == 22055\n",
            "- assert b...\n",
            "--------------------------------------------------\n",
            "Task ID: 5\n",
            "Prompt (truncated): Write a python function to find the average of cubes of first n natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert find_Average_Of_Cube(4) == 16\n",
            "- assert find_Average_Of_Cube(5) == 25\n",
            "- assert find_Average_Of_Cube(6) == 36\n",
            "- assert find_Average_Of_Cube(7) == 49\n",
            "- assert find_Average_Of_Cube(8) == 64\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 6\n",
            "Prompt (truncated): Write a function to extract every first or specified element from a given two-dimensional list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fu...\n",
            "Generated Code (truncated): - assert specified_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]],3)==[6,7,1]\n",
            "- assert specified_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]],-1)==[]\n",
            "- assert specified_element([[1, 2, 3, 2]...\n",
            "--------------------------------------------------\n",
            "Task ID: 7\n",
            "Prompt (truncated): Write a function to caluclate the area of a tetrahedron.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by run...\n",
            "Generated Code (truncated): - assert area_tetrahedron(1)==1\n",
            "- assert area_tetrahedron(0)==0\n",
            "- assert area_tetrahedron(1.5)==1.296296296296296\n",
            "- assert area_tetrahedron(1.25)==1.296296296296296\n",
            "- assert area_tetrahedron(1.1)==1.2...\n",
            "--------------------------------------------------\n",
            "Task ID: 8\n",
            "Prompt (truncated): Write a python function to count the maximum number of equilateral triangles that can be formed within a given equilateral triangle.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {promp...\n",
            "Generated Code (truncated): - assert No_of_Triangle(1,1) == 1\n",
            "- assert No_of_Triangle(1,2) == 1\n",
            "- assert No_of_Triangle(1,4) == -1\n",
            "- assert No_of_Triangle(1,5) == -1\n",
            "- assert No_of_Triangle(1,6) == -1\n",
            "- assert No_of_Triangle(1,7...\n",
            "--------------------------------------------------\n",
            "Task ID: 9\n",
            "Prompt (truncated): Write a python function to left rotate the string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running a...\n",
            "Generated Code (truncated): - assert left_rotate(\"kafka\",1 ) == \"akofka\" \n",
            "- assert left_rotate(\"kafka\",2 ) == \"akofk\" \n",
            "- assert left_rotate(\"kafka\",3 ) == \"akofk\" \n",
            "- assert left_rotate(\"kafka\",4 ) == \"akofk\" \n",
            "- assert left_rotat...\n",
            "--------------------------------------------------\n",
            "Task ID: 10\n",
            "Prompt (truncated): Write a function to split the given string at uppercase letters by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert split_list(\"CreatingAnApiToConnectAllTheThings\") == ['Creating', 'An', 'Api', 'To', 'Connect', 'All', 'The', 'Things']\n",
            "- assert split_list(\"DesigningAnApiToConnectAllTheThings\") == ['Designin...\n",
            "--------------------------------------------------\n",
            "Task ID: 11\n",
            "Prompt (truncated): Write a python function to find minimum sum of factors of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass ...\n",
            "Generated Code (truncated): - assert find_Min_Sum(1) == 1\n",
            "- assert find_Min_Sum(1, 1) == 1\n",
            "- assert find_Min_Sum(1, 2) == 1\n",
            "- assert find_Min_Sum(1, 3) == 1\n",
            "- assert find_Min_Sum(1, 4) == 1\n",
            "- assert find_Min_Sum(1, 5) == 1\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 12\n",
            "Prompt (truncated): Write a function to find the longest common prefix in the given set of strings.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert common_prefix([\"apple\", \"apricot\", \"apricot\"], 3) == 'ap'\n",
            "- assert common_prefix([\"apple\", \"apricot\", \"apricot\"], 4) == ''\n",
            "- assert common_prefix([\"apple\", \"apricot\", \"apricot\"], 5) == ''\n",
            "- a...\n",
            "--------------------------------------------------\n",
            "Task ID: 13\n",
            "Prompt (truncated): Write a python function to find the difference between largest and smallest value in a given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pytho...\n",
            "Generated Code (truncated): - assert big_diff([1,1,1,1]) == 0\n",
            "- assert big_diff([1,1,1,1,1]) == 0\n",
            "- assert big_diff([1,1,1,1,1,1]) == 0\n",
            "- assert big_diff([1,1,1,1,1,1,1]) == 0\n",
            "- assert big_diff([1,1,1,1,1,1,1,1]) == 0\n",
            "- assert b...\n",
            "--------------------------------------------------\n",
            "Task ID: 14\n",
            "Prompt (truncated): Write a function to find the list with maximum length using lambda function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert max_length_list([[1,2,3,4,5],[1,2,3,4],[1,2,3],[1,2],[1]])==(5,[1,2,3,4,5])\n",
            "- assert max_length_list([[1,2,3,4,5],[1,2,3,4],[1,2,3],[1,2],[1]])==(5,[1,2,3,4,5])\n",
            "- assert max_length_list([[1,2...\n",
            "--------------------------------------------------\n",
            "Task ID: 15\n",
            "Prompt (truncated): Write a function of recursion list sum.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running assert state...\n",
            "Generated Code (truncated): - assert recursive_list_sum(([7, 10, [15,14],[19,41]]))==106\n",
            "- assert recursive_list_sum(([7, 10, [15,14],[19,41]]))==106\n",
            "- assert recursive_list_sum(([7, 10, [15,14],[19,41]]))==106\n",
            "- assert recursiv...\n",
            "--------------------------------------------------\n",
            "Task ID: 16\n",
            "Prompt (truncated): Write a function to find numbers divisible by m or n from a list of numbers using lambda function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python...\n",
            "Generated Code (truncated): - assert div_of_nums([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],1,2)==[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "- assert div_of_nums([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],1,3)==[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "- assert div_of_nu...\n",
            "--------------------------------------------------\n",
            "Task ID: 17\n",
            "Prompt (truncated): Write a function to split a string at uppercase letters.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by run...\n",
            "Generated Code (truncated): - assert split_upperstring(\"PythonProgramLanguage\")==['Python','Program','Language']\n",
            "- assert split_upperstring(\"PythonProgramLanguage\")==['Python','Program','Language']\n",
            "- assert split_upperstring(\"Py...\n",
            "--------------------------------------------------\n",
            "Task ID: 18\n",
            "Prompt (truncated): Write a function to find the ascii value of a character.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by run...\n",
            "Generated Code (truncated): - assert ascii_value('T')==84\n",
            "- assert ascii_value('U')==85\n",
            "- assert ascii_value('V')==86\n",
            "- assert ascii_value('W')==87\n",
            "- assert ascii_value('X')==88\n",
            "- assert ascii_value('Y')==89\n",
            "- assert ascii_value...\n",
            "--------------------------------------------------\n",
            "Task ID: 19\n",
            "Prompt (truncated): Write a python function to check if a given number is one less than twice its reverse.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert check(122) == True\n",
            "- assert check(201) == False\n",
            "- assert check(2011) == False\n",
            "- assert check(2017) == False\n",
            "- assert check(2019) == False\n",
            "- assert check(2018) == False\n",
            "- assert check(2016) ==...\n",
            "--------------------------------------------------\n",
            "Task ID: 20\n",
            "Prompt (truncated): Write a python function to get the first element of each sublist.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert Extract([[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,6...\n",
            "--------------------------------------------------\n",
            "Task ID: 21\n",
            "Prompt (truncated): Write a function to sum all amicable numbers from 1 to a specified number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass...\n",
            "Generated Code (truncated): - assert amicable_numbers_sum(1)==1\n",
            "- assert amicable_numbers_sum(99999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999...\n",
            "--------------------------------------------------\n",
            "Task ID: 22\n",
            "Prompt (truncated): Write a python function to count the number of squares in a rectangle.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert count_Squares(1,1) == 1\n",
            "- assert count_Squares(1,1) == 1\n",
            "- assert count_Squares(1,1) == 1\n",
            "- assert count_Squares(1,1) == 1\n",
            "- assert count_Squares(1,1) == 1\n",
            "- assert count_Squares(1,1) == 1\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 23\n",
            "Prompt (truncated): Write a function to extract specified number of elements from a given list, which follow each other continuously.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should retur...\n",
            "Generated Code (truncated): - assert extract_elements([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 24\n",
            "Prompt (truncated): Write a function to find the ration of negative numbers in an array of integers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert negative_count([1, 2, -1, -5, 6, 0, -3, -2, 3, 4, 6, 8])==0.31\n",
            "- assert negative_count([1, 2, -1, -5, 6, 0, -3, -2, 3, 4, 6, 8])==0.31\n",
            "- assert negative_count([1, 2, -1, -5, 6, 0, -3, -2, 3, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 25\n",
            "Prompt (truncated): Write a python function to remove negative numbers from a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert remove_negs([-1,2,3,-4]) == []\n",
            "- assert remove_negs([-1,2,3,4,5,6,7,8,9,10]) == []\n",
            "- assert remove_negs([-1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,3...\n",
            "--------------------------------------------------\n",
            "Task ID: 26\n",
            "Prompt (truncated): Write a function to reverse words in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running...\n",
            "Generated Code (truncated): - assert reverse_words(\"this is a test\")==(\"test is a\")\n",
            "- assert reverse_words(\"this is a test with spaces\")==(\"test with spaces is a\")\n",
            "- assert reverse_words(\"this is a test with spaces with newlines...\n",
            "--------------------------------------------------\n",
            "Task ID: 27\n",
            "Prompt (truncated): Write a python function to find the sum of squares of first n odd natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert square_Sum(5) == 210\n",
            "- assert square_Sum(6) == 504\n",
            "- assert square_Sum(7) == 1331\n",
            "- assert square_Sum(8) == 2966\n",
            "- assert square_Sum(9) == 6556\n",
            "- assert square_Sum(10) == 13360\n",
            "- assert squar...\n",
            "--------------------------------------------------\n",
            "Task ID: 28\n",
            "Prompt (truncated): Write a python function to find the first maximum length of even word.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert find_Max_Len_Even(\"even length\") == \"-1\"\n",
            "- assert find_Max_Len_Even(\"even length python\") == \"-1\"\n",
            "- assert find_Max_Len_Even(\"even length python language\") == \"-1\"\n",
            "- assert find_Max_Len_Even(...\n",
            "--------------------------------------------------\n",
            "Task ID: 29\n",
            "Prompt (truncated): Write a function to perform index wise addition of tuple elements in the given two nested tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python ...\n",
            "Generated Code (truncated): - assert add_nested_tuples(((1, 3), (4, 5), (2, 9), (1, 10)), ((6, 7), (3, 9), (1, 1), (7, 3))) == ((7, 10), (7, 14), (3, 10), (8, 13))\n",
            "- assert add_nested_tuples(((2, 4), (5, 6), (3, 10), (2, 11)), (...\n",
            "--------------------------------------------------\n",
            "Task ID: 30\n",
            "Prompt (truncated): Write a python function to check whether the elements in a list are same or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert chkList(['one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','one','o...\n",
            "--------------------------------------------------\n",
            "Task ID: 31\n",
            "Prompt (truncated): Write a python function to check whether the two numbers differ at one bit position only or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert differ_At_One_Bit_Pos(7,6) == False\n",
            "- assert differ_At_One_Bit_Pos(7,7) == False\n",
            "- assert differ_At_One_Bit_Pos(7,8) == False\n",
            "- assert differ_At_One_Bit_Pos(7,9) == False\n",
            "- assert differ_At_O...\n",
            "--------------------------------------------------\n",
            "Task ID: 32\n",
            "Prompt (truncated): Write a function to calculate the sum of all digits of the base to the specified power.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert power_base_sum(16,15)==81\n",
            "- assert power_base_sum(16,25)==81\n",
            "- assert power_base_sum(16,50)==81\n",
            "- assert power_base_sum(16,100)==81\n",
            "- assert power_base_sum(16,500)==81\n",
            "- assert power_base_sum...\n",
            "--------------------------------------------------\n",
            "Task ID: 33\n",
            "Prompt (truncated): Write a function to count the elements in a list until an element is a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert count_elim([10,20,30,(10,20,40)])==3\n",
            "- assert count_elim([10,20,30,(10,20,40,50)])==3\n",
            "- assert count_elim([10,20,30,(10,20,40,50,60)])==3\n",
            "- assert count_elim([10,20,30,(10,20,40,50,60,70)])==...\n",
            "--------------------------------------------------\n",
            "Task ID: 34\n",
            "Prompt (truncated): Write a python function to toggle bits of the number except the first and the last bit.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert toggle_middle_bits(12) == 11\n",
            "- assert toggle_middle_bits(13) == 15\n",
            "- assert toggle_middle_bits(14) == 15\n",
            "- assert toggle_middle_bits(15) == 15\n",
            "- assert toggle_middle_bits(16) == 16\n",
            "- assert t...\n",
            "--------------------------------------------------\n",
            "Task ID: 35\n",
            "Prompt (truncated): Write a function to rotate a given list by specified number of items to the right direction.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert rotate_right([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],7,7)==[7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 36\n",
            "Prompt (truncated): Write a function to find uppercase, lowercase, special character and numeric values using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert find_character(\"HelloWorld\") == (['H', 'e', 'l', 'l', 'o', 'W', 'o', 'r', 'l', 'd'], ['H', 'e', 'l', 'l', 'o', 'W', 'o', 'r', 'l', 'd'], ['o', 'r', 'l', 'd'], [])\n",
            "- assert find_character(\"Hel...\n",
            "--------------------------------------------------\n",
            "Task ID: 37\n",
            "Prompt (truncated): Write a python function to check whether the frequency of each digit is less than or equal to the digit itself.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return ...\n",
            "Generated Code (truncated): - assert validate(123) == False\n",
            "- assert validate(123456) == False\n",
            "- assert validate(1234567) == False\n",
            "- assert validate(123456789) == False\n",
            "- assert validate(1234567890) == False\n",
            "- assert validate(12...\n",
            "--------------------------------------------------\n",
            "Task ID: 38\n",
            "Prompt (truncated): Write a function to choose specified number of colours from three different colours and generate all the combinations with repetitions.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {pr...\n",
            "Generated Code (truncated): - assert combinations_colors( [\"Red\",\"Green\",\"Blue\"],4)==[('Red', 'Red', 'Red', 'Red'), ('Red', 'Red', 'Red', 'Green'), ('Red', 'Red', 'Red', 'Blue'), ('Red', 'Red', 'Green', 'Green'), ('Red', 'Red', ...\n",
            "--------------------------------------------------\n",
            "Task ID: 39\n",
            "Prompt (truncated): Write a python function to find sum of odd factors of a number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert sum_of_odd_Factors(1) == 1\n",
            "- assert sum_of_odd_Factors(7) == 7\n",
            "- assert sum_of_odd_Factors(15) == 15\n",
            "- assert sum_of_odd_Factors(25) == 25\n",
            "- assert sum_of_odd_Factors(31) == 31\n",
            "- assert sum_o...\n",
            "--------------------------------------------------\n",
            "Task ID: 40\n",
            "Prompt (truncated): Write a function that matches a string that has an 'a' followed by anything, ending in 'b'.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert text_starta_endb(\"aaabbbccddd\")==('Found a match!')\n",
            "- assert text_starta_endb(\"aaabbbccddd\")==('Found a match!')\n",
            "- assert text_starta_endb(\"aaabbbccddd\")==('Found a match!')\n",
            "- assert text_sta...\n",
            "--------------------------------------------------\n",
            "Task ID: 41\n",
            "Prompt (truncated): Write a python function to find the minimum difference between any two elements in a given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python ...\n",
            "Generated Code (truncated): - assert find_Min_Diff((1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 42\n",
            "Prompt (truncated): Write a python function to find the maximum element in a sorted and rotated array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert find_Max([1,2,3],1,2) == 3\n",
            "- assert find_Max([1,2,3],1,3) == 3\n",
            "- assert find_Max([1,2,3],1,1) == 1\n",
            "- assert find_Max([1,2,3],1,2) == 3\n",
            "- assert find_Max([1,2,3],1,3) == 3\n",
            "- assert find_Max([1...\n",
            "--------------------------------------------------\n",
            "Task ID: 43\n",
            "Prompt (truncated): Write a python function to count the number of rectangles in a circle of radius r.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert count_Rectangles(3) == 6\n",
            "- assert count_Rectangles(4) == 12\n",
            "- assert count_Rectangles(5) == 20\n",
            "- assert count_Rectangles(6) == 30\n",
            "- assert count_Rectangles(7) == 42\n",
            "- assert count_Rectangles(...\n",
            "--------------------------------------------------\n",
            "Task ID: 44\n",
            "Prompt (truncated): Write a function to find the minimum product from the pairs of tuples within a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functio...\n",
            "Generated Code (truncated): - assert min_product_tuple([(1, 1), (1, 1), (1, 1), (1, 1)] )==1\n",
            "- assert min_product_tuple([(1, 1), (1, 1), (1, 1), (1, 1)] )==1\n",
            "- assert min_product_tuple([(1, 1), (1, 1), (1, 1), (1, 1)] )==1\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 45\n",
            "Prompt (truncated): Write a function to convert camel case string to snake case string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert camel_to_snake('programmingLanguage')==('programming_language')\n",
            "- assert camel_to_snake('programmingLanguageWithSpaces')==('programming_language_with_spaces')\n",
            "- assert camel_to_snake('program...\n",
            "--------------------------------------------------\n",
            "Task ID: 46\n",
            "Prompt (truncated): Write a python function to convert complex numbers to polar coordinates.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert convert(6) == (6.0,0.0)\n",
            "- assert convert(7) == (7.0,0.0)\n",
            "- assert convert(8) == (8.0,0.0)\n",
            "- assert convert(9) == (9.0,0.0)\n",
            "- assert convert(10) == (10.0,0.0)\n",
            "- assert convert(11) == (11.0,0.0...\n",
            "--------------------------------------------------\n",
            "Task ID: 47\n",
            "Prompt (truncated): Write a python function to find the frequency of a number in a given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert frequency([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 48\n",
            "Prompt (truncated): Write a function to count coin change.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running assert statem...\n",
            "Generated Code (truncated): - assert coin_change([1,2,3],1,1)==1\n",
            "- assert coin_change([1,2,3],1,2)==1\n",
            "- assert coin_change([1,2,3],1,3)==1\n",
            "- assert coin_change([1,2,3],1,4)==1\n",
            "- assert coin_change([1,2,3],1,5)==1\n",
            "- assert coin_c...\n",
            "--------------------------------------------------\n",
            "Task ID: 49\n",
            "Prompt (truncated): Write a function to find the minimum value in a given heterogeneous list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass ...\n",
            "Generated Code (truncated): - assert min_val([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,...\n",
            "--------------------------------------------------\n",
            "Task ID: 50\n",
            "Prompt (truncated): Write a function to convert a list to a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running asser...\n",
            "Generated Code (truncated): - assert list_tuple([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
            "- assert list_tuple([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26...\n",
            "--------------------------------------------------\n",
            "Task ID: 51\n",
            "Prompt (truncated): Write a python function to find sum of product of binomial co-efficients.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass ...\n",
            "Generated Code (truncated): - assert sum_Of_product(2) == 6\n",
            "- assert sum_Of_product(0) == 1\n",
            "- assert sum_Of_product(5) == 120\n",
            "- assert sum_Of_product(6) == 720\n",
            "- assert sum_Of_product(7) == 5040\n",
            "- assert sum_Of_product(8) == 403...\n",
            "--------------------------------------------------\n",
            "Task ID: 52\n",
            "Prompt (truncated): Write a python function to count the number of distinct power of prime factor of given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert count_Fac(6) == 1\n",
            "- assert count_Fac(7) == 1\n",
            "- assert count_Fac(15) == 1\n",
            "- assert count_Fac(25) == 1\n",
            "- assert count_Fac(30) == 1\n",
            "- assert count_Fac(60) == 1\n",
            "- assert count_Fac(84) == 1\n",
            "- asse...\n",
            "--------------------------------------------------\n",
            "Task ID: 53\n",
            "Prompt (truncated): Write a function to print all permutations of a given string including duplicates.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert permute_string('abcd')==['abcd', 'bacd', 'bcad', 'bcda', 'acbd', 'cabd', 'cbad', 'cbda', 'acdb', 'cadb', 'cdab', 'cdba', 'abdc', 'badc', 'bdac', 'bdca', 'adbc', 'dabc', 'dbac', 'dbca', 'adcb'...\n",
            "--------------------------------------------------\n",
            "Task ID: 54\n",
            "Prompt (truncated): Write a function to find the maximum sum of increasing subsequence from prefix till ith index and also including a given kth element which is after i, i.e., k > i .\n",
            "\n",
            "You are an expert Python programme...\n",
            "Generated Code (truncated): - assert max_sum_increasing_subseq([1, 101, 2, 3, 100, 4, 5 ], 7, 6, 7) == 7\n",
            "- assert max_sum_increasing_subseq([1, 101, 2, 3, 100, 4, 5 ], 7, 7, 7) == 7\n",
            "- assert max_sum_increasing_subseq([1, 101, 2,...\n",
            "--------------------------------------------------\n",
            "Task ID: 55\n",
            "Prompt (truncated): Write a function to find the product of it’s kth index in the given tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert find_k_product([(7, 8, 9), (3, 5, 7), (10, 11, 21)], 1) == 210\n",
            "- assert find_k_product([(7, 8, 9), (3, 5, 7), (10, 11, 21)], 2) == 210\n",
            "- assert find_k_product([(7, 8, 9), (3, 5, 7), (10, 11, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 56\n",
            "Prompt (truncated): Write a function to find the occurrences of n most common words in a given text.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert n_common_words(\"python is a programming language\",1)==[('python', 1)]\n",
            "- assert n_common_words(\"python is a programming language\",1)==[('python', 1)]\n",
            "- assert n_common_words(\"python is a progr...\n",
            "--------------------------------------------------\n",
            "Task ID: 57\n",
            "Prompt (truncated): Write a function that matches a string that has an a followed by zero or more b's by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python ...\n",
            "Generated Code (truncated): - assert text_match(\"aaabbbcc\") == 'Found a match!'\n",
            "- assert text_match(\"aaabbbccaaabbbcc\") == 'Found a match!'\n",
            "- assert text_match(\"aaabbbccaaabbbccaaabbbccaaabbbccaaabbbccaaabbbccaaabbbccaaabbbccaaa...\n",
            "--------------------------------------------------\n",
            "Task ID: 58\n",
            "Prompt (truncated): Write a python function to find the smallest missing number from the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert find_First_Missing([1,2,3,6,7,8,9],0,4) == 1\n",
            "- assert find_First_Missing([1,2,3,6,7,8,9],1,4) == 2\n",
            "- assert find_First_Missing([1,2,3,6,7,8,9],2,4) == 3\n",
            "- assert find_First_Missing([1,2,3,6,7...\n",
            "--------------------------------------------------\n",
            "Task ID: 59\n",
            "Prompt (truncated): Write a function to find the volume of a sphere.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ass...\n",
            "Generated Code (truncated): - assert volume_sphere(15)==25281.252252252252\n",
            "- assert volume_sphere(10)==25281.252252252252\n",
            "- assert volume_sphere(25)==65449.84694978735\n",
            "- assert volume_sphere(20)==33510.32163829113\n",
            "- assert volum...\n",
            "--------------------------------------------------\n",
            "Task ID: 60\n",
            "Prompt (truncated): Write a python function to check for even parity of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert check_Even_Parity(19) == False\n",
            "- assert check_Even_Parity(20) == True\n",
            "- assert check_Even_Parity(22) == False\n",
            "- assert check_Even_Parity(23) == False\n",
            "- assert check_Even_Parity(25) == False\n",
            "-...\n",
            "--------------------------------------------------\n",
            "Task ID: 61\n",
            "Prompt (truncated): Write a function to perform the mathematical bitwise xor operation across the given tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert bitwise_xor((13, 7, 9, 12), (8, 4, 6, 7)) == (11, 3, 11, 11)\n",
            "- assert bitwise_xor((14, 8, 10, 13), (9, 5, 7, 8)) == (11, 1, 11, 11)\n",
            "- assert bitwise_xor((15, 10, 12, 15), (11, 6, 7, 7)) == (1...\n",
            "--------------------------------------------------\n",
            "Task ID: 62\n",
            "Prompt (truncated): Write a function to find the nested list elements which are present in another list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and ...\n",
            "Generated Code (truncated): - assert intersection_nested_lists([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],[[12, 18, 23, 25, 45], [7, 11, 19, 24, 28], [1, 5, 8, 18, 15, 16]]],[[12, 18, 23, 25, 45], [7, 11, 19, 24, 28], [1, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 63\n",
            "Prompt (truncated): Write a python function to check whether the sum of divisors are same or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert areEquivalent(1,1) == True\n",
            "- assert areEquivalent(1,1) == False\n",
            "- assert areEquivalent(1,1) == False\n",
            "- assert areEquivalent(1,1) == False\n",
            "- assert areEquivalent(1,1) == False\n",
            "- assert areEqui...\n",
            "--------------------------------------------------\n",
            "Task ID: 64\n",
            "Prompt (truncated): Write a function to find all index positions of the maximum values in a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert position_max([1,1,1,1,1,1,1,1,1,1,1,1])==[1,1,1,1,1,1,1,1,1,1,1,1]\n",
            "- assert position_max([1,1,1,1,1,1,1,1,1,1,1,1])==[1,1,1,1,1,1,1,1,1,1,1,1]\n",
            "- assert position_max([1,1,1,1,1,1,1,1,1,1,1,1])...\n",
            "--------------------------------------------------\n",
            "Task ID: 65\n",
            "Prompt (truncated): Write a python function to find remainder of two numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ru...\n",
            "Generated Code (truncated): - assert find(25,7) == 1\n",
            "- assert find(25,25) == 0\n",
            "- assert find(25,25) == 0\n",
            "- assert find(25,25) == 0\n",
            "- assert find(25,25) == 0\n",
            "- assert find(25,25) == 0\n",
            "- assert find(25,25) == 0\n",
            "- assert find(25,25...\n",
            "--------------------------------------------------\n",
            "Task ID: 66\n",
            "Prompt (truncated): Write a function to remove all tuples with all none values in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert remove_tuple([(None, 2), (None, None), (3, 4), (12, 3), (None, )] ) == '[(None, 2), (3, 4), (12, 3)]'\n",
            "- assert remove_tuple([(None, None), (None, None), (3, 6), (17, 3), (None,1 )] ) == '[(3,...\n",
            "--------------------------------------------------\n",
            "Task ID: 67\n",
            "Prompt (truncated): Write a python function to check whether the given string is a binary string or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and ...\n",
            "Generated Code (truncated): - assert check(\"01010101010\") == \"Yes\"\n",
            "- assert check(\"01010101010\") == \"Yes\"\n",
            "- assert check(\"01010101010\") == \"Yes\"\n",
            "- assert check(\"01010101010\") == \"Yes\"\n",
            "- assert check(\"01010101010\") == \"Yes\"\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 68\n",
            "Prompt (truncated): Write a python function to count the pairs with xor as an even number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert find_even_Pair([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 69\n",
            "Prompt (truncated): Write a function to rotate a given list by specified number of items to the left direction.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert rotate_left([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],7,7)==[8, 9, 10, 1, 2, 3, 4, 5, 6, 7]\n",
            "- assert rotate_left([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],6,7)==[8, 9, 10, 1, 2, 3, 4, 5, 6, 7]\n",
            "- assert rotate_le...\n",
            "--------------------------------------------------\n",
            "Task ID: 70\n",
            "Prompt (truncated): Write a function to find the intersection of two arrays using lambda function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert intersection_array([1, 2, 3, 5, 7, 8, 9, 10],[1, 2, 3, 4, 6, 7, 8, 9, 10])==[]\n",
            "- assert intersection_array([1, 2, 3, 5, 7, 8, 9, 10],[1, 2, 3, 4, 6, 7, 8, 9, 10, 11])==[]\n",
            "- assert intersectio...\n",
            "--------------------------------------------------\n",
            "Task ID: 71\n",
            "Prompt (truncated): Write a function to perform the concatenation of two string tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert concatenate_strings((\"Kapil\", \"Kapoor\", \"Kapoor\"), (\"Kapoor\", \"Kapoor\", \"Kapoor\")) == ('KapilKapilKapil')\n",
            "- assert concatenate_strings((\"Kapil\", \"Kapoor\", \"Kapoor\"), (\"Kapoor\", \"Kapoor\", \"Kap...\n",
            "--------------------------------------------------\n",
            "Task ID: 72\n",
            "Prompt (truncated): Write a function to add two numbers and print number of digits of sum.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert count_digits(1234567,500)==(7)\n",
            "- assert count_digits(1234567,500)==(7)\n",
            "- assert count_digits(1234567,500)==(7)\n",
            "- assert count_digits(1234567,500)==(7)\n",
            "- assert count_digits(1234567,500)==(7)\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 73\n",
            "Prompt (truncated): Write a python function to remove all occurrences of a character in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert remove_Char(\"aaabbbcc\",'b') == \"aaabbbcc\"\n",
            "- assert remove_Char(\"aaabbbcc\",'c') == \"aaabbbcc\"\n",
            "- assert remove_Char(\"aaabbbcc\",'d') == \"aaabbbcc\"\n",
            "- assert remove_Char(\"aaabbbcc\",'e') == \"aaabbb...\n",
            "--------------------------------------------------\n",
            "Task ID: 74\n",
            "Prompt (truncated): Write a function to calculate the discriminant value.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runnin...\n",
            "Generated Code (truncated): - assert discriminant_value(1,1,1)==(\"one solution\",1)\n",
            "- assert discriminant_value(1,1,1)==(\"one solution\",1)\n",
            "- assert discriminant_value(1,1,1)==(\"one solution\",1)\n",
            "- assert discriminant_value(1,1,1)=...\n",
            "--------------------------------------------------\n",
            "Task ID: 75\n",
            "Prompt (truncated): Write a function to sort the given array without using any sorting algorithm. the given array consists of only 0, 1, and 2.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You sh...\n",
            "Generated Code (truncated): - assert sort_by_dnf([1,1,1,1,1,1,1,1,1,1], 10) == [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "- assert sort_by_dnf([1,1,1,1,1,1,1,1,1,1], 10) == [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "- assert sort_by_dnf([1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 76\n",
            "Prompt (truncated): Write a function to find the item with maximum occurrences in a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert max_occurrences([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 77\n",
            "Prompt (truncated): Write a function to check whether the entered number is greater than the elements of the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyt...\n",
            "Generated Code (truncated): - assert check_greater([1, 2, 3, 4, 5], 1) == 'No, entered number is less than those in the array'\n",
            "- assert check_greater([1, 2, 3, 4, 5], 6) == 'No, entered number is less than those in the array'\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 78\n",
            "Prompt (truncated): Write a function to search a literals string in a string and also find the location within the original string where the pattern occurs.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {p...\n",
            "Generated Code (truncated): - assert search_literal('language','python programming language')==(27,31)\n",
            "- assert search_literal('language','python programming language')==(31,36)\n",
            "- assert search_literal('language','python program...\n",
            "--------------------------------------------------\n",
            "Task ID: 79\n",
            "Prompt (truncated): Write a function to find out the number of ways of painting the fence such that at most 2 adjacent posts have the same color for the given fence with n posts and k colors.\n",
            "\n",
            "You are an expert Python pr...\n",
            "Generated Code (truncated): - assert count_no_of_ways(5, 3) == 60\n",
            "- assert count_no_of_ways(6, 3) == 84\n",
            "- assert count_no_of_ways(7, 3) == 84\n",
            "- assert count_no_of_ways(8, 3) == 84\n",
            "- assert count_no_of_ways(9, 3) == 84\n",
            "- assert c...\n",
            "--------------------------------------------------\n",
            "Task ID: 80\n",
            "Prompt (truncated): Write a function to find frequency count of list of lists.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by r...\n",
            "Generated Code (truncated): - assert frequency_lists([[1,2,3,4],[5,6,7,8],[9,10,11,12]])=={1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1,10:1,11:1,12:1}\n",
            "- assert frequency_lists([[20,30,40,17],[18,16,14,13],[10,20,30,40]]...\n",
            "--------------------------------------------------\n",
            "Task ID: 81\n",
            "Prompt (truncated): Write a function to find the largest triangle that can be inscribed in an ellipse.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert largest_triangle(7,6)==7.296296296296296\n",
            "- assert largest_triangle(6,7)==7.296296296296296\n",
            "- assert largest_triangle(7,7)==7.296296296296296\n",
            "- assert largest_triangle(7,7)==7.296296296296296\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 82\n",
            "Prompt (truncated): Write a function to remove all the words with k length in the given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert remove_length('You can not say that you are not', 3) == 'You can not say that you not'\n",
            "- assert remove_length('You can not say that you are not', 3) == 'You can not say that you not'\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 83\n",
            "Prompt (truncated): Write a function to convert snake case string to camel case string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert snake_to_camel('programming_languages')==('ProgrammingLanguages')\n",
            "- assert snake_to_camel('programming_languages_in_python')==('ProgrammingLanguagesInPython')\n",
            "- assert snake_to_camel('program...\n",
            "--------------------------------------------------\n",
            "Task ID: 84\n",
            "Prompt (truncated): Write a python function to find the sum of the three lowest positive numbers from a given list of numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only ...\n",
            "Generated Code (truncated): - assert sum_three_smallest_nums([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 85\n",
            "Prompt (truncated): Write a python function to find the first missing positive number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert first_Missing_Positive([1,2,3,4,5,6,7,8,9,10],10) == 1\n",
            "- assert first_Missing_Positive([1,2,3,4,5,6,7,8,9,10],11) == 1\n",
            "- assert first_Missing_Positive([1,2,3,4,5,6,7,8,9,10],12) == 1\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 86\n",
            "Prompt (truncated): Write a python function to find the sum of all odd natural numbers within the range l and r.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert sum_in_Range(13,25) == 81\n",
            "- assert sum_in_Range(25,50) == 122\n",
            "- assert sum_in_Range(50,100) == 252\n",
            "- assert sum_in_Range(100,200) == 576\n",
            "- assert sum_in_Range(200,500) == 1224\n",
            "- assert sum_in...\n",
            "--------------------------------------------------\n",
            "Task ID: 87\n",
            "Prompt (truncated): Write a python function to find the position of the last removed element from the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert get_Position([1,2,3,4],1,1) == 1\n",
            "- assert get_Position([1,2,3,4],1,3) == 3\n",
            "- assert get_Position([1,2,3,4],1,4) == 4\n",
            "- assert get_Position([1,2,3,4],1,2) == 2\n",
            "- assert get_Position([1,2,3,4],...\n",
            "--------------------------------------------------\n",
            "Task ID: 88\n",
            "Prompt (truncated): Write a python function to check whether the length of the word is even or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert word_len(\"world\") == False\n",
            "- assert word_len(\"worlds\") == False\n",
            "- assert word_len(\"worlds\") == False\n",
            "- assert word_len(\"worlds\") == False\n",
            "- assert word_len(\"worlds\") == False\n",
            "- assert word_le...\n",
            "--------------------------------------------------\n",
            "Task ID: 89\n",
            "Prompt (truncated): Write a python function to convert a decimal number to binary number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test...\n",
            "Generated Code (truncated): - assert decimal_To_Binary(25) == 10101\n",
            "- assert decimal_To_Binary(30) == 10110\n",
            "- assert decimal_To_Binary(31) == 10111\n",
            "- assert decimal_To_Binary(40) == 11000\n",
            "- assert decimal_To_Binary(50) == 11001\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 90\n",
            "Prompt (truncated): Write a function to find the maximum sum of bi-tonic sub-sequence for the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert max_sum([1, 15, 51, 45, 33, 100, 12, 18, 9], 9) == 194\n",
            "- assert max_sum([80, 60, 30, 40, 20, 10], 6) == 210\n",
            "- assert max_sum([2, 3,14, 16, 21, 23, 29, 30], 8) == 138\n",
            "- assert max_sum([1, 15, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 91\n",
            "Prompt (truncated): Write a function to concatenate each element of tuple by the delimiter.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass te...\n",
            "Generated Code (truncated): - assert concatenate_tuple((\"KTM\", \"is\", 4, \"KTM\") ) == 'KTM-is-4-KTM'\n",
            "- assert concatenate_tuple((\"KTM\", \"is\", 4, \"KTM\") ) == 'KTM-is-4-KTM'\n",
            "- assert concatenate_tuple((\"KTM\", \"is\", 4, \"KTM\") ) == 'K...\n",
            "--------------------------------------------------\n",
            "Task ID: 92\n",
            "Prompt (truncated): Write a function to round up a number to specific digits.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ru...\n",
            "Generated Code (truncated): - assert round_up(123.01247,3)==123.012\n",
            "- assert round_up(123.01247,4)==123.0124\n",
            "- assert round_up(123.01247,5)==123.01247\n",
            "- assert round_up(123.01247,6)==123.01247\n",
            "- assert round_up(123.01247,7)==123...\n",
            "--------------------------------------------------\n",
            "Task ID: 93\n",
            "Prompt (truncated): Write a function to find the sum of maximum increasing subsequence of the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert max_sum_increasing_subsequence([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10) == 55\n",
            "- assert max_sum_increasing_subsequence([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 7) == 25\n",
            "- assert max_sum_increasing_subsequ...\n",
            "--------------------------------------------------\n",
            "Task ID: 94\n",
            "Prompt (truncated): Write a function to extract the frequency of unique tuples in the given list order irrespective.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert extract_freq([(1, 2), (1, 2), (1, 2), (1, 2)] ) == 1\n",
            "- assert extract_freq([(1, 2), (1, 2), (1, 2), (1, 2), (1, 2)] ) == 1\n",
            "- assert extract_freq([(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2...\n",
            "--------------------------------------------------\n",
            "Task ID: 95\n",
            "Prompt (truncated): Write a function to create the next bigger number by rearranging the digits of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert rearrange_bigger(201)==202\n",
            "- assert rearrange_bigger(2011)==2012\n",
            "- assert rearrange_bigger(201201)==201202\n",
            "- assert rearrange_bigger(2012011)==2012012\n",
            "- assert rearrange_bigger(201201201)==20...\n",
            "--------------------------------------------------\n",
            "Task ID: 96\n",
            "Prompt (truncated): Write a python function to find the first odd number in a given list of numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert first_odd([1,2,3,4,5,6,7,8,9,10]) == 1\n",
            "- assert first_odd([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,...\n",
            "--------------------------------------------------\n",
            "Task ID: 97\n",
            "Prompt (truncated): Write a function to find the median of two sorted arrays of same size.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert get_median([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 98\n",
            "Prompt (truncated): Write a function to find the item with maximum frequency in a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass ...\n",
            "Generated Code (truncated): - assert max_occurrences([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 99\n",
            "Prompt (truncated): Write a function to find the number of flips required to make the given binary string a sequence of alternate characters.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You shou...\n",
            "Generated Code (truncated): - assert min_flip_to_make_string_alternate(\"1101101101\") == 3\n",
            "- assert min_flip_to_make_string_alternate(\"1101101101\") == 3\n",
            "- assert min_flip_to_make_string_alternate(\"1101101101\") == 3\n",
            "- assert min_f...\n",
            "--------------------------------------------------\n",
            "Task ID: 100\n",
            "Prompt (truncated): Write a function to check whether all items of a list are equal to a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert check_element([\"green\", \"green\", \"green\", \"green\"],'green')==True\n",
            "- assert check_element([\"green\", \"green\", \"green\", \"green\"],'green')==True\n",
            "- assert check_element([\"green\", \"green\", \"green\",...\n",
            "--------------------------------------------------\n",
            "Task ID: 101\n",
            "Prompt (truncated): Write a function to find the depth of a dictionary.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ...\n",
            "Generated Code (truncated): - assert dict_depth({'a':1, 'b': {'c': {'d': {'e': {'f': {'g': {'h': {'i': {'j': {'k': {'l': {'m': {'n': {'o': {'p': {'q': {'r': {'s': {'t': {'u': {'v': {'w': {'x': {'y': {'z': {'a': {'b': {'c': {'d':...\n",
            "--------------------------------------------------\n",
            "Task ID: 102\n",
            "Prompt (truncated): Write a python function to find the first non-repeated character in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert first_non_repeating_character(\"abcabcabc\") == None\n",
            "- assert first_non_repeating_character(\"abcabcabcabc\") == None\n",
            "- assert first_non_repeating_character(\"abcabcabcabcabcabcabcabcabcabcabcabca...\n",
            "--------------------------------------------------\n",
            "Task ID: 103\n",
            "Prompt (truncated): Write a function to find the n - cheap price items from a given dataset using heap queue algorithm.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pytho...\n",
            "Generated Code (truncated): - assert cheap_items([{'name': 'Item-1', 'price': 101.1},{'name': 'Item-2', 'price': 555.22}, {'name': 'Item-3', 'price': 45.09},{'name': 'Item-4', 'price': 22.75}],2)==[{'name': 'Item-1', 'price': 10...\n",
            "--------------------------------------------------\n",
            "Task ID: 104\n",
            "Prompt (truncated): Write a function to find the lcm of the given array elements.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases b...\n",
            "Generated Code (truncated): - assert get_lcm([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,...\n",
            "--------------------------------------------------\n",
            "Task ID: 105\n",
            "Prompt (truncated): Write a function to find the length of the shortest string that has both str1 and str2 as subsequences.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a P...\n",
            "Generated Code (truncated): - assert super_seq(\"kakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakaka...\n",
            "--------------------------------------------------\n",
            "Task ID: 106\n",
            "Prompt (truncated): Write a python function to count the number of digits in factorial of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and...\n",
            "Generated Code (truncated): - assert find_Digits(3) == 1\n",
            "- assert find_Digits(1) == 0\n",
            "- assert find_Digits(0) == 1\n",
            "- assert find_Digits(1) == 1\n",
            "- assert find_Digits(1) == 1\n",
            "- assert find_Digits(1) == 1\n",
            "- assert find_Digits(1) ==...\n",
            "--------------------------------------------------\n",
            "Task ID: 107\n",
            "Prompt (truncated): Write a function for nth catalan number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running assert stat...\n",
            "Generated Code (truncated): - assert catalan_number(6)==403\n",
            "- assert catalan_number(5)==403\n",
            "- assert catalan_number(4)==403\n",
            "- assert catalan_number(3)==403\n",
            "- assert catalan_number(2)==403\n",
            "- assert catalan_number(1)==403\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 108\n",
            "Prompt (truncated): Write a function to count repeated items of a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running...\n",
            "Generated Code (truncated): - assert count_tuplex((2, 4, 7, 7, 7, 3, 4, 4, 7),1)==1\n",
            "- assert count_tuplex((2, 4, 7, 7, 7, 3, 4, 4, 7),0)==0\n",
            "- assert count_tuplex((2, 4, 7, 7, 7, 3, 4, 4, 7),-1)==-1\n",
            "- assert count_tuplex((2, 4, 7...\n",
            "--------------------------------------------------\n",
            "Task ID: 109\n",
            "Prompt (truncated): Write a function to group a sequence of key-value pairs into a dictionary of lists.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert group_keyvalue([('python', 1), ('python', 2), ('python', 3), ('python', 4), ('python', 5)])=={'python': [1,2,3,4,5]}\n",
            "- assert group_keyvalue([('yellow', 1), ('blue', 2), ('yellow', 3), ('blue...\n",
            "--------------------------------------------------\n",
            "Task ID: 110\n",
            "Prompt (truncated): Write a function to count the number of unique lists within a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert unique_sublists([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]...\n",
            "--------------------------------------------------\n",
            "Task ID: 111\n",
            "Prompt (truncated): Write a python function to calculate the sum of the numbers in a list between the indices of a specified range.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return ...\n",
            "Generated Code (truncated): - assert sum_Range_list([1,2,3,4,5],1,6) == 15\n",
            "- assert sum_Range_list([1,2,3,4,5],1,7) == 15\n",
            "- assert sum_Range_list([1,2,3,4,5],1,8) == 15\n",
            "- assert sum_Range_list([1,2,3,4,5],1,9) == 15\n",
            "- assert sum...\n",
            "--------------------------------------------------\n",
            "Task ID: 112\n",
            "Prompt (truncated): Write a function to find the perimeter of a triangle.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runnin...\n",
            "Generated Code (truncated): - assert perimeter_triangle(1,1,1)==0\n",
            "- assert perimeter_triangle(1,1,1)==0\n",
            "- assert perimeter_triangle(1,1,1)==0\n",
            "- assert perimeter_triangle(1,1,1)==0\n",
            "- assert perimeter_triangle(1,1,1)==0\n",
            "- assert p...\n",
            "--------------------------------------------------\n",
            "Task ID: 113\n",
            "Prompt (truncated): Write a python function to find the missing number in a sorted array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test...\n",
            "Generated Code (truncated): - assert find_missing([1,2,3,4,5,6,7,8,9,10],7) == 1\n",
            "- assert find_missing([1,2,3,4,5,6,7,8,9,10],11) == 1\n",
            "- assert find_missing([1,2,3,4,5,6,7,8,9,10],12) == 1\n",
            "- assert find_missing([1,2,3,4,5,6,7,8,...\n",
            "--------------------------------------------------\n",
            "Task ID: 114\n",
            "Prompt (truncated): Write a function to find common elements in given nested lists. * list item * list item * list item * list item\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return ...\n",
            "Generated Code (truncated): - assert common_in_nested_lists([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1...\n",
            "--------------------------------------------------\n",
            "Task ID: 115\n",
            "Prompt (truncated): Write a python function to find smallest power of 2 greater than or equal to n.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert next_Power_Of_2(25) == 64\n",
            "- assert next_Power_Of_2(81) == 128\n",
            "- assert next_Power_Of_2(65536) == 65536\n",
            "- assert next_Power_Of_2(65536) == 65536\n",
            "- assert next_Power_Of_2(65536) == 65536\n",
            "- asse...\n",
            "--------------------------------------------------\n",
            "Task ID: 116\n",
            "Prompt (truncated): Write a function to convert the given decimal number to its binary equivalent.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert decimal_to_binary(15) == '1111'\n",
            "- assert decimal_to_binary(25) == '10000'\n",
            "- assert decimal_to_binary(31) == '10011'\n",
            "- assert decimal_to_binary(63) == '11111'\n",
            "- assert decimal_to_binary(127) =...\n",
            "--------------------------------------------------\n",
            "Task ID: 117\n",
            "Prompt (truncated): Write a python function to find the sum of hamming distances of all consecutive numbers from o to n.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyth...\n",
            "Generated Code (truncated): - assert Total_Hamming_Distance(6) == 7\n",
            "- assert Total_Hamming_Distance(7) == 7\n",
            "- assert Total_Hamming_Distance(8) == 7\n",
            "- assert Total_Hamming_Distance(9) == 7\n",
            "- assert Total_Hamming_Distance(10) == 7...\n",
            "--------------------------------------------------\n",
            "Task ID: 118\n",
            "Prompt (truncated): Write a function to calculate volume of a tetrahedron.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runni...\n",
            "Generated Code (truncated): - assert volume_tetrahedron(25)==2017.81\n",
            "- assert volume_tetrahedron(30)==4037.81\n",
            "- assert volume_tetrahedron(35)==8057.81\n",
            "- assert volume_tetrahedron(40)==13381.81\n",
            "- assert volume_tetrahedron(45)==22...\n",
            "--------------------------------------------------\n",
            "Task ID: 119\n",
            "Prompt (truncated): Write a python function to find the last digit of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert last_Digit(999) == 9\n",
            "- assert last_Digit(999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999...\n",
            "--------------------------------------------------\n",
            "Task ID: 120\n",
            "Prompt (truncated): Write a function to extract year, month and date from a url by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert extract_date(\"https://www.theguardian.com/commentisfree/2017/dec/03/2017-2018-2019-2016-2017-2016-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-2017-201...\n",
            "--------------------------------------------------\n",
            "Task ID: 121\n",
            "Prompt (truncated): Write a python function to count the number of digits of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert count_Digit(11223305) == 8\n",
            "- assert count_Digit(4123459) == 7\n",
            "- assert count_Digit(11223305) == 8\n",
            "- assert count_Digit(4123459) == 7\n",
            "- assert count_Digit(11223305) == 8\n",
            "- assert count_Digit(4...\n",
            "--------------------------------------------------\n",
            "Task ID: 122\n",
            "Prompt (truncated): Write a function to find the cumulative sum of all the values that are present in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a P...\n",
            "Generated Code (truncated): - assert cummulative_sum([(1, 3, 5), (7, 8, 9, 10), (2, 6, 7, 8, 9)]) == 54\n",
            "- assert cummulative_sum([(1, 3, 5, 7), (7, 8, 9, 10, 11), (2, 6, 7, 8, 9, 10)]) == 60\n",
            "- assert cummulative_sum([(1, 3, 5, 7...\n",
            "--------------------------------------------------\n",
            "Task ID: 123\n",
            "Prompt (truncated): Write a python function to determine whether all the numbers are different from each other are not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pytho...\n",
            "Generated Code (truncated): - assert test_distinct([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 124\n",
            "Prompt (truncated): Write a python function to print positive numbers in a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by...\n",
            "Generated Code (truncated): - assert pos_nos([1,2,3,4,5,6,7,8,9,10]) == 1,2,3,4,5,6,7,8,9,10\n",
            "- assert pos_nos([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,...\n",
            "--------------------------------------------------\n",
            "Task ID: 125\n",
            "Prompt (truncated): Write a function to find the surface area of a cylinder.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by run...\n",
            "Generated Code (truncated): - assert surfacearea_cylinder(10,10)==2521.296\n",
            "- assert surfacearea_cylinder(10,20)==2521.296\n",
            "- assert surfacearea_cylinder(20,20)==2521.296\n",
            "- assert surfacearea_cylinder(20,10)==2521.296\n",
            "- assert sur...\n",
            "--------------------------------------------------\n",
            "Task ID: 126\n",
            "Prompt (truncated): Write a function to sort the given tuple list basis the total digits in tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert sort_list([(3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...\n",
            "--------------------------------------------------\n",
            "Task ID: 127\n",
            "Prompt (truncated): Write function to find the sum of all items in the given dictionary.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert return_sum({'a': 25, 'b':18, 'c':45}) == 88\n",
            "- assert return_sum({'a': 25, 'b':18, 'c':45}) == 88\n",
            "- assert return_sum({'a': 25, 'b':18, 'c':45}) == 88\n",
            "- assert return_sum({'a': 25, 'b':18, 'c'...\n",
            "--------------------------------------------------\n",
            "Task ID: 128\n",
            "Prompt (truncated): Write a python function to count the occurence of all elements of list in a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert count_Occurrence(('a', 'a', 'c', 'b', 'd'),['a', 'b'] ) == 3\n",
            "- assert count_Occurrence((1, 2, 3, 1, 4, 6, 7, 1, 4),[1, 4, 7]) == 6\n",
            "- assert count_Occurrence((1,2,3,4,5,6),[1,2]) == 2\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 129\n",
            "Prompt (truncated): Write a function to find a pair with the highest product from a given array of integers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function ...\n",
            "Generated Code (truncated): - assert max_product([1, 2, 3, 4, 7, 0, 8, 4])==(7, 8)\n",
            "- assert max_product([0, -1, -2, -4, 5, 0, -6])==(-4, -6)\n",
            "- assert max_product([1, 3, 5, 6, 8, 9])==(8,9)\n",
            "- assert max_product([1, 2, 3, 4, 7, 0,...\n",
            "--------------------------------------------------\n",
            "Task ID: 130\n",
            "Prompt (truncated): Write a function to find length of the subarray having maximum sum.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert max_sub_array_sum([1, 2, 3, 4, 5],6) == 6\n",
            "- assert max_sub_array_sum([1, 2, 3, 4, 5],7) == 7\n",
            "- assert max_sub_array_sum([1, 2, 3, 4, 5],8) == 8\n",
            "- assert max_sub_array_sum([1, 2, 3, 4, 5],9) =...\n",
            "--------------------------------------------------\n",
            "Task ID: 131\n",
            "Prompt (truncated): Write a function to compute maximum product of three numbers of a given array of integers using heap queue algorithm.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should r...\n",
            "Generated Code (truncated): - assert maximum_product([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,...\n",
            "--------------------------------------------------\n",
            "Task ID: 132\n",
            "Prompt (truncated): Write a function to find the equilibrium index of the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert equilibrium_index([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 133\n",
            "Prompt (truncated): Write a python function to find the maximum difference between any two elements in a given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python ...\n",
            "Generated Code (truncated): - assert max_Abs_Diff((1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 134\n",
            "Prompt (truncated): Write a python function to find k number of operations required to make all elements equal.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert min_Ops([1,1,1,1,1],1,1) == 0\n",
            "- assert min_Ops([1,1,1,1,1],1,1) == 0\n",
            "- assert min_Ops([1,1,1,1,1],1,1) == 0\n",
            "- assert min_Ops([1,1,1,1,1],1,1) == 0\n",
            "- assert min_Ops([1,1,1,1,1],1,1) == 0\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 135\n",
            "Prompt (truncated): Write a function to check for the number of jumps required of given length to reach a point of form (d, 0) from origin in a 2d plane.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prom...\n",
            "Generated Code (truncated): - assert min_Jumps(11,14,0)==1\n",
            "- assert min_Jumps(11,14,11)==1\n",
            "- assert min_Jumps(11,14,0)==1\n",
            "- assert min_Jumps(11,14,11)==1\n",
            "- assert min_Jumps(11,14,0)==1\n",
            "- assert min_Jumps(11,14,11)==1\n",
            "- assert mi...\n",
            "--------------------------------------------------\n",
            "Task ID: 136\n",
            "Prompt (truncated): Write a function to find t-nth term of arithemetic progression.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert tn_ap(1,7,7)==63\n",
            "- assert tn_ap(1,8,8)==256\n",
            "- assert tn_ap(1,9,9)==65536\n",
            "- assert tn_ap(1,10,10)==16777216\n",
            "- assert tn_ap(1,11,11)==4294967296\n",
            "- assert tn_ap(1,12,12)==1073741824\n",
            "- assert tn_...\n",
            "--------------------------------------------------\n",
            "Task ID: 137\n",
            "Prompt (truncated): Write a function to count bidirectional tuple pairs.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running...\n",
            "Generated Code (truncated): - assert count_bidirectional([(5, 6), (1, 2), (6, 5), (9, 1), (6, 5), (2, 1)] ) == '3'\n",
            "- assert count_bidirectional([(5, 6), (1, 2), (6, 5), (9, 1), (6, 5), (2, 1)] ) == '3'\n",
            "- assert count_bidirection...\n",
            "--------------------------------------------------\n",
            "Task ID: 138\n",
            "Prompt (truncated): Write a function to calculate the nth pell number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running a...\n",
            "Generated Code (truncated): - assert get_pell(9) == 836\n",
            "- assert get_pell(10) == 1664\n",
            "- assert get_pell(11) == 3328\n",
            "- assert get_pell(12) == 65536\n",
            "- assert get_pell(13) == 131072\n",
            "- assert get_pell(14) == 262144\n",
            "- assert get_pell...\n",
            "--------------------------------------------------\n",
            "Task ID: 139\n",
            "Prompt (truncated): Write a function to find the surface area of a sphere.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runni...\n",
            "Generated Code (truncated): - assert surfacearea_sphere(25)==8057.252252252252\n",
            "- assert surfacearea_sphere(30)==12254.252252252252\n",
            "- assert surfacearea_sphere(35)==17481.252252252252\n",
            "- assert surfacearea_sphere(40)==23754.252252...\n",
            "--------------------------------------------------\n",
            "Task ID: 140\n",
            "Prompt (truncated): Write a function to interleave lists of the same length.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by run...\n",
            "Generated Code (truncated): - assert interleave_lists([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61...\n",
            "--------------------------------------------------\n",
            "Task ID: 141\n",
            "Prompt (truncated): Write a python function to find the nth digit in the proper fraction of two given numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functio...\n",
            "Generated Code (truncated): - assert find_Nth_Digit(7,7,7) == 7\n",
            "- assert find_Nth_Digit(7,7,7,7) == 7\n",
            "- assert find_Nth_Digit(7,7,7,7,7) == 7\n",
            "- assert find_Nth_Digit(7,7,7,7,7,7) == 7\n",
            "- assert find_Nth_Digit(7,7,7,7,7,7,7) == 7\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 142\n",
            "Prompt (truncated): Write a python function to reverse only the vowels of a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test...\n",
            "Generated Code (truncated): - assert reverse_vowels(\"aa\") == \"aa\"\n",
            "- assert reverse_vowels(\"aaab\") == \"aaab\"\n",
            "- assert reverse_vowels(\"aaabaa\") == \"aaabaa\"\n",
            "- assert reverse_vowels(\"aaabaaab\") == \"aaabaaab\"\n",
            "- assert reverse_vowels(...\n",
            "--------------------------------------------------\n",
            "Task ID: 143\n",
            "Prompt (truncated): Write a python function to toggle all odd bits of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert even_bit_toggle_number(40) == 1\n",
            "- assert even_bit_toggle_number(50) == 15\n",
            "- assert even_bit_toggle_number(60) == 1\n",
            "- assert even_bit_toggle_number(70) == 11\n",
            "- assert even_bit_toggle_number(80...\n",
            "--------------------------------------------------\n",
            "Task ID: 144\n",
            "Prompt (truncated): Write a python function to toggle all even bits of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert even_bit_toggle_number(40) == 20\n",
            "- assert even_bit_toggle_number(50) == 30\n",
            "- assert even_bit_toggle_number(60) == 40\n",
            "- assert even_bit_toggle_number(70) == 50\n",
            "- assert even_bit_toggle_number(...\n",
            "--------------------------------------------------\n",
            "Task ID: 145\n",
            "Prompt (truncated): Write a function to find the index of the first occurrence of a given number in a sorted array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fu...\n",
            "Generated Code (truncated): - assert find_first_occurrence([2, 3, 5, 5, 6, 6, 8, 9, 9, 9], 7) == -1\n",
            "- assert find_first_occurrence([2, 3, 5, 5, 6, 6, 8, 9, 9, 9], 1) == 1\n",
            "- assert find_first_occurrence([2, 3, 5, 5, 6, 6, 8, 9, 9...\n",
            "--------------------------------------------------\n",
            "Task ID: 146\n",
            "Prompt (truncated): Write a function to add the given tuple to the given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by r...\n",
            "Generated Code (truncated): - assert add_tuple([7, 8, 9], (12, 13)) == [7, 8, 9, 12, 13]\n",
            "- assert add_tuple([7, 8, 9], (13, 14)) == [7, 8, 9, 13, 14]\n",
            "- assert add_tuple([7, 8, 9], (14, 15)) == [7, 8, 9, 14, 15]\n",
            "- assert add_tupl...\n",
            "--------------------------------------------------\n",
            "Task ID: 147\n",
            "Prompt (truncated): Write a function to find common first element in given list of tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test...\n",
            "Generated Code (truncated): - assert group_tuples([('a', 'b', 'c'), ('d', 'e', 'f')]) == [('a', 'b', 'c'), ('d', 'e', 'f')]\n",
            "- assert group_tuples([('a', 'b', 'c', 'd'), ('e', 'f', 'g', 'h')]) == [('a', 'b', 'c', 'd'), ('e', 'f',...\n",
            "--------------------------------------------------\n",
            "Task ID: 148\n",
            "Prompt (truncated): Write a python function to check whether the given number can be represented as difference of two squares or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should retur...\n",
            "Generated Code (truncated): - assert dif_Square(20) == False\n",
            "- assert dif_Square(25) == True\n",
            "- assert dif_Square(30) == False\n",
            "- assert dif_Square(35) == True\n",
            "- assert dif_Square(40) == False\n",
            "- assert dif_Square(45) == True\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 149\n",
            "Prompt (truncated): Write a function to sort a list of tuples using lambda.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runn...\n",
            "Generated Code (truncated): - assert subject_marks([('Maths',89),('Science',90),('Social',81)])==([('Maths',89),('Science',90),('Social',81)])\n",
            "- assert subject_marks([('Maths',89),('Science',90),('Social',81)])==([('Maths',89),(...\n",
            "--------------------------------------------------\n",
            "Task ID: 150\n",
            "Prompt (truncated): Write a python function to check whether all the characters in a given string are unique.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function...\n",
            "Generated Code (truncated): - assert unique_Characters('aaab') == False\n",
            "- assert unique_Characters('aaabcc') == False\n",
            "- assert unique_Characters('aaabccaaabcc') == False\n",
            "- assert unique_Characters('aaabccaaabccaaabcc') == False\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 151\n",
            "Prompt (truncated): Write a function to find minimum number of coins that make a given value.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass ...\n",
            "Generated Code (truncated): - assert min_coins([1, 2, 3],1,3)==1\n",
            "- assert min_coins([1, 2, 3],1,1)==1\n",
            "- assert min_coins([1, 2, 3],1,1)==1\n",
            "- assert min_coins([1, 2, 3],1,1)==1\n",
            "- assert min_coins([1, 2, 3],1,1)==1\n",
            "- assert min_co...\n",
            "--------------------------------------------------\n",
            "Task ID: 152\n",
            "Prompt (truncated): Write a python function to accept the strings which contains all vowels.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert check('kakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakaka...\n",
            "--------------------------------------------------\n",
            "Task ID: 153\n",
            "Prompt (truncated): Write a python function to calculate the number of odd days in a given year.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert odd_Days(2017) == 1\n",
            "- assert odd_Days(2016) == 0\n",
            "- assert odd_Days(2018) == 1\n",
            "- assert odd_Days(2019) == 2\n",
            "- assert odd_Days(2020) == 3\n",
            "- assert odd_Days(2021) == 4\n",
            "- assert odd_Days(2022) ==...\n",
            "--------------------------------------------------\n",
            "Task ID: 154\n",
            "Prompt (truncated): Write a function to insert a given string at the beginning of all items in a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert add_string([1,2,3,4],'temp{0}')==['temp1', 'temp2', 'temp3', 'temp4']\n",
            "- assert add_string(['a','b','c','d'], 'python{0}')==[ 'pythona', 'pythonb', 'pythonc', 'pythond']\n",
            "- assert add_string([5...\n",
            "--------------------------------------------------\n",
            "Task ID: 155\n",
            "Prompt (truncated): Write a python function to check whether the last element of given array is even or odd after performing an operation p times.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You...\n",
            "Generated Code (truncated): - assert check_last([1,2,3],1,1) == \"ODD\"\n",
            "- assert check_last([1,2,3],1,2) == \"ODD\"\n",
            "- assert check_last([1,2,3],1,3) == \"ODD\"\n",
            "- assert check_last([1,2,3],2,1) == \"ODD\"\n",
            "- assert check_last([1,2,3],2,2)...\n",
            "--------------------------------------------------\n",
            "Task ID: 156\n",
            "Prompt (truncated): Write a function to find the next smallest palindrome of a specified number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert next_smallest_palindrome(122)==122\n",
            "- assert next_smallest_palindrome(1221)==1331\n",
            "- assert next_smallest_palindrome(12222)==13322\n",
            "- assert next_smallest_palindrome(122222)==133222\n",
            "- assert nex...\n",
            "--------------------------------------------------\n",
            "Task ID: 157\n",
            "Prompt (truncated): Write a function to reflect the modified run-length encoding from a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass ...\n",
            "Generated Code (truncated): - assert modified_encode('test')==['t', 'e','s', 't']\n",
            "- assert modified_encode('test', 1)==['t', 'e','s', 't', 1]\n",
            "- assert modified_encode('test', 1, 1)==['t', 'e','s', 't', 1, 1]\n",
            "- assert modified_en...\n",
            "--------------------------------------------------\n",
            "Task ID: 158\n",
            "Prompt (truncated): Write a function to find n-th rencontres number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ass...\n",
            "Generated Code (truncated): - assert rencontres_number(3, 2) == 6\n",
            "- assert rencontres_number(3, 3) == 12\n",
            "- assert rencontres_number(3, 4) == 24\n",
            "- assert rencontres_number(3, 5) == 48\n",
            "- assert rencontres_number(3, 6) == 96\n",
            "- asse...\n",
            "--------------------------------------------------\n",
            "Task ID: 159\n",
            "Prompt (truncated): Write a function to sort a list of dictionaries using lambda function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert sorted_models([{'make':'Samsung','model':7,'color':'Blue'},{'make':'Mi Max','model':2,'color':'Gold'},{'make':'Nokia','model':216,'color':'Black'}])==([{'make':'Mi Max','model':2,'color':'Gol...\n",
            "--------------------------------------------------\n",
            "Task ID: 160\n",
            "Prompt (truncated): Write a python function to find the maximum occurring character in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert get_max_occuring_char(\"brilliant girl\") == \"i\"\n",
            "- assert get_max_occuring_char(\"brilliant girl\") == \"i\"\n",
            "- assert get_max_occuring_char(\"brilliant girl\") == \"i\"\n",
            "- assert get_max_occuring_char(\"...\n",
            "--------------------------------------------------\n",
            "Task ID: 161\n",
            "Prompt (truncated): Write a python function to count the total set bits from 1 to n.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert count_Set_Bits(7) == 7\n",
            "- assert count_Set_Bits(1) == 1\n",
            "- assert count_Set_Bits(15) == 31\n",
            "- assert count_Set_Bits(11) == 22\n",
            "- assert count_Set_Bits(10) == 20\n",
            "- assert count_Set_Bits(12) == 24\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 162\n",
            "Prompt (truncated): Write a function to check whether the given month number contains 28 days or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert check_monthnum_number(4)==False\n",
            "- assert check_monthnum_number(5)==False\n",
            "- assert check_monthnum_number(6)==False\n",
            "- assert check_monthnum_number(7)==False\n",
            "- assert check_monthnum_number(8)==F...\n",
            "--------------------------------------------------\n",
            "Task ID: 163\n",
            "Prompt (truncated): Write a function to remove consecutive duplicates of a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert consecutive_duplicates([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 164\n",
            "Prompt (truncated): Write a python function to find the type of triangle from the given sides.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass...\n",
            "Generated Code (truncated): - assert check_Type_Of_Triangle(1,1,1) == \"Equilateral Triangle\"\n",
            "- assert check_Type_Of_Triangle(1,1,1) == \"Isosceles Triangle\"\n",
            "- assert check_Type_Of_Triangle(1,1,1) == \"Scalene Triangle\"\n",
            "- assert ch...\n",
            "--------------------------------------------------\n",
            "Task ID: 165\n",
            "Prompt (truncated): Write a python function to set all even bits of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert even_bit_set_number(40) == 40\n",
            "- assert even_bit_set_number(50) == 50\n",
            "- assert even_bit_set_number(60) == 60\n",
            "- assert even_bit_set_number(70) == 70\n",
            "- assert even_bit_set_number(80) == 80\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 166\n",
            "Prompt (truncated): Write a function to find tuples which have all elements divisible by k from the given list of tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyt...\n",
            "Generated Code (truncated): - assert find_tuples([(7, 9, 16), (8, 16, 4), (19, 17, 18)], 7) == '[(7, 9, 16)]'\n",
            "- assert find_tuples([(7, 9, 16), (8, 16, 4), (19, 17, 18)], 19) == '[(7, 9, 16)]'\n",
            "- assert find_tuples([(7, 9, 16), (...\n",
            "--------------------------------------------------\n",
            "Task ID: 167\n",
            "Prompt (truncated): Write a function to return true if the password is valid.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ru...\n",
            "Generated Code (truncated): - assert pass_validity(\"password@10!!\")==False\n",
            "- assert pass_validity(\"password@10!!!!\")==False\n",
            "- assert pass_validity(\"password@10!!!!!!\")==False\n",
            "- assert pass_validity(\"password@10!!!!!!!!\")==False\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 168\n",
            "Prompt (truncated): Write a python function to check whether the word is present in a given sentence or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function ...\n",
            "Generated Code (truncated): - assert is_Word_Present(\"python\",\"code\") == True\n",
            "- assert is_Word_Present(\"python\",\"programming\") == False\n",
            "- assert is_Word_Present(\"python\",\"programming\") == False\n",
            "- assert is_Word_Present(\"python\",...\n",
            "--------------------------------------------------\n",
            "Task ID: 169\n",
            "Prompt (truncated): Write a python function to check whether the two given strings are isomorphic to each other or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pytho...\n",
            "Generated Code (truncated): - assert is_Isomorphic(\"aa\",\"aa\") == True\n",
            "- assert is_Isomorphic(\"aa\",\"ab\") == False\n",
            "- assert is_Isomorphic(\"aa\",\"abc\") == False\n",
            "- assert is_Isomorphic(\"aa\",\"aaa\") == False\n",
            "- assert is_Isomorphic(\"aa\"...\n",
            "--------------------------------------------------\n",
            "Task ID: 170\n",
            "Prompt (truncated): Write a function to check whether the given string starts and ends with the same character or not using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return o...\n",
            "Generated Code (truncated): - assert check_char(\"aa\") == \"Invalid\"\n",
            "- assert check_char(\"aaab\") == \"Invalid\"\n",
            "- assert check_char(\"aaabbb\") == \"Invalid\"\n",
            "- assert check_char(\"aaabbbcc\") == \"Invalid\"\n",
            "- assert check_char(\"aaabbbccddd...\n",
            "--------------------------------------------------\n",
            "Task ID: 171\n",
            "Prompt (truncated): Write a function to find maximum run of uppercase characters in the given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert max_run_uppercase('Kakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakakaka...\n",
            "--------------------------------------------------\n",
            "Task ID: 172\n",
            "Prompt (truncated): Write a function to convert the given snake case string to camel case string by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert snake_to_camel('apple_tv') == 'AppleTv'\n",
            "- assert snake_to_camel('apple_tv_1') == 'AppleTv1'\n",
            "- assert snake_to_camel('apple_tv_2') == 'AppleTv2'\n",
            "- assert snake_to_camel('apple_tv_3') == 'Apple...\n",
            "--------------------------------------------------\n",
            "Task ID: 173\n",
            "Prompt (truncated): Write a function to count the pairs of reverse strings in the given string list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert count_reverse_pairs([\"geeks\", \"best\", \"for\", \"skeeg\", \"for\", \"rof\"]) == '3'\n",
            "- assert count_reverse_pairs([\"geeks\", \"best\", \"for\", \"skeeg\", \"for\", \"rof\", \"for\", \"sekam\"]) == '4'\n",
            "- assert count...\n",
            "--------------------------------------------------\n",
            "Task ID: 174\n",
            "Prompt (truncated): Write a function to convert more than one list to nested dictionary.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert convert_list_dictionary([\"A1\",\"A2\",\"A3\",\"A4\"],[\"java\",\"C\",\"C++\",\"DBMS\"],[10,20,30,40,50])==[{'A1':{'java':10}},{'A2':{'C':20}},{'A3':{'C++':30}},{'A4':{'DBMS':40}},{'A4':{'DBMS':50}}]\n",
            "- asser...\n",
            "--------------------------------------------------\n",
            "Task ID: 175\n",
            "Prompt (truncated): Write a function to generate a two-dimensional array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runnin...\n",
            "Generated Code (truncated): - assert multi_list(15,20)==[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
            "--------------------------------------------------\n",
            "Task ID: 176\n",
            "Prompt (truncated): Write a function to remove the nested record from the given tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert remove_nested((4, 8, 10, (7, 9), 13)) == (4, 8, 10, 13)\n",
            "- assert remove_nested((5, 9, 11, (8, 10), 14)) == (5, 9, 11, 14)\n",
            "- assert remove_nested((6, 10, 12, (9, 11), 15)) == (6, 10, 12, 15)\n",
            "-...\n",
            "--------------------------------------------------\n",
            "Task ID: 177\n",
            "Prompt (truncated): Write a python function to find the sum of common divisors of two given numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert sum(7,7) == 7\n",
            "- assert sum(7,7) == 7\n",
            "- assert sum(7,7) == 7\n",
            "- assert sum(7,7) == 7\n",
            "- assert sum(7,7) == 7\n",
            "- assert sum(7,7) == 7\n",
            "- assert sum(7,7) == 7\n",
            "- assert sum(7,7) == 7\n",
            "- assert sum(7,7...\n",
            "--------------------------------------------------\n",
            "Task ID: 178\n",
            "Prompt (truncated): Write a function to check whether the given string is ending with only alphanumeric characters or not using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should retu...\n",
            "Generated Code (truncated): - assert check_alphanumeric(\"skdmsam326\") == 'Accept'\n",
            "- assert check_alphanumeric(\"cooltricks@\") == 'Discard'\n",
            "- assert check_alphanumeric(\"skdmsam326\") == 'Accept'\n",
            "- assert check_alphanumeric(\"cooltri...\n",
            "--------------------------------------------------\n",
            "Task ID: 179\n",
            "Prompt (truncated): Write a python function to sort a list according to the second element in sublist.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert Sort([['k', 10], ['k', 20], ['k', 30], ['k', 40]]) == [['k', 10], ['k', 20], ['k', 30], ['k', 40]]\n",
            "- assert Sort([['k', 10], ['k', 20], ['k', 30], ['k', 40], ['k', 50]]) == [['k', 10], ['k', ...\n",
            "--------------------------------------------------\n",
            "Task ID: 180\n",
            "Prompt (truncated): Write a function to print check if the triangle is equilateral or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert check_equilateral(6,6,6)==True\n",
            "- assert check_equilateral(6,6,6)==True\n",
            "- assert check_equilateral(6,6,6)==True\n",
            "- assert check_equilateral(6,6,6)==True\n",
            "- assert check_equilateral(6,6,6)==True\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 181\n",
            "Prompt (truncated): Write a python function to move all zeroes to the end of the given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert move_zero([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 182\n",
            "Prompt (truncated): Write a python function to check whether a sequence of numbers has a decreasing trend or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python func...\n",
            "Generated Code (truncated): - assert decreasing_trend([1,1,1]) == False\n",
            "- assert decreasing_trend([1,1,1,1]) == False\n",
            "- assert decreasing_trend([1,1,1,1,1]) == False\n",
            "- assert decreasing_trend([1,1,1,1,1,1]) == False\n",
            "- assert dec...\n",
            "--------------------------------------------------\n",
            "Task ID: 183\n",
            "Prompt (truncated): Write a function to convert a tuple of string values to a tuple of integer values.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert tuple_int_str((('333', '33'), ('333', '33')))==((333, 333), (333, 333))\n",
            "- assert tuple_int_str((('333', '33'), ('333', '33', '333', '333')))==((333, 333), (333, 333, 333, 333))\n",
            "- assert tuple...\n",
            "--------------------------------------------------\n",
            "Task ID: 184\n",
            "Prompt (truncated): Write a python function to find the sum of even numbers at even positions.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass...\n",
            "Generated Code (truncated): - assert sum_even_and_even_index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],7) == 81\n",
            "- assert sum_even_and_even_index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 185\n",
            "Prompt (truncated): Write a python function to count the number of pairs whose sum is equal to ‘sum’.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert get_Pairs_Count([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 186\n",
            "Prompt (truncated): Write a python function to find the index of smallest triangular number with n digits.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert find_Index(5) == 231\n",
            "- assert find_Index(6) == 2310\n",
            "- assert find_Index(7) == 23160\n",
            "- assert find_Index(8) == 231600\n",
            "- assert find_Index(9) == 2316000\n",
            "- assert find_Index(10) == 23160000\n",
            "- as...\n",
            "--------------------------------------------------\n",
            "Task ID: 187\n",
            "Prompt (truncated): Write a function to calculate the geometric sum of n-1.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runn...\n",
            "Generated Code (truncated): - assert geometric_sum(1) == 1\n",
            "- assert geometric_sum(0) == 1\n",
            "- assert geometric_sum(-1) == 1\n",
            "- assert geometric_sum(-2) == 1\n",
            "- assert geometric_sum(-3) == 1\n",
            "- assert geometric_sum(-4) == 1\n",
            "- assert g...\n",
            "--------------------------------------------------\n",
            "Task ID: 188\n",
            "Prompt (truncated): Write a python function to remove the k'th element from a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test...\n",
            "Generated Code (truncated): - assert remove_kth_element([1,1,2,3,4,4,5,1],6)==[1, 1, 3, 4, 4, 5, 1]\n",
            "- assert remove_kth_element([1,1,2,3,4,4,5,1],7)==[1, 1, 3, 4, 4, 5, 1]\n",
            "- assert remove_kth_element([1,1,2,3,4,4,5,1],8)==[1, 1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 189\n",
            "Prompt (truncated): Write a python function to check whether the count of divisors is even or odd.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert count_Divisors(150) == \"Odd\"\n",
            "- assert count_Divisors(200) == \"Even\"\n",
            "- assert count_Divisors(250) == \"Odd\"\n",
            "- assert count_Divisors(300) == \"Even\"\n",
            "- assert count_Divisors(350) == \"Odd\"\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 190\n",
            "Prompt (truncated): Write a function to find the peak element in the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases b...\n",
            "Generated Code (truncated): - assert find_peak([1, 3, 20, 4, 1, 0], 7) == 1\n",
            "- assert find_peak([1, 3, 20, 4, 1, 0], 6) == 2\n",
            "- assert find_peak([1, 3, 20, 4, 1, 0], 7) == 1\n",
            "- assert find_peak([1, 3, 20, 4, 1, 0], 6) == 2\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 191\n",
            "Prompt (truncated): Write a function to find the most common elements and their counts of a specified text.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert most_common_elem('lkseropewdssafsdfafkpwe',1)==[('s', 4), ('e', 3), ('f', 3), ('k', 2), ('p', 2), ('w', 2), ('d', 2), ('s', 1)]\n",
            "- assert most_common_elem('lkseropewdssafsdfafkpwe',0)==[]\n",
            "- as...\n",
            "--------------------------------------------------\n",
            "Task ID: 192\n",
            "Prompt (truncated): Write a function to find the minimum cost path to reach (m, n) from (0, 0) for the given cost matrix cost[][] and a position (m, n) in cost[][].\n",
            "\n",
            "You are an expert Python programmer, and here is your ...\n",
            "Generated Code (truncated): - assert min_cost([[1, 2, 3], [4, 8, 2], [1, 5, 3]], 1, 1) == 1\n",
            "- assert min_cost([[2, 3, 4], [5, 9, 3], [2, 6, 4]], 1, 1) == 9\n",
            "- assert min_cost([[3, 4, 5], [6, 10, 4], [3, 7, 5]], 1, 1) == 15\n",
            "- asse...\n",
            "--------------------------------------------------\n",
            "Task ID: 193\n",
            "Prompt (truncated): Write a function to calculate the harmonic sum of n-1.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runni...\n",
            "Generated Code (truncated): - assert harmonic_sum(1)==1.0000000000000001\n",
            "- assert harmonic_sum(0)==1.0000000000000001\n",
            "- assert harmonic_sum(1)==1.0000000000000001\n",
            "- assert harmonic_sum(1)==1.0000000000000001\n",
            "- assert harmonic_su...\n",
            "--------------------------------------------------\n",
            "Task ID: 194\n",
            "Prompt (truncated): Write a python function to find the hamming distance between given two integers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert hamming_Distance(1,1) == 0\n",
            "- assert hamming_Distance(1,3) == 1\n",
            "- assert hamming_Distance(1,7) == 2\n",
            "- assert hamming_Distance(1,9) == 1\n",
            "- assert hamming_Distance(1,11) == 1\n",
            "- assert hamming_Di...\n",
            "--------------------------------------------------\n",
            "Task ID: 195\n",
            "Prompt (truncated): Write a function to find squares of individual elements in a list using lambda function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function ...\n",
            "Generated Code (truncated): - assert square_nums([1,2,3,4,5,6,7,8,9,10])==([1,4,9,16,25,36,49,64,81,100])\n",
            "- assert square_nums([1,2,3,4,5,6,7,8,9,10])==([1,4,9,16,25,36,49,64,81,100])\n",
            "- assert square_nums([1,2,3,4,5,6,7,8,9,10])...\n",
            "--------------------------------------------------\n",
            "Task ID: 196\n",
            "Prompt (truncated): Write a function to extract a specified column from a given nested list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert extract_column([[1, 3], [5, 7], [1, 3], [13, 15, 17], [5, 7], [9, 11]],1)==[1, 5, 1, 13, 5, 9]\n",
            "- assert extract_column([[1, 3], [5, 7], [1, 3], [13, 15, 17], [5, 7], [9, 11]],2)==[1, 5, 1, 13...\n",
            "--------------------------------------------------\n",
            "Task ID: 197\n",
            "Prompt (truncated): Write a python function to convert the given string to lower case.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert is_lower(\"Hello, World!\") == \"hello, world!\"\n",
            "- assert is_lower(\"Hello, World!\") == \"hello, world!\"\n",
            "- assert is_lower(\"Hello, World!\") == \"hello, world!\"\n",
            "- assert is_lower(\"Hello, World!\") == ...\n",
            "--------------------------------------------------\n",
            "Task ID: 198\n",
            "Prompt (truncated): Write a function to convert camel case string to snake case string by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert camel_to_snake('Windows10') == 'windows_10'\n",
            "- assert camel_to_snake('Windows11') == 'windows_11'\n",
            "- assert camel_to_snake('Windows11Pro') == 'windows_11_pro'\n",
            "- assert camel_to_snake('Windows11...\n",
            "--------------------------------------------------\n",
            "Task ID: 199\n",
            "Prompt (truncated): Write a function to zip the two given tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running assert...\n",
            "Generated Code (truncated): - assert zip_tuples((7, 8, 4, 5, 9, 10),(1, 5, 6) ) == [(7, 1), (8, 5), (4, 6), (5, 1), (9, 5), (10, 6)]\n",
            "- assert zip_tuples((8, 9, 5, 6, 10, 11),(2, 6, 7) ) == [(8, 2), (9, 6), (5, 7), (6, 2), (10, 6...\n",
            "--------------------------------------------------\n",
            "Task ID: 200\n",
            "Prompt (truncated): Write a python function to calculate the product of the unique numbers of a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert unique_product([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 201\n",
            "Prompt (truncated): Write a function to extract maximum and minimum k elements in the given tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert extract_min_max((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,...\n",
            "--------------------------------------------------\n",
            "Task ID: 202\n",
            "Prompt (truncated): Write a function to add the k elements to each element in the tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert add_K_element([(1, 2, 3), (4, 5, 6), (7, 8, 9)], 7) == [(7, 8, 9), (10, 11, 12), (13, 14, 15)]\n",
            "- assert add_K_element([(1, 2, 3), (4, 5, 6), (7, 8, 9)], 6) == [(7, 8, 9), (10, 11, 12), (13, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 203\n",
            "Prompt (truncated): Write a function to count unique keys for each value present in the tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass...\n",
            "Generated Code (truncated): - assert get_unique([(7, 7), (7, 7), (7, 7), (7, 7), (7, 7), (7, 7), (7, 7), (7, 7), (7, 7)] ) == '{7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7, 7: 7...\n",
            "--------------------------------------------------\n",
            "Task ID: 204\n",
            "Prompt (truncated): Write a function to find the minimum number of platforms required for a railway/bus station.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert find_platform([1,2,3,4],[1,2,3,4],1)==1\n",
            "- assert find_platform([1,2,3,4],[1,2,3,4],1)==1\n",
            "- assert find_platform([1,2,3,4],[1,2,3,4],1)==1\n",
            "- assert find_platform([1,2,3,4],[1,2,3,4],1)==1\n",
            "- as...\n",
            "--------------------------------------------------\n",
            "Task ID: 205\n",
            "Prompt (truncated): Write a function to substract the elements of the given nested tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert substract_elements(((19, 7), (18, 7), (19, 11), (17, 12)), ((12, 9), (17, 11), (13, 3), (19, 5))) == ((7, -4), (1, -4), (6, 8), (-2, 7))\n",
            "- assert substract_elements(((19, 7), (18, 7), (19, 11...\n",
            "--------------------------------------------------\n",
            "Task ID: 206\n",
            "Prompt (truncated): Write a function to find the longest bitonic subsequence for the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert lbs([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 207\n",
            "Prompt (truncated): Write a function to trim each tuple by k in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert trim_tuple([(7, 8, 4, 9), (11, 8, 12, 4), (4, 1, 7, 8), (3, 6, 9, 7)], 2) == '[(7, 8, 4, 9), (11, 8, 12, 4)]'\n",
            "- assert trim_tuple([(7, 8, 4, 9), (11, 8, 12, 4), (4, 1, 7, 8), (3, 6, 9, 7)], 3...\n",
            "--------------------------------------------------\n",
            "Task ID: 208\n",
            "Prompt (truncated): Write a function to calculate the area of a regular polygon.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by...\n",
            "Generated Code (truncated): - assert area_polygon(7,7)==49.999999999999999\n",
            "- assert area_polygon(7,7)==49.999999999999999\n",
            "- assert area_polygon(7,7)==49.999999999999999\n",
            "- assert area_polygon(7,7)==49.999999999999999\n",
            "- assert are...\n",
            "--------------------------------------------------\n",
            "Task ID: 209\n",
            "Prompt (truncated): Write a function to find nth centered hexagonal number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runn...\n",
            "Generated Code (truncated): - assert centered_hexagonal_number(11) == 252\n",
            "- assert centered_hexagonal_number(12) == 277\n",
            "- assert centered_hexagonal_number(13) == 296\n",
            "- assert centered_hexagonal_number(14) == 317\n",
            "- assert centere...\n",
            "--------------------------------------------------\n",
            "Task ID: 210\n",
            "Prompt (truncated): Write a function to convert tuple to a string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running asser...\n",
            "Generated Code (truncated): - assert tup_string(('e','x','e','r','c','i','s','e','s'))==(\"exercises\")\n",
            "- assert tup_string(('p','y','t','h','o','n','e','s'))==(\"python\")\n",
            "- assert tup_string(('p','r','o','g','r','a','m','e','s'))=...\n",
            "--------------------------------------------------\n",
            "Task ID: 211\n",
            "Prompt (truncated): Write a function to find all adverbs and their positions in a given sentence.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert find_adverb_position(\"incredible!! the earth is round\")==(0, 19, 'incredible')\n",
            "- assert find_adverb_position(\"incredible!! the earth is round\")==(0, 19, 'incredible')\n",
            "- assert find_adverb_pos...\n",
            "--------------------------------------------------\n",
            "Task ID: 212\n",
            "Prompt (truncated): Write a python function to remove the characters which have odd index values of a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fu...\n",
            "Generated Code (truncated): - assert odd_values_string('abc') == ''\n",
            "- assert odd_values_string('defg') == ''\n",
            "- assert odd_values_string('hijkl') == ''\n",
            "- assert odd_values_string('mnopqr') == ''\n",
            "- assert odd_values_string('stuvwx...\n",
            "--------------------------------------------------\n",
            "Task ID: 213\n",
            "Prompt (truncated): Write a function to find the volume of a cylinder.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running a...\n",
            "Generated Code (truncated): - assert volume_cylinder(10,10)==2520.00000000000003\n",
            "- assert volume_cylinder(10,20)==2520.00000000000003\n",
            "- assert volume_cylinder(20,20)==2520.00000000000003\n",
            "- assert volume_cylinder(20,10)==2520.000...\n",
            "--------------------------------------------------\n",
            "Task ID: 214\n",
            "Prompt (truncated): Write a function to split the given string with multiple delimiters by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert multiple_split('I am using the\\nWindows OS with the latest updates.') == ['I am using the', 'Windows OS with the latest updates.']\n",
            "- assert multiple_split('I am using the\\nWindows OS with the...\n",
            "--------------------------------------------------\n",
            "Task ID: 215\n",
            "Prompt (truncated): Write a python function to find smallest number in a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by r...\n",
            "Generated Code (truncated): - assert smallest_num([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) == 1\n",
            "- assert smallest_num([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]) == 1\n",
            "- assert smallest_num([1, 2, 3, 4, 5, 6,...\n",
            "--------------------------------------------------\n",
            "Task ID: 216\n",
            "Prompt (truncated): Write a function to verify validity of a string of parentheses.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert is_valid_parenthese(\"()[]\")==True\n",
            "- assert is_valid_parenthese(\"()[]{}\")==False\n",
            "- assert is_valid_parenthese(\"()[]{}[]\")==False\n",
            "- assert is_valid_parenthese(\"()[]{}[][]\")==False\n",
            "- assert is_v...\n",
            "--------------------------------------------------\n",
            "Task ID: 217\n",
            "Prompt (truncated): Write a python function to check whether the given number is odd or not using bitwise operator.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fu...\n",
            "Generated Code (truncated): - assert is_odd(8) == False\n",
            "- assert is_odd(9) == True\n",
            "- assert is_odd(10) == False\n",
            "- assert is_odd(11) == True\n",
            "- assert is_odd(12) == False\n",
            "- assert is_odd(13) == True\n",
            "- assert is_odd(14) == False\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 218\n",
            "Prompt (truncated): Write a function to count the frequency of consecutive duplicate elements in a given list of numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyt...\n",
            "Generated Code (truncated): - assert count_duplic([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 219\n",
            "Prompt (truncated): Write a function to perform the adjacent element concatenation in the given tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert concatenate_elements((\"MAM\", \"IS \", \"BEST \", \"FOR \", \"ALL \", \"SKD\")) == ('MAMIS ', 'IS BEST ', 'BEST FOR ', 'FOR ALL ', 'ALL SKD')\n",
            "- assert concatenate_elements((\"MAM\", \"IS \", \"BEST \", \"FOR \"...\n",
            "--------------------------------------------------\n",
            "Task ID: 220\n",
            "Prompt (truncated): Write a python function to find the first even number in a given list of numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert first_even([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) == 2\n",
            "- assert first_even([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...\n",
            "--------------------------------------------------\n",
            "Task ID: 221\n",
            "Prompt (truncated): Write a function to sort a given matrix in ascending order according to the sum of its rows.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert sort_matrix([[1, 2, 3], [2, 4, 5], [1, 1, 1]])==[[1, 1, 1], [1, 2, 3], [2, 4, 5]]\n",
            "- assert sort_matrix([[1, 2, 3], [-2, 4, -5], [1, -1, 1]])==[[-2, 4, -5], [1, -1, 1], [1, 2, 3]]\n",
            "- assert sor...\n",
            "--------------------------------------------------\n",
            "Task ID: 222\n",
            "Prompt (truncated): Write a function to check if the given tuples contain the k or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert check_K((7, 8, 9, 44, 11, 12), 12) == False\n",
            "- assert check_K((7, 8, 9, 44, 11, 12), 13) == False\n",
            "- assert check_K((7, 8, 9, 44, 11, 12), 14) == False\n",
            "- assert check_K((7, 8, 9, 44, 11, 12), 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 223\n",
            "Prompt (truncated): Write a function to find out the maximum sum such that no two chosen numbers are adjacent for the given rectangular grid of dimension 2 x n.\n",
            "\n",
            "You are an expert Python programmer, and here is your task...\n",
            "Generated Code (truncated): - assert max_sum_rectangular_grid([ [1, 2, 3, 4, 5], [6, 7, 8, 9, 10] ], 6) == 25\n",
            "- assert max_sum_rectangular_grid([ [1, 2, 3, 4, 5], [6, 7, 8, 9, 10] ], 7) == 31\n",
            "- assert max_sum_rectangular_grid([ ...\n",
            "--------------------------------------------------\n",
            "Task ID: 224\n",
            "Prompt (truncated): Write a function to return the sum of all divisors of a number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert sum_div(15)==15\n",
            "- assert sum_div(20)==25\n",
            "- assert sum_div(25)==25\n",
            "- assert sum_div(30)==30\n",
            "- assert sum_div(40)==40\n",
            "- assert sum_div(50)==50\n",
            "- assert sum_div(60)==60\n",
            "- assert sum_div(70)==70\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 225\n",
            "Prompt (truncated): Write a python function to count characters at same position in a given string (lower and uppercase characters) as in english alphabet.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {pr...\n",
            "Generated Code (truncated): - assert count_char_position(\"abcde\") == 6\n",
            "- assert count_char_position(\"abcde\") == 6\n",
            "- assert count_char_position(\"abcde\") == 6\n",
            "- assert count_char_position(\"abcde\") == 6\n",
            "- assert count_char_position...\n",
            "--------------------------------------------------\n",
            "Task ID: 226\n",
            "Prompt (truncated): Write a function to check if all values are same in a dictionary.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert check_value({'Cierra Vega': 12, 'Alden Cantrell': 12, 'Kierra Gentry': 12, 'Pierre Cox': 12},6)==True\n",
            "- assert check_value({'Cierra Vega': 12, 'Alden Cantrell': 12, 'Kierra Gentry': 12, 'Pier...\n",
            "--------------------------------------------------\n",
            "Task ID: 227\n",
            "Prompt (truncated): Write a function to find the maximum element of all the given tuple records.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert find_max([(1, 2), (3, 4), (6, 7), (8, 9), (10, 11)]) == 11\n",
            "- assert find_max([(1, 2), (3, 4), (6, 7), (8, 9), (10, 11)]) == 11\n",
            "- assert find_max([(1, 2), (3, 4), (6, 7), (8, 9), (10, 11)]) ==...\n",
            "--------------------------------------------------\n",
            "Task ID: 228\n",
            "Prompt (truncated): Write a python function to find even numbers from a mixed list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert Split([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,6...\n",
            "--------------------------------------------------\n",
            "Task ID: 229\n",
            "Prompt (truncated): Write a function to group the 1st elements on the basis of 2nd elements in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert group_element([(7, 6), (3, 8), (3, 6), (9, 8), (10, 9), (4, 8)]) == {6: [7, 3], 7: [3, 9, 4], 8: [3, 10, 4], 9: [10]}\n",
            "- assert group_element([(7, 6), (3, 8), (3, 6), (9, 8), (10, 9), (4, 8)])...\n",
            "--------------------------------------------------\n",
            "Task ID: 230\n",
            "Prompt (truncated): Write a function to check if the given expression is balanced or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test...\n",
            "Generated Code (truncated): - assert check_expression(\"{()}[{][[]]}({})\") == False\n",
            "- assert check_expression(\"{()}[{][[]]}({})[{}]\") == False\n",
            "- assert check_expression(\"{()}[{][[]]}({})[{}][]\") == False\n",
            "- assert check_expression...\n",
            "--------------------------------------------------\n",
            "Task ID: 231\n",
            "Prompt (truncated): Write a function to find whether all the given tuples have equal length or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert get_equal([(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)], 10) == 'All tuples do not have same length'\n",
            "- assert get_equal([(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23...\n",
            "--------------------------------------------------\n",
            "Task ID: 232\n",
            "Prompt (truncated): Write a function to extract elements that occur singly in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert extract_singly([(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,...\n",
            "--------------------------------------------------\n",
            "Task ID: 233\n",
            "Prompt (truncated): Write a function to calculate the sum of the negative numbers of a given list of numbers using lambda function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return ...\n",
            "Generated Code (truncated): - assert sum_negativenum([1, -2, -3, -4, -5, -6, -7, -8, -9, -10])==-60\n",
            "- assert sum_negativenum([1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15, -16, -17, -18, -19, -20, -21, -22, -2...\n",
            "--------------------------------------------------\n",
            "Task ID: 234\n",
            "Prompt (truncated): Write a python function to count the number of integral co-ordinates that lie inside a square.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert count_Intgral_Points(1,1,1,1) == 1\n",
            "- assert count_Intgral_Points(1,1,1,1,1) == 1\n",
            "- assert count_Intgral_Points(1,1,1,1,1,1) == 1\n",
            "- assert count_Intgral_Points(1,1,1,1,1,1,1) == 1\n",
            "- assert cou...\n",
            "--------------------------------------------------\n",
            "Task ID: 235\n",
            "Prompt (truncated): Write a function to find sum and average of first n natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert sum_average(25)==(250, 10.0)\n",
            "- assert sum_average(30)==(300, 10.0)\n",
            "- assert sum_average(35)==(350, 10.0)\n",
            "- assert sum_average(40)==(400, 10.0)\n",
            "- assert sum_average(45)==(450, 10.0)\n",
            "- assert s...\n",
            "--------------------------------------------------\n",
            "Task ID: 236\n",
            "Prompt (truncated): Write a python function to print duplicants from a list of integers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert Repeat([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 237\n",
            "Prompt (truncated): Write a function to calculate the permutation coefficient of given p(n, k).\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert permutation_coefficient(10, 4) == 252\n",
            "- assert permutation_coefficient(10, 5) == 2520\n",
            "- assert permutation_coefficient(10, 6) == 25200\n",
            "- assert permutation_coefficient(10, 7) == 252000\n",
            "- asse...\n",
            "--------------------------------------------------\n",
            "Task ID: 238\n",
            "Prompt (truncated): Write a python function to choose points from two ranges such that no point lies in both the ranges.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyth...\n",
            "Generated Code (truncated): - assert find_Points(1,5,7,9) == (7,9)\n",
            "- assert find_Points(1,5,7,9) == (7,9)\n",
            "- assert find_Points(1,5,7,9) == (7,9)\n",
            "- assert find_Points(1,5,7,9) == (7,9)\n",
            "- assert find_Points(1,5,7,9) == (7,9)\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 239\n",
            "Prompt (truncated): Write a function to find the top k integers that occur most frequently from given lists of sorted and distinct integers using heap queue algorithm.\n",
            "\n",
            "You are an expert Python programmer, and here is yo...\n",
            "Generated Code (truncated): - assert func([[1, 2, 6], [1, 3, 4, 5, 7, 8], [1, 3, 5, 6, 8, 9], [2, 5, 7, 11], [1, 4, 7, 8, 12]],6)==[6, 7, 1, 8, 1, 5]\n",
            "- assert func([[1, 2, 6], [1, 3, 4, 5, 7, 8], [1, 3, 5, 6, 8, 9], [2, 5, 7, 11...\n",
            "--------------------------------------------------\n",
            "Task ID: 240\n",
            "Prompt (truncated): Write a function to find the lateral surface area of cuboid\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ...\n",
            "Generated Code (truncated): - assert lateralsurface_cuboid(20,30,40)==2520\n",
            "- assert lateralsurface_cuboid(40,50,60)==2520\n",
            "- assert lateralsurface_cuboid(60,70,80)==2520\n",
            "- assert lateralsurface_cuboid(80,90,100)==2520\n",
            "- assert la...\n",
            "--------------------------------------------------\n",
            "Task ID: 241\n",
            "Prompt (truncated): Write a function to find the maximum sum in the given right triangle of numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert max_sum([[1], [1, 2], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 242\n",
            "Prompt (truncated): Write a function to find minimum k records from tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ...\n",
            "Generated Code (truncated): - assert min_k([('tanmay', 14), ('Amer', 11), ('Ayesha', 9), ('SKD', 16)], 2) == [('Ayesha', 9), ('tanmay', 14)]\n",
            "- assert min_k([('tanmay', 14), ('Amer', 11), ('Ayesha', 9), ('SKD', 16)], 3) == [('tan...\n",
            "--------------------------------------------------\n",
            "Task ID: 243\n",
            "Prompt (truncated): Write a function to find kth element from the given two sorted arrays.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert find_kth([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48...\n",
            "--------------------------------------------------\n",
            "Task ID: 244\n",
            "Prompt (truncated): Write a function to create a list of empty dictionaries.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by run...\n",
            "Generated Code (truncated): - assert empty_list(8)==[{},{},{},{},{},{},{},{}]\n",
            "- assert empty_list(9)==[{},{},{},{},{},{},{},{},{}]\n",
            "- assert empty_list(10)==[{},{},{},{},{},{},{},{},{},{}]\n",
            "- assert empty_list(11)==[{},{},{},{},{}...\n",
            "--------------------------------------------------\n",
            "Task ID: 245\n",
            "Prompt (truncated): Write a function to extract all the pairs which are symmetric in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert extract_symmetric([(7, 8), (3, 4), (8, 7), (10, 9), (11, 3), (9, 10)] ) == {(9, 10), (7, 8)}\n",
            "- assert extract_symmetric([(7, 8), (3, 4), (8, 7), (10, 9), (11, 3), (9, 10)] ) == {(9, 10), (7, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 246\n",
            "Prompt (truncated): Write a python function to find the average of odd numbers till a given odd number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert average_Odd(7) == 4\n",
            "- assert average_Odd(13) == 7\n",
            "- assert average_Odd(15) == 10\n",
            "- assert average_Odd(17) == 12\n",
            "- assert average_Odd(19) == 15\n",
            "- assert average_Odd(21) == 18\n",
            "- assert average_...\n",
            "--------------------------------------------------\n",
            "Task ID: 247\n",
            "Prompt (truncated): Write a function to find the maximum total path sum in the given triangle.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass...\n",
            "Generated Code (truncated): - assert max_path_sum([[1, 1, 1], [1, 1, 1], [1, 1, 1]], 1, 1) == 1\n",
            "- assert max_path_sum([[1, 1, 1], [1, 1, 1], [1, 1, 1]], 1, 1) == 1\n",
            "- assert max_path_sum([[1, 1, 1], [1, 1, 1], [1, 1, 1]], 1, 1) =...\n",
            "--------------------------------------------------\n",
            "Task ID: 248\n",
            "Prompt (truncated): Write a function to find the surface area of a cone.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running...\n",
            "Generated Code (truncated): - assert surfacearea_cone(25,25)==2526.252252252252\n",
            "- assert surfacearea_cone(30,30)==2526.252252252252\n",
            "- assert surfacearea_cone(40,40)==2526.252252252252\n",
            "- assert surfacearea_cone(50,50)==2526.25225...\n",
            "--------------------------------------------------\n",
            "Task ID: 249\n",
            "Prompt (truncated): Write a python function to find two distinct numbers such that their lcm lies within the given range.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyt...\n",
            "Generated Code (truncated): - assert answer(1,7) == (1,7)\n",
            "- assert answer(1,9) == (1,9)\n",
            "- assert answer(1,11) == (1,11)\n",
            "- assert answer(1,12) == (1,12)\n",
            "- assert answer(1,13) == (1,13)\n",
            "- assert answer(1,14) == (1,14)\n",
            "- assert ans...\n",
            "--------------------------------------------------\n",
            "Task ID: 250\n",
            "Prompt (truncated): Write a function to find the volume of a cone.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running asser...\n",
            "Generated Code (truncated): - assert volume_cone(25,25)==25225.201201201201\n",
            "- assert volume_cone(30,30)==25225.201201201201\n",
            "- assert volume_cone(40,40)==25225.201201201201\n",
            "- assert volume_cone(50,50)==25225.201201201201\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 251\n",
            "Prompt (truncated): Write a function to check whether an element exists within a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert check_tuplex((\"w\", 3, \"r\", \"e\", \"s\", \"o\", \"u\", \"r\", \"c\", \"e\"),'r',3)==False\n",
            "- assert check_tuplex((\"w\", 3, \"r\", \"e\", \"s\", \"o\", \"u\", \"r\", \"c\", \"e\"),'r',3,3)==True\n",
            "- assert check_tuplex((\"w\", 3...\n",
            "--------------------------------------------------\n",
            "Task ID: 252\n",
            "Prompt (truncated): Write a function to print check if the triangle is isosceles or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert check_isosceles(6,6,6)==True\n",
            "- assert check_isosceles(6,6,12)==False\n",
            "- assert check_isosceles(6,6,6)==True\n",
            "- assert check_isosceles(6,6,6)==True\n",
            "- assert check_isosceles(6,6,6)==True\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 253\n",
            "Prompt (truncated): Write a python function to check whether all the characters are same or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert all_Characters_Same(\"aa\") == False\n",
            "- assert all_Characters_Same(\"aa\") == False\n",
            "- assert all_Characters_Same(\"aa\") == False\n",
            "- assert all_Characters_Same(\"aa\") == False\n",
            "- assert all_Characters_...\n",
            "--------------------------------------------------\n",
            "Task ID: 254\n",
            "Prompt (truncated): Write a function to check if the given number is woodball or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert is_woodall(201) == False\n",
            "- assert is_woodall(202) == False\n",
            "- assert is_woodall(203) == False\n",
            "- assert is_woodall(204) == False\n",
            "- assert is_woodall(205) == False\n",
            "- assert is_woodall(206) == Fa...\n",
            "--------------------------------------------------\n",
            "Task ID: 255\n",
            "Prompt (truncated): Write a function to check if a string represents an integer or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert check_integer(\"abc\")==False\n",
            "- assert check_integer(\"1.1\")==False\n",
            "- assert check_integer(\"1.1.1\")==False\n",
            "- assert check_integer(\"1.1.1.1\")==False\n",
            "- assert check_integer(\"1.1.1.1.1\")==False\n",
            "- a...\n",
            "--------------------------------------------------\n",
            "Task ID: 256\n",
            "Prompt (truncated): ## write a function to find the minimum number of jumps to reach the end of the array for the given array of integers where each element represents the max number of steps that can be made forward fro...\n",
            "Generated Code (truncated): - assert min_jumps([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 11) == 10\n",
            "- assert min_jumps([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 11) == 10\n",
            "- assert min_jumps([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 11) == 10\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 257\n",
            "Prompt (truncated): Write a function to find the dissimilar elements in the given two tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass ...\n",
            "Generated Code (truncated): - assert find_dissimilar((1, 2, 3, 4), (1, 2, 3, 4)) == (1, 2, 3, 4)\n",
            "- assert find_dissimilar((1, 2, 3, 4), (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) == (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
            "- assert find_dissimilar...\n",
            "--------------------------------------------------\n",
            "Task ID: 258\n",
            "Prompt (truncated): Write a python function to shift last element to first position in the given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert move_first([1,2,3,4,5,6,7,8,9,10]) == [10,1,2,3,4,5,6,7,8,9]\n",
            "- assert move_first([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,4...\n",
            "--------------------------------------------------\n",
            "Task ID: 259\n",
            "Prompt (truncated): Write a python function to find the kth element in an array containing odd elements first and then even elements.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should retur...\n",
            "Generated Code (truncated): - assert get_Number(7,7) == 7\n",
            "- assert get_Number(7,6) == 7\n",
            "- assert get_Number(7,4) == 7\n",
            "- assert get_Number(7,3) == 7\n",
            "- assert get_Number(7,1) == 7\n",
            "- assert get_Number(7,0) == 7\n",
            "- assert get_Number(...\n",
            "--------------------------------------------------\n",
            "Task ID: 260\n",
            "Prompt (truncated): Write a python function to find the sum of fifth power of n natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert fifth_Power_Sum(1) == 1\n",
            "- assert fifth_Power_Sum(5) == 625\n",
            "- assert fifth_Power_Sum(6) == 216\n",
            "- assert fifth_Power_Sum(7) == 576\n",
            "- assert fifth_Power_Sum(8) == 1536\n",
            "- assert fifth_Power_Sum(9...\n",
            "--------------------------------------------------\n",
            "Task ID: 261\n",
            "Prompt (truncated): Write a python function to split a string into characters.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by r...\n",
            "Generated Code (truncated): - assert split('programming') == ['p','r','o','g','r','a','m','i','n','g']\n",
            "- assert split('programming languages') == ['p','r','o','g','r','a','m','l','a','n','g','e','s']\n",
            "- assert split('programming ...\n",
            "--------------------------------------------------\n",
            "Task ID: 262\n",
            "Prompt (truncated): Write a python function to find whether the given number is present in the infinite sequence or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyth...\n",
            "Generated Code (truncated): - assert does_Contain_B(1,7,7) == False\n",
            "- assert does_Contain_B(7,7,7) == False\n",
            "- assert does_Contain_B(7,7,7) == False\n",
            "- assert does_Contain_B(7,7,7) == False\n",
            "- assert does_Contain_B(7,7,7) == False\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 263\n",
            "Prompt (truncated): Write a function to extract the elementwise and tuples from the given two tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert and_tuples((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 264\n",
            "Prompt (truncated): Write a function to find the summation of tuple elements in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert sum_elements((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47...\n",
            "--------------------------------------------------\n",
            "Task ID: 265\n",
            "Prompt (truncated): Write a function to find all adverbs and their positions in a given sentence by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert find_adverbs(\"Do not talk to the police\") == '7-15: do not'\n",
            "- assert find_adverbs(\"Do not talk to the police\") == '7-15: do not'\n",
            "- assert find_adverbs(\"Do not talk to the police\") == '7-15: d...\n",
            "--------------------------------------------------\n",
            "Task ID: 266\n",
            "Prompt (truncated): Write a python function to check whether the product of digits of a number at even and odd places is equal or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should retu...\n",
            "Generated Code (truncated): - assert product_Equal(1121) == False\n",
            "- assert product_Equal(1121) == False\n",
            "- assert product_Equal(1121) == False\n",
            "- assert product_Equal(1121) == False\n",
            "- assert product_Equal(1121) == False\n",
            "- assert p...\n",
            "--------------------------------------------------\n",
            "Task ID: 267\n",
            "Prompt (truncated): Write a function to find the top or bottom surface area of a cylinder.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert topbottom_surfacearea(3)==25.201\n",
            "- assert topbottom_surfacearea(2)==12.201\n",
            "- assert topbottom_surfacearea(1)==6.201\n",
            "- assert topbottom_surfacearea(0)==3.201\n",
            "- assert topbottom_surfacearea(1)=...\n",
            "--------------------------------------------------\n",
            "Task ID: 268\n",
            "Prompt (truncated): Write a python function to copy a list from a singleton tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases ...\n",
            "Generated Code (truncated): - assert lcopy([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 4...\n",
            "--------------------------------------------------\n",
            "Task ID: 269\n",
            "Prompt (truncated): Write a function to find the smallest multiple of the first n numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert smallest_multiple(0)==0\n",
            "- assert smallest_multiple(7)==2520\n",
            "- assert smallest_multiple(6)==720\n",
            "- assert smallest_multiple(5)==120\n",
            "- assert smallest_multiple(4)==40\n",
            "- assert smallest_multiple(...\n",
            "--------------------------------------------------\n",
            "Task ID: 270\n",
            "Prompt (truncated): Write a function to find sum of the numbers in a list between the indices of a specified range.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fu...\n",
            "Generated Code (truncated): - assert sum_range_list( [2,1,5,6,8,3,4,9,10,11,8,12],7,7)==16\n",
            "- assert sum_range_list( [2,1,5,6,8,3,4,9,10,11,8,12],7,6)==15\n",
            "- assert sum_range_list( [2,1,5,6,8,3,4,9,10,11,8,12],7,6)==15\n",
            "- assert su...\n",
            "--------------------------------------------------\n",
            "Task ID: 271\n",
            "Prompt (truncated): Write a function to search an element in the given array by using binary search.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert binary_search([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 4...\n",
            "--------------------------------------------------\n",
            "Task ID: 272\n",
            "Prompt (truncated): Write a function to find nth polite number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running assert s...\n",
            "Generated Code (truncated): - assert is_polite(6) == 10\n",
            "- assert is_polite(15) == 25\n",
            "- assert is_polite(20) == 36\n",
            "- assert is_polite(25) == 44\n",
            "- assert is_polite(30) == 55\n",
            "- assert is_polite(40) == 66\n",
            "- assert is_polite(50) == 8...\n",
            "--------------------------------------------------\n",
            "Task ID: 273\n",
            "Prompt (truncated): Write a python function to convert a string to a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runni...\n",
            "Generated Code (truncated): - assert Convert('Machine Learning') == ['Machine','Learning']\n",
            "- assert Convert('Machine Learning with Python') == ['Machine','Learning','with','Python']\n",
            "- assert Convert('Machine Learning with Python...\n",
            "--------------------------------------------------\n",
            "Task ID: 274\n",
            "Prompt (truncated): Write a function to return true if the given number is even else return false.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert even_num(1)==True\n",
            "- assert even_num(1.5)==True\n",
            "- assert even_num(1.6)==False\n",
            "- assert even_num(1.7)==False\n",
            "- assert even_num(1.8)==False\n",
            "- assert even_num(1.9)==False\n",
            "- assert even_num(1.99)=...\n",
            "--------------------------------------------------\n",
            "Task ID: 275\n",
            "Prompt (truncated): Write a python function to check whether every odd index contains odd numbers of a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert odd_position([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 276\n",
            "Prompt (truncated): Write a function to find the first duplicate element in a given array of integers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert find_first_duplicate([1, 1, 1, 1, 1, 1, 1])==1\n",
            "- assert find_first_duplicate([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 277\n",
            "Prompt (truncated): Write a python function to find the slope of a line.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running...\n",
            "Generated Code (truncated): - assert slope(1,1,1,1) == 1\n",
            "- assert slope(1,1,1,1) == 1\n",
            "- assert slope(1,1,1,1) == 1\n",
            "- assert slope(1,1,1,1) == 1\n",
            "- assert slope(1,1,1,1) == 1\n",
            "- assert slope(1,1,1,1) == 1\n",
            "- assert slope(1,1,1,1) ==...\n",
            "--------------------------------------------------\n",
            "Task ID: 278\n",
            "Prompt (truncated): Write a python function to check whether an array can be sorted or not by picking only the corner elements.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only...\n",
            "Generated Code (truncated): - assert check([1,2,3,4,5,6],7) == False\n",
            "- assert check([1,2,3,4,5,6],6) == False\n",
            "- assert check([1,2,3,4,5,6],7) == False\n",
            "- assert check([1,2,3,4,5,6],6) == False\n",
            "- assert check([1,2,3,4,5,6],7) == F...\n",
            "--------------------------------------------------\n",
            "Task ID: 279\n",
            "Prompt (truncated): Write a function to find the nth delannoy number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running as...\n",
            "Generated Code (truncated): - assert dealnnoy_num(4, 6) == 2521\n",
            "- assert dealnnoy_num(4, 7) == 2521\n",
            "- assert dealnnoy_num(4, 8) == 2521\n",
            "- assert dealnnoy_num(4, 9) == 2521\n",
            "- assert dealnnoy_num(4, 10) == 2521\n",
            "- assert dealnnoy_n...\n",
            "--------------------------------------------------\n",
            "Task ID: 280\n",
            "Prompt (truncated): Write a function to check if given tuple is distinct or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by...\n",
            "Generated Code (truncated): - assert check_distinct((1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 281\n",
            "Prompt (truncated): Write a function to find the area of a rombus.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running asser...\n",
            "Generated Code (truncated): - assert rombus_area(1,1)==1\n",
            "- assert rombus_area(1,1)==1\n",
            "- assert rombus_area(1,1)==1\n",
            "- assert rombus_area(1,1)==1\n",
            "- assert rombus_area(1,1)==1\n",
            "- assert rombus_area(1,1)==1\n",
            "- assert rombus_area(1,1)=...\n",
            "--------------------------------------------------\n",
            "Task ID: 282\n",
            "Prompt (truncated): Write a python function to check whether the product of numbers is even or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert is_Product_Even([1,1,1,1],1) == False\n",
            "- assert is_Product_Even([1,1,1,1,1],1) == False\n",
            "- assert is_Product_Even([1,1,1,1,1,1],1) == False\n",
            "- assert is_Product_Even([1,1,1,1,1,1,1],1) == False\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 283\n",
            "Prompt (truncated): Write a python function to find minimum possible value for the given periodic function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert floor_Min(1,1,1) == 1\n",
            "- assert floor_Min(1,1,1) == 1\n",
            "- assert floor_Min(1,1,1) == 1\n",
            "- assert floor_Min(1,1,1) == 1\n",
            "- assert floor_Min(1,1,1) == 1\n",
            "- assert floor_Min(1,1,1) == 1\n",
            "- assert floor...\n",
            "--------------------------------------------------\n",
            "Task ID: 284\n",
            "Prompt (truncated): Write a function to count number of unique lists within a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert unique_sublists([[1, 3], [5, 7], [1, 3], [13, 15, 17], [5, 7], [9, 11]])=={(1, 3): 2, (5, 7): 2, (13, 15, 17): 1, (9, 11): 1}\n",
            "- assert unique_sublists([[1, 3], [5, 7], [1, 3], [13, 15, 17], [...\n",
            "--------------------------------------------------\n",
            "Task ID: 285\n",
            "Prompt (truncated): Write a python function to check whether the given string is made up of two alternating characters or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only ...\n",
            "Generated Code (truncated): - assert is_Two_Alter(\"aaabbbcc\") == False\n",
            "- assert is_Two_Alter(\"aaabbbccaaabbbcc\") == True\n",
            "- assert is_Two_Alter(\"aaabbbccaaabbbccaaabbbcc\") == False\n",
            "- assert is_Two_Alter(\"aaabbbccaaabbbccaaabbbcca...\n",
            "--------------------------------------------------\n",
            "Task ID: 286\n",
            "Prompt (truncated): Write a function to find the longest chain which can be formed from the given set of pairs.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert max_chain_length([Pair(1, 2), Pair(3, 4),Pair(5, 6), Pair(7, 8)], 6) == 7\n",
            "- assert max_chain_length([Pair(1, 2), Pair(3, 4),Pair(5, 6), Pair(7, 8)], 7) == 7\n",
            "- assert max_chain_length([Pair(1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 287\n",
            "Prompt (truncated): Write a function to find eulerian number a(n, m).\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running as...\n",
            "Generated Code (truncated): - assert eulerian_num(6, 1) == 7\n",
            "- assert eulerian_num(7, 1) == 7\n",
            "- assert eulerian_num(7, 2) == 7\n",
            "- assert eulerian_num(7, 3) == 7\n",
            "- assert eulerian_num(7, 4) == 7\n",
            "- assert eulerian_num(7, 5) == 7\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 288\n",
            "Prompt (truncated): Write a function to find minimum of three numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running a...\n",
            "Generated Code (truncated): - assert min_of_three(10,20,0)==0\n",
            "- assert min_of_three(19,15,18)==15\n",
            "- assert min_of_three(-10,-20,-30)==-30\n",
            "- assert min_of_three(10,20,0)==0\n",
            "- assert min_of_three(19,15,18)==15\n",
            "- assert min_of_thre...\n",
            "--------------------------------------------------\n",
            "Task ID: 289\n",
            "Prompt (truncated): Write a function to check if two lists of tuples are identical or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert check_identical([(1, 2), (3, 7)], [(1, 2), (3, 7)]) == False\n",
            "- assert check_identical([(1, 2), (3, 7)], [(1, 2), (3, 7)]) == False\n",
            "- assert check_identical([(1, 2), (3, 7)], [(1, 2), (3, 7)])...\n",
            "--------------------------------------------------\n",
            "Task ID: 290\n",
            "Prompt (truncated): Write a function to find the index of the last occurrence of a given number in a sorted array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert find_last_occurrence([2, 2, 1, 1, 1, 1, 1, 1, 1, 1], 1) == 0\n",
            "- assert find_last_occurrence([2, 2, 1, 1, 1, 1, 1, 1, 1, 1], 1) == 0\n",
            "- assert find_last_occurrence([2, 2, 1, 1, 1, 1, 1, 1, 1, 1]...\n",
            "--------------------------------------------------\n",
            "Task ID: 291\n",
            "Prompt (truncated): Write a function to find all the values in a list that are greater than a specified number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert greater_specificnum([1,2,3,4],20)==True\n",
            "- assert greater_specificnum([1,2,3,4],30)==False\n",
            "- assert greater_specificnum([1,2,3,4],40)==False\n",
            "- assert greater_specificnum([1,2,3,4],50)==False\n",
            "-...\n",
            "--------------------------------------------------\n",
            "Task ID: 292\n",
            "Prompt (truncated): Write a function to check whether the given month name contains 28 days or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert check_monthnum(\"April\")==False\n",
            "- assert check_monthnum(\"May\")==False\n",
            "- assert check_monthnum(\"June\")==False\n",
            "- assert check_monthnum(\"July\")==False\n",
            "- assert check_monthnum(\"August\")==False\n",
            "- a...\n",
            "--------------------------------------------------\n",
            "Task ID: 293\n",
            "Prompt (truncated): Write a function to determine if there is a subset of the given set with sum equal to the given sum.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyth...\n",
            "Generated Code (truncated): - assert is_subset_sum([3, 34, 4, 12, 5, 2], 6, 7) == False\n",
            "- assert is_subset_sum([3, 34, 4, 12, 5, 2], 6, 6) == True\n",
            "- assert is_subset_sum([3, 34, 4, 12, 5, 2], 6, 7) == False\n",
            "- assert is_subset_su...\n",
            "--------------------------------------------------\n",
            "Task ID: 294\n",
            "Prompt (truncated): Write a function to count those characters which have vowels as their neighbors in the given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pyth...\n",
            "Generated Code (truncated): - assert count_vowels('advertising') == 7\n",
            "- assert count_vowels('advertising') == 7\n",
            "- assert count_vowels('advertising') == 7\n",
            "- assert count_vowels('advertising') == 7\n",
            "- assert count_vowels('advertisi...\n",
            "--------------------------------------------------\n",
            "Task ID: 295\n",
            "Prompt (truncated): Write a python function to get the last element of each sublist.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert Extract([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) == [6, 9]\n",
            "- assert Extract([[1, 2, 3], [4, 5, 6], [7, 8, 9, 10]]) == [6, 9, 10]\n",
            "- assert Extract([[1, 2, 3], [4, 5, 6], [7, 8, 9, 10, 11]]) == [6, 9...\n",
            "--------------------------------------------------\n",
            "Task ID: 296\n",
            "Prompt (truncated): Write a python function to find the first repeated character in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert first_repeated_char(\"abcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcab...\n",
            "--------------------------------------------------\n",
            "Task ID: 297\n",
            "Prompt (truncated): Write a function to find the perimeter of a square.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ...\n",
            "Generated Code (truncated): - assert square_perimeter(3)==12\n",
            "- assert square_perimeter(2)==8\n",
            "- assert square_perimeter(1)==4\n",
            "- assert square_perimeter(0)==0\n",
            "- assert square_perimeter(1.5)==7.5\n",
            "- assert square_perimeter(1.25)==6....\n",
            "--------------------------------------------------\n",
            "Task ID: 298\n",
            "Prompt (truncated): Write a function to check whether the given key is present in the dictionary or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and ...\n",
            "Generated Code (truncated): - assert is_key_present({1: 10, 2: 20, 3: 30, 4: 40, 5: 50, 6: 60},11)==False\n",
            "- assert is_key_present({1: 10, 2: 20, 3: 30, 4: 40, 5: 50, 6: 60},12)==False\n",
            "- assert is_key_present({1: 10, 2: 20, 3: 30...\n",
            "--------------------------------------------------\n",
            "Task ID: 299\n",
            "Prompt (truncated): Write a function to find number of odd elements in the given list using lambda function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function ...\n",
            "Generated Code (truncated): - assert count_odd([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])==20\n",
            "- assert count_odd([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 2...\n",
            "--------------------------------------------------\n",
            "Task ID: 300\n",
            "Prompt (truncated): Write a python function to find binomial co-efficient.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runni...\n",
            "Generated Code (truncated): - assert binomial_Coeff(2,1) == 1\n",
            "- assert binomial_Coeff(1,1) == 1\n",
            "- assert binomial_Coeff(0,1) == 1\n",
            "- assert binomial_Coeff(1,0) == 1\n",
            "- assert binomial_Coeff(0,0) == 1\n",
            "- assert binomial_Coeff(1,1) =...\n",
            "--------------------------------------------------\n",
            "Task ID: 301\n",
            "Prompt (truncated): Write a python function to check whether the given array is monotonic or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert is_Monotonic([1, 1, 1, 1]) == True\n",
            "- assert is_Monotonic([1, 1, 1, 1, 1]) == True\n",
            "- assert is_Monotonic([1, 1, 1, 1, 1, 1]) == True\n",
            "- assert is_Monotonic([1, 1, 1, 1, 1, 1, 1]) == True\n",
            "- asse...\n",
            "--------------------------------------------------\n",
            "Task ID: 302\n",
            "Prompt (truncated): Write a python function to find common divisor between two numbers in a given pair.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert num_comm_div(12,36) == 6\n",
            "- assert num_comm_div(12,48) == 6\n",
            "- assert num_comm_div(12,60) == 6\n",
            "- assert num_comm_div(12,72) == 6\n",
            "- assert num_comm_div(12,84) == 6\n",
            "- assert num_comm_div(12,96) =...\n",
            "--------------------------------------------------\n",
            "Task ID: 303\n",
            "Prompt (truncated): Write a function to iterate over elements repeating each as many times as its count.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and ...\n",
            "Generated Code (truncated): - assert count_variable(1,1,1,1)==['q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', ...\n",
            "--------------------------------------------------\n",
            "Task ID: 304\n",
            "Prompt (truncated): Write a function to access dictionary key’s element by index.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases b...\n",
            "Generated Code (truncated): - assert access_key({'physics': 80,'math': 90, 'chemistry': 86},1)== 'chemistry'\n",
            "- assert access_key({'physics': 80,'math': 90, 'chemistry': 86},2)== 'physics'\n",
            "- assert access_key({'physics': 80,'math...\n",
            "--------------------------------------------------\n",
            "Task ID: 305\n",
            "Prompt (truncated): Write a function to flatten a given nested list structure.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by r...\n",
            "Generated Code (truncated): - assert flatten_list([[1,2,3], [4,5,6], [7,8,9], [10,11,12], [13,14,15], [16,17,18], [19,20,21], [22,23,24], [25,26,27], [28,29,30], [31,32,33], [34,35,36], [37,38,39], [40,41,42], [43,44,45], [46,47...\n",
            "--------------------------------------------------\n",
            "Task ID: 306\n",
            "Prompt (truncated): Write a function to find the median of a trapezium.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ...\n",
            "Generated Code (truncated): - assert median_trapezium(7,7,7)==7\n",
            "- assert median_trapezium(7,7,7)==7\n",
            "- assert median_trapezium(7,7,7)==7\n",
            "- assert median_trapezium(7,7,7)==7\n",
            "- assert median_trapezium(7,7,7)==7\n",
            "- assert median_trap...\n",
            "--------------------------------------------------\n",
            "Task ID: 307\n",
            "Prompt (truncated): Write a function to find the number which occurs for odd number of times in the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert get_odd_occurence([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 308\n",
            "Prompt (truncated): Write a python function to count occurences of a character in a repeated string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert count_Char(\"abc\",'c') == 1\n",
            "- assert count_Char(\"abc\",'b') == 0\n",
            "- assert count_Char(\"abc\",'d') == 0\n",
            "- assert count_Char(\"abc\",'e') == 0\n",
            "- assert count_Char(\"abc\",'f') == 0\n",
            "- assert count_Char(...\n",
            "--------------------------------------------------\n",
            "Task ID: 309\n",
            "Prompt (truncated): Write a function to convert the given string of integers into a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert str_to_tuple(\"1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47...\n",
            "--------------------------------------------------\n",
            "Task ID: 310\n",
            "Prompt (truncated): Write a function to replace the last element of the list with another list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert replace_list([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,...\n",
            "--------------------------------------------------\n",
            "Task ID: 311\n",
            "Prompt (truncated): Write a function to find the longest common subsequence for the given three string sequence.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert lcs_of_three('abcd1e2', 'bc12ea', 'bd1ea', 7, 6, 5) == 3\n",
            "- assert lcs_of_three('abcd1e2', 'bc12ea', 'bd1ea', 7, 6, 5) == 3\n",
            "- assert lcs_of_three('abcd1e2', 'bc12ea', 'bd1ea', 7, 6, 5) == 3\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 312\n",
            "Prompt (truncated): Write a function to find the number of rotations in a circularly sorted array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert find_rotation_count([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) == 1\n",
            "- assert find_rotation_count([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) == 2\n",
            "- assert find_rotation_count([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 313\n",
            "Prompt (truncated): Write a function to find the minimum number of elements that should be removed such that amax-amin<=k.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Py...\n",
            "Generated Code (truncated): - assert removals([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 20, 19) == 1\n",
            "- assert removals([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 19, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 314\n",
            "Prompt (truncated): Write a python function to count positive numbers in a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by...\n",
            "Generated Code (truncated): - assert pos_count([1,2,3,4,5]) == 5\n",
            "- assert pos_count([1,2,3,4,5,6]) == 6\n",
            "- assert pos_count([1,2,3,4,5,6,7]) == 7\n",
            "- assert pos_count([1,2,3,4,5,6,7,8]) == 8\n",
            "- assert pos_count([1,2,3,4,5,6,7,8,9]) ...\n",
            "--------------------------------------------------\n",
            "Task ID: 315\n",
            "Prompt (truncated): Write a function to calculate the harmonic sum of n-1.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runni...\n",
            "Generated Code (truncated): - assert harmonic_sum(1) == 1.0000000000000001\n",
            "- assert harmonic_sum(0) == 1.0000000000000001\n",
            "- assert harmonic_sum(1e-6) == 1.0000000000000001\n",
            "- assert harmonic_sum(1e-7) == 1.0000000000000001\n",
            "- asse...\n",
            "--------------------------------------------------\n",
            "Task ID: 316\n",
            "Prompt (truncated): [link text](https:// [link text](https:// [link text](https://)))write a function to convert a string to a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return...\n",
            "Generated Code (truncated): - assert string_to_list(\"function to convert a string to a list\")==['function','to','convert','a','string','to','a','list']\n",
            "- assert string_to_list(\"function to convert a string to a list with the def...\n",
            "--------------------------------------------------\n",
            "Task ID: 317\n",
            "Prompt (truncated): Write a function to convert tuple string to integer tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by r...\n",
            "Generated Code (truncated): - assert tuple_str_int(\"(7, 8, 9, 10)\") == (7, 8, 9, 10)\n",
            "- assert tuple_str_int(\"(1, 2, 3, 4)\") == (1, 2, 3, 4)\n",
            "- assert tuple_str_int(\"(1, 2, 3, 4, 5)\") == (1, 2, 3, 4, 5)\n",
            "- assert tuple_str_int(\"(1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 318\n",
            "Prompt (truncated): Write a function to caluclate perimeter of a parallelogram.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ...\n",
            "Generated Code (truncated): - assert parallelogram_perimeter(10,10)==400\n",
            "- assert parallelogram_perimeter(15,15)==300\n",
            "- assert parallelogram_perimeter(20,20)==400\n",
            "- assert parallelogram_perimeter(25,25)==500\n",
            "- assert parallelogr...\n",
            "--------------------------------------------------\n",
            "Task ID: 319\n",
            "Prompt (truncated): Write a function to get the word with most number of occurrences in the given strings list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert most_occurrences([\"I am the best\", \"I am the best\", \"I am the best\"] ) == 'best'\n",
            "- assert most_occurrences([\"I am the best\", \"I am the best\", \"I am the best\"] ) == 'best'\n",
            "- assert most_occurr...\n",
            "--------------------------------------------------\n",
            "Task ID: 320\n",
            "Prompt (truncated): Write a python function to count the upper case characters in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert upper_ctr('Python') == 1\n",
            "- assert upper_ctr('Python3') == 1\n",
            "- assert upper_ctr('Python3.7') == 1\n",
            "- assert upper_ctr('Python3.7.1') == 1\n",
            "- assert upper_ctr('Python3.7.1-rc1') == 1\n",
            "- assert upp...\n",
            "--------------------------------------------------\n",
            "Task ID: 321\n",
            "Prompt (truncated): Write a function to sort a given list of elements in ascending order using heap queue algorithm.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert heap_assending([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 322\n",
            "Prompt (truncated): Write a function to convert the given binary tuple to integer.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases ...\n",
            "Generated Code (truncated): - assert binary_to_integer((1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 323\n",
            "Prompt (truncated): Write a function to sort the given list based on the occurrence of first element of tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert sort_on_occurence([('a', 'apple'), ('b', 'ball'), ('a', 'apple'), ('b', 'ball')]) == [('a', 'apple', 'apple', 3), ('b', 'ball', 2)]\n",
            "- assert sort_on_occurence([('a', 'apple'), ('b', 'ball'), ...\n",
            "--------------------------------------------------\n",
            "Task ID: 324\n",
            "Prompt (truncated): Write a python function to count numbers whose oth and nth bits are set.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert count_Num(4) == 1\n",
            "- assert count_Num(5) == 1\n",
            "- assert count_Num(6) == 1\n",
            "- assert count_Num(7) == 1\n",
            "- assert count_Num(8) == 1\n",
            "- assert count_Num(9) == 1\n",
            "- assert count_Num(10) == 1\n",
            "- assert c...\n",
            "--------------------------------------------------\n",
            "Task ID: 325\n",
            "Prompt (truncated): Write a function to count occurrence of a character in a string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert count_char(\"assert\",'s')==2\n",
            "- assert count_char(\"assert\",'s')==2\n",
            "- assert count_char(\"assert\",'s')==2\n",
            "- assert count_char(\"assert\",'s')==2\n",
            "- assert count_char(\"assert\",'s')==2\n",
            "- assert count_...\n",
            "--------------------------------------------------\n",
            "Task ID: 326\n",
            "Prompt (truncated): Write a function to find the last occurrence of a character in a string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert last_occurence_char(\"world\",'w')==1\n",
            "- assert last_occurence_char(\"world\",'w')==1\n",
            "- assert last_occurence_char(\"world\",'w')==1\n",
            "- assert last_occurence_char(\"world\",'w')==1\n",
            "- assert last_occure...\n",
            "--------------------------------------------------\n",
            "Task ID: 327\n",
            "Prompt (truncated): Write a python function to check whether every even index contains even numbers of a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert even_position([1,2,3,4]) == True\n",
            "- assert even_position([1,2,3,4,5]) == False\n",
            "- assert even_position([1,2,3,4,5,6]) == False\n",
            "- assert even_position([1,2,3,4,5,6,7]) == False\n",
            "- assert even_pos...\n",
            "--------------------------------------------------\n",
            "Task ID: 328\n",
            "Prompt (truncated): Write a function to get a colon of a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running assert s...\n",
            "Generated Code (truncated): - assert colon_tuplex((\"HELLO\", 5, [], True),2,1000)==(\"HELLO\", 5, [1000], True)\n",
            "- assert colon_tuplex((\"HELLO\", 5, [], True),2,5000)==(\"HELLO\", 5, [5000], True)\n",
            "- assert colon_tuplex((\"HELLO\", 5, [],...\n",
            "--------------------------------------------------\n",
            "Task ID: 329\n",
            "Prompt (truncated): Write a python function to find the product of non-repeated elements in a given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert find_Product([1,1,1,1,1],6) == 1\n",
            "- assert find_Product([1,1,1,1,1,1],7) == 1\n",
            "- assert find_Product([1,1,1,1,1,1,1],8) == 1\n",
            "- assert find_Product([1,1,1,1,1,1,1,1],9) == 1\n",
            "- assert find_Produc...\n",
            "--------------------------------------------------\n",
            "Task ID: 330\n",
            "Prompt (truncated): Write a python function to find the sum of absolute differences in all pairs of the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert sum_Pairs([1,2,3,4,5,7,9,11,14],7) == 189\n",
            "- assert sum_Pairs([1,2,3,4,5,7,9,11,14],6) == 189\n",
            "- assert sum_Pairs([1,2,3,4,5,7,9,11,14],5) == 189\n",
            "- assert sum_Pairs([1,2,3,4,5,7,9,11,14],4) == ...\n",
            "--------------------------------------------------\n",
            "Task ID: 331\n",
            "Prompt (truncated): Write a function to flatten the tuple list to a string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runn...\n",
            "Generated Code (truncated): - assert flatten_tuple([('1', '2', '3'), ('4', '5', '6'), ('7', '8', '9'), ('10', '11', '12')]) == '1 2 3 4 5 6 7 8 9 10 11 12'\n",
            "- assert flatten_tuple([('1', '2', '3', '4'), ('5', '6', '7', '8'), ('9'...\n",
            "--------------------------------------------------\n",
            "Task ID: 332\n",
            "Prompt (truncated): Write a python function to remove all digits from a list of strings.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert remove(['2017-03-03','2017-03-03','2017-03-03']) == ['2017-03-03','2017-03-03','2017-03-03']\n",
            "- assert remove(['2017-03-03','2017-03-03','2017-03-03','2017-03-03']) == ['2017-03-03','2017-03-0...\n",
            "--------------------------------------------------\n",
            "Task ID: 333\n",
            "Prompt (truncated): Write a python function to find the minimum number of squares whose sum is equal to a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pytho...\n",
            "Generated Code (truncated): - assert get_Min_Squares(7) == 2\n",
            "- assert get_Min_Squares(1) == 1\n",
            "- assert get_Min_Squares(3) == 1\n",
            "- assert get_Min_Squares(5) == 1\n",
            "- assert get_Min_Squares(8) == 1\n",
            "- assert get_Min_Squares(9) == 1\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 334\n",
            "Prompt (truncated): Write a function to perform index wise multiplication of tuple elements in the given two tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert index_multiplication(((1, 2), (3, 4), (5, 6), (7, 8)),((9, 10), (6, 7), (3, 4), (1, 2)) ) == ((18, 40), (30, 84), (15, 22), (25, 44))\n",
            "- assert index_multiplication(((1, 2), (3, 4), (5, 6), (7...\n",
            "--------------------------------------------------\n",
            "Task ID: 335\n",
            "Prompt (truncated): Write a function to find the maximum sum that can be formed which has no three consecutive elements present.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return onl...\n",
            "Generated Code (truncated): - assert max_sum_of_three_consecutive([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10) == 81\n",
            "- assert max_sum_of_three_consecutive([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 20) == 2...\n",
            "--------------------------------------------------\n",
            "Task ID: 336\n",
            "Prompt (truncated): Write a function to extract all the adjacent coordinates of the given coordinate tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert get_coordinates((6, 7)) == [[5, 6], [5, 7], [5, 8], [6, 6], [6, 7], [6, 8], [7, 6], [7, 7], [7, 8]]\n",
            "- assert get_coordinates((7, 8)) == [[6, 7], [6, 8], [6, 9], [7, 7], [7, 8], [7, 9], [8, 7]...\n",
            "--------------------------------------------------\n",
            "Task ID: 337\n",
            "Prompt (truncated): Write a function to check if a url is valid or not using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert is_valid_URL(\"https://www.google.com/abc\") == False\n",
            "- assert is_valid_URL(\"https://www.google.com/abc\") == False\n",
            "- assert is_valid_URL(\"https://www.google.com/abc\") == False\n",
            "- assert is_valid...\n",
            "--------------------------------------------------\n",
            "Task ID: 338\n",
            "Prompt (truncated): Write a function to increment the numeric values in the given strings by k.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert increment_numerics([\"Kotlin\", \"201\", \"is\", \"81\", \"201\", \"K\", \"7\"], 7) == ['Kotlin', '208', 'is', '89', '201', 'K', '8']\n",
            "- assert increment_numerics([\"Java\", \"201\", \"is\", \"81\", \"201\", \"K\", \"7\"...\n",
            "--------------------------------------------------\n",
            "Task ID: 339\n",
            "Prompt (truncated): Write a function to check if the two given strings are permutations of each other.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert check_permutation(\"abc\", \"acb\") == False\n",
            "- assert check_permutation(\"abc\", \"bac\") == False\n",
            "- assert check_permutation(\"abc\", \"bca\") == False\n",
            "- assert check_permutation(\"abc\", \"cab\") == False\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 340\n",
            "Prompt (truncated): Write a function to get the n largest items from a dataset.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ...\n",
            "Generated Code (truncated): - assert larg_nnum([10, 20, 50, 70, 90, 20, 50, 40, 60, 80, 100],6)==[]\n",
            "- assert larg_nnum([10, 20, 50, 70, 90, 20, 50, 40, 60, 80, 100],7)==[]\n",
            "- assert larg_nnum([10, 20, 50, 70, 90, 20, 50, 40, 60, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 341\n",
            "Prompt (truncated): Write a function to find all words which are at least 4 characters long in a string by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pytho...\n",
            "Generated Code (truncated): - assert find_char_long('Jhingai wulu road Zone 3') == ['Jhingai', 'wulu', 'road', 'Zone']\n",
            "- assert find_char_long('Jhingai wulu road Zone 3') == ['Jhingai', 'wulu', 'road', 'Zone']\n",
            "- assert find_char...\n",
            "--------------------------------------------------\n",
            "Task ID: 342\n",
            "Prompt (truncated): Write a function to find the number of subsequences having product smaller than k for the given non negative array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should ret...\n",
            "Generated Code (truncated): - assert no_of_subsequences([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 343\n",
            "Prompt (truncated): Write a function to find the smallest range that includes at-least one element from each of the given arrays.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return on...\n",
            "Generated Code (truncated): - assert find_minimum_range([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 344\n",
            "Prompt (truncated): Write a python function to convert a given string list to a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert string_list_to_tuple([\"this\", \"is\", \"a\", \"test\", \"string\"]) == ('t', 'h', 'i','s', 'i','s', 'a', 't', 'e','s', 't', 'r', 'i', 'n', 'g')\n",
            "- assert string_list_to_tuple([\"this\", \"is\", \"a\", \"test...\n",
            "--------------------------------------------------\n",
            "Task ID: 345\n",
            "Prompt (truncated): Write a function to remove uppercase substrings from a given string by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert remove_uppercase('hElPTherMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHeMAnDThIsTHe...\n",
            "--------------------------------------------------\n",
            "Task ID: 346\n",
            "Prompt (truncated): Write a function to perfom the modulo of tuple elements in the given two tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert tuple_modulo((13, 7, 8, 9), (8, 9, 10, 8)) == (6, 7, 8, 1)\n",
            "- assert tuple_modulo((14, 8, 9, 10), (9, 10, 11, 9)) == (7, 8, 9, 1)\n",
            "- assert tuple_modulo((15, 9, 10, 11), (10, 11, 12, 10)) == (8...\n",
            "--------------------------------------------------\n",
            "Task ID: 347\n",
            "Prompt (truncated): Write a function to remove empty lists from a given list of lists.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert remove_empty([[], [], [],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[...\n",
            "--------------------------------------------------\n",
            "Task ID: 348\n",
            "Prompt (truncated): Write a python function to find minimum adjacent swaps required to sort binary array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and...\n",
            "Generated Code (truncated): - assert find_Min_Swaps([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 349\n",
            "Prompt (truncated): Write a function to find the maximum sum possible by using the given equation f(n) = max( (f(n/2) + f(n/3) + f(n/4) + f(n/5)), n).\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt}...\n",
            "Generated Code (truncated): - assert get_max_sum(1) == 1\n",
            "- assert get_max_sum(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 350\n",
            "Prompt (truncated): Write a python function to check whether two given lines are parallel or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert parallel_lines([3,3],[3,3]) == False\n",
            "- assert parallel_lines([3,3],[3,3,3]) == False\n",
            "- assert parallel_lines([3,3],[3,3,3,3]) == False\n",
            "- assert parallel_lines([3,3],[3,3,3,3,3]) == False\n",
            "- as...\n",
            "--------------------------------------------------\n",
            "Task ID: 351\n",
            "Prompt (truncated): Write a function to sum a specific column of a list in a given list of lists.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert sum_column( [[1,2,3,2],[4,5,6,2],[7,8,9,5],],4)==7\n",
            "- assert sum_column( [[1,2,3,2],[4,5,6,2],[7,8,9,5],],5)==6\n",
            "- assert sum_column( [[1,2,3,2],[4,5,6,2],[7,8,9,5],],6)==5\n",
            "- assert sum_column(...\n",
            "--------------------------------------------------\n",
            "Task ID: 352\n",
            "Prompt (truncated): Write a function to find the maximum of nth column from the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert max_of_nth([(7, 8, 9), (3, 5, 7), (10, 11, 21)], 2) == 21\n",
            "- assert max_of_nth([(7, 8, 9), (3, 5, 7), (10, 11, 21)], 3) == 21\n",
            "- assert max_of_nth([(7, 8, 9), (3, 5, 7), (10, 11, 21)], 4) == 21...\n",
            "--------------------------------------------------\n",
            "Task ID: 353\n",
            "Prompt (truncated): Write a function to find out the minimum no of swaps required for bracket balancing in the given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a ...\n",
            "Generated Code (truncated): - assert swap_count(\"[[][]][[]]\") == 1\n",
            "- assert swap_count(\"[[][]][[]][[]]\") == 1\n",
            "- assert swap_count(\"[[][]][[]][[]][[]]\") == 1\n",
            "- assert swap_count(\"[[][]][[]][[]][[]][[]]\") == 1\n",
            "- assert swap_count(...\n",
            "--------------------------------------------------\n",
            "Task ID: 354\n",
            "Prompt (truncated): Write a function to calculate the value of 'a' to the power 'b'.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert power(7,7) == 2527\n",
            "- assert power(1,1) == 1\n",
            "- assert power(0,0) == 1\n",
            "- assert power(1,1) == 1\n",
            "- assert power(1,1) == 1\n",
            "- assert power(1,1) == 1\n",
            "- assert power(1,1) == 1\n",
            "- assert power(1,1) ==...\n",
            "--------------------------------------------------\n",
            "Task ID: 355\n",
            "Prompt (truncated): Write a function to find the focus of a parabola.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running as...\n",
            "Generated Code (truncated): - assert parabola_focus(7,7,7)==(-1.0, 7.0)\n",
            "- assert parabola_focus(1,1,1)==(-1.0, 1.0)\n",
            "- assert parabola_focus(1,1,1)==(-1.0, 1.0)\n",
            "- assert parabola_focus(1,1,1)==(-1.0, 1.0)\n",
            "- assert parabola_focus(...\n",
            "--------------------------------------------------\n",
            "Task ID: 356\n",
            "Prompt (truncated): Write a python function to find the difference between sum of even and odd digits.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert is_Diff(121211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211211...\n",
            "--------------------------------------------------\n",
            "Task ID: 357\n",
            "Prompt (truncated): Write a function to check whether it follows the sequence given in the patterns array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert is_samepatterns([\"red\",\"green\",\"green\"], [\"a\",\"b\",\"b\"])==False \n",
            "- assert is_samepatterns([\"red\",\"green\",\"green\"], [\"a\",\"b\",\"b\"])==False \n",
            "- assert is_samepatterns([\"red\",\"green\",\"green\"], [\"a\"...\n",
            "--------------------------------------------------\n",
            "Task ID: 358\n",
            "Prompt (truncated): Write a function to find the area of a pentagon.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ass...\n",
            "Generated Code (truncated): - assert area_pentagon(20)==655.2151522651357\n",
            "- assert area_pentagon(25)==1017.3338364076557\n",
            "- assert area_pentagon(30)==1477.4625715301857\n",
            "- assert area_pentagon(35)==2017.5913066727157\n",
            "- assert area...\n",
            "--------------------------------------------------\n",
            "Task ID: 359\n",
            "Prompt (truncated): Write a function to replace whitespaces with an underscore and vice versa in a given string by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only...\n",
            "Generated Code (truncated): - assert replace_spaces('The Avengers 2') == 'The_Avengers_2'\n",
            "- assert replace_spaces('The Avengers 3') == 'The_Avengers_3'\n",
            "- assert replace_spaces('The Avengers 4') == 'The_Avengers_4'\n",
            "- assert repla...\n",
            "--------------------------------------------------\n",
            "Task ID: 360\n",
            "Prompt (truncated): Write a function to search a literals string in a string and also find the location within the original string where the pattern occurs by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here i...\n",
            "Generated Code (truncated): - assert find_literals('You can\\'t say that\\'s true', 'true') == ('true', 7, 11)\n",
            "- assert find_literals('You\\'re not the only one', 'only') == ('only', 7, 11)\n",
            "- assert find_literals('You\\'re not the o...\n",
            "--------------------------------------------------\n",
            "Task ID: 361\n",
            "Prompt (truncated): Write a function to search some literals strings in a string by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert check_literals('The quick brown fox jumps over the lazy dog.',['fox', 'dog']) == 'Matched!'\n",
            "- assert check_literals('The quick brown fox jumps over the lazy dog.',['fox', 'dog', 'lazy']) == '...\n",
            "--------------------------------------------------\n",
            "Task ID: 362\n",
            "Prompt (truncated): Write a python function to find the first repeated character in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert first_Repeated_Char(\"Hello, World!\") == \"l\"\n",
            "- assert first_Repeated_Char(\"Hello, World!\") == \"l\"\n",
            "- assert first_Repeated_Char(\"Hello, World!\") == \"l\"\n",
            "- assert first_Repeated_Char(\"Hello, Worl...\n",
            "--------------------------------------------------\n",
            "Task ID: 363\n",
            "Prompt (truncated): Write a function to find all pairs in an integer array whose sum is equal to a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert get_pairs_count([1, 1, 1, 1, 1], 1, 1) == 1\n",
            "- assert get_pairs_count([1, 1, 1, 1, 1, 1], 1, 1) == 1\n",
            "- assert get_pairs_count([1, 1, 1, 1, 1, 1, 1], 1, 1) == 1\n",
            "- assert get_pairs_count([1, 1, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 364\n",
            "Prompt (truncated): Write a function to get dictionary keys as a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running a...\n",
            "Generated Code (truncated): - assert get_key({})==[]\n",
            "- assert get_key({})==[]\n",
            "- assert get_key({})==[]\n",
            "- assert get_key({})==[]\n",
            "- assert get_key({})==[]\n",
            "- assert get_key({})==[]\n",
            "- assert get_key({})==[]\n",
            "- assert get_key({})==[]\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 365\n",
            "Prompt (truncated): Write a function to calculate a grid of hexagon coordinates where function returns a list of lists containing 6 tuples of x, y point coordinates.\n",
            "\n",
            "You are an expert Python programmer, and here is your...\n",
            "Generated Code (truncated): - assert calculate_polygons(7,7,7,7,7)==[[(-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7.0, -7.0), (-7....\n",
            "--------------------------------------------------\n",
            "Task ID: 366\n",
            "Prompt (truncated): Write a function to remove all characters except letters and numbers using regex\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert remove_char(\"Hello1234:,! Howare33u\") == 'Hello1234Howare33u'\n",
            "- assert remove_char(\"Cool543Triks@:, Make@987Trips\") == 'Cool543TriksMake987Trips' \n",
            "- assert remove_char(\"Hello1234:,! Howare33u...\n",
            "--------------------------------------------------\n",
            "Task ID: 367\n",
            "Prompt (truncated): Write a function to calculate distance between two points using latitude and longitude.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert distance_lat_long(10,20,30,40)==6783.751974994595\n",
            "- assert distance_lat_long(10,20,30,40)==6783.751974994595\n",
            "- assert distance_lat_long(10,20,30,40)==6783.751974994595\n",
            "- assert distance_lat_l...\n",
            "--------------------------------------------------\n",
            "Task ID: 368\n",
            "Prompt (truncated): Write a function to check if one tuple is a subset of another tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert check_subset((7, 8, 9, 10), (7, 8, 9, 10)) == True\n",
            "- assert check_subset((7, 8, 9, 10), (7, 8, 9, 10, 7, 8, 9, 10)) == True\n",
            "- assert check_subset((7, 8, 9, 10), (7, 8, 9, 10, 7, 8, 9, 10, 7, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 369\n",
            "Prompt (truncated): Write a function to find the size of the given tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runnin...\n",
            "Generated Code (truncated): - assert tuple_size((1, \"Raju\", 2, \"Nikhil\", 3, \"Deepanshu\", 4, \"Kapil\", 5, \"Kapil\", 6, \"Kapil\", 7, \"Kapil\", 8, \"Kapil\", 9, \"Kapil\", 10, \"Kapil\", 11, \"Kapil\", 12, \"Kapil\", 13, \"Kapil\", 14, \"Kapil\", 15...\n",
            "--------------------------------------------------\n",
            "Task ID: 370\n",
            "Prompt (truncated): Write a function that matches a string that has an a followed by one or more b's.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert text_match_one(\"aaabbbcc\")==('Found a match!')\n",
            "- assert text_match_one(\"aaabbbcc\")==('Found a match!')\n",
            "- assert text_match_one(\"aaabbbcc\")==('Found a match!')\n",
            "- assert text_match_one(\"aaabbbc...\n",
            "--------------------------------------------------\n",
            "Task ID: 371\n",
            "Prompt (truncated): Write a function to convert the given tuple to a key-value dictionary using adjacent elements.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert tuple_to_dict((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 4...\n",
            "--------------------------------------------------\n",
            "Task ID: 372\n",
            "Prompt (truncated): Write a function to find out, if the given number is abundant.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases ...\n",
            "Generated Code (truncated): - assert is_abundant(15)==True\n",
            "- assert is_abundant(16)==False\n",
            "- assert is_abundant(20)==True\n",
            "- assert is_abundant(25)==False\n",
            "- assert is_abundant(30)==False\n",
            "- assert is_abundant(40)==False\n",
            "- assert i...\n",
            "--------------------------------------------------\n",
            "Task ID: 373\n",
            "Prompt (truncated): Write a python function to find the parity of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases b...\n",
            "Generated Code (truncated): - assert find_Parity(15) == \"Odd Parity\"\n",
            "- assert find_Parity(20) == \"Even Parity\"\n",
            "- assert find_Parity(25) == \"Odd Parity\"\n",
            "- assert find_Parity(30) == \"Even Parity\"\n",
            "- assert find_Parity(35) == \"Odd P...\n",
            "--------------------------------------------------\n",
            "Task ID: 374\n",
            "Prompt (truncated): Write a function to remove duplicates from a list of lists.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ...\n",
            "Generated Code (truncated): - assert remove_duplicate([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3...\n",
            "--------------------------------------------------\n",
            "Task ID: 375\n",
            "Prompt (truncated): Write a function to reverse strings in a given list of string values.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test...\n",
            "Generated Code (truncated): - assert reverse_string_list(['kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','kak','k...\n",
            "--------------------------------------------------\n",
            "Task ID: 376\n",
            "Prompt (truncated): Write a function to find the n'th lucas number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running asse...\n",
            "Generated Code (truncated): - assert find_lucas(2) == 1\n",
            "- assert find_lucas(1) == 1\n",
            "- assert find_lucas(0) == 1\n",
            "- assert find_lucas(-1) == 1\n",
            "- assert find_lucas(1e6) == 1\n",
            "- assert find_lucas(1e7) == 1\n",
            "- assert find_lucas(1e8) ==...\n",
            "--------------------------------------------------\n",
            "Task ID: 377\n",
            "Prompt (truncated): Write a python function to find the last two digits in factorial of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert last_Two_Digits(1) == 1\n",
            "- assert last_Two_Digits(0) == 0\n",
            "- assert last_Two_Digits(10) == 40\n",
            "- assert last_Two_Digits(15) == 120\n",
            "- assert last_Two_Digits(20) == 240\n",
            "- assert last_Two_Digits(25...\n",
            "--------------------------------------------------\n",
            "Task ID: 378\n",
            "Prompt (truncated): Write a function to find the demlo number for the given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert find_demlo(\"13333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333...\n",
            "--------------------------------------------------\n",
            "Task ID: 379\n",
            "Prompt (truncated): Write a function to check if the given tuple list has all k elements.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test...\n",
            "Generated Code (truncated): - assert check_k_elements([(7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...\n",
            "--------------------------------------------------\n",
            "Task ID: 380\n",
            "Prompt (truncated): Write a function to caluclate area of a parallelogram.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runni...\n",
            "Generated Code (truncated): - assert parallelogram_area(10,10)==100\n",
            "- assert parallelogram_area(15,15)==225\n",
            "- assert parallelogram_area(20,20)==400\n",
            "- assert parallelogram_area(25,25)==625\n",
            "- assert parallelogram_area(30,30)==900\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 381\n",
            "Prompt (truncated): Write a function to get an item of a tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running assert s...\n",
            "Generated Code (truncated): - assert get_item((\"w\", 3, \"r\", \"e\", \"s\", \"o\", \"u\", \"r\", \"c\", \"e\"),-2)==('s')\n",
            "- assert get_item((\"w\", 3, \"r\", \"e\", \"s\", \"o\", \"u\", \"r\", \"c\", \"e\"),-1)==('o')\n",
            "- assert get_item((\"w\", 3, \"r\", \"e\", \"s\", \"o...\n",
            "--------------------------------------------------\n",
            "Task ID: 382\n",
            "Prompt (truncated): Write a python function to count numeric values in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert number_ctr('1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63...\n",
            "--------------------------------------------------\n",
            "Task ID: 383\n",
            "Prompt (truncated): Write a python function to find the item with maximum occurrences in a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert max_occurrences([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 384\n",
            "Prompt (truncated): Write a python function to find sum of inverse of divisors.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ...\n",
            "Generated Code (truncated): - assert Sum_of_Inverse_Divisors(1,1) == 1\n",
            "- assert Sum_of_Inverse_Divisors(1,1) == 1\n",
            "- assert Sum_of_Inverse_Divisors(1,1) == 1\n",
            "- assert Sum_of_Inverse_Divisors(1,1) == 1\n",
            "- assert Sum_of_Inverse_Divi...\n",
            "--------------------------------------------------\n",
            "Task ID: 385\n",
            "Prompt (truncated): Write a python function to find the perimeter of a cylinder.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by...\n",
            "Generated Code (truncated): - assert perimeter(1,1) == 2\n",
            "- assert perimeter(1,1) == 2\n",
            "- assert perimeter(1,1) == 2\n",
            "- assert perimeter(1,1) == 2\n",
            "- assert perimeter(1,1) == 2\n",
            "- assert perimeter(1,1) == 2\n",
            "- assert perimeter(1,1) ==...\n",
            "--------------------------------------------------\n",
            "Task ID: 386\n",
            "Prompt (truncated): Write a python function to set the right most unset bit.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by run...\n",
            "Generated Code (truncated): - assert set_Right_most_Unset_Bit(25) == 25\n",
            "- assert set_Right_most_Unset_Bit(7) == 7\n",
            "- assert set_Right_most_Unset_Bit(19) == 19\n",
            "- assert set_Right_most_Unset_Bit(31) == 31\n",
            "- assert set_Right_most_Un...\n",
            "--------------------------------------------------\n",
            "Task ID: 387\n",
            "Prompt (truncated): Write a function to calculate the difference between the squared sum of first n natural numbers and the sum of squared first n natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your t...\n",
            "Generated Code (truncated): - assert sum_difference(81)==252252252\n",
            "- assert sum_difference(120)==252252252252\n",
            "- assert sum_difference(2016)==252252252252252252252252252252252252252252252252252252252252252252252252252252252252252...\n",
            "--------------------------------------------------\n",
            "Task ID: 388\n",
            "Prompt (truncated): Write a function to find sequences of lowercase letters joined with an underscore using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert text_match(\"aaab_cbbbc\") == 'Found a match!'\n",
            "- assert text_match(\"aaab_Abbbc\") == 'Not matched!'\n",
            "- assert text_match(\"aaab_abbbc\") == 'Not matched!'\n",
            "- assert text_match(\"aaab_cbbbc\") == 'Foun...\n",
            "--------------------------------------------------\n",
            "Task ID: 389\n",
            "Prompt (truncated): Write a function to remove lowercase substrings from a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert remove_lowercase(\"Kitten, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, cat, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 390\n",
            "Prompt (truncated): Write a function to count character frequency of a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert char_frequency('programming')=={'p': 1, 'r': 1, 'o': 1, 'g': 1, 'a': 1,'m': 1, 'i': 1, 'n': 1, 'g': 1, 'u': 1, 'n': 1}\n",
            "- assert char_frequency('programming languages')=={'p': 1, 'r': 1, 'o': ...\n",
            "--------------------------------------------------\n",
            "Task ID: 391\n",
            "Prompt (truncated): Write a function to find the n-th rectangular number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runnin...\n",
            "Generated Code (truncated): - assert find_rect_num(7) == 56\n",
            "- assert find_rect_num(8) == 70\n",
            "- assert find_rect_num(9) == 84\n",
            "- assert find_rect_num(10) == 98\n",
            "- assert find_rect_num(11) == 112\n",
            "- assert find_rect_num(12) == 126\n",
            "- a...\n",
            "--------------------------------------------------\n",
            "Task ID: 392\n",
            "Prompt (truncated): Write a python function to check whether a string has atleast one letter and one number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function ...\n",
            "Generated Code (truncated): - assert check_String('thishasboth1') == False\n",
            "- assert check_String('thishasboth2') == False\n",
            "- assert check_String('thishasboth3') == False\n",
            "- assert check_String('thishasboth4') == False\n",
            "- assert che...\n",
            "--------------------------------------------------\n",
            "Task ID: 393\n",
            "Prompt (truncated): Write a function to concatenate the given two tuples to a nested tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass te...\n",
            "Generated Code (truncated): - assert concatenate_nested((1, 2, 3), (4, 5, 6)) == (1, 2, 3, 4, 5, 6)\n",
            "- assert concatenate_nested((1, 2, 3, 4), (5, 6, 7, 8)) == (1, 2, 3, 4, 5, 6, 7, 8)\n",
            "- assert concatenate_nested((1, 2, 3, 4, 5),...\n",
            "--------------------------------------------------\n",
            "Task ID: 394\n",
            "Prompt (truncated): Write a python function to find lcm of two positive integers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases b...\n",
            "Generated Code (truncated): - assert lcm(7,7) == 7\n",
            "- assert lcm(1,1) == 1\n",
            "- assert lcm(1,1) == 1\n",
            "- assert lcm(1,1) == 1\n",
            "- assert lcm(1,1) == 1\n",
            "- assert lcm(1,1) == 1\n",
            "- assert lcm(1,1) == 1\n",
            "- assert lcm(1,1) == 1\n",
            "- assert lcm(1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 395\n",
            "Prompt (truncated): Write a function to find the surface area of a cube.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running...\n",
            "Generated Code (truncated): - assert surfacearea_cube(20)==1200\n",
            "- assert surfacearea_cube(30)==1800\n",
            "- assert surfacearea_cube(40)==2100\n",
            "- assert surfacearea_cube(50)==2520\n",
            "- assert surfacearea_cube(60)==3000\n",
            "- assert surfacearea...\n",
            "--------------------------------------------------\n",
            "Task ID: 396\n",
            "Prompt (truncated): Write a python function to find the sum of fifth power of first n odd natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert odd_Num_Sum(4) == 57681\n",
            "- assert odd_Num_Sum(5) == 110587\n",
            "- assert odd_Num_Sum(6) == 201201\n",
            "- assert odd_Num_Sum(7) == 317201\n",
            "- assert odd_Num_Sum(8) == 488201\n",
            "- assert odd_Num_Sum(9) == 6962...\n",
            "--------------------------------------------------\n",
            "Task ID: 397\n",
            "Prompt (truncated): Write a python function to check whether the hexadecimal number is even or odd.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert even_or_odd(\"AAAA\") == \"Even\"\n",
            "- assert even_or_odd(\"AAAAAA\") == \"Even\"\n",
            "- assert even_or_odd(\"AAAAA\") == \"Even\"\n",
            "- assert even_or_odd(\"AAAAA\") == \"Even\"\n",
            "- assert even_or_odd(\"AAAAA\") == \"Even\"\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 398\n",
            "Prompt (truncated): Write a function to check if the given tuple has any none value or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass te...\n",
            "Generated Code (truncated): - assert check_none((7, 8, 9, 11, 14, None)) == False\n",
            "- assert check_none((1, 2, 3, 4, 5, None)) == False\n",
            "- assert check_none((7, 8, 9, 11, 14, 15)) == False\n",
            "- assert check_none((1, 2, 3, 4, 5, 6, Non...\n",
            "--------------------------------------------------\n",
            "Task ID: 399\n",
            "Prompt (truncated): Write a function to convert a date of yyyy-mm-dd format to dd-mm-yyyy format by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python funct...\n",
            "Generated Code (truncated): - assert change_date_format(\"2021-03-25\") == '25-03-2021'\n",
            "- assert change_date_format(\"2021-03-25-2021-03-25\") == '25-03-2021'\n",
            "- assert change_date_format(\"2021-03-25-2021-03-25-2021-03-25\") == '25-03...\n",
            "--------------------------------------------------\n",
            "Task ID: 400\n",
            "Prompt (truncated): Write a function to check whether all dictionaries in a list are empty or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert empty_dit({})==False\n",
            "- assert empty_dit({})==False\n",
            "- assert empty_dit({})==False\n",
            "- assert empty_dit({})==False\n",
            "- assert empty_dit({})==False\n",
            "- assert empty_dit({})==False\n",
            "- assert empty_dit({...\n",
            "--------------------------------------------------\n",
            "Task ID: 401\n",
            "Prompt (truncated): Write a function to insert an element before each element of a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert insert_element(['apple', 'banana', 'orange'],'apple')==['apple', 'apple', 'apple', 'banana', 'banana', 'banana', 'orange', 'orange', 'orange'] \n",
            "- assert insert_element(['apple', 'banana', 'or...\n",
            "--------------------------------------------------\n",
            "Task ID: 402\n",
            "Prompt (truncated): Write a python function to check whether the value exists in a sequence or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert overlapping([1,2,3,4,5,6,7,8,9,10],[1,2,3,4,5,6,7,8,9,10]) == True\n",
            "- assert overlapping([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,...\n",
            "--------------------------------------------------\n",
            "Task ID: 403\n",
            "Prompt (truncated): Write a python function to check whether a sequence of numbers has an increasing trend or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert increasing_trend([1,1,1,1]) == False\n",
            "- assert increasing_trend([1,1,1,1,1]) == False\n",
            "- assert increasing_trend([1,1,1,1,1,1]) == False\n",
            "- assert increasing_trend([1,1,1,1,1,1,1]) == False\n",
            "- as...\n",
            "--------------------------------------------------\n",
            "Task ID: 404\n",
            "Prompt (truncated): Write a python function to check whether one root of the quadratic equation is twice of the other or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a...\n",
            "Generated Code (truncated): - assert Check_Solution(1,1,1) == \"Yes\"\n",
            "- assert Check_Solution(1,1,1,1) == \"Yes\"\n",
            "- assert Check_Solution(1,1,1,1,1) == \"Yes\"\n",
            "- assert Check_Solution(1,1,1,1,1,1) == \"Yes\"\n",
            "- assert Check_Solution(1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 405\n",
            "Prompt (truncated): Write a function to find the n-th number in newman conway sequence.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test c...\n",
            "Generated Code (truncated): - assert sequence(4) == 3\n",
            "- assert sequence(5) == 4\n",
            "- assert sequence(6) == 5\n",
            "- assert sequence(7) == 6\n",
            "- assert sequence(8) == 7\n",
            "- assert sequence(9) == 8\n",
            "- assert sequence(10) == 9\n",
            "- assert sequence...\n",
            "--------------------------------------------------\n",
            "Task ID: 406\n",
            "Prompt (truncated): Write a python function to find the sum of fourth power of first n odd natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert odd_Num_Sum(5) == 25281\n",
            "- assert odd_Num_Sum(6) == 252576\n",
            "- assert odd_Num_Sum(7) == 2525761\n",
            "- assert odd_Num_Sum(8) == 25257612\n",
            "- assert odd_Num_Sum(9) == 252576122\n",
            "- assert odd_Num_Sum(10) ...\n",
            "--------------------------------------------------\n",
            "Task ID: 407\n",
            "Prompt (truncated): Write a python function to remove even numbers from a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert remove_even([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 408\n",
            "Prompt (truncated): Write a function to abbreviate 'road' as 'rd.' in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert road_rd(\"kakatiya Road\")==('kakatiya Rd.')\n",
            "- assert road_rd(\"kakatiya Road\")==('kakatiya Rd.')\n",
            "- assert road_rd(\"kakatiya Road\")==('kakatiya Rd.')\n",
            "- assert road_rd(\"kakatiya Road\")==('kakatiy...\n",
            "--------------------------------------------------\n",
            "Task ID: 409\n",
            "Prompt (truncated): Write a function to check if there is a subset with sum divisible by m.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass te...\n",
            "Generated Code (truncated): - assert modular_sum([1, 7, 6], 2, 5) == False\n",
            "- assert modular_sum([1, 7, 6, 7], 2, 5) == False\n",
            "- assert modular_sum([1, 7, 6, 7, 7], 2, 5) == False\n",
            "- assert modular_sum([1, 7, 6, 7, 7, 7], 2, 5) == ...\n",
            "--------------------------------------------------\n",
            "Task ID: 410\n",
            "Prompt (truncated): Write a python function to check whether all the bits are within a given range or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert all_Bits_Set_In_The_Given_Range(7,2,7) == False\n",
            "- assert all_Bits_Set_In_The_Given_Range(7,2,7) == False\n",
            "- assert all_Bits_Set_In_The_Given_Range(7,2,7) == False\n",
            "- assert all_Bits_Set_In_The_...\n",
            "--------------------------------------------------\n",
            "Task ID: 411\n",
            "Prompt (truncated): Write a function to combine two given sorted lists using heapq module.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert combine_lists([1,3,7,9],[2,4,6,10])==[1,2,3,4,6,7,9,10]\n",
            "- assert combine_lists([1,3,7,9,11],[2,4,6,10,12])==[1,2,3,4,6,7,9,10,11,12]\n",
            "- assert combine_lists([1,3,7,9,11,12],[2,4,6,10,12,14])==...\n",
            "--------------------------------------------------\n",
            "Task ID: 412\n",
            "Prompt (truncated): Write a function to remove characters from the first string which are present in the second string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Pytho...\n",
            "Generated Code (truncated): - assert remove_dirty_chars(\"advertising\", \"advertising\") == 'advertising'\n",
            "- assert remove_dirty_chars(\"advertising\", \"advertising\") == 'advertising'\n",
            "- assert remove_dirty_chars(\"advertising\", \"advert...\n",
            "--------------------------------------------------\n",
            "Task ID: 413\n",
            "Prompt (truncated): Write a function to replace maximum n occurrences of spaces, commas, or dots with a colon.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functio...\n",
            "Generated Code (truncated): - assert replace_max_specialchar('ram reshma,ram rahim',1)==('ram:reshma,ram rahim')\n",
            "- assert replace_max_specialchar('ram reshma,ram rahim',1)==('ram:reshma,ram rahim')\n",
            "- assert replace_max_specialch...\n",
            "--------------------------------------------------\n",
            "Task ID: 414\n",
            "Prompt (truncated): Write a python function to find the last digit when factorial of a divides factorial of b.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functio...\n",
            "Generated Code (truncated): - assert compute_Last_Digit(1,1) == 1\n",
            "- assert compute_Last_Digit(1,1) == 1\n",
            "- assert compute_Last_Digit(1,1) == 1\n",
            "- assert compute_Last_Digit(1,1) == 1\n",
            "- assert compute_Last_Digit(1,1) == 1\n",
            "- assert c...\n",
            "--------------------------------------------------\n",
            "Task ID: 415\n",
            "Prompt (truncated): Write a function to find the number of possible sequences of length n such that each of the next element is greater than or equal to twice of the previous element but less than or equal to m.\n",
            "\n",
            "You are...\n",
            "Generated Code (truncated): - assert get_total_number_of_sequences(7, 7) == 252\n",
            "- assert get_total_number_of_sequences(7, 7) == 252\n",
            "- assert get_total_number_of_sequences(7, 7) == 252\n",
            "- assert get_total_number_of_sequences(7, 7)...\n",
            "--------------------------------------------------\n",
            "Task ID: 416\n",
            "Prompt (truncated): Write a python function to check whether a given sequence is linear or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert Seq_Linear([1,2,3,4,5,6,7,8,9,10]) == \"Linear Sequence\"\n",
            "- assert Seq_Linear([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,...\n",
            "--------------------------------------------------\n",
            "Task ID: 417\n",
            "Prompt (truncated): Write a python function to find number of elements with odd factors in a given range.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and...\n",
            "Generated Code (truncated): - assert count_Odd_Squares(7,25) == 3\n",
            "- assert count_Odd_Squares(1,25) == 1\n",
            "- assert count_Odd_Squares(1,25) == 1\n",
            "- assert count_Odd_Squares(1,25) == 1\n",
            "- assert count_Odd_Squares(1,25) == 1\n",
            "- assert c...\n",
            "--------------------------------------------------\n",
            "Task ID: 418\n",
            "Prompt (truncated): Write a function to check if a triangle of positive area is possible with the given angles.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert is_triangleexists(60,60,60)==True\n",
            "- assert is_triangleexists(60,60,60)==True\n",
            "- assert is_triangleexists(60,60,60)==True\n",
            "- assert is_triangleexists(60,60,60)==True\n",
            "- assert is_triangleexists(6...\n",
            "--------------------------------------------------\n",
            "Task ID: 419\n",
            "Prompt (truncated): Write a function to divide a number into two parts such that the sum of digits is maximum.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functio...\n",
            "Generated Code (truncated): - assert sum_digits_twoparts(201)==19\n",
            "- assert sum_digits_twoparts(2017)==19\n",
            "- assert sum_digits_twoparts(2017-2016)==19\n",
            "- assert sum_digits_twoparts(2017-2017)==19\n",
            "- assert sum_digits_twoparts(2017-2...\n",
            "--------------------------------------------------\n",
            "Task ID: 420\n",
            "Prompt (truncated): Write a python function to count the number of substrings with same first and last characters.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert count_Substring_With_Equal_Ends('abcabcabc') == 7\n",
            "- assert count_Substring_With_Equal_Ends('abcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabcabc...\n",
            "--------------------------------------------------\n",
            "Task ID: 421\n",
            "Prompt (truncated): Write a python function to find maximum possible value for the given periodic function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert floor_Max(1,1,1) == 1\n",
            "- assert floor_Max(1,1,1) == 1\n",
            "- assert floor_Max(1,1,1) == 1\n",
            "- assert floor_Max(1,1,1) == 1\n",
            "- assert floor_Max(1,1,1) == 1\n",
            "- assert floor_Max(1,1,1) == 1\n",
            "- assert floor...\n",
            "--------------------------------------------------\n",
            "Task ID: 422\n",
            "Prompt (truncated): Write a python function to left rotate the bits of a given number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert left_Rotate(7,3) == 576\n",
            "- assert left_Rotate(7,1) == 576\n",
            "- assert left_Rotate(7,0) == 7\n",
            "- assert left_Rotate(7,1) == 7\n",
            "- assert left_Rotate(7,2) == 7\n",
            "- assert left_Rotate(7,3) == 7\n",
            "- assert l...\n",
            "--------------------------------------------------\n",
            "Task ID: 423\n",
            "Prompt (truncated): Write a function to replace all spaces in the given string with character * list item * list item * list item * list item '%20'.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} Y...\n",
            "Generated Code (truncated): - assert replace_spaces(\"I am a Programmer in Python\") == 'I%20am%20a%20Programmer%20in%20Python'\n",
            "- assert replace_spaces(\"I love Coding in Python\") == 'I%20love%20Coding%20in%20Python'\n",
            "- assert repla...\n",
            "--------------------------------------------------\n",
            "Task ID: 424\n",
            "Prompt (truncated): Write a python function to find the maximum occuring divisor in an interval.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert find_Divisor(7,7) == 7\n",
            "- assert find_Divisor(7,7) == 7\n",
            "- assert find_Divisor(7,7) == 7\n",
            "- assert find_Divisor(7,7) == 7\n",
            "- assert find_Divisor(7,7) == 7\n",
            "- assert find_Divisor(7,7) == 7\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 425\n",
            "Prompt (truncated): Write a function to check a decimal with a precision of 2.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by r...\n",
            "Generated Code (truncated): - assert is_decimal('1.234587')==False\n",
            "- assert is_decimal('1.234587')==False\n",
            "- assert is_decimal('1.234587')==False\n",
            "- assert is_decimal('1.234587')==False\n",
            "- assert is_decimal('1.234587')==False\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 426\n",
            "Prompt (truncated): Write a function to remove all whitespaces from a string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ru...\n",
            "Generated Code (truncated): - assert remove_all_spaces(' python  program')==('pythonprogram')\n",
            "- assert remove_all_spaces(' python  program')==('pythonprogram')\n",
            "- assert remove_all_spaces(' python  program')==('pythonprogram')\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 427\n",
            "Prompt (truncated): Write a function to find the maximum value in a given heterogeneous list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass ...\n",
            "Generated Code (truncated): - assert max_val([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,...\n",
            "--------------------------------------------------\n",
            "Task ID: 428\n",
            "Prompt (truncated): Write a function to find the longest palindromic subsequence in the given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert lps(\"TEN FOR TENS FOR TENS FOR TENS FOR TENS\") == 11\n",
            "- assert lps(\"CARDIO FOR CARDS FOR CARDS FOR CARDS FOR CARDS FOR CARDS FOR CARDS FOR CARDS FOR CARDS FOR CARDS FOR CARDS FOR CARDS FOR CAR...\n",
            "--------------------------------------------------\n",
            "Task ID: 429\n",
            "Prompt (truncated): Write a python function to shift first element to the end of given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert move_last([1,2,3,4,5,6,7,8,9,10]) == [2,3,4,5,6,7,8,9,10,1]\n",
            "- assert move_last([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,...\n",
            "--------------------------------------------------\n",
            "Task ID: 430\n",
            "Prompt (truncated): Write a function to count array elements having modular inverse under given prime number p equal to itself.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only...\n",
            "Generated Code (truncated): - assert modular_inverse([1, 2, 3, 4, 5], 6, 7) == 1\n",
            "- assert modular_inverse([1, 2, 3, 4, 5], 7, 6) == 1\n",
            "- assert modular_inverse([1, 2, 3, 4, 5], 6, 7) == 1\n",
            "- assert modular_inverse([1, 2, 3, 4, 5],...\n",
            "--------------------------------------------------\n",
            "Task ID: 431\n",
            "Prompt (truncated): Write a function to find the n-th power of individual elements in a list using lambda function.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fu...\n",
            "Generated Code (truncated): - assert nth_nums([1,2,3,4,5,6,7,8,9,10],7)==([1, 4, 9, 16, 25, 36, 49, 64, 81, 100])\n",
            "- assert nth_nums([1,2,3,4,5,6,7,8,9,10],8)==([1, 4, 9, 16, 25, 36, 49, 64, 81, 100])\n",
            "- assert nth_nums([1,2,3,4,5...\n",
            "--------------------------------------------------\n",
            "Task ID: 432\n",
            "Prompt (truncated): Write a python function to find the cube sum of first n natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert sum_Of_Series(4) == 64\n",
            "- assert sum_Of_Series(6) == 216\n",
            "- assert sum_Of_Series(7) == 343\n",
            "- assert sum_Of_Series(8) == 512\n",
            "- assert sum_Of_Series(10) == 625\n",
            "- assert sum_Of_Series(11) == 836\n",
            "-...\n",
            "--------------------------------------------------\n",
            "Task ID: 433\n",
            "Prompt (truncated): Write a python function to find sum of prime numbers between 1 to n.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert sum_Of_Primes(1) == 1\n",
            "- assert sum_Of_Primes(1) == 1\n",
            "- assert sum_Of_Primes(1) == 1\n",
            "- assert sum_Of_Primes(1) == 1\n",
            "- assert sum_Of_Primes(1) == 1\n",
            "- assert sum_Of_Primes(1) == 1\n",
            "- assert sum_O...\n",
            "--------------------------------------------------\n",
            "Task ID: 434\n",
            "Prompt (truncated): Write a function to sort a given list of strings of numbers numerically.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert sort_numeric_strings(['1','3','5','7','1', '3','13', '15', '17','5', '7 ','9','1', '11', '12', '15', '17', '19', '1', '3', '13', '15', '17', '19', '1', '3', '13', '15', '17', '19', '1', '3', ...\n",
            "--------------------------------------------------\n",
            "Task ID: 435\n",
            "Prompt (truncated): Write a function to find the nth tetrahedral number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running...\n",
            "Generated Code (truncated): - assert tetrahedral_number(8) == 120.0\n",
            "- assert tetrahedral_number(9) == 156.0\n",
            "- assert tetrahedral_number(10) == 201.0\n",
            "- assert tetrahedral_number(11) == 252.0\n",
            "- assert tetrahedral_number(12) == 300...\n",
            "--------------------------------------------------\n",
            "Task ID: 436\n",
            "Prompt (truncated): Write a function to check if the given array represents min heap or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert check_min_heap([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 0) == False\n",
            "- assert check_min_heap([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,...\n",
            "--------------------------------------------------\n",
            "Task ID: 437\n",
            "Prompt (truncated): Write a python function to find the sum of fifth power of first n even natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert even_Power_Sum(4) == 576\n",
            "- assert even_Power_Sum(5) == 576\n",
            "- assert even_Power_Sum(6) == 576\n",
            "- assert even_Power_Sum(7) == 576\n",
            "- assert even_Power_Sum(8) == 576\n",
            "- assert even_Power_Sum(9) == ...\n",
            "--------------------------------------------------\n",
            "Task ID: 438\n",
            "Prompt (truncated): Write a python function to find the sum of xor of all pairs of numbers in the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functio...\n",
            "Generated Code (truncated): - assert pair_OR_Sum([7,7],1) == 0\n",
            "- assert pair_OR_Sum([7,7,7],3) == 7\n",
            "- assert pair_OR_Sum([7,7,7,7],4) == 7\n",
            "- assert pair_OR_Sum([7,7,7,7,7],5) == 7\n",
            "- assert pair_OR_Sum([7,7,7,7,7,7],6) == 7\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 439\n",
            "Prompt (truncated): Write a function to find minimum of two numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ass...\n",
            "Generated Code (truncated): - assert min_of_two(10,10)==10\n",
            "- assert min_of_two(19,19)==19\n",
            "- assert min_of_two(-10,-10)==-10\n",
            "- assert min_of_two(10,19)==19\n",
            "- assert min_of_two(-10,19)==-19\n",
            "- assert min_of_two(-19,19)==19\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 440\n",
            "Prompt (truncated): Write a python function to check if the elements of a given list are unique or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert all_unique([1,2,3,4,1]) == False\n",
            "- assert all_unique([1,2,3,4,1,1]) == False\n",
            "- assert all_unique([1,2,3,4,1,1,1]) == False\n",
            "- assert all_unique([1,2,3,4,1,1,1,1]) == False\n",
            "- assert all_unique(...\n",
            "--------------------------------------------------\n",
            "Task ID: 441\n",
            "Prompt (truncated): Write a function to count the same pair in three given lists.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases b...\n",
            "Generated Code (truncated): - assert count_samepair([1,2,3,4,5,6,7,8],[2,2,3,1,2,6,7,8],[2,1,3,1,2,6,7,8])==6\n",
            "- assert count_samepair([1,2,3,4,5,6,7,8],[2,2,3,1,2,6,7,8],[2,1,3,1,2,6,7,8])==7\n",
            "- assert count_samepair([1,2,3,4,5,6...\n",
            "--------------------------------------------------\n",
            "Task ID: 442\n",
            "Prompt (truncated): Write a function for computing square roots using the babylonian method.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert babylonian_squareroot(1)==1\n",
            "- assert babylonian_squareroot(0)==0\n",
            "- assert babylonian_squareroot(1e-6)==1e-6\n",
            "- assert babylonian_squareroot(1e-7)==1e-7\n",
            "- assert babylonian_squareroot(1e-8)==1e...\n",
            "--------------------------------------------------\n",
            "Task ID: 443\n",
            "Prompt (truncated): Write a python function to check whether the given strings are rotations of each other or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python fun...\n",
            "Generated Code (truncated): - assert are_Rotations(\"abcd\",\"adcb\") == False\n",
            "- assert are_Rotations(\"abcd\",\"adcb\") == False\n",
            "- assert are_Rotations(\"abcd\",\"adcb\") == False\n",
            "- assert are_Rotations(\"abcd\",\"adcb\") == False\n",
            "- assert are...\n",
            "--------------------------------------------------\n",
            "Task ID: 444\n",
            "Prompt (truncated): Write a python function to check whether the first and last characters of a given string are equal or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only ...\n",
            "Generated Code (truncated): - assert check_Equality(\"abcda\") == \"Equal\"\n",
            "- assert check_Equality(\"abcda\") == \"Equal\"\n",
            "- assert check_Equality(\"abcda\") == \"Equal\"\n",
            "- assert check_Equality(\"abcda\") == \"Equal\"\n",
            "- assert check_Equality(...\n",
            "--------------------------------------------------\n",
            "Task ID: 445\n",
            "Prompt (truncated): Write a function that gives profit amount if the given amount has profit else return none.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functio...\n",
            "Generated Code (truncated): - assert profit_amount(500,500)==None\n",
            "- assert profit_amount(500,500)==None\n",
            "- assert profit_amount(500,500)==None\n",
            "- assert profit_amount(500,500)==None\n",
            "- assert profit_amount(500,500)==None\n",
            "- assert p...\n",
            "--------------------------------------------------\n",
            "Task ID: 446\n",
            "Prompt (truncated): Write a python function to find the sum of repeated elements in a given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not by...\n",
            "Generated Code (truncated): - assert find_Sum([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 447\n",
            "Prompt (truncated): Write a function to re-arrange the given tuples based on the given ordered list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert re_arrange_tuples([(7, 6), (3, 8), (5, 7), (2, 4)],  [7, 6, 3, 5]) == [(7, 6), (3, 8), (5, 7), (2, 4)]\n",
            "- assert re_arrange_tuples([(7, 6), (3, 8), (5, 7), (2, 4)],  [7, 6, 3, 5, 2]) == [(7, 6...\n",
            "--------------------------------------------------\n",
            "Task ID: 448\n",
            "Prompt (truncated): Write a function to generate a square matrix filled with elements from 1 to n raised to the power of 2 in spiral order.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should...\n",
            "Generated Code (truncated): - assert generate_matrix(1)==[[1]]\n",
            "- assert generate_matrix(0)==[]\n",
            "- assert generate_matrix(-1)==[]\n",
            "- assert generate_matrix(-2)==[]\n",
            "- assert generate_matrix(-3)==[]\n",
            "- assert generate_matrix(-4)==[]\n",
            "-...\n",
            "--------------------------------------------------\n",
            "Task ID: 449\n",
            "Prompt (truncated): Write a function to remove duplicate words from a given list of strings.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass t...\n",
            "Generated Code (truncated): - assert remove_duplic_list([\"Python\", \"Exercises\", \"Practice\", \"Solution\", \"Exercises\",\"Java\", \"C++\", \"C\", \"Java\", \"C\", \"C++\", \"Java\", \"C++\", \"Java\", \"C++\", \"Java\", \"C++\", \"Java\", \"C++\", \"Java\", \"C++...\n",
            "--------------------------------------------------\n",
            "Task ID: 450\n",
            "Prompt (truncated): Write a function to remove everything except alphanumeric characters from the given string by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only ...\n",
            "Generated Code (truncated): - assert remove_extra_char('****//Google Firebase//*** - 478. ') == 'GoogleFirebase478'\n",
            "- assert remove_extra_char('****//Google Firebase//*** - 478. ') == 'GoogleFirebase478'\n",
            "- assert remove_extra_ch...\n",
            "--------------------------------------------------\n",
            "Task ID: 451\n",
            "Prompt (truncated): Write a python function to count unequal element pairs from the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert count_Pairs([1,1,1,1,1],6) == 1\n",
            "- assert count_Pairs([1,1,1,1,1,1],7) == 1\n",
            "- assert count_Pairs([1,1,1,1,1,1,1],8) == 1\n",
            "- assert count_Pairs([1,1,1,1,1,1,1,1],9) == 1\n",
            "- assert count_Pairs([1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 452\n",
            "Prompt (truncated): Write a function to convert the given tuple to a floating-point number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass te...\n",
            "Generated Code (truncated): - assert tuple_to_float((9, 456)) == 9.456\n",
            "- assert tuple_to_float((10, 789)) == 10.789\n",
            "- assert tuple_to_float((11, 4567)) == 11.4567\n",
            "- assert tuple_to_float((12, 7896)) == 12.7896\n",
            "- assert tuple_to_...\n",
            "--------------------------------------------------\n",
            "Task ID: 453\n",
            "Prompt (truncated): Write a function to convert degrees to radians.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running asse...\n",
            "Generated Code (truncated): - assert radian_degree(180)==3.141592653589793\n",
            "- assert radian_degree(270)==4.71238898038469\n",
            "- assert radian_degree(360)==6.283185307179586\n",
            "- assert radian_degree(0)==0\n",
            "- assert radian_degree(-90)==-1...\n",
            "--------------------------------------------------\n",
            "Task ID: 454\n",
            "Prompt (truncated): Write a function to find the closest smaller number than n.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ...\n",
            "Generated Code (truncated): - assert closest_num(15) == 14\n",
            "- assert closest_num(16) == 15\n",
            "- assert closest_num(19) == 18\n",
            "- assert closest_num(20) == 19\n",
            "- assert closest_num(25) == 24\n",
            "- assert closest_num(30) == 29\n",
            "- assert close...\n",
            "--------------------------------------------------\n",
            "Task ID: 455\n",
            "Prompt (truncated): Write a function to check if the string is a valid email address or not using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and ...\n",
            "Generated Code (truncated): - assert check_email(\"ankitaoie326.com\") == 'Invalid Email'\n",
            "- assert check_email(\"ankitaoie326.com\") == 'Invalid Email'\n",
            "- assert check_email(\"ankitaoie326.com\") == 'Invalid Email'\n",
            "- assert check_email...\n",
            "--------------------------------------------------\n",
            "Task ID: 456\n",
            "Prompt (truncated): Write a function to find the count of all binary sequences of length 2n such that sum of first n bits is same as sum of last n bits.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {promp...\n",
            "Generated Code (truncated): - assert count_binary_seq(4) == 70.0\n",
            "- assert count_binary_seq(5) == 252.0\n",
            "- assert count_binary_seq(6) == 924.0\n",
            "- assert count_binary_seq(7) == 3360.0\n",
            "- assert count_binary_seq(8) == 11220.0\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 457\n",
            "Prompt (truncated): Write a function to convert the given tuples into set.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by runni...\n",
            "Generated Code (truncated): - assert tuple_to_set(('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l','m', 'n', 'o', 'p', 'q', 'r','s', 't', 'u', 'v', 'w', 'x', 'y', 'z') ) == {'y', 'x', 'z', 'a', 'b', 'c', 'd', 'e', 'f'...\n",
            "--------------------------------------------------\n",
            "Task ID: 458\n",
            "Prompt (truncated): Write a python function to add a minimum number such that the sum of array becomes even.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function ...\n",
            "Generated Code (truncated): - assert min_Num([1,2,3,4,5,6,7,8,9,10],10) == 1\n",
            "- assert min_Num([1,2,3,4,5,6,7,8,9,10,11],11) == 2\n",
            "- assert min_Num([1,2,3,4,5,6,7,8,9,10,11,12],12) == 3\n",
            "- assert min_Num([1,2,3,4,5,6,7,8,9,10,11,12...\n",
            "--------------------------------------------------\n",
            "Task ID: 459\n",
            "Prompt (truncated): Write a function to find the combinations of sums with tuples in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function an...\n",
            "Generated Code (truncated): - assert find_combinations([(1, 2), (3, 4), (6, 7), (8, 9)]) == [(7, 10), (6, 7), (7, 12), (10, 7), (11, 14), (10, 10)]\n",
            "- assert find_combinations([(1, 2), (3, 4), (6, 7), (8, 9), (10, 11)]) == [(7, 1...\n",
            "--------------------------------------------------\n",
            "Task ID: 460\n",
            "Prompt (truncated): Write a function to check if the given integer is a prime number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cas...\n",
            "Generated Code (truncated): - assert prime_num(1)==False\n",
            "- assert prime_num(0)==False\n",
            "- assert prime_num(1)==False\n",
            "- assert prime_num(1)==False\n",
            "- assert prime_num(1)==False\n",
            "- assert prime_num(1)==False\n",
            "- assert prime_num(1)==Fal...\n",
            "--------------------------------------------------\n",
            "Task ID: 461\n",
            "Prompt (truncated): Write a python function to check whether the given number is co-prime or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not byp...\n",
            "Generated Code (truncated): - assert is_coprime(25,25) == True\n",
            "- assert is_coprime(25,25) == False\n",
            "- assert is_coprime(25,25) == False\n",
            "- assert is_coprime(25,25) == False\n",
            "- assert is_coprime(25,25) == False\n",
            "- assert is_coprime(2...\n",
            "--------------------------------------------------\n",
            "Task ID: 462\n",
            "Prompt (truncated): Write a function to check whether the given amount has no profit and no loss\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert noprofit_noloss(500,500)==True\n",
            "- assert noprofit_noloss(500,500)==True\n",
            "- assert noprofit_noloss(500,500)==True\n",
            "- assert noprofit_noloss(500,500)==True\n",
            "- assert noprofit_noloss(500,500)==True\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 463\n",
            "Prompt (truncated): Write a function to iterate over all pairs of consecutive items in a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not ...\n",
            "Generated Code (truncated): - assert pair_wise([1,1,1,1,1,1,1,1,1,1])==[(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]\n",
            "- assert pair_wise([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 464\n",
            "Prompt (truncated): Write a function to check if any list element is present in the given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypas...\n",
            "Generated Code (truncated): - assert check_element((1, 2, 3, 4, 5),  [6, 7, 8, 9, 10]) == False\n",
            "- assert check_element((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3...\n",
            "--------------------------------------------------\n",
            "Task ID: 465\n",
            "Prompt (truncated): Write a function to find the maximum sum of subsequences of given array with no adjacent elements.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python...\n",
            "Generated Code (truncated): - assert max_sum_subseq([1, 3, 10, 6, 7, 0, 7, 15, 22]) == 54\n",
            "- assert max_sum_subseq([1, 3, 10, 7, 7, 0, 7, 15, 22]) == 54\n",
            "- assert max_sum_subseq([1, 3, 10, 7, 7, 0, 7, 15, 22]) == 54\n",
            "- assert max_s...\n",
            "--------------------------------------------------\n",
            "Task ID: 466\n",
            "Prompt (truncated): Write a function to split a given list into two parts where the length of the first part of the list is given.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return o...\n",
            "Generated Code (truncated): - assert split_two_parts([1,1,2,3,4,4,5,1],3)==([1, 1, 2], [3, 4, 4, 5, 1])\n",
            "- assert split_two_parts(['a', 'b', 'c', 'd'],2)==(['a', 'b'], ['c', 'd'])\n",
            "- assert split_two_parts(['p', 'y', 't', 'h', 'o'...\n",
            "--------------------------------------------------\n",
            "Task ID: 467\n",
            "Prompt (truncated): Write a function to check if the given tuple contains only k elements.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert check_tuples((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47...\n",
            "--------------------------------------------------\n",
            "Task ID: 468\n",
            "Prompt (truncated): Write a function to get a lucid number smaller than or equal to n.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert get_ludic(60) == [1, 2, 3, 5, 7, 11, 13, 17, 23, 25, 29, 37, 41, 43, 47, 53, 59]\n",
            "- assert get_ludic(90) == [1, 2, 3, 5, 7, 11, 13, 17, 23, 25, 29, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 469\n",
            "Prompt (truncated): Write a function to extract the maximum numeric value from a string by using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert extract_max('thisisadull252function') == 252\n",
            "- assert extract_max('thisisadull252function') == 252\n",
            "- assert extract_max('thisisadull252function') == 252\n",
            "- assert extract_max('thisisadull252fu...\n",
            "--------------------------------------------------\n",
            "Task ID: 470\n",
            "Prompt (truncated): Write a python function to check whether the given number can be represented by sum of two squares or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only ...\n",
            "Generated Code (truncated): - assert sum_Square(16) == False\n",
            "- assert sum_Square(12) == True\n",
            "- assert sum_Square(11) == False\n",
            "- assert sum_Square(10) == False\n",
            "- assert sum_Square(9) == False\n",
            "- assert sum_Square(8) == False\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 471\n",
            "Prompt (truncated): Write a python function to remove odd numbers from a given list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert remove_odd([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]) == [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
            "- assert remove_odd([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,2...\n",
            "--------------------------------------------------\n",
            "Task ID: 472\n",
            "Prompt (truncated): Write a function to print check if the triangle is scalene or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ca...\n",
            "Generated Code (truncated): - assert check_isosceles(6,6,15)==False\n",
            "- assert check_isosceles(6,15,15)==True\n",
            "- assert check_isosceles(6,15,20)==False\n",
            "- assert check_isosceles(6,6,6)==True\n",
            "- assert check_isosceles(6,6,6)==False\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 473\n",
            "Prompt (truncated): Write a function to filter a dictionary based on values.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by run...\n",
            "Generated Code (truncated): - assert dict_filter({'Cierra Vega': 175, 'Alden Cantrell': 180, 'Kierra Gentry': 165, 'Pierre Cox': 190},170, 180, 190)=={ 'Alden Cantrell': 180, 'Pierre Cox': 190}\n",
            "- assert dict_filter({'Cierra Vega...\n",
            "--------------------------------------------------\n",
            "Task ID: 474\n",
            "Prompt (truncated): Write a function to find the perimeter of a rombus.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ...\n",
            "Generated Code (truncated): - assert rombus_perimeter(3)==12\n",
            "- assert rombus_perimeter(2)==8\n",
            "- assert rombus_perimeter(1)==4\n",
            "- assert rombus_perimeter(0)==0\n",
            "- assert rombus_perimeter(1)==1\n",
            "- assert rombus_perimeter(2)==1\n",
            "- asser...\n",
            "--------------------------------------------------\n",
            "Task ID: 475\n",
            "Prompt (truncated): Write a function to count number of lists in a given list of lists and square the count.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function ...\n",
            "Generated Code (truncated): - assert count_list([[1, 3], [[6,8], [4,5,8]], [10, 12, 14], [[15,17], [19,20,22]]])==25\n",
            "- assert count_list([[1, 3], [[6,8], [4,5,8]], [10, 12, 14], [[15,17], [19,20,22]]], 1) == 1\n",
            "- assert count_lis...\n",
            "--------------------------------------------------\n",
            "Task ID: 476\n",
            "Prompt (truncated): Write a python function to count minimum number of swaps required to convert one binary string to another.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only ...\n",
            "Generated Code (truncated): - assert min_Swaps(\"1101\",\"1101\") == 0\n",
            "- assert min_Swaps(\"1101\",\"1100\") == 1\n",
            "- assert min_Swaps(\"1101\",\"1101\") == 1\n",
            "- assert min_Swaps(\"1101\",\"1101\") == 1\n",
            "- assert min_Swaps(\"1101\",\"1101\") == 1\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Task ID: 477\n",
            "Prompt (truncated): Write a function to find the longest subsequence such that the difference between adjacents is one for the given array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should...\n",
            "Generated Code (truncated): - assert longest_subseq_with_diff_one([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43...\n",
            "--------------------------------------------------\n",
            "Task ID: 478\n",
            "Prompt (truncated): Write a function to calculate a dog's age in dog's years.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ru...\n",
            "Generated Code (truncated): - assert dog_age(25)==110\n",
            "- assert dog_age(30)==133\n",
            "- assert dog_age(31)==134\n",
            "- assert dog_age(40)==202\n",
            "- assert dog_age(50)==252\n",
            "- assert dog_age(60)==312\n",
            "- assert dog_age(70)==412\n",
            "- assert dog_age(8...\n",
            "--------------------------------------------------\n",
            "Task ID: 479\n",
            "Prompt (truncated): Write a python function to find the maximum volume of a cuboid with given sum of sides.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function a...\n",
            "Generated Code (truncated): - assert max_volume(1, 1, 1) == 1\n",
            "- assert max_volume(1, 1, 1, 1) == 1\n",
            "- assert max_volume(1, 1, 1, 1, 1) == 1\n",
            "- assert max_volume(1, 1, 1, 1, 1, 1) == 1\n",
            "- assert max_volume(1, 1, 1, 1, 1, 1, 1) == 1\n",
            "...\n",
            "--------------------------------------------------\n",
            "Task ID: 480\n",
            "Prompt (truncated): Write a python function to find the minimum of two numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by ...\n",
            "Generated Code (truncated): - assert minimum(1,1) == 1\n",
            "- assert minimum(-1,1) == -1\n",
            "- assert minimum(-1,0) == -1\n",
            "- assert minimum(1,1) == 1\n",
            "- assert minimum(-1,1) == -1\n",
            "- assert minimum(-1,0) == -1\n",
            "- assert minimum(1,1) == 1\n",
            "- a...\n",
            "--------------------------------------------------\n",
            "Task ID: 481\n",
            "Prompt (truncated): Write a function to check if the given string starts with a substring using regex.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and no...\n",
            "Generated Code (truncated): - assert check_substring(\"Hello\", \"Hello\") =='string starts with the given substring'\n",
            "- assert check_substring(\"Hello\", \"world\") =='string doesnt start with the given substring'\n",
            "- assert check_substri...\n",
            "--------------------------------------------------\n",
            "Task ID: 482\n",
            "Prompt (truncated): Write a function to multiply two integers without using the * operator in python.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert multiply_int(7,7)==49\n",
            "- assert multiply_int(1,1)==1\n",
            "- assert multiply_int(1,1)==1\n",
            "- assert multiply_int(1,1)==1\n",
            "- assert multiply_int(1,1)==1\n",
            "- assert multiply_int(1,1)==1\n",
            "- assert multiply_i...\n",
            "--------------------------------------------------\n",
            "Task ID: 483\n",
            "Prompt (truncated): Write a function to calculate the maximum aggregate from the list of tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert max_aggregate([('Juan Whelan',20),('Sabah Colley',30),('Peter Nichols',40),('Juan Whelan',50),('Sabah Colley',60)])==('Juan Whelan', 110)\n",
            "- assert max_aggregate([('Juan Whelan',20),('Sabah Co...\n",
            "--------------------------------------------------\n",
            "Task ID: 484\n",
            "Prompt (truncated): Write a function to find the volume of a cuboid.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ass...\n",
            "Generated Code (truncated): - assert volume_cuboid(1,1,1)==1\n",
            "- assert volume_cuboid(1,1,1)==1\n",
            "- assert volume_cuboid(1,1,1)==1\n",
            "- assert volume_cuboid(1,1,1)==1\n",
            "- assert volume_cuboid(1,1,1)==1\n",
            "- assert volume_cuboid(1,1,1)==1\n",
            "- ...\n",
            "--------------------------------------------------\n",
            "Task ID: 485\n",
            "Prompt (truncated): Write a function to find k number of pairs which consist of one element from the first array and one element from the second array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt...\n",
            "Generated Code (truncated): - assert k_smallest_pairs([1,3,7],[2,4,6],3)==[[1, 2], [1, 4], [3, 2], [7, 6]]\n",
            "- assert k_smallest_pairs([1,3,7],[2,4,6],4)==[[1, 2], [1, 4], [3, 2], [7, 6], [1, 6], [3, 4], [7, 6], [1, 7], [3, 7], [7...\n",
            "--------------------------------------------------\n",
            "Task ID: 486\n",
            "Prompt (truncated): Write a python function to find the element that appears only once in a sorted array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and...\n",
            "Generated Code (truncated): - assert search([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...\n",
            "--------------------------------------------------\n",
            "Task ID: 487\n",
            "Prompt (truncated): Write a python function to check whether the given number can be represented as sum of non-zero powers of 2 or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should ret...\n",
            "Generated Code (truncated): - assert is_Sum_Of_Powers_Of_Two(15) == False\n",
            "- assert is_Sum_Of_Powers_Of_Two(16) == False\n",
            "- assert is_Sum_Of_Powers_Of_Two(17) == False\n",
            "- assert is_Sum_Of_Powers_Of_Two(18) == False\n",
            "- assert is_Sum_...\n",
            "--------------------------------------------------\n",
            "Task ID: 488\n",
            "Prompt (truncated): Write a function to find if the given number is a keith number or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert is_num_keith(201) == False\n",
            "- assert is_num_keith(2017) == True\n",
            "- assert is_num_keith(2016) == False\n",
            "- assert is_num_keith(2015) == False\n",
            "- assert is_num_keith(2014) == False\n",
            "- assert is_num_k...\n",
            "--------------------------------------------------\n",
            "Task ID: 489\n",
            "Prompt (truncated): Write a python function to find the smallest prime divisor of a number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass te...\n",
            "Generated Code (truncated): - assert smallest_Divisor(37) == 37\n",
            "- assert smallest_Divisor(43) == 43\n",
            "- assert smallest_Divisor(47) == 47\n",
            "- assert smallest_Divisor(53) == 53\n",
            "- assert smallest_Divisor(59) == 59\n",
            "- assert smallest_Di...\n",
            "--------------------------------------------------\n",
            "Task ID: 490\n",
            "Prompt (truncated): Write a python function to find the sum of squares of first n even natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and n...\n",
            "Generated Code (truncated): - assert square_Sum(5) == 252\n",
            "- assert square_Sum(6) == 504\n",
            "- assert square_Sum(7) == 896\n",
            "- assert square_Sum(8) == 1536\n",
            "- assert square_Sum(9) == 2304\n",
            "- assert square_Sum(10) == 36864\n",
            "- assert square...\n",
            "--------------------------------------------------\n",
            "Task ID: 491\n",
            "Prompt (truncated): Write a python function to find gcd of two positive integers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases b...\n",
            "Generated Code (truncated): - assert gcd(7,7) == 1\n",
            "- assert gcd(7,7) == 1\n",
            "- assert gcd(7,7) == 1\n",
            "- assert gcd(7,7) == 1\n",
            "- assert gcd(7,7) == 1\n",
            "- assert gcd(7,7) == 1\n",
            "- assert gcd(7,7) == 1\n",
            "- assert gcd(7,7) == 1\n",
            "- assert gcd(7,7...\n",
            "--------------------------------------------------\n",
            "Task ID: 492\n",
            "Prompt (truncated): Write a python function to count the number of rotations required to generate a sorted array.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python func...\n",
            "Generated Code (truncated): - assert count_Rotation([7,8,9,1,2,3],7) == 1\n",
            "- assert count_Rotation([7,8,9,1,2,3],8) == 2\n",
            "- assert count_Rotation([7,8,9,1,2,3],9) == 3\n",
            "- assert count_Rotation([7,8,9,1,2,3],10) == 4\n",
            "- assert count_...\n",
            "--------------------------------------------------\n",
            "Task ID: 493\n",
            "Prompt (truncated): Write a function to convert tuple into list by adding the given string after every element.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert add_str((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,...\n",
            "--------------------------------------------------\n",
            "Task ID: 494\n",
            "Prompt (truncated): Write a function to swap two numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running assert stateme...\n",
            "Generated Code (truncated): - assert swap_numbers(1,2)==(2,1)\n",
            "- assert swap_numbers(1,1)==(1,1)\n",
            "- assert swap_numbers(1,1)==(1,1)\n",
            "- assert swap_numbers(1,1)==(1,1)\n",
            "- assert swap_numbers(1,1)==(1,1)\n",
            "- assert swap_numbers(1,1)==(1...\n",
            "--------------------------------------------------\n",
            "Task ID: 495\n",
            "Prompt (truncated): Write a python function to find the length of the shortest word.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert len_log([\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"...\n",
            "--------------------------------------------------\n",
            "Task ID: 496\n",
            "Prompt (truncated): Write a function to convert the given string of float type into tuple.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert float_to_tuple(\"1.2, 1.3, 2.3, 2.4, 6.5, 7.6, 8.7, 9.8, 10.9, 11.1, 12.2, 12.3, 13.4, 14.5, 15.6, 16.7, 17.8, 18.9, 19.1, 20.2, 20.3, 20.4, 20.5, 20.6, 20.7, 20.8, 20.9, 21.1, 21.2, 21.3, 21....\n",
            "--------------------------------------------------\n",
            "Task ID: 497\n",
            "Prompt (truncated): Write a function that matches a word containing 'z', not at the start or end of the word.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function...\n",
            "Generated Code (truncated): - assert text_match_wordz_middle(\"abc.\")==('Not matched!')\n",
            "- assert text_match_wordz_middle(\"abc.\")==('Not matched!')\n",
            "- assert text_match_wordz_middle(\"abc.\")==('Not matched!')\n",
            "- assert text_match_wor...\n",
            "--------------------------------------------------\n",
            "Task ID: 498\n",
            "Prompt (truncated): Write a python function to find the first natural number whose factorial is divisible by x.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python functi...\n",
            "Generated Code (truncated): - assert first_Factorial_Divisible_Number(7) == 7\n",
            "- assert first_Factorial_Divisible_Number(11) == 11\n",
            "- assert first_Factorial_Divisible_Number(12) == 12\n",
            "- assert first_Factorial_Divisible_Number(13) ...\n",
            "--------------------------------------------------\n",
            "Task ID: 499\n",
            "Prompt (truncated): Write a function to repeat the given tuple n times.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by running ...\n",
            "Generated Code (truncated): - assert repeat_tuples((1, 2, 3, 4, 5), 6) == ((1, 2, 3, 4, 5), (1, 2, 3, 4, 5), (1, 2, 3, 4, 5), (1, 2, 3, 4, 5), (1, 2, 3, 4, 5))\n",
            "- assert repeat_tuples((1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 11) == ((1, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 500\n",
            "Prompt (truncated): Write a function to find the list of lists with maximum length.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases...\n",
            "Generated Code (truncated): - assert max_length([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12, 13, 14, 15]])==(3, [7, 8, 9])\n",
            "- assert max_length([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21...\n",
            "--------------------------------------------------\n",
            "Task ID: 501\n",
            "Prompt (truncated): Write a function to find the lateral surface area of a cone.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases by...\n",
            "Generated Code (truncated): - assert lateralsurface_cone(25,25)==2017.20120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120120...\n",
            "--------------------------------------------------\n",
            "Task ID: 502\n",
            "Prompt (truncated): Write a function to find the maximum difference between available pairs in the given tuple list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python f...\n",
            "Generated Code (truncated): - assert max_difference([(1, 2), (3, 4), (5, 6), (7, 8)]) == 1\n",
            "- assert max_difference([(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)]) == 1\n",
            "- assert max_difference([(1, 2), (3, 4), (5, 6), (7, 8), (9, 10),...\n",
            "--------------------------------------------------\n",
            "Task ID: 503\n",
            "Prompt (truncated): Write a python function to find the cube sum of first n odd natural numbers.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypa...\n",
            "Generated Code (truncated): - assert cube_Sum(5) == 65525\n",
            "- assert cube_Sum(6) == 40320\n",
            "- assert cube_Sum(7) == 362880\n",
            "- assert cube_Sum(8) == 39916800\n",
            "- assert cube_Sum(9) == 479001600\n",
            "- assert cube_Sum(10) == 6227020800\n",
            "- asse...\n",
            "--------------------------------------------------\n",
            "Task ID: 504\n",
            "Prompt (truncated): Write a python function to count lower case letters in a given string.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass tes...\n",
            "Generated Code (truncated): - assert lower_ctr('Hello, World!') == 7\n",
            "- assert lower_ctr('Hello, World!') == 7\n",
            "- assert lower_ctr('Hello, World!') == 7\n",
            "- assert lower_ctr('Hello, World!') == 7\n",
            "- assert lower_ctr('Hello, World!') ...\n",
            "--------------------------------------------------\n",
            "Task ID: 505\n",
            "Prompt (truncated): Write a function to find average value of the numbers in a given tuple of tuples.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not...\n",
            "Generated Code (truncated): - assert average_tuple(((1, 1, -5), (30, -15, 56), (81, -60, -39), (-10, 2, 3)))== [25.5, -18.0, 3.75]\n",
            "- assert average_tuple(((1, 1, -5), (30, -15, 56), (81, -60, -39), (-10, 2, 3)))== [25.5, -18.0, ...\n",
            "--------------------------------------------------\n",
            "Task ID: 506\n",
            "Prompt (truncated): Write a python function to check whether the given two arrays are equal or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not b...\n",
            "Generated Code (truncated): - assert are_Equal([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
            "--------------------------------------------------\n",
            "Task ID: 507\n",
            "Prompt (truncated): Write a python function to find the sum of even factors of a number.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test ...\n",
            "Generated Code (truncated): - assert sumofFactors(12) == 20\n",
            "- assert sumofFactors(15) == 30\n",
            "- assert sumofFactors(25) == 50\n",
            "- assert sumofFactors(27) == 54\n",
            "- assert sumofFactors(30) == 48\n",
            "- assert sumofFactors(40) == 80\n",
            "- assert...\n",
            "--------------------------------------------------\n",
            "Task ID: 508\n",
            "Prompt (truncated): Write a function to find if the given number is abundant or not.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test case...\n",
            "Generated Code (truncated): - assert check_abundant(20) == False\n",
            "- assert check_abundant(25) == True\n",
            "- assert check_abundant(30) == False\n",
            "- assert check_abundant(35) == True\n",
            "- assert check_abundant(40) == False\n",
            "- assert check_ab...\n",
            "--------------------------------------------------\n",
            "Task ID: 509\n",
            "Prompt (truncated): Write a function to find the second smallest number in a list.\n",
            "\n",
            "You are an expert Python programmer, and here is your task: {prompt} You should return only a Python function and not bypass test cases ...\n",
            "Generated Code (truncated): - assert second_smallest([1, 1, -0.5, 0, 2, -2, -2, -2])==-2\n",
            "- assert second_smallest([1, 1, -0.5, 0, 2, -2, -2, -2, -2])==-2\n",
            "- assert second_smallest([1, 1, -0.5, 0, 2, -2, -2, -2, -2, -2])==-2\n",
            "- ass...\n",
            "--------------------------------------------------\n",
            "Saving results to mbpp_results_20250328_190833.csv...\n",
            "Saved 510 results to mbpp_results_20250328_190833.csv\n",
            "Results saved to c:\\Users\\adity\\LayerSkip\\mbpp_results_20250328_190833.csv\n",
            "{'predicted_text': {'saved_to_csv': 'c:\\\\Users\\\\adity\\\\LayerSkip\\\\mbpp_results_20250328_190833.csv'}}\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset mbpp \\\n",
        "       --num_samples 510 \\\n",
        "       --generation_strategy layerdrop \\\n",
        "       --dropout_rate 0.2 \\\n",
        "       --layerdrop_seed 42 \\\n",
        "       --output_dir ./logs \\\n",
        "       --distributed False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: race_m\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on RACE_M with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
            "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
            "\n",
            "Question: We have   _   in the dining hall.\n",
            "A. breakfast\n",
            "B. lunch\n",
            "C. dinner\n",
            "D. supper\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Kids have unbelievable imaginations. We asked one hundred kids how robots might help them learn better. This is what they thought.\n",
            "Roberts can make learning fun\n",
            "Kids dreamed robots would make learning fun. One 9-year-old boy in Germany says, \"When I get home, my robot helps me with my homework. My mother and father came in and said 'no video games now, homework first'. When they saw that I had finished my homework, they'd be surprised\".\n",
            "Robots take care of the dirty work\n",
            "Dirty dishes? No problem. A quarter of kids surveyed imagined that their robots could do chores and boring work so that they might be freed up.\n",
            "Robots are our friends\n",
            "Two-thirds of the kids thought that their robots could be friends. One 10-year-old French boy describes his dream robot: \"He created books for me to read, we played with toy cars. He keeps my secrets. I can tell him anything, and he gives me suggestions.\"\n",
            "Robots are cool\n",
            "An 8-year-old girl in the U.S. imagines that her robot is \"really smart and everyone likes to talk to her. She has a funny voice, but we do not laugh at her.\"\n",
            "\n",
            "Question: The boy from Germany wanted his robot to  _  .\n",
            "A. help him with the homework\n",
            "B. play game spot with him\n",
            "C. surprise his parents\n",
            "D. make fun of him\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Visiting Harvard University\n",
            "For All Visitors\n",
            "Attend an hour-long group information meeting in the Admissions Office  \n",
            "Admissions officers give information and answer questions about the visit. No appointment or registration   is required for families or groups of 20 people or less who wish to visit the university. Groups of more than 20 people should email tours @ fas. Harvard. Edu to plan a visit.\n",
            "Take a tour\n",
            "Take a student-led tour of the university. But the dorms  , academic departments , athletic facilities  and libraries are not included on any of our tours.\n",
            "Attend a class\n",
            "The Admissions Office provides a list of the meeting times and locations of courses held during the academic year that visitors are welcome to attend.\n",
            "Speak with the Harvard teachers\n",
            "Teachers and other staff members are often glad to talk to people who have questions about our programs. It is best to write ahead directly to the office to arrange an appointment.\n",
            "For Seniors Only\n",
            "Eat a meal with Harvard students\n",
            "During the academic year, high school seniors are our guests for one meal in Annenberg Hall, the first-year dining hall, or in one of the House dining halls if accompanied by a House resident.\n",
            "Stay overnight in one of the residence halls\n",
            "Our office can arrange for high school seniors to stay with volunteer student hosts for one night, Monday through Thursday, from October 1st through early March. We need to hear from you by phone (617-495-1551) or by mail at least three weeks in advance for us to be able to confirm your stay with a host.\n",
            "\n",
            "Question: Which of the following activities is NOT available  to all visitors?\n",
            "A. A meeting in the Admissions Office.\n",
            "B. An opportunity  to talk with a teacher.\n",
            "C. A tour of the university.\n",
            "D. A meal with Harvard students.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3333\n",
            "Current Mean Accuracy: 0.3333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Tommy hated school and was always looking for excuses  not to go.If he sneezed, he asked his mother to write a note saying he had a cold.If he had a headache, he asked his mother to take him to the doctor during school hours.\n",
            "He spent more time at home than he did at school.On the days that he did go to school, he looked for excuses to come home early.One morning he came home when the lessons were only half finished.His father was surprised.\n",
            "\"You've come home early,\" he said. \"Is the school closed today?\"\n",
            "\"No, Dad, \" Tommy said - \"It's open. I came home early.\n",
            "\"How did you do that?\" his father asked him. \"What did you say to the teacher?\"\n",
            "\"I told her that I had a new baby brother and that I had to come home and help you . \"\n",
            "\"But your mother has had twins,\" his father said, \"a boy and a girl. You've got a baby brother and a baby sister.\"\n",
            "\"Yes, I know, Dad, \" Tommy said. \"I'm saving up my baby sister for next week \"\n",
            "\n",
            "Question: When he did go to school,he   _  .\n",
            "A. was always later\n",
            "B. tried to leave early\n",
            "C. was always sick\n",
            "D. was very happy\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2500\n",
            "Current Mean Accuracy: 0.2500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
            "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
            "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
            "What could she do now?\n",
            "\n",
            "Question: What would happen if Celina told Joseph the truth?\n",
            "A. Joseph would go on the camping trip himself.\n",
            "B. Joseph's family would be angry with Celina.\n",
            "C. Celina might have trouble with her friends.\n",
            "D. Joseph would be thankful to his classmates.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2000\n",
            "Current Mean Accuracy: 0.2000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
            "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
            "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
            "What could she do now?\n",
            "\n",
            "Question: If Joseph bought a sleeping bag,   _  .\n",
            "A. he would have it for no use.\n",
            "B. everyone else would also buy one\n",
            "C. it would be the best in the class\n",
            "D. Celina would pay for it\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3333\n",
            "Current Mean Accuracy: 0.3333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: A mother and her young son got into a bus in New York City and sat down. The bus conductor  came to them for their money. The mother said, \"I want one ticket  to Central Park, \"and gave him two dollars. The conductor looked at the small boy for a few seconds and then asked him, \"How old are you, young man?\"  The mother just began to speak, but the conductor stopped her, and the boy said, \"I'm four years old at home, and two and a half on buses and trains.\"  The mother felt shamed , so she took another dollar out of her bag and gave the money to the conductor. The conductor gave her one and a half tickets.\n",
            "\n",
            "Question: One day the mother took a bus   _  .\n",
            "A. to a small city\n",
            "B. to get some money\n",
            "C. with her son\n",
            "D. to school\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4286\n",
            "Current Mean Accuracy: 0.4286\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When you look up into the sky at night, have you ever felt that your eyes are playing tricks on   you? It seems that the stars are moving all the time.\n",
            "Actually, there is nothing wrong with your eyes. This twinkling effect is called scintillation  . Scintillation happens because of air movements in the earth's atmosphere  . Light is \"bent  \" when it travels through different parts of the earth's atmosphere. As the air in the earth's atmosphere is moving all the time, the light from the stars looks as if it is moving too.\n",
            "The same thing also happens to things on the ground. On a very hot and shiny day, if you look at the road, the image in the distance is not clear and things move slightly. You can also see the same effect if you drop a rock into water. The rock appears a little unclear under the moving water.\n",
            "This twinkling effect causes a lot of problems for astronomers   since they cannot _ the stars clearly. A telescope   was sent into space so that the air movements in the atmosphere could be avoided  . It took a long time to build the space telescope but finally in 1990, a huge space telescope called the Hubble Space Telescope was successfully sent into space. Since then, astronomers have many important observations that have helped people understand space better.\n",
            ",.  (10)\n",
            "\n",
            "Question: What can you see when you drop a rock into the water?\n",
            "A. The rock gets broken.\n",
            "B. The rock becomes unclear.\n",
            "C. The water becomes much polluted.\n",
            "D. The water does not move anymore.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: The Biggest and the Gentle\n",
            "The elephant is the biggest four-legged animal in the world.It is also the gentlest,but not always!\n",
            "Elephants are like us in some ways.They live for a long time--fifty or sixty years.They can remember things very well.They never forget great sadness or great happiness.When female elephant dies,her daughters and her granddaughters are sad for many months.They stay with the dead body.Then they carry a bit of it away with them.They never forget a dear friend.\n",
            "Elephants are like us,but they are also different.They live in families of females.There will be a few young males a few\"baby boys\".But the females will soon send them away.And elephant family keeps only its daughters,mothers and grandmothers.And its great-grandmothers.\n",
            "The females stay together for fifty,sixty...a hundred years.The older animals look after the younger ones.The mothers teach their daughters and set a good example.\n",
            "And what happens to male elephants?Well,the young males stay with their family.Then the females just send them away.A bull elephant does not often have a friend.He lives apart,away from the family,and often away from other bulls.\n",
            "Sometimes the females call a bull.He can visit them then,and stay for some time.But soon his\"wives\"and sisters send him away again.The females have a very happy family life.What do the bulls think about it?We don't know.\n",
            "\n",
            "Question: When a female elephant dies,the others  _  .\n",
            "A. leave its dead body there\n",
            "B. shed tears together\n",
            "C. take a bit of the dead body away sadly\n",
            "D. bury the dead\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5556\n",
            "Current Mean Accuracy: 0.5556\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Did you notice the number on the book in a library? That number is part of the system used by libraries to organize their collections of books. And it's used in many countries. The number on each book tells you exactly what kind of book it is. This system is also useful for knowing where to go in the library to find a book.\n",
            "In this system, there are ten large groups of books. Each of these groups has its own number, such as 100, 200, etc. So, for example, any books about language will have a number 400. On the other hand, any books about history will have a number 900. So, a number in the hundreds place tells you what general group a book is in. If you find a book that has a number in the 500s, you know it is a book about science.\n",
            "However, science is a big group, so the tens place is used to make a more detailed set of science books. For example, math books are included in the group of science books. Math books all have numbers between 510 and 519. Books about the history of Africa have numbers between 960 and 969.\n",
            "The system uses the ones place to give a more exact limit for the subject of a book. A book on the history of South Africa will have the number 968.\n",
            "As you can see, it is a simple system to use as long as you understand what the numbers mean. With this system, the library can keep its books well organized, and people can easily find the book that they want.\n",
            "\n",
            "Question: A book about math can be found in the same group of books as  _  .\n",
            "A. reference books\n",
            "B. school books\n",
            "C. science books\n",
            "D. art books\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: I am a Chinese boy. My name is Li Ming. I'm a student. In my class, some of the boys like playing football very much. Wu Jun and I are on school football team. And some of them like playing basketball. _ Han Mei and Zhang Hong are on school volleyball team. Each of them has a tennis racket. In a word  , everyone in our class likes sports very much.\n",
            "\n",
            "Question: The girls like playing   _  .\n",
            "A. tennis and basketball\n",
            "B. football and basketball\n",
            "C. tennis and volleyball\n",
            "D. volleyball and basketball\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5455\n",
            "Current Mean Accuracy: 0.5455\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Would you like to adopt an animal? Although this sounds very unusual, some children have done just this. The Natural Zoo has given people the chance to adopt animals by paying for all of its food for one year. One of the animals that needed parents was a young tiger named Brocky. The people at the zoo said that it would cost about $900 a year for the food for Brocky.\n",
            "Not many boys and girls have $900 to spend. That is why several hundred children and grown-ups each have sent a little money to the zoo to help pay for Brocky's food. Some children sent in only a quarter because that was all the money they had. Other children sent in more money than that.\n",
            "Since so many people sent money to the zoo to help pay for Brocky's food, he now will be able to eat as much as he wants. Brocky surely must be a happy tiger to know that he has so many adopted parents. Many children must also be happy to know that they have helped to feed him. It really will be thrilling for those children to go to the Natural Zoo to visit their adopted tiger Brocky.\n",
            "\n",
            "Question: With so many people's money, Brocky now can   _  .\n",
            "A. play with many toys\n",
            "B. live without being hungry\n",
            "C. eat meat every day\n",
            "D. have an air-conditioned room to live in\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5833\n",
            "Current Mean Accuracy: 0.5833\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
            "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
            "\n",
            "Question: What colours does Nancy like?\n",
            "A. Red and blue.\n",
            "B. Red and yellow.\n",
            "C. Green and yellow.\n",
            "D. Green and blue.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5385\n",
            "Current Mean Accuracy: 0.5385\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Snack time is a part of the day for children of all ages. But new research suggests that kids snacking in big groups could be at risk for _ .\n",
            "Scientists from American University looked at the eating behavior of 54 kids between the ages of 2 and 6. At snack time, the scientist watched the amount of food each child ate while they were in groups of either three or nine. According to the study, the more children there are in a group, the more likely they are to eat more. Those in the larger group ate nearly 30 percent more than those in the smaller group, and they actually ate faster.\n",
            "Since this is the first such study in children, scientists are quick to point out the importance of encouraging healthy habits in kids as early as possible.\n",
            "\"If you know kids eat more in large groups, it seems perfect to use this information to keep snack groups small or use small tables,\" says Dr. Jana Klauer, an expert in New York.\n",
            "Smaller groups would allow for a quiet and more relaxing environment-a perfect chance to teach children about food, manners and how to know when they feel full. \"This would have an effect on kids' eating,\" adds Klauer. \"They would slow down and eat less.\"\n",
            "\n",
            "Question: Why do children in smaller groups lose weight?\n",
            "A. Because children in smaller groups eat faster.\n",
            "B. Because children in smaller groups don't like eating.\n",
            "C. Because children in smaller groups don't know about food.\n",
            "D. Because children in smaller groups eat slowly and eat less.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
            "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
            "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
            "\n",
            "Question: What did the white lambs think of the black lamb?\n",
            "A. Friendly.\n",
            "B. Kind.\n",
            "C. Ugly.\n",
            "D. Beautiful.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5333\n",
            "Current Mean Accuracy: 0.5333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: In a small village in England about 150 years ago, a mail coach (    ) was standing on the street . It didn't come to that village often  . People had to pay a lot to get a letter . The person who sent the letter didn't have to pay the postage (     )  , while the receiver had to .\n",
            "\"Here's a letter for Miss Alice Brown , \" said the mailman .\n",
            "\" I'm  Alice Brown , \" a girl of about 18 said in a low voice .\n",
            "Alice looked at the envelope  for a minute , and then handed it back to the mailman .\n",
            "\" I'm sorry I can't take it , I don't have enough money to pay it\", she said .\n",
            "A gentleman standing around were very sorry for her . Then he came up and paid the postage for her .\n",
            "When the gentleman gave the letter to her , she said with a smile , \" Thank you very much ,This letter is from Tom . I'm going to marry him . He went to London to look for work . I've waited a long time for this letter , but now I don't need it , there is nothing in it .\"\n",
            "\" Really ? How do you know that ? \" the gentleman said in surprise .\n",
            "\" He told me that he would put some signs on the envelope . Look ,sir ,this cross in the corner means that he is well and this circle means he has found work . That's good news .\"\n",
            "The gentleman was Sir Rowland Hill . He didn't forgot Alice and her letter .\n",
            "\" The postage to be paid by the receiver has to be changed ,\" he said to himself and had a good plan .\n",
            "\" The postage has to be much lower , what about a penny (    ) ? And the person who sends the letter pays the postage . He has to buy a stamp and put it on the envelope .\" he said .\n",
            "The government accepted his plan . Then the first stamp was put out in 1840 . It was called the \" Penny Black \" . It had a picture of the Queen on it .\n",
            "\n",
            "Question: The girl handed the letter back to the mailman because   _   .\n",
            "A. she didn't know whose letter it was\n",
            "B. she had no money to pay the postage\n",
            "C. she received the letter but she didn't want to open it\n",
            "D. she had already known what was written in the letter\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
            "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
            "\n",
            "Question: Tony is from  _  .\n",
            "A. England\n",
            "B. America\n",
            "C. English\n",
            "D. American\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5294\n",
            "Current Mean Accuracy: 0.5294\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Just as \"Tiger Mom\" leaves, here comes the \"Wolf Daddy\" called Xiao Baiyou. He believes he's the best parent in the world. Some days ago, Xiao Baiyou's latest book about how to be a successful parent came out. He is pretty strict with his four children. Sometimes he even beat them. But the children don't hate their daddy at all. And all of them finally went to Pecking University, one of the top universities in China. So Xiao proudly tells others about his education idea that children need strict rules. In his microblog, he said, \"Come on, want your children to enter Peking University without rules? You must be joking.\" And, \"Leave your children more money, and strict rules at the same time.\"But the \"Wolf Daddy\" way was soon questioned by other parents. Some say that Xiao Baiyou just want to be famous by doing so. The \"Wolf Daddy\" Xiao Baiyou is a 47-year-old Guangdong businessman who deals in luxury goods  in Hong Kong. Unlike many other parents who usually have one child, Xiao has four children. Two of them were born in Hong Kong and two in the US. Some people on the Internet think the reason why his children were able to enter Peking University is because the exam is much easier taken from Hong Kong.\n",
            "\n",
            "Question: As for how to be a parent, Xiao Baiyu thinks   _  .\n",
            "A. children don't need rules\n",
            "B. children need strict rules\n",
            "C. children don't need money\n",
            "D. children need luxury goods\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5556\n",
            "Current Mean Accuracy: 0.5556\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: In today's world many people seem to be hungry for money. Some of them even have lost their lives for it. Money does have a great effect on the poor, but if a person has a rich life, a lot more money doesn't mean more happiness.\n",
            "If money were everything, all millionaires would have true love, real friendship, health and a long life. However, this is not always true.\n",
            "Nothing else is more pleasant than the three words \"I love you\", but can love be bought? I'm afraid not. Love means \"give\", not \" take\". Health and a long life are precious things for every person. Well, can health and a long life be bought with money? The answer is \"No\". Of all the people who live longest in the world, few of them are millionaires. Real friendship can't be bought, either.\n",
            "In a word, where money is _ , money can cause brothers to quarrel, lovers to hate, strangers to fight and so on. No matter how much money you have, _ is still not enough to make you a happy person if you have no one to laugh with and no one to cry for.\n",
            ",\n",
            "\n",
            "Question: What does the passage mainly tell us?\n",
            "A. Money is as important as true love.\n",
            "B. Money isn't necessary.\n",
            "C. Money is important, but not the most important.\n",
            "D. Money can cause some problems.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5789\n",
            "Current Mean Accuracy: 0.5789\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: In some places around China,the junior high school graduates have to take a P. E. test. The full marks are usually 30 points and it counts for much in the senior high school entrance exam.\n",
            "In Nanjing the test is held in April. Students have the test in their own schools. Each student is tested on three sports. They can choose long jump, basketball dribbling   or volleyball. The _ is for boys and girls can choose the sit-up. Both boys and girls must skip  in the test.\n",
            "Most students find the test easy and more than 90%of them can get full marks. That's because they have been training for it during the three whole years. Students in Junior Three usually do lots of practice in P. E. classes. The training makes the test easier than it seems to be.\n",
            "Students in Nanjing don't need to run a lot for the test, but students in Beijing must do lots of running for the test. Running is one of the sports in test. So in P. E. classes, they usually run a lot. Sometimes they have to run 3,000 meters in one class. Most teachers and parents welcome the P. E. test. They say it helps students build up their health and it's really useful.\n",
            ",.\n",
            "\n",
            "Question: The P. E. test in Nanjing includes all of these sports except   _  .\n",
            "A. skipping\n",
            "B. basketball\n",
            "C. football\n",
            "D. volleyball\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5500\n",
            "Current Mean Accuracy: 0.5500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Dear Boris,\n",
            "Thanks for your nice letter.\n",
            "After I had spent a week with my English family, I slowly began to understand their English a little better. It's very different from what I learned at school! Students in my group are from different cities of Britain and their dialects   are different too! Some of their accents   are quite strong and they also have their own words and expressions.\n",
            "But it's not the language that's different and surprising. Before I came to England I had thought that fish and chips were eaten every day. That's quite wrong! I get rather mad now when I hear all the foolish words about typical   English food.\n",
            "I had expected to see \"London fog\". Do you remember our texts about it? We had no idea that most of this 'thick fog' disappeared many years ago when people stopped using coal in their homes. But the idea to speak about the weather was very helpful. The weather in London is really changeable.\n",
            "On the other hand habits are different. People tell me what is typically British here in London is not always typical in Wales or Scotland. Local habits and traditions are not the same as what we knew.\n",
            "But what is ordinary for all British is that they follow traditions. Probably Britain has more living signs of its past than many other countries. And people have always been proud of having ancient buildings in capitals, big cities and the countryside.\n",
            "I will tell you more about Britain in my other letters.\n",
            "Love from Britain,\n",
            "Peter\n",
            "\n",
            "Question: The British people like to talk about weather because   _  .\n",
            "A. there is thick fog in London\n",
            "B. they like the weather in Britain\n",
            "C. the weather changes a lot\n",
            "D. it can be helpful\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5238\n",
            "Current Mean Accuracy: 0.5238\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Once a traveller came into a village which was suffering from hunger. The villagers asked him to leave, for they feared he wanted them to give him food. They told him that there was no food. The traveller explained that he didn't need any food and that, in fact, he was planning to make a soup to share with them instead. The villagers watched suspiciously as he built a fire and filled a pot with water With great ceremony , he pulled a stone from a bag, and dropped the stone into the pot of water. After a moment, he smelt the soup and shouted with excitement, \"How delicious the soup is!\" As the villagers began to show interest, he mentioned how good the soup would be with just a little cabbage in it. A villager brought out a cabbage to share. This episode  repeated itself until the soup had cabbage, carrots, onions, and beets--indeed, a full pot of soup that could feed everyone in the village was ready. This story describes when there are not enough resources , humans will store things. We do not want to share. The story of stone soup helps us realize that, in doing so, we often prevent ourselves and everyone else from having a feast .The meaning of this story goes far beyond food. We keep to ourselves ideas, love, and energy, thinking we will be richer, but in fact we make the world, and ourselves, poorer. The traveller was able to see that the villagers were holding back, and he had the ability to inspire  them to give. In this way, they created a large meal that none of them could have created alone. Are you like one of the villagers? If you come forward and share your gifts, you will inspire others to do the same. The reward is a feast that can feed many.\n",
            "\n",
            "Question: The writer mainly wants to tell us that .\n",
            "A. storing things in hard times is human nature\n",
            "B. a good leader is very necessary in hard times\n",
            "C. skills are needed to inspire people to share with others\n",
            "D. sharing is more important than keeping things to oneself\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5455\n",
            "Current Mean Accuracy: 0.5455\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Why do we come to school? Most of us may say we come to school to study. But to study needs a right way, or you either waste the time or the money. The following are the ways for studying.\n",
            "The best time for reading is morning. In the morning the air is fresh and the mind is clear. For that reason we can get good results.\n",
            "In studying we must have patience . If we have not known a text well, we must read it again. We should not read the next one until we have learned the first one well.\n",
            "When we are studying, we must put our hearts into the books, or we can get nothing from the books while we are reading.\n",
            "We must always ask \"whys\". If it is not well understood, write it down and ask our teachers or our parents, brothers or friends. In any possible way, we must know it completely and what we have learned can be used well and made better.\n",
            "Though there are many ways for studying, yet what I have said above will be enough if we can keep them in heart and do so.\n",
            "\n",
            "Question: While reading we can't get anything from the book if we   _  .\n",
            "A. read very fast\n",
            "B. read in the afternoon\n",
            "C. don't read it again\n",
            "D. can't put our hearts into it\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5652\n",
            "Current Mean Accuracy: 0.5652\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
            "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
            "\n",
            "Question: Tony comes to China with  _  .\n",
            "A. his father\n",
            "B. his mother\n",
            "C. his father and mother\n",
            "D. his friends\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5833\n",
            "Current Mean Accuracy: 0.5833\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: In many countries, holidays are important parts in people's life. Let's show some countries to you.\n",
            "America\n",
            "American people's holidays are flexible ( ). They can use up their holidays once, and they can also use them up a few times. During the holidays, they still get money.\n",
            "Canada\n",
            "Many people in Canada can rest three days a week. They have all kinds of activities   for holidays. They may go fishing, boating or mountain climbing. Also, they have long holidays. They may go to the beach to spend a sunny winter holiday. Like American people, Canadians also get money during the holidays.\n",
            "France\n",
            "People in France are very good at enjoying life. They have a 6-week holiday every year, and they work less than 40 hours a week.\n",
            "\n",
            "Question: Which of the following activities is not mentioned in the passage?\n",
            "A. Go fishing.\n",
            "B. Go boating.\n",
            "C. Go skating.\n",
            "D. Go mountain climbing.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
            "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
            "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
            "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
            "\n",
            "Question: What does the user mean by saying \"After 14 days of detention, Ko's acting skills grew a lot\"?\n",
            "A. He thinks Ko is still a good actor.\n",
            "B. He supports Ko no matter what happened.\n",
            "C. He doesn't trust what Ko said.\n",
            "D. He thinks Ko has trained hard and improved his acting skills.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6154\n",
            "Current Mean Accuracy: 0.6154\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Usually, students are not encouraged to run or jump around in the corridor  . However, students in a British grammar school really enjoy running on the corridor tiles   and their teachers even encourage them to do that.\n",
            "Why? It is because the corridor was built with special kinetic   tiles. When students jump on the tiles, electricity will be produced. After one year, the electricity produced from the tiles can fully charge 853 mobile phones or power  an electric car to drive seven miles. It's amazing, isn't it?\n",
            "The corridor tiles are really a brilliant invention. Students can not only play on the corridor, but also help power the lights in their school corridors and other equipment in their classrooms. Besides, this is a good way to teach students to be creative. They will be _ to be scientists, inventors and engineers in the future to find clean energy for all humans.\n",
            "The inventor of the magic corridor tiles is Laurence Kemball-Cook. He was once a student in this school. Now, he is CEO of his own company. The corridor tiles are not Laurence's only invention. He has also invented a special dance floor, which can be used at music festivals. It allows dancers to charge their mobile phones while they are dancing on the dance floor.\n",
            "\n",
            "Question: After one year, the electricity produced from the tiles can provide enough energy for   _  .\n",
            "A. over 800 mobile phones\n",
            "B. all the lights of the school\n",
            "C. an electric car to drive 70 miles\n",
            "D. the lights and other equipment in their classrooms.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6296\n",
            "Current Mean Accuracy: 0.6296\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: There was a new maths teacher and some new students in the school. One of the new students named Karl was very _ . The other students tried to explain   numbers to him, but he didn't understand.\n",
            "Before Karl arrived, maths was the most boring lesson of all. Now it was great fun. The children would listen to Karl and correct his mistakes. They all wanted to be the first to find his mistakes, and then tried to think up the best ways to explain them.\n",
            "But little Lewis was sure that Karl felt sad and wanted to talk with him. So, one day, he decided to walk after Karl after school. Lewis was sure he would see him crying. On the way home, Karl walked a few minutes to a park, and there he waited for someone to meet him...\n",
            "It was the new teacher!\n",
            "They went off, hand in hand. Lewis could hear them talking about maths. And that stupid Karl knew everything about it, and even much more than anyone else in the class!\n",
            "\n",
            "Question: Which lesson was the most boring of all before Karl arrived?\n",
            "A. Chinese.\n",
            "B. English.\n",
            "C. Maths.\n",
            "D. Music.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6429\n",
            "Current Mean Accuracy: 0.6429\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Some women are talking about the problems of getting old.\n",
            "One woman says, \" Sometimes I stand in front of the bag with an egg. But I can't remember _ I need to put it in or get it out to make bread.\"\n",
            "\"Yes, I have the same problem,\" the second woman says. \"Sometimes I stand on the stairs . But I can't remember whether I am going on my way up or down.\"\n",
            "\"Well, I don't have that problem,\" the last woman says, keeping knocking  on the table.\n",
            "The other two women ask, \"Why are you knocking on the table?\"\n",
            "\"Sorry, I ?don't know. Someone is knocking at the door ,isn't\n",
            "It? Let me see who it is,\" the last woman says.\n",
            "\n",
            "Question: Whose problem is the most serious   in the story?\n",
            "A. The first woman.\n",
            "B. The second woman.\n",
            "C. The third woman.\n",
            "D. The fourth woman.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6552\n",
            "Current Mean Accuracy: 0.6552\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
            "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
            "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
            "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
            "\n",
            "Question: Little Mike went to the park and   _  .\n",
            "A. played with pigeons\n",
            "B. met an old lady\n",
            "C. fed pigeons\n",
            "D. saw a friend of his grandma's\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When someone says, \"Well, I guess I'll have to face the music\", it doesn't mean that he is going to hear a singer. It is something far less happy, as you are called in by your leader to explain why you did this and did that or why you did not do this or that.\n",
            "At some time or another, every one of us has to \"face the music\", especially as children. We can all remember father's angry words \"I want to talk to you.\" And only because we did not listen to him. What a bad thing it was!\n",
            "In the middle or at the end of every term, we students have to \"face the music\". The result of the exam will decide whether we will face the music or not. If you got a \"D\" in the exam, that means parents' cold faces and the contempt  of the classmates.\n",
            "\"To face the music\" is well-known to every American, young or old. It is at least 100 years old. It really means that you have to do something, no matter how terrible the whole thing might be, because you have no choice.\n",
            "\n",
            "Question: Which of the following is wrong?\n",
            "A. \"To face the music\" is well-known in the US.\n",
            "B. \"To face the music\" has a history of more than 100 years.\n",
            "C. The young Americans know the meaning of \"to face the music\".\n",
            "D. Only the old in the US know the meaning of \"to face the music\"\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6452\n",
            "Current Mean Accuracy: 0.6452\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: It is very important for children to get to school safely and on time every day. Luckily, there is a new program called Free Home to School Transport . It gives children free rides to school. But to enjoy the free trip. Children have to qualify .\n",
            "Children can take free home to school transport if they:\n",
            "*are between 5 and 16 years old\n",
            "*are going to the nearest school\n",
            "*live far away from school\n",
            "No matter how far away children live from school, they Can take the free transport if they have walking problems or there is no safe road for them. A safe road usually has crossings, lights and should be clean.\n",
            "Also, there are still free home to school _ for children in poor families and children with special educational needs, you can find out more on the Internet and see if your children are qualified.\n",
            "\n",
            "Question: According to the passage, it is very important for children not to be   _  for school every day.\n",
            "A. late\n",
            "B. away\n",
            "C. early\n",
            "D. ill\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6250\n",
            "Current Mean Accuracy: 0.6250\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
            "\n",
            "Question: They work on   _  .\n",
            "A. weekends\n",
            "B. Friday\n",
            "C. Sundays\n",
            "D. weekdays\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6364\n",
            "Current Mean Accuracy: 0.6364\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Kitesurfing as a water sport began in the 1980s, but didn't get popular until the end of last century. It is also known as kiteboarding, and in some European countries as flysurfing. Kitesurfing works through wind power  by using a large kite to pull a rider on the water at high speed.\n",
            "At first, kitesurfing was a difficult and dangerous sport. Now it is becoming easier and safer because of the safer kite design. For an able and strong person, kitesurfing can be a very fun, extremely exciting sport, just like skating on the water with a feeling of flying. It has become more and more popular.\n",
            "Compared with other water sports, kitesurfing is easier to learn. A beginner can understand how to operate the kite with 5--10 hours of training. And anybody aged from 13 to 65 can learn. It is not expensive to get the equipment for kitesurfing, which costs $1,000 to 82,500. Training lessons _ from $200 to $500 for two or three hours. With the development of its equipment progress, kitesurfing is becoming even safer. After some training, you can enjoy its excitement and challenging feeling.\n",
            "With the rising popularity of kitesurfing, most major seaside cities have kitesurfing clubs. In China, Xiamen is the only place that has the kitesurfing club, which provides professional kitesurfing training and equipments.\n",
            "\n",
            "Question: The most important reason for the popularity of kitesurfing is that   _  .\n",
            "A. its price is getting lower and lower\n",
            "B. more and more people are enjoying its excitement\n",
            "C. its equipment progress makes it easier and safer\n",
            "D. all people can learn and take part in it\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6471\n",
            "Current Mean Accuracy: 0.6471\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
            "\n",
            "Question: In the south of China,many people go to work   _  .\n",
            "A. by plane\n",
            "B. on foot\n",
            "C. by boat\n",
            "D. by ropeway\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6571\n",
            "Current Mean Accuracy: 0.6571\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Where are the animals having the sports meeting?\n",
            "A. In the forest\n",
            "B. In a park\n",
            "C. In a zoo\n",
            "D. In a school.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
            "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
            "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
            "\n",
            "Question: Why do people go and live in valleys near rives ?\n",
            "A. The temperature isn't too low in winter.\n",
            "B. The resources like oil can bring them much money.\n",
            "C. People can make their living by catching and selling fish.\n",
            "D. It's easier for people to grow plants or keep animals.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6486\n",
            "Current Mean Accuracy: 0.6486\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Last Sunday afternoon, I was having dinner in a restaurant when my friend Poor came in. Poor is working in a bank and is quite rich, but he is always borrowing money from his friends and never pays it back. Poor saw me and came to sit at my table. He had never borrowed any money from me. When he was eating, I asked him to lend me two dollars. To my surprise, he gave me the money at once.\"I have never borrowed any money from you,\"Poor said,\"So you can pay for my dinner.\"\n",
            "Read the passage and choose the best answers.(,. )\n",
            "\n",
            "Question: The story happened    _    .\n",
            "A. at home\n",
            "B. in a restaurant\n",
            "C. in a bank\n",
            "D. in an office\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6316\n",
            "Current Mean Accuracy: 0.6316\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello! My name is Zhang Fei. I am Chinese. I am twelve. I'm in No.1 Middle School in Nanjing. This is my friend. His name is Tony Green. He is an English boy .He is twelve. He and I are in the same  class. Our classroom is next to  the teachers' office .We have Chinese and English lessons  every day. Our English teacher is Mr. Read. He is English but he can speak Chinese. Our Chinese teacher is Mr. Ding. They are good teachers, and they are our friends, too\n",
            "\n",
            "Question: Mr. Read is Zhang Fei's  _\n",
            "A. English teacher\n",
            "B. Chinese teacher\n",
            "C. father\n",
            "D. classmate\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  A\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6154\n",
            "Current Mean Accuracy: 0.6154\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: South Korean stars shined brightly at the Opening Ceremony of the 17th Asian Games held here on Friday, Sept. 19 in Inchen .\n",
            "Many stars gave shows during the welcoming performance.The most famous K-pop boy group, EXO, performed two songs on stage.Famous actors followed to show up on stage, including Jang Dong-gun, Hyun Bin, and Kim Soo-hyun.Lee Young-ae, the South Korean actress known for volunteering, was the last torchbearer  and lighted the cauldron  with two children.\n",
            "After the lighting of the flame, 16 more minutes of other K-pop performances were held. JYJ sang the theme song 'Only One' and Psy and Chinese pianist Lang Lang finally performed \"Gangnam Style\" with the 60,000-strong audience.\n",
            "\n",
            "Question: _   lighted the cauldron at last.\n",
            "A. Jang Dong-gun\n",
            "B. Hyun Bin\n",
            "C. Kim Soo-hyun\n",
            "D. Lee Young-ae\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6250\n",
            "Current Mean Accuracy: 0.6250\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
            "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
            "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
            "She understood that she hadn't worn the hair clip to school at all.\n",
            "\n",
            "Question: Which of the following sentence is true?\n",
            "A. The girl is not as beautiful as other girls.\n",
            "B. Nobody liked the girl.\n",
            "C. The girl's classmates thought she was more beautiful than before with the hair clip.\n",
            "D. The girl wanted to be more beautiful, so she decided to wear the hair clip.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6098\n",
            "Current Mean Accuracy: 0.6098\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When my wife left this world, I chose to travel in Antigua looking for a peaceful place to rest my old body. Not quite old and weak, I felt I wanted something more than the usual hotel room with 24-hour room service.\n",
            "I decided this year to try something completely new and booked myself a private holiday home in Antigua. This was the best decision I had ever made, as there was plenty to do, plenty to see and lots of lovely restaurants to visit. There was a private swimming pool, and a cool, wide yard where I ate my breakfast most mornings.\n",
            "Antigua has to be one of the loveliest places on earth to spend a holiday. The bright blue sea and the endless blue around the beach areas proved to be an excellent place for me to spend the long afternoons.\n",
            "I had to hurry to do what I wanted to do before the holiday came to an end. I managed to visit the Sugar Mill and Shirley Heights on my last two days and yet found myself wondering whether I could extend for a few more days.\n",
            "I rented a boat and came home after a day's sailing, refreshed, looking forward to dinner. Everything is so pleasant on these beautiful islands, swept by the trade winds and warmed by the sun for so many summer months. The food just tasted better to me, perhaps because I was having such a great holiday. There was always someone to have a drink with---- that's what I liked most.\n",
            "\n",
            "Question: The passage is most likely to be taken from a part of   _  .\n",
            "A. a tour guide\n",
            "B. a travel diary\n",
            "C. a student's report\n",
            "D. a health report\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6190\n",
            "Current Mean Accuracy: 0.6190\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
            "\n",
            "Question: From the passage, we know   _   .\n",
            "A. Jim and Andy like seeing movies\n",
            "B. Jim and Andy like helping others\n",
            "C. Jim and Andy want to be actors\n",
            "D. the four people in the story become friends after that\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6047\n",
            "Current Mean Accuracy: 0.6047\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Dr. Sharon M. Draper is an excellent teacher as well as a successful writer. She is a woman of achievements.\n",
            "She had been honored  as the National Teacher of the Year, is a five-time winner of the Coretta Scott King Literary Awards, and is a New York Times bestselling writer. Tears of a Tiger has received many awards. It was one of the top 100 books for young adults.\n",
            "She was chosen as Ohio's Outstanding High School Language Arts Educator, Ohio Teacher of the Year, and as a NCNW Excellence in Teaching Award winner.\n",
            "She is a Milken Family Foundation National Educator Award winner.\n",
            "She is a YWCA Career Woman of Achievement, and is the recipient  if the Dean's Award from Howard University School of Education.\n",
            "5 years ago she was named Ohio Pioneer in Education by the Ohio State Department of Education, and received the Beacon of Light Humanitarian Award, as well as the Doctor of Laws Degree from Pepperdine University.\n",
            "She has been honored at the White House six times, and was chosen as one of only four writers in the country to speak at National Book Festival Gala in Washington, D.C. Her book Copper Sun has been chosen by the US State Department and the International Reading Association as the United States novel for the international reading project. Students in the US, Nigeria, and Ghana are reading the book and sharing the ideas.\n",
            "She has worked all over the United States, as well as in Russia, Ghana, Togo, Kenya, Ethiopia, Bermuda, and Guam, spreading the word about the power of successful teaching and excellence in education.\n",
            "She became known when she won first prize in a literary  competition. She was given $5000 and her short story, One Small Torch, came out. Besides her short stories, poems, articles can often be read in literary journals . Her books are also very popular in America, too. Here are some:\n",
            "We Beat the Street (Dutton, 2005)\n",
            "Copper Sun (Simon and Schuster, 2006)\n",
            "Fire from the Rock (Dutton, 2007)\n",
            "Just Another Hero (Simon and Schuster, 2009)\n",
            "Out of my Mind (Simon and Schuster, 2010)\n",
            "\n",
            "Question: The passage is mainly about   _  .\n",
            "A. Draper's achievements\n",
            "B. Draper's experience\n",
            "C. Draper's character\n",
            "D. Draper's effort\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5909\n",
            "Current Mean Accuracy: 0.5909\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Music is an important part in our life. We may feel boring without music. Today when you go to stores, stations, restaurants and other places, do you notice music playing at any of these places? The answer must be \"Yes\". And you might even hear music in an office or on a farm.\n",
            "I like many kinds of music. Classical music is great. Rock music is fast. Light music is relaxing. But I like folk music best. It sounds very beautiful. It can bring me into the dream land. It can make me relax and forget all the problems. It makes me learn better and helps me to be more active. It is true that I learn better when I am relaxed.\n",
            "Music can also influence  people's behavior . Classical music makes people feel rich . When a restaurant plays classical music, people spend more money on food and drinks. When the restaurant plays modern music, people spend less money. Without music, people spend evenless. Restaurants can make more money in this way.\n",
            "\n",
            "Question: Which type of music below can make the writer relax?\n",
            "A. Light music.\n",
            "B. Folk music.\n",
            "C. Rock music.\n",
            "D. Pop music.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Which of the following is NOT right?\n",
            "A. The elephants and lions are playing soccer.\n",
            "B. Some pandas are watching the soccer game.\n",
            "C. A dolphin and a penguin are swimming in the pool.\n",
            "D. A giraffe is eating apples under the trees\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5870\n",
            "Current Mean Accuracy: 0.5870\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Kinsale may be one of the smallest towns in Southern Ireland, and it's also one of the most famous towns. It is well known for its wonderful fish restaurants. Some of the best known chiefs in the world have practiced in the restaurants there. The town itself is very beautiful in Southern Ireland by the sea. Here it is cooler in summer than other island towns. A big building overlooks the town and it is one of the most beautiful in the whole country. To the north of the town there is a high mountain standing in the country. The town is very beautiful, with its many craft shops and narrow cobbled streets. Most travelers visit Kinsale for its fish restaurants, which are family owned. This means that the service is better than that in other restaurants. People are more welcoming there than those anywhere else. The food may be expensive but you'll have one of the most pleasant evenings in your life there. So go ahead and visit Kinsale.\n",
            "\n",
            "Question: The food in the restaurants may be   _  .\n",
            "A. cheap\n",
            "B. expensive\n",
            "C. salty\n",
            "D. spicy\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5957\n",
            "Current Mean Accuracy: 0.5957\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Most People don't like mice, but they love one mouse -- Mickey Mouse. In their mind, this mouse is their favourite animal. About 70 years ago, an American man called Walt Disney created  a cartoon mouse for films. He named this mouse Mickey Mouse. From the beginning, Mickey Mouse is a clean mouse. He always does many interesting things. That's why many children and people love him. He makes them happy and _ . In the film, Mickey Mouse also has a lot of friends, for example, Donald Duck and Pluto. Donald can do many things that Mickey cannot. Pluto is a dog. He always does foolish things and makes foolish mistakes. Many children like these cartoon animals, but they like Mickey most because the mouse is a star of beauty and wisdom .\n",
            "\n",
            "Question: Many children and people like Mickey Mouse because  _  .\n",
            "A. He never makes mistakes\n",
            "B. He is like a real mouse.\n",
            "C. He always does many interesting things\n",
            "D. He has many friends.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6042\n",
            "Current Mean Accuracy: 0.6042\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: October is getting closer and it also means that the year of 2014 is coming to an end. \"Hooray! It's a holiday!\" While you are thinking of putting textbooks aside and playing video games, let's take a look at what children in other continents usually do during their holidays.\n",
            "Children in America don't have much homework to do. They keep themselves busy by playing camp games. A parent says, \"My daughter Shirley usually attends different camps. We don't ask her to spend plenty of time on maths problems or spelling tests.\"\n",
            "Children in Australia take partin activities on over twenty different themes  . They learn painting, dancing, singing, history, culture and so on. Parents can _ their kids to enjoy the learning process and to build a closer relationship with them.\n",
            "These are what African kids do: build a boat, have a camel race, make a drum and make a rag   football. Don't you think it is interesting that kids in other places have no idea how to make a drum, but kids in Africa do?\n",
            "Plan your holiday well and try what you want to try. Make a good plan and you will have a lot of fun.\n",
            "\n",
            "Question: What is the purpose of this passage?\n",
            "A. To advise kids to make holiday plans.\n",
            "B. To introduce some good holiday camps.\n",
            "C. To encourage kids to make friends with parents.\n",
            "D. To show the importance of doing homework during holidays.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5918\n",
            "Current Mean Accuracy: 0.5918\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
            "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
            "\n",
            "Question: There are   _   classrooms in Betty's school?\n",
            "A. 12\n",
            "B. 14\n",
            "C. 24\n",
            "D. 34\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Mr. Yang is a doctor. He cares a lot about not only others' health but also his own. He controls( )his weight carefully. To him, _ is the most important thing to do if one wants to enjoy good health.\n",
            "Mr. Yang controls his weight in two ways: exercising and not eating much. As a doctor. Mr. Yang is too busy to go to the gym. He exercises by getting off the bus one or two stops early and walking the rest of the way to his office.\n",
            "Besides, he doesn't eat much. Mr. Yang has a special habit. When he buys a belt, he asks the salesperson to punch a hole in the belt at 90cm from the buckle end of the belt, so that he ca always remind  himself. He will stop eating if he feels the belt a little too tight . Mr. Yang thinks exercising doesn't work as well as eating less.\n",
            "\n",
            "Question: Which of the following is true?\n",
            "A. Mr. Yang takes exercise at the gym.\n",
            "B. Mr. Yang walks all the way to work.\n",
            "C. Mr. Yang uses a belt to control how much he eats.\n",
            "D. Mr. Yang thinks exercising is better than eating less in controlling wight.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6078\n",
            "Current Mean Accuracy: 0.6078\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Tony, 18. a member of an anti-tobacco group, he says, \"Kids feel that everyone around them smokes.\" Tony wants kids to realize that most people don't smoke. He also wants to tell them that smoking doesn't make one look cool. Two national studies show that teenage smoking is down. Still, there is work to be done.\n",
            "Smoking is an unhealthy habit. It can cause heart disease, lung cancer and other serious illnesses. Just being around cigarette smoke can make you sick.\n",
            "In the 1990s, all 50 states went to court to fight tobacco companies. The states won money from the companies. It helps to pay for anti-smoking groups, but the money is not enough.\n",
            "Each day, about 4,000 kids light up for the first time. \"We have to do a better job of stopping kids from smoking,\" says Husten. Ads that tell ugly facts about smoking help to change minds. Setting smoke-free areas in public places works too. Just this month, a California town _ smoking in all public places, such as schools, shopping malls and libraries. It may be bad news for smokers. Health experts say that they will fight until all Americans get the message.\n",
            ",.\n",
            "\n",
            "Question: The states use the money that they won from tobacco companies to  _  .\n",
            "A. pay for anti-smoking programs\n",
            "B. sell more cigarettes\n",
            "C. win more court cases\n",
            "D. build more schools\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6154\n",
            "Current Mean Accuracy: 0.6154\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello! My name is Kitty. I want to talk about my home town today.\n",
            "My home town is small but pretty. It's about two hours away from London by train. In the centre of the town there is a small lake. There are lots of trees and flowers around the lake. My parents often walk around the lake at the weekend. The air in my home town is very fresh   and clean.\n",
            "There are two schools in my home town, one primary school and one secondary school. I study in the secondary school and my younger sister studies in the primary school. I often ride my bike to school.\n",
            "I usually go to the youth centre to learn drawing with my sister on Friday afternoons. I like going shopping at the weekend. There are two big shopping malls there.[:Zxxk.Com]\n",
            "\n",
            "Question: There is  _  in the centre of the town.\n",
            "A. a primary school\n",
            "B. a secondary school\n",
            "C. a small lake\n",
            "D. a shopping mall\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6038\n",
            "Current Mean Accuracy: 0.6038\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: On February 9 th,2013,Sarah Darling was walking along the street when she met a homeless man named Billy Ray Harris.She reached into her change purse,emptied out all the coins she had and gave them to the homeless man.Neither of them realized that this small generous act would change their lives.\n",
            "Sarah didn't realize that she had given Billy not only all her change but also her diamond ring that she had put in her change purse earlier until the following morning.She and her husband,Bill Krejci,rushed to see if they could find Billy.The homeless man was not only in the same place,he also immediately returned the ring.The grateful couple paid him back for his honesty by emptying out their pockets of all the money they had.\n",
            "Bill Krejci,a web designer,felt that he needed to do something more for this amazingly\n",
            "honest man.So on February 18th,he set up a special page to raise money for him.In just four days,Billy received over $ 85,000 and there seems to be no end yet.\n",
            "That is not enough.Billy is 1iving with a person who is generous instead of living in the streets.And that's not all--thanks to the news report,he got together again with his older brother,Edwin Harris who he had been unable to find for 27 years.\n",
            "All the good luck is just because Billy did the right thing--returning something that did not belong to him.\n",
            "\n",
            "Question: When did Sarah realize that she had also given Billy her diamond ring?\n",
            "A. On February 9 th,2013.\n",
            "B. On February 10th,2013.\n",
            "C. On February 18th,2013.\n",
            "D. On February 22nd,2013.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5926\n",
            "Current Mean Accuracy: 0.5926\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Joe, an outgoing girl, is from a rich family. Therefore she can afford almost everything. But Joe's parents are too busy to spend enough time with her, which makes Joe more than lonely. So, she always goes to WeChat. On WeChat, she can do a lot of things like buying things, reading articles, and making friends with those she either knows or not.\n",
            "She uses the name Linda on WeChat and has made a lot of friends there. Last year Joe made a foreign friend on WeChat. Her name was Catherine and she lived in Sydney. Catherine once sent a picture of \"herself\": a tall, good-looking young woman with big eyes. Catherine and Joe were both interested in rock music and modern dance. So, they liked each other very much.\n",
            "When Joe's father told her that he was meeting a client in Sydney this summer, she went with him to give Catherine a surprise for her birthday. When Joe came to Catherine's house in Sydney, she found that her foreign \"girlfriend\" was a ten-year-old boy named Jim! What a surprise!\n",
            "\n",
            "Question: What is the real name of Joe's \"girlfriend\"?\n",
            "A. Catherine\n",
            "B. Joe\n",
            "C. Jim\n",
            "D. Linda\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: More and more parents leave their homes and come into the big cities to make money. But their children can't go with them because their children have to go to school in their hometown. They are called home-left children. The problems of home-left children become more and more serious. And it becomes a big _ of our society. The main problem is that some home-left children become very lonely when they don't have their parents' love. And they are too young to tell right or wrong in many things. So they are fooled very easily by others.\n",
            "Xiao Mei , a 14-year-old girl, is a home-left child. Her parents are both in Shanghai. She is in her hometown with her grandpa. She likes playing games on the Internet. Her parents and grandpa only give her money and food. They hardly ever care for her studies. One day, she had no money to pay for the games in the Net bar. So she stole some money from her neighbor. Just at that time, Xiao Fang, a 9-year-old girl saw it. Xiao Mei was afraid that Xiao Fang would tell others about it. She cut Xiao Fang's throat with a knife, and then she went to school just like nothing happened. Luckily, Xiao Fang was saves by doctors. When she opened her eyes and wrote the fact to the policeman with a pencil, everybody was very surprised. This sad story reminds the parents to care for their children no matter how busy they are.\n",
            "Are you one of the home-left children? What do you need from your parents? Food, money or love? I think most children need love mostly. Let's care for the group together.\n",
            ",A, B, C, D,. 5,2,10\n",
            "\n",
            "Question: What does Xiao Mei only get from her parents?\n",
            "A. Clothes.\n",
            "B. Love.\n",
            "C. Money and food.\n",
            "D. Computers.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6071\n",
            "Current Mean Accuracy: 0.6071\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Have you heard of EXO? EXO is a Chinese-South Korean boy band with 12 people. They are in two teams: EXO-M and EXO-K. There's even a \"competition\" between the two teams. \"I will not call it a competition. It's always in good fun,\" said Sehun of EXO-K.\n",
            "Here comes the new superstar! His name is Austin Mahone. The 18-year-old is a pop singer in the US. His success story is just like that of Justin Bieber. Last month Mahone's new album The Secret came out. Maybe it's a good chance for us to know more about him and his music.\n",
            "Forget about Super Junior. We now have TFBOYS. TFBOYS is a popular Chinese boy band made up of three members. They are Wang Junkai, 14, Wang Yuan, 13, and Yi Yangqianxi, 13. The boys are all junior middle school students. Their songs are full of positive energy  . In their latest album, they call on teenagers not to be afraid of dreaming big.\n",
            "\n",
            "Question: Austin Mahone's success story is almost the same as   _  .\n",
            "A. TFBOY's\n",
            "B. Justin Bieber's\n",
            "C. EXO's\n",
            "D. Taylor Swift's\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5965\n",
            "Current Mean Accuracy: 0.5965\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
            "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
            "\n",
            "Question: Where is Wendy from?\n",
            "A. China.\n",
            "B. England.\n",
            "C. America.\n",
            "D. Australia.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6034\n",
            "Current Mean Accuracy: 0.6034\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When you read an article you will understand and remember it better if you can work out how the writer has put the ideas together.Sometimes a writer puts ideas together by asking questions and then answering them.For example,if the article is about groundhogs ,the set of questions in the writer's head might be:\n",
            "What does a groundhog look like?\n",
            "Where do groundhogs live?\n",
            "What do they eat?...\n",
            "In the article,the author might answer those questions.\n",
            "Sometimes an author writes out her questions in the article.These questions give you signals.They tell you what the author is going to write next.Often an author has a question in her head but she doesn't write it out for you.You have to work out her question for yourself.Here's a sample reading for you to practice this method.\n",
            "Earthworms\n",
            "Do you know how many kinds of earthworms there are?There are about 1800 kinds in the world! They can be brown,purple,green.They can be as small as 3 cm long and as large as 3 m long.\n",
            "The best time to see earthworms is at night,especially a cool,damp night.That's when they come up from their burrows to hunt for food.Earthworms don't like to be in the sun.That's because they breathe through their skin,and they can't breathe if their skin gets too dry.Earthworms must come out of the earth if it rains a lot,because they can't breathe in their flooded burrows.What a dangerous life!\n",
            "Earthworms don't have eyes,so how can they tell when it's dark? They have special places on their skin that are sensitive to light.These spots tell whether it's light or dark.If you shine a flashlight on an earthworm at night,it will quickly disappear into the ground.\n",
            "Earthworms don't have ears either,but they can hear by feeling movements in the earth.If you want to hear like an earthworm,lie on the ground with your fingers in your ears.Then have a friend stamp his or her feet near you.This is how earthworms feel birds and people walking,and moles digging,near them.\n",
            "Earthworms are useful.Farmers and gardeners like having lots of earthworms in their land because the worms help to make better soil when they dig.That digging keeps the soil loose and airy .In one year earthworms can pile up as much as 23,000 kg of castings in an area about the size of a football field.\n",
            "\n",
            "Question: Which question CANNOT be answered in the passage?\n",
            "A. How do earthworms help with gardeners?\n",
            "B. What life are earthworms living with?\n",
            "C. When may people observe earthworms?\n",
            "D. Why can human listen like earthworms?\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5932\n",
            "Current Mean Accuracy: 0.5932\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Kate is an American girl. Now she lives in New York with her parents. She lives in a community called Sunny Community. It's on Blue Street. There are five rows  of buildings in the community. Her house is in the first row. She lives on the third floor.\n",
            "There is a post office on Blue Street . Next to it ,there is a bank. Across from the bank ,there is a bookstore. The workers in the bookstore are very friendly to people. Mrs Green works in it. She is Kate's new neighbor. She has a son. His name is Bob. He is in the same class as Kate.\n",
            "Kate thinks the traffic here is very good, because she never meets any accidents here. She loves her community very much.\n",
            "\n",
            "Question: Where does Mrs Green work ?\n",
            "A. In a post office.\n",
            "B. In a bank.\n",
            "C. In a bookstore.\n",
            "D. In a school.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Foreign visitors are often puzzled   in Japan because most streets there don't have names. In Japan, people use _ in their directions instead of street names. For example, the Japanese will say to travelers, \"Go straight down to the corner. Turn left at the big hotel and go pass a fruit market. The post office is across from the bus stop.\"\n",
            "In the countryside of the American Midwest, usually there are not many landmarks. There are no mountains, so the land is very flat  . In many places there are no towns or buildings within miles. Instead of landmarks, people will tell you directions and distance. In Kansas or lowa, for example, people will say, \"Go north two miles. Turn east, and then go another mile.\"\n",
            "People in Los Angeles, California, have no idea of distance on the map: the measure   distance by means of time, not miles. \"How far away is the post office?\" you ask. \"Oh,\" they answer, \"it's about five minutes from here.\" you say, \"Yes, but how many miles away is it?\" They don't know.\n",
            "People in Greece sometimes do not even try to give directions because visitors seldom understand the Greek language. Instead of giving you the direction, a Greek will often say, \"Follow me.\" Then he'll lead you through the streets of the city to the post office.\n",
            "Sometimes a person doesn't know the answer to your question. What happen in this situation? A New Yorker might say, \"sorry, I have no idea.\" But in Yucatan, Mexico, no one answer, \"I don't know.\" They think that it is impolite. They usually give an answer, often a wrong one. A visitor can get lost in Yucatan.\n",
            "One thing will help you everywhere. You might not understand a person's words, by maybe you can understand his body language. He or she will usually turn and then point in the correct direction.\n",
            "\n",
            "Question: What does the passage mainly talk about?\n",
            "A. we needn't carry a map for travel.\n",
            "B. There are not many landmarks in the American Midwest.\n",
            "C. There are different ways to give directions in different parts of the world.\n",
            "D. Americans and Japanese have different body languages when you ask for directions.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6066\n",
            "Current Mean Accuracy: 0.6066\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: Adult editors may invite   _   to the meeting to make the paper more popular with kids.\n",
            "A. a college student\n",
            "B. a middle school student\n",
            "C. an adult editor\n",
            "D. a reporter\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5968\n",
            "Current Mean Accuracy: 0.5968\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Tom was a farmer. He worked on the farm all day,but sometimes he went to the town market to sell fruit and vegetables. One day, a terrible sound attracted his attention in the town market. He saw a young bull for sale. The bull was white and yellow. It was looking at Tom in fear. Tom walked up and touched its head gently. Just at that time they both seemed to have known each other for a long time. How amazing!Tom bought it at once and called it Amba.\n",
            "From then on , Tom and Amba got on well with each other. But some friends told him that it was dangerous to have such a close relationship with an animal.\n",
            "One afternoon , Tom was walking through the forest with Amba. Suddenly , Amba stopped walking and kept pushing Tom with its head. Tom was very surprised and looked around. There was a big snake in front of him. It was beautiful but poisonous. Quickly Amba stepped on the snake's tail with its foot and at the same time Tom picked up a stick and hit the snake's head heavily. Soon the snake . died.\n",
            "Tom was very grateful for Amba's help. When people heard this, they were shocked at the bull's expression of love for Tom. But for Tom, Amba was not a bull but a member of his family.\n",
            "\n",
            "Question: Which of the following statements is NOT true?\n",
            "A. Tom went to the town market to sell fruit and vegetables.\n",
            "B. Tom's friends thought animals were safe.\n",
            "C. Tom hit the snake's head heavily with a stick.\n",
            "D. For Tom, Amba was a member of his family.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5873\n",
            "Current Mean Accuracy: 0.5873\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: It was very late at night when Sam got off the train . He was tired and wanted to find a hotel to have a rest. He looked around and saw a hotel not far away. There were three floors in it. Then Sam went in.\n",
            "\"How much do I need to pay for a single  room a night?\" Sam asked.\n",
            "\"Well , sir,\"said the girl, \"a single room on the first floor is fifty dollars a night.\"\n",
            "\"What about the one on the second floor?\" asked Sam.\n",
            "\"Forty dollars.\"\n",
            "\"Then how about the one on the third floor?\"\n",
            "\"Thirty dollars.\"\n",
            "Sam picked up his suitcase  and wanted to go out.\n",
            "\"Don't you think our price is reasonable?\" The girl said.\n",
            "\"Yes,\" said Sam. \"Your price is of course _ , but I'm sure your hotel is not high enough.\"\n",
            "\n",
            "Question: How many floors were there in the hotel?\n",
            "A. One\n",
            "B. Two\n",
            "C. Three\n",
            "D. Four\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5938\n",
            "Current Mean Accuracy: 0.5938\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: There are   _   people in Mike's family.\n",
            "A. four\n",
            "B. five\n",
            "C. six\n",
            "D. seven\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5846\n",
            "Current Mean Accuracy: 0.5846\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Autumn is the harvest season. There must be a lot for us to eat !Yes, autumn is a great time for fruit and vegetables. Let's find out about some of the best.\n",
            "Apples: You can eat apples all the year round, but they are better and cheaper in autumn. People say \"An apple a day keeps the doctor away\". Apples have a lot of vitamin C and fiber  in them. They are good for the heart and can make your mouth fresh.\n",
            "Pears: Pears are in season from autumn to mid winter. They have minerals and vitamins C and E in them. They are good for the heart and can keep cancer   away.\n",
            "Pumpkins: Pumpkin is a nice vegetable in autumn. They are rich in beta carotene  , which is turned into vitamin A in our bodies. Pumpkins also have calcium ,iron and vitamin C in them. Eating pumpkins can make us look young.\n",
            "Sweet corn  : Sweet corn is in season near the end of the year. It has minerals in it. It's good for the heart.\n",
            "Autumn weather is cold and dry. Try to eat as much fruit and vegetables as you can. They will make you healthy.\n",
            "\n",
            "Question: _   are /is in rich beta carotene.\n",
            "A. Pumpkins\n",
            "B. Sweet corn\n",
            "C. Apples\n",
            "D. Pears\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5758\n",
            "Current Mean Accuracy: 0.5758\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Dan was the doorman of a club in a big city. Every day, thousands of people passed his door, and a lot of them stopped and asked him, \"What's the time, please?\"\n",
            "After a few months, Dan said to himself, \"I'm not going to answer all those stupid people any more. I'm going to buy a big clock and put it on the wall here.\" Then he did so.\n",
            "\"Now people aren't going to stop and ask me the time.\" He thought happily.\n",
            "But after that, a lot of people stopped, looked at the clock and asked Dan, \"Is that clock right?\"\n",
            "\n",
            "Question: What would be the best title for the passage?\n",
            "A. Hardworking Dan\n",
            "B. A Big Clock\n",
            "C. Stupid Question\n",
            "D. Boring People\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5672\n",
            "Current Mean Accuracy: 0.5672\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When you were very young, you liked to play with your friends. Did you find that playtime was always more fun when everyone shared the toys? Everyone got a turn. No one was left out.\n",
            "That's a life lesson that changes as you get older. As you grow up, you begin to understand that others have less than you do - in China and in the world. And that those of us who \"have\" things should help those who \" have less\" than we do. The idea of sharing _ \n",
            "At your age, you can \"share\" with people in need in three ways.\n",
            "1. You can give them a part of your money. Many adults do that regularly.\n",
            "2. You can share items you no longer use, such as clothing and toys. You can pass them onto others who cannot buy them.\n",
            "3. You can help people by giving your time and your energy.\n",
            "The last one is also called volunteering. Volunteering is about giving your time to take part in activities that will help others. Every year, many thousands of volunteers in the world give the most valuable gift of all. They give their time. They give their talent. They give of themselves. And they are enjoying it. Volunteering isn't just about work. It's about fun too.\n",
            ",.\n",
            "\n",
            "Question: What's the best title for this passage?\n",
            "A. Work hard to have more than others.\n",
            "B. Be a volunteer.\n",
            "C. Make your playtime more enjoyable.\n",
            "D. Share your love with others.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5588\n",
            "Current Mean Accuracy: 0.5588\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: The largest number of people in a race\n",
            "The biggest race is in San Francisco, the USA. More than 100,000 people run the 12 kilometers in the race. Another famous race is in London every year. This race is longer and harder, it is more than 42 kilometers, but 25,000 people usually finish it. [:Zxxk.Com]\n",
            "The youngest international player\n",
            "The youngest international player in any sport was Jamaica. Her name was Joy Foster. She was the Jamaican table tennis champion   in1958 when she was 8 years old.\n",
            "The strongest superlative  \n",
            "Have you ever tried walking backwards? The world record for walking backwards is 12,875 kilometers. A man from Texas, the USA, walked backwards for 18 months in 1931--1032. Nobody else has ever broken this record  .\n",
            "The most popular sport\n",
            "The popular sport team game in the world is football. People play football in villages, streets and stadiums all over the world. The most famous football competition is the World Cup. It happens every four years, and nearly 2,000,000,000 people watch it on TV. The first Women's World Cup was in 1991.\n",
            "\n",
            "Question: _   walked more than 12,875 kilometers' backwards.\n",
            "A. Few people\n",
            "B. Nobody else\n",
            "C. One man has\n",
            "D. Many people\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5507\n",
            "Current Mean Accuracy: 0.5507\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: English breakfast is a very big meal--eggs, tomatoes, tea, coffee... For many people, lunch is a quick  meal. In cities there are a lot of sandwich  bars . People can buy sandwiches there. Students can have a hot meal at school, but many just take a sandwich, a drink and some fruit from home.\n",
            "\"Tea\" means two things. It is a drink and a meal! Some people have afternoon tea, with sandwiches, cakes and a cup of tea.\n",
            "They usually have dinner quite early , between 6:00 and 8:00(......), and often all the family eat together .\n",
            "People often get take-away  meals--they buy the food outside\n",
            "\n",
            "Question: When they get a take-away meal, they often eat it   _  .\n",
            "A. at home\n",
            "B. in the school\n",
            "C. outside\n",
            "D. in the bars\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5429\n",
            "Current Mean Accuracy: 0.5429\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Once upon a time, there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day the feelings were told that the island would sink, so all built boats and left, except Love. Love was the only one who stayed. Love wanted to hold out  until the last possible moment.\n",
            "When the island had almost sunk, Love decided to ask for help.\n",
            "Richness was passing by Love in a big boat. Love said, \"Richness, can you take me with you?\"\n",
            "Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
            "Love decided to ask Vanity  who was also passing by in a beautiful ship.\"Vanity, please help me!\"\n",
            "\"I can't help you, Love. You are all wet and might damage  my boat, \"Vanity answered.\n",
            "Sadness was close by so Love asked, \"Sadness, let me go with you.\"\n",
            "\"Oh...Love, I am so sad that I need to be by myself!\"\n",
            "Happiness passed by Love, too, but she was so happy that she did not even hear when Love called her.\n",
            "Suddenly, there was a voice, \"Come, Love, I will take you.\"It was an elder. So thankful and happy, Love even forgot to ask the elder where they were going. When they arrived at dry land, the elder went her own way. Realizing how much was owed  the elder, Love asked Knowledge, another elder, \"Who helped me?\"\n",
            "\"It was Time, \"Knowledge answered.\n",
            "\"Time?\"asked Love.\"But why did Time help me?\"\n",
            "Knowledge smiled with deep wisdom  and answered, \"Because only Time is able to understand how valuable Love is.\"\n",
            "\n",
            "Question: Which of the following might be the best title of the passage?\n",
            "A. Love and Time\n",
            "B. An Accident\n",
            "C. A sinking island\n",
            "D. Different Feelings\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5352\n",
            "Current Mean Accuracy: 0.5352\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: If you won a lottery and had lots of money, what would you do? Most people start by buying themselves things, such as a new car or a bigger TV.\n",
            "Many people who win lots of money may suddenly find that they have a lot of socalled friends. The new friends they make may follow them for their money but they may also leave them when all the money is spent. Besides that, they can't decide what to do with the money, so they try to think what they want. In the end, most people usually decide to save the money.\n",
            "There are some lottery winners who decide to quit their jobs, because they think they have enough money and don't need to work any longer. Some big lottery winners make even bigger changes--they end their marriages. They think that winning a lot of money has suddenly made them more intelligent and more attractive .So they feel that they have to be with a younger or more attractive man or woman.\n",
            "They don't know their new money is just a bit of luck. _ can't change everything.\n",
            "Next time when you buy a lottery ticket, think about what you would like to do and what you wouldn't  like to do with the money if you won.\n",
            "\n",
            "Question: A lottery winner may suddenly find himself with many socalled  friends, probably because   _  .\n",
            "A. he wants to make lots of friends\n",
            "B. he doesn't  know what to do with all the money\n",
            "C. these new friends are usually kind to the lottery winner\n",
            "D. these new friends want the lottery winner to give them some money\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5278\n",
            "Current Mean Accuracy: 0.5278\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Do you obey the rules in your school? What do you think of your school rules? Are you allowed to dye   hair? A lot of school rules are similar around the world, but some are different. Some students may enjoy more freedom in some countries. But freedom doesn't mean \"no rules\". Every school has its own rules.\n",
            "There are some rules in Japanese schools. The students are not allowed to dye their hair and are supposed to keep their hair black. They are not allowed to wear earrings either. Almost all schools used to require students to wear school uniforms but now half of the schools require uniforms. The students feel happy to wear all kinds of clothes. The students must get to school on time. If they are late, they cannot get into the school because the school gate is closed. In Japan, students are not allowed to have part-time jobs.\n",
            "American schools have their own rules too. For example, at Morton High School, students are not allowed to choose their own clothes. They must get to school or leave school on time. Food, drinks or snacks shouldn't be taken into the classroom. They must wear sports shoes in PE class. They are supposed to keep quiet on the school bus. In America, the students can have part-time jobs in their free time. (<<>> )\n",
            "\n",
            "Question: Which school rules have changed in some Japanese schools?\n",
            "A. About wearing earrings.\n",
            "B. About uniforms.\n",
            "C. About food and drinks.\n",
            "D. About part-time jobs.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5205\n",
            "Current Mean Accuracy: 0.5205\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: My friends like different clothes. Sue likes red clothes. She is often in a red skirt and red shoes. Mina likes white clothes. She is in a white shirt. Her sister Emma likes to wear a green skirt. She looks nice. David often wears a white cap and black pants. Peter often wears a white coat and black pants.\n",
            ",.\n",
            "\n",
            "Question: What color does Sue like?\n",
            "A. White.\n",
            "B. Red.\n",
            "C. Yellow.\n",
            "D. Green.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5135\n",
            "Current Mean Accuracy: 0.5135\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: There is lots of junk  in space .Some of it is from rockets. In 1996, a rocket broke into about 300,000 small pieces. So far, scientists have found over 10,000 man-made pieces flying around in space. Only 6-7%of them are satellites and space probes  . Astronauts also lose small things while working in space. In 1965, during the first American spacewalk , astronaut Edward White lost a glove .For a month, the glove stayed in space, travelling at a speed of 28,000 kilometers per hour .It became the most dangerous piece of clothing for the Earth in history it flew away. Things move very fast in space. If they hit one another, it can be dangerous .A little piece of paint from a satellite once made a hole in a spacecraft window. Last year two US spacecraft dropped some bolts , and scientists on the Earth worried a lot. Luckily the bolts floated  away into space. They couldn't hit the spacecraft.\n",
            ",.\n",
            "\n",
            "Question: The glove in space may travel at a speed of    _    kilometers per hour.\n",
            "A. 300,000\n",
            "B. 28,000\n",
            "C. 10,000\n",
            "D. 21,000\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5067\n",
            "Current Mean Accuracy: 0.5067\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: \"You know, these cups brings to my mind a story I heard,\" Mary said to her students.\n",
            "She poured some tea. There were four of them and there were four completely different cups on the tables.\n",
            "\"I heard there was a teacher who took all his students for tea. His students were surprised that all the cups on the table were different. They all took a cup and started drinking their tea, each looking at the cups of others. The teacher said, \"Did you notice your behavior? You are all looking at each other's tea cup and some of you even envy the finer cups of others.\"\n",
            "\"I put the different cups here on purpose. I want to say life is like this tea. You all have the same thing in your cups----tea. And yet you cannot truly enjoy it in your envy of another's cup. You forget to enjoy your own life when you envy someone else's life. We all have the same thing----life. We should care more about the tastes of your own life. So now, taste your own tea. Does it matter from which cup it came from?\" Mary finished telling her story and her students all sat in silence for a while, enjoying their tea. And it really did not matter a bit from which teacup they drank.\n",
            "\n",
            "Question: What should we learn from the story?\n",
            "A. Envy others and make progress.\n",
            "B. All the lives are the same.\n",
            "C. Work hard and catch up with others.\n",
            "D. Try to enjoy your own life.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5132\n",
            "Current Mean Accuracy: 0.5132\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: If you think you are too shy and want to be a little outgoing, try the following. You can make it.\n",
            "Tell people you are shy. Just let people know that you are a shy kid. When they know that, they'll understand you better. This also helps you feel more at home when talking with others.\n",
            "Try to smile more. People think you are friendly and easy to talk to. Remember that most of us would like to talk to friendly people and we will stay away from an angry-looking face.\n",
            "Talk to others first. If you find it hard to do, say something nice about people around you. Think about how great you feel when someone says something nice to you. Doesn't it make you want to keep talking to those people?\n",
            "Turn your attention to somewhere else. Think more about ways to enjoy the party or the game. Don't worry about your looks or care if people like you.\n",
            "Reward  yourself. Each time after you say \"hi\" or smile at someone for the first time , say to yourself \"You did it!\" or buy yourself an ice cream.\n",
            "Keep trying and one day you won't be shy any more when you talk to others.\n",
            "\n",
            "Question: Which of the following is NOT true?\n",
            "A. People can understand you better when they know you are shy.\n",
            "B. Most people don't like to talk to those people with angry faces.\n",
            "C. Don't care what you look like at the party or the game.\n",
            "D. Each time after you smile at someone for the first time, you should buy yourself an ice cream.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5065\n",
            "Current Mean Accuracy: 0.5065\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Many people think sports are just for winning and honor, but there is a lot more you can gain from (get out of) them. I have learned over the past years that sometimes when I lose, I get a lot more out of it than winning. Also, I find a lot of times in sports, people are getting too caught up in the game instead of just having fun. The real purpose of sports is to have fun and learn life lessons along the way.\n",
            "I greatly encourage you to be a part of the school sports. Even if you are not the best, you can still have fun. Sports give people a great and healthy way of spending an afternoon, instead of lying around playing video games or even getting into bad things. Sports also give us a sense of achievement. There isn't a better feeling than to have done something fun and productive for my day.\n",
            "I think that we all need sports to give us courage. If we try hard in sports, we usually do well. If we did the same in study, we would all be champions. Another reason why I encourage you to play sports is that it's just fun. Without sports, our lives would just be boring. So as you may be able to tell, sports are amazing!\n",
            "Our coaches not only teach us to play sports, but show class and good sportsmanship while playing them. It's never fun when you lose to have the competitor rub it in your face. That's why our coaches teach us to show class when we lose; also, when coaches _ , don't get down. They only want to see you improve and learn from what they say. When you do badly and they don't shout loudly is when you should start worrying because they are giving up on you.\n",
            "Overall, sports are great! They bring out the best and worst of a lot of us. However, we can' t let sports get too serious to where it brings down all the fun. So to have the most fun in sports, you just need try your best and not worry so much about the winning or losing.\n",
            "\n",
            "Question: Which of the following statements is TRUE according to the passage?\n",
            "A. Sports bring us great fun only if we have the talent.\n",
            "B. Sports give us the best way of spending free time.\n",
            "C. We can get more out of winning than losing.\n",
            "D. We should take pleasure in doing sports.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: On May 1, a wildfire started in a forest near the Alberta town of Fort McMurray in Canada. Within two days, the fire grew larger and the people who lived in Fort McMurray had to leave their homes. While there have been very few people injured   by the large fire itself, it has been harmful to the community.\n",
            "Canadians in other places have been helping by sending money and _ to the Red Cross. Many people in Alberta have taken in people from Fort McMurray, letting them stay in their homes for free until the fire is put out. Many firefighters are needed to fight the fire and some of them have come from other parts of Canada to help. The brave firefighters were able to save 25,000 homes as well as the hospital and all of the town's schools, according to CBC news.\n",
            "There have been thousands of other acts of kindness towards the people of Fort McMurray. Some musicians, such as Great Big Sea's Alan Doyle, are holding special concerts, with the money going to Fort McMurray people. And companies have been helping, as well. Beer-maker Labatt filled thousands of cans with water--instead of beer--and sent them to the people in Fort McMurray.\n",
            "The fire is huge, spreading over more than 229,000 hectares  , but firefighters say they believe they are starting to get it under control--it is becoming smaller instead of spreading.\n",
            "\n",
            "Question: How many people have been injured by the large fire itself?\n",
            "A. 25,000.\n",
            "B. Very few.\n",
            "C. 229,000.\n",
            "D. Many.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4937\n",
            "Current Mean Accuracy: 0.4937\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
            "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
            "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
            "\n",
            "Question: The writer thinks many people don't live near the north or south pole because  _  .\n",
            "A. they can't get enough food there\n",
            "B. the natural sights there don't arrract people\n",
            "C. the unpleasant weather keeps them away\n",
            "D. the length of nighttime keeps them away\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Mr. and Mrs. Green lived in a big city. One summer they went to the country for their holiday. They enjoyed it very much because it was a quiet, clean place.\n",
            "One day they went for a walk early in the morning and met an old man. He lived on a farm, and he was sitting in the warm sun in front of his house. Mr. Green asked him, \"Do you like to live in this quiet place?\"\n",
            "The old man said, \"Yes, I do.\"\n",
            "Mr. Green then asked, \"What are the good things about it?\"\n",
            "The old man answered, \"Well, the people here know each other. They often come and visit me, and I often go and visit them. And there are also many children here.\" Mr. Green said, \"That's interesting, and what are the bad things?\"\n",
            "The old man thought for a moment and then said, \"Well, the same things, really.\"\n",
            "\n",
            "Question: The old man sometimes liked the people to   _  , but sometimes he didn't.\n",
            "A. ask him questions\n",
            "B. keep the place quiet and clean\n",
            "C. come and visit him\n",
            "D. make interesting things\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4938\n",
            "Current Mean Accuracy: 0.4938\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Do you know why different animals or pests have their special colours? Colours in them seem to be mainly used to protect themselves.\n",
            "Some birds like eating locusts , but birds cannot easily catch them. Why? It is because locusts change their colurs with the changes of the colours of crops .When crops are green, locusts look green .But as the harvest time comes, locusts change into the same brown colour as crops have .Some other pests whose colours are different from plants are easily found and eaten by others .So they have to hide themselves for lives and appear only at night.\n",
            "If you study the animals' life, you'll find the main use of colours is to protect themselves .Bears, lions and other animals move quietly through forests .They cannot be easily seen by hunters because their colours are much like the trees.\n",
            "Colours are useful not only on the land , but also in the sea .A kind of fish in the sea can give out a kind of black liquid when the fish face danger. The liquid spreads over quickly, so they cannot be found by their enemies and can quickly swim away. That is why they can live safely though they are not strong at all.\n",
            "\n",
            "Question: Bears and lions can keep safe because  _  .\n",
            "A. their colours are much like the trees\n",
            "B. they move quickly\n",
            "C. they are very strong\n",
            "D. they live in forests\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: There are several ways you can find out about the countries and places you wish to visit. You can talk to friends who have traveled to the places, you can go and see a colour film about them, or you can read a travel book.\n",
            "It seems that there are three kinds of travel books. The first are those that give a personal, subjective  idea of travels which their writer has got himself. These books can be useful if the writers share their traveling experiences with others. The second kind are those books which give objective  information of things to be done and seen. If _ has written such a book about the facts of a place, then it is more useful. The third kind are those books which are called \"a guide\" to some place or other. If they are good, they will describe and explain the place in detail. Like the first kind , they can be interesting and exciting, but their main purpose is to help the reader plan his travel in the most practical way.\n",
            "Whatever kind of travel book you choose, you must make sure that the book does not describe everything as interesting, exciting or fantastic. You must also keep an open eyes on its date of publication  because travel is very practical matter and many things change quickly in the 21st century. Finally, you should make sure that it's easy to find the useful information for you travel.\n",
            "\n",
            "Question: The date of publication must be noticed because   _  .\n",
            "A. the prices of travel books may be different\n",
            "B. the writers of travel books may be different\n",
            "C. the information in travel books is always the same\n",
            "D. the information in travel books is always changing\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4940\n",
            "Current Mean Accuracy: 0.4940\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
            "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
            "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
            "She understood that she hadn't worn the hair clip to school at all.\n",
            "\n",
            "Question: Her classmates wanted to know what had happened to the girl because  _\n",
            "A. she didn't tell her classmates about her beautiful hair clip.\n",
            "B. she was always unhappy but that day she was so happy.\n",
            "C. she looked more beautiful wearing the hair clip.\n",
            "D. she wanted to talk to others.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4881\n",
            "Current Mean Accuracy: 0.4881\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: When people talk about air pollution, they usually think of smog, acid rain ,and other forms  of outdoor air pollution. But did you know that air pollution also is inside homes, offices, hotels and other buildings?Indoor air pollution is more serious. The air in your home can be 2 to 100 times  more polluted than the air outdoors!In fact, some American doctors say that 50% of illnesses have something to do with polluted indoor air. Indoor air pollution is bad for our health in many ways. Young children and the old often suffer  more from air pollution. People with health problems may also suffer more when the air is polluted. Indoor air pollution can be bad for people's eyes, nose and throat. Air pollution, both indoor and outdoor, can also lead to cancer, heart disease, and even bad for the brain!In the great London fog in 1952, 4,000 people died in a few days because of air pollution!It is said that half a million young kids and women die each year in India because of indoor air pollution!\n",
            "There're many ways to reduce  indoor air pollution. Here are some of them and see if they can help you:\n",
            "Increase outdoor air coming indoors and open your windows for 15 to 30 minutes each day.\n",
            "Turn off all the lights and fans when you don't need them.\n",
            "Share your room with others when the air conditioner is running.\n",
            "Don't smoke and try to stop your family members from smoking. People who smoke are going to have trouble breathing and even die someday. If you're smart, don't ever start.\n",
            "Environment-friendly products, such as water-based paints pollute less and work well.\n",
            "\n",
            "Question: How many ways does the writer talk about to reduce indoor air pollution?\n",
            "A. Four.\n",
            "B. Five.\n",
            "C. Six.\n",
            "D. Seven.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4824\n",
            "Current Mean Accuracy: 0.4824\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: \"You know, these cups brings to my mind a story I heard,\" Mary said to her students.\n",
            "She poured some tea. There were four of them and there were four completely different cups on the tables.\n",
            "\"I heard there was a teacher who took all his students for tea. His students were surprised that all the cups on the table were different. They all took a cup and started drinking their tea, each looking at the cups of others. The teacher said, \"Did you notice your behavior? You are all looking at each other's tea cup and some of you even envy the finer cups of others.\"\n",
            "\"I put the different cups here on purpose. I want to say life is like this tea. You all have the same thing in your cups----tea. And yet you cannot truly enjoy it in your envy of another's cup. You forget to enjoy your own life when you envy someone else's life. We all have the same thing----life. We should care more about the tastes of your own life. So now, taste your own tea. Does it matter from which cup it came from?\" Mary finished telling her story and her students all sat in silence for a while, enjoying their tea. And it really did not matter a bit from which teacup they drank.\n",
            "\n",
            "Question: Which is the best title for the story?\n",
            "A. More than tea in a cup\n",
            "B. The same cups, the same tea\n",
            "C. The taste of the tea\n",
            "D. Different cups, different tea\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4767\n",
            "Current Mean Accuracy: 0.4767\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: The newspaper should not be   _\n",
            "A. simple\n",
            "B. interesting\n",
            "C. difficult\n",
            "D. easy\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4828\n",
            "Current Mean Accuracy: 0.4828\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: At the age of sixteen, I went on my first volunteer program in West Virginia to repair or build homes for poor families. When we arrived, we discovered that the family we were going to help was living in a trailer that was in poor condition, no bigger than two parking spaces. A group of people had been working on it for two weeks, but every time they finished one problem, another appeared.\n",
            "We soon decided that the only way was to build a new house. It was something unusual because normally our goal was to repair old homes. The family was pleased with their new house that was 20 by 30 feet with three bedrooms, a bath and a kitchen.\n",
            "On Tuesday of that week, I asked the family's three boys, Josh, Eric and Ryan, \"What do you want for your new room?\" Kids in the families we had helped usually wanted toys or posters, so we were surprised when Josh, the oldest boy said, \"We just want beds.\" The boys had never slept in a bed. That night we had a meeting and decided that beds would be the perfect gift. On Thursday night, a few adults in our group drove to the nearest city and bought beds and new bedding.\n",
            "On Friday when we saw the truck coming, we told the family about the surprise. They were very excited.\n",
            "That afternoon, while we were setting up the beds, Eric ran into the house to watch us with wide eyes. As Maggie, a member of our group, put one of the pillows on the bed, Eric asked, \"What is that?\"\n",
            "\"A pillow,\" she replied.\n",
            "\"What do you do with it?\" Eric went on asking.\n",
            "\"When you go to sleep, you put your head on it,\" Maggie answered softly. Tears came to our eyes as she handed Eric the pillow.\n",
            "\"Oh . . . that's soft,\" he said, holding it tightly.\n",
            "Now, when my sister or I start to ask for something that seems very urgent , my dad always asks, \"Do you have a pillow?\" We know exactly what he means.\n",
            "\n",
            "Question: What can we learn from the story?\n",
            "A. The family needed two parking spaces.\n",
            "B. The boys of the family wanted toys and posters.\n",
            "C. The family were excited about the beds and bedding.\n",
            "D. The writer's group made some furniture for the family.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4886\n",
            "Current Mean Accuracy: 0.4886\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: One day my wife and I went shopping at  the shop. We took the car as we had a lot of things to buy because my brother and his family were going to spend the weekend with us. We stopped the car in front of the shop. An hour later we came back to the car with a lot of things. Then the trouble started. We could not open the car door.\n",
            "\"Oh, dear,\" said my wife, \"What are you going to do?\"\n",
            "\"Let's ask that policeman,\" I said. The policeman was very kind and glad to help us. A few minutes later he got the door open. Just at that moment an angry man came up and shouted, \"What are you doing with my car?\"\n",
            "We looked at the number of the car and our faces turned very red.\n",
            "\n",
            "Question: How long did they spend in the shop doing their shopping?\n",
            "A. About half an hour.\n",
            "B. A whole morning.\n",
            "C. One hour or so.\n",
            "D. A whole day.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4831\n",
            "Current Mean Accuracy: 0.4831\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: Wang Hao is in   _   now.\n",
            "A. England\n",
            "B. the USA\n",
            "C. Jiangsu\n",
            "D. Beijing\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4889\n",
            "Current Mean Accuracy: 0.4889\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
            "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
            "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
            "\n",
            "Question: Why does Victory work so hard? Because   _  .\n",
            "A. he is very strong\n",
            "B. he likes his work very much\n",
            "C. he is helping his parents\n",
            "D. he is saving up to buy a house\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4835\n",
            "Current Mean Accuracy: 0.4835\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: The word, \"photography\", was first used in 1839. It comes from the Greek words that mean \"to write with light\". But photography could only give people _ pictures. So scientists were trying hard to find ways to make pictures that can move. They made lots of experiments, but failed again and again. It was Eadweard Muybridge who finally succeeded. He was the first photographer to try this successfully. But how did he make it? It was an interesting story.\n",
            "Back in 1872, people didn't know exactly whether all four of a horse's hooves   left the ground at the same time when it was running. A gentleman called Leland Stanford made a bet with his friend about it. Most people believed that a horse always had one hoof on the ground, or it would fall over. But Stanford didn't think so.\n",
            "At that time, it was hard to know who could win the bet, because a horse's legs move so fast that it is impossible to tell just by looking. So they needed a way to record the movement of a running horse. Then Stanford offered $25,000 to the famous photographer, Muybridge, to help find the answer. In the beginning, Muybridge failed to get clear images, but he didn't give up. He continued to improve his cameras. In 1878, after many experiments, he managed to get a sequence   of 12 photos. One of them clearly showed that all four of the horse's hooves were off the ground at the same time. And when the photos moved fast, people could see a horse running.\n",
            "Though is usually considered as the person who created the first movie in 1889, it was the work of Eadweard Muybridge and the bet that led to Edison's invention.\n",
            "\n",
            "Question: The passage mainly tells us   _  .\n",
            "A. that Thomas Edison created the first movie .\n",
            "B. that Eadweard Muybridge created the first static pictures\n",
            "C. how photography helped people know more about animals\n",
            "D. how Eadweard Muybridge got pictures of motion   successfully\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4891\n",
            "Current Mean Accuracy: 0.4891\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Music education hasn't changed much since the 1970s. Students are still taught to read notation so they can recite compositions that they would never listen to on their MP3 players or play with friends. Playing music enriches life. The question is: Why do schools teach music in a way that _ so many young people rather than catch their imagination? Can we do a better job of using the power of music to get kids excited about school?\n",
            "The experience of an organization called Little Kids Rock suggests the answer is yes -- if we change the way music is taught. Little Kids Rock has helped music programs in over a thousand public schools and served 150,000 children. The organization has given 30,000 free instruments out, mainly guitars, and trained 1,500 teachers to run music classes in which students quickly experience the joys of playing their favorite songs, performing in bands , and writing their own music.\n",
            "The key to Little Kids Rock is that it teaches children to play music the way many musicians learn to play it -- not by notation, but by listening, imitation and meaningful experimentation. \"The knowledge you need to get started playing rock music is very limited,\" explains Dave Wish, the founder of Little Kids Rock. \"In high school, my friend Paul taught me a couple of chords and my life was changed forever. On the first day of class, Little Kids Rock teachers place guitars in the hands of their students and get them practicing chords that will enable them to play thousands of songs. The kids decide what songs they want to learn and the class is off and running. Their progress is surprising. Within a year, eight and nine-year-olds are playing musical instruments, and giving concerts, even performing their own songs.\n",
            "One of the biggest advantages that music offers is the ability to encourage students who are otherwise bored by school. \"I've had students start coming back to school because of this program,\" said Adkison Thomas, who heads up music for the Dallas Independent School District. He added, \"One of the best things is that the teachers discover a new side of their students. They see kids become successful who weren't before.\"\n",
            "\n",
            "Question: What does the writer want to tell us?\n",
            "A. Learning music is a good way to become successful.\n",
            "B. Teaching in a proper way does good to students' development.\n",
            "C. It's necessary for students to practice a lot in learning music.\n",
            "D. It's important for teachers to discover the new sides of students.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4839\n",
            "Current Mean Accuracy: 0.4839\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Children in England mustn't work until they are 13. They need to have a work permit   to start working.\n",
            "The jobs teenagers can do\n",
            "Delivering   newspapers\n",
            "Many teenagers will get up early to deliver newspapers to houses in their local area before going to school. They are known as Paper-boys or Papergirls.\n",
            "Babysitting: Looking after young children in their home while their parents have gone out for the evening is a popular job for teenagers, as they get money for watching children and television all at the same time!\n",
            "Helping the Milkman: From the age of 14 some teenagers help the milkman deliver milk to houses.\n",
            "Other popular jobs : Working in a shop; Office work; Washing cars ; In a cafe or restaurant. The hours teenagers (13 and 14 year olds )can work:\n",
            "School Days\n",
            "Not more than 2 hours in one day during the following periods:\n",
            "Morning 7 a. m. --start of school or Evening\n",
            "close of school-- 7 p. m.\n",
            "Saturdays: Up to 5 hours between 7 a.m. and 7 p.m.\n",
            "Sundays\n",
            "Up to 2 hours between 7 a.m. and 11 a. m.\n",
            "Term time\n",
            "Up to 12 hours a week (Including weekends)\n",
            "\n",
            "Question: Teenagers in England can do all of the following except   _   .\n",
            "A. work in an office\n",
            "B. work in a night club\n",
            "C. look after young children\n",
            "D. deliver newspapers\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4787\n",
            "Current Mean Accuracy: 0.4787\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Are you always unwilling to do housework and cleaning for no reason? Well, you will be happy today. Today is No Housework Day. It's time to forget about housework and be relaxed.\n",
            "No Housework Day is always on April 7th. It is your chance to do anything, except housework. Better still, have someone else do housework for a day. Housework is a daily and endless job and most people think it's boring to do housework. I have many friends and their wish is to stay away from housework. In fact, their wish can never come true.\n",
            "Do you know how to celebrate No Housework Day? Well , there are two different ways.\n",
            "If you usually do the housework around the house, forget it on this day. Instead, kick back and enjoy the day. Relax and do anything, except housework.\n",
            "If you never do housework, you can do it for your family. It gives your parents a break from the housework. And, you just might get a chance to know how much housework your parents need to do every day.\n",
            "\n",
            "Question: The writer has many friends and their wish is   _  .\n",
            "A. not to do any housework any more\n",
            "B. to ask others to do their housework\n",
            "C. to celebrate No Housework Day\n",
            "D. to ask all the family members to do housework\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4737\n",
            "Current Mean Accuracy: 0.4737\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
            "\n",
            "Question: Andy and Jim think the tall man is   _   .\n",
            "A. an actor\n",
            "B. a thief\n",
            "C. a policeman\n",
            "D. the short man's friend.\n",
            "Answer:\n",
            "Predicted: B"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   1%|          | 1/100 [00:01<01:49,  1.10s/it]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   3%|▎         | 3/100 [00:01<00:33,  2.93it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   5%|▌         | 5/100 [00:01<00:19,  4.94it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   7%|▋         | 7/100 [00:01<00:12,  7.26it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   9%|▉         | 9/100 [00:01<00:09,  9.19it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  11%|█         | 11/100 [00:01<00:08, 11.12it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  14%|█▍        | 14/100 [00:01<00:06, 13.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  16%|█▌        | 16/100 [00:02<00:06, 13.97it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  18%|█▊        | 18/100 [00:02<00:05, 15.24it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  20%|██        | 20/100 [00:02<00:05, 15.49it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  22%|██▏       | 22/100 [00:02<00:05, 15.31it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  24%|██▍       | 24/100 [00:02<00:04, 16.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  26%|██▌       | 26/100 [00:02<00:04, 15.76it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  28%|██▊       | 28/100 [00:02<00:04, 16.17it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  30%|███       | 30/100 [00:02<00:04, 16.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  32%|███▏      | 32/100 [00:02<00:04, 16.97it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  34%|███▍      | 34/100 [00:03<00:03, 17.64it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:03<00:03, 18.26it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  40%|████      | 40/100 [00:03<00:03, 19.00it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  42%|████▏     | 42/100 [00:03<00:03, 18.05it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  44%|████▍     | 44/100 [00:03<00:03, 17.78it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:03<00:02, 18.45it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:03<00:02, 18.13it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  52%|█████▏    | 52/100 [00:04<00:02, 18.53it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  54%|█████▍    | 54/100 [00:04<00:02, 18.39it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  56%|█████▌    | 56/100 [00:04<00:02, 17.45it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  58%|█████▊    | 58/100 [00:04<00:02, 17.23it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  60%|██████    | 60/100 [00:04<00:02, 16.32it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  62%|██████▏   | 62/100 [00:04<00:02, 15.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  64%|██████▍   | 64/100 [00:04<00:02, 16.28it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  67%|██████▋   | 67/100 [00:04<00:01, 17.88it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  69%|██████▉   | 69/100 [00:05<00:01, 17.80it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  71%|███████   | 71/100 [00:05<00:01, 17.50it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  73%|███████▎  | 73/100 [00:05<00:01, 17.39it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  76%|███████▌  | 76/100 [00:05<00:01, 18.22it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  78%|███████▊  | 78/100 [00:05<00:01, 17.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  80%|████████  | 80/100 [00:05<00:01, 16.77it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:05<00:01, 16.79it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:05<00:00, 16.47it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:06<00:00, 16.28it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  88%|████████▊ | 88/100 [00:06<00:00, 14.91it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  90%|█████████ | 90/100 [00:06<00:00, 15.62it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  92%|█████████▏| 92/100 [00:06<00:00, 15.82it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  94%|█████████▍| 94/100 [00:06<00:00, 15.06it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  96%|█████████▌| 96/100 [00:06<00:00, 15.65it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  98%|█████████▊| 98/100 [00:06<00:00, 16.50it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M: 100%|██████████| 100/100 [00:06<00:00, 15.91it/s]\n",
            "Benchmarking RACE_M: 100%|██████████| 100/100 [00:06<00:00, 14.36it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4792\n",
            "Current Mean Accuracy: 0.4792\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Plants are very important living things. Life could not go on if there were no plants. This is because plants can make food from air, water and sunlight. Animals and man cannot make food from air, water and sunlight. Animals get their food by eating plants and other animals. Therefore animals and man need plants in order to live. This is why we find that there are so many plants around us.\n",
            "If you look carefully at the plants around you, you will find that there are two kinds of plants: flowering plants and non-flowering  plants.\n",
            "Flowering plants can make seeds . The seeds are protected by the fruits. Some fruits have one seed, some have two, three or four, and some have many seeds. But a few fruits have no seeds at all. An example of a fruit without seeds is the banana fruit.\n",
            "Most non-flowering plants do not grow from seeds. They grow from spores . Spores are very, very small. Some spores are so small and light that they can float in the air. We may say that spores are quite the same as seeds. When these spores fall on wet and shady  places, they usually grow into new plants.\n",
            "\n",
            "Question: This passage is most likely to be taken from   _  .\n",
            "A. a story book\n",
            "B. a novel\n",
            "C. a science magazine\n",
            "D. a laboratory report\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4845\n",
            "Current Mean Accuracy: 0.4845\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: This is a special class. The students come from different countries. Some come from America. Others come from Canada, Japan, Australia and England. They speak different languages,but all of them can speak English. They are good friends. They study together, play together and live together. They help each other. All the teachers of this class are Chinese, but they can speak English. They are very kind and friendly. They work hard. The students in this class study Chinese cooking and Chinese gongfu.\n",
            "All the students like China. They say China is a great country and the Chinese people are very friendly. And they are happy in China.\n",
            ",.\n",
            "\n",
            "Question: What kind of class is this?\n",
            "A. A Chinese cooking class\n",
            "B. A Chinese gongfu class\n",
            "C. A foreign language class\n",
            "D. Both A and B\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4796\n",
            "Current Mean Accuracy: 0.4796\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: We have twenty minutes' break time after the second class in the morning.  Look!  Most of us are playing during the break time. Some students are on the playground . They are playing basketball. Oh! A boy is running with the ball.  And another is stopping  him. They look so cool. And there are some girls watching the game. Some students are in the classroom. They are talking.  A few of them are reading and doing homework. Look! A girl is looking at the birds in the tree in front of the classroom. She must be thinking of something interesting because she is smiling .\n",
            "What are the teachers doing? Some of them are working in the office. And some are talking with students. Everyone is doing his or her things, busy but happy!\n",
            "\n",
            "Question: The passage is mainly about   _   .\n",
            "A. students\n",
            "B. a basketball game\n",
            "C. break time activities\n",
            "D. teachers\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4848\n",
            "Current Mean Accuracy: 0.4848\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "Input: Article: Before I left to meet Lynne, my friend told me that I had better take some money, but I didn't listen to him. I thought that Lynne would pay because she invited me.\n",
            "I arrived at the restaurant on time because I knew Americans like to be on time. Lynne and I sat at a table near the door and soon we began to enjoy ourselves there.\n",
            "The food there was very delicious. I talked a lot about Saudi Arabia and Lynne told me all about herself. After two hours the waiter came and asked if we wanted one check  or two. Lynne said two. Lynne paid her check, and the waiter gave me mine, I had no money. Then I had an idea, I called my friend. In a few minutes he arrived with some money. He laughed at me all the way home.\n",
            "Now, I think it's funny, but I guess you can understand how I felt at that time. So when you visit a foreign country, you have to learn their language and culture.\n",
            "\n",
            "Question: After the meal,  _  ,\n",
            "A. Lynne paid only for herself\n",
            "B. Lynne paid for both of us.\n",
            "C. I would like to pay for myself\n",
            "D. I paid for both of us.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4800\n",
            "Current Mean Accuracy: 0.4800\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (RACE_M) ---\n",
            "Final Exact Match Accuracy: 0.4800\n",
            "Final Mean Accuracy: 0.4800\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.47999998927116394, 'accuracy': 0.48}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.06834071636199951}, 'time_per_token': {'mean': 0.06834071636199951}, 'tokens_per_second': {'mean': 17.696622350811957}}\n",
            "Valid formats: ['chat_format', 'cnn_dm_summarization', 'cnn_dm_lm', 'xsum_summarization', 'human_eval', 'custom_jsonl', 'top_v2', 'mmlu', 'race_m', 'race_h']\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset race_m \\\n",
        "       --num_samples 100 \\\n",
        "       --generation_strategy layerdrop \\\n",
        "       --dropout_rate 0.2 \\\n",
        "       --layerdrop_seed 42 \\\n",
        "       --output_dir ./logs \\\n",
        "       --distributed False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: race_m\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on RACE_M with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking RACE_M:   0%|          | 0/100 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 527, in <module>\n",
            "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 499, in main\n",
            "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config, args.seed)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 369, in benchmark\n",
            "    generation_result = generator.generate(\n",
            "                        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\self_speculation\\generator_base.py\", line 111, in generate\n",
            "    generation_strategy_result = self.generation_strategy.generate_token_ids(\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\self_speculation\\self_speculation_generator.py\", line 99, in generate_token_ids\n",
            "    acceptance_rate=total_draft_matches / total_generations,\n",
            "                    ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset race_m \\\n",
        "       --num_samples 100 \\\n",
        "       --generation_strategy self_speculative \\\n",
        "       --dropout_rate 0.2 \\\n",
        "       --layerdrop_seed 42 \\\n",
        "       --output_dir ./logs \\\n",
        "       --distributed False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: mmlu\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on MMLU with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 527, in <module>\n",
            "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 499, in main\n",
            "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config, args.seed)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 369, in benchmark\n",
            "    generation_result = generator.generate(\n",
            "                        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\self_speculation\\generator_base.py\", line 111, in generate\n",
            "    generation_strategy_result = self.generation_strategy.generate_token_ids(\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\self_speculation\\self_speculation_generator.py\", line 99, in generate_token_ids\n",
            "    acceptance_rate=total_draft_matches / total_generations,\n",
            "                    ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset mmlu \\\n",
        "       --num_samples 100 \\\n",
        "       --generation_strategy self_speculative \\\n",
        "       --dropout_rate 0.2 \\\n",
        "       --layerdrop_seed 42 \\\n",
        "       --output_dir ./logs \\\n",
        "       --distributed False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: race_m\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on RACE_M with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.68212890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.583984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
            "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
            "\n",
            "Question: We have   _   in the dining hall.\n",
            "A. breakfast\n",
            "B. lunch\n",
            "C. dinner\n",
            "D. supper\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 1.0000\n",
            "Current Mean Accuracy: 1.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9208984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Kids have unbelievable imaginations. We asked one hundred kids how robots might help them learn better. This is what they thought.\n",
            "Roberts can make learning fun\n",
            "Kids dreamed robots would make learning fun. One 9-year-old boy in Germany says, \"When I get home, my robot helps me with my homework. My mother and father came in and said 'no video games now, homework first'. When they saw that I had finished my homework, they'd be surprised\".\n",
            "Robots take care of the dirty work\n",
            "Dirty dishes? No problem. A quarter of kids surveyed imagined that their robots could do chores and boring work so that they might be freed up.\n",
            "Robots are our friends\n",
            "Two-thirds of the kids thought that their robots could be friends. One 10-year-old French boy describes his dream robot: \"He created books for me to read, we played with toy cars. He keeps my secrets. I can tell him anything, and he gives me suggestions.\"\n",
            "Robots are cool\n",
            "An 8-year-old girl in the U.S. imagines that her robot is \"really smart and everyone likes to talk to her. She has a funny voice, but we do not laugh at her.\"\n",
            "\n",
            "Question: The boy from Germany wanted his robot to  _  .\n",
            "A. help him with the homework\n",
            "B. play game spot with him\n",
            "C. surprise his parents\n",
            "D. make fun of him\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 1.0000\n",
            "Current Mean Accuracy: 1.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1543\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.78564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Visiting Harvard University\n",
            "For All Visitors\n",
            "Attend an hour-long group information meeting in the Admissions Office  \n",
            "Admissions officers give information and answer questions about the visit. No appointment or registration   is required for families or groups of 20 people or less who wish to visit the university. Groups of more than 20 people should email tours @ fas. Harvard. Edu to plan a visit.\n",
            "Take a tour\n",
            "Take a student-led tour of the university. But the dorms  , academic departments , athletic facilities  and libraries are not included on any of our tours.\n",
            "Attend a class\n",
            "The Admissions Office provides a list of the meeting times and locations of courses held during the academic year that visitors are welcome to attend.\n",
            "Speak with the Harvard teachers\n",
            "Teachers and other staff members are often glad to talk to people who have questions about our programs. It is best to write ahead directly to the office to arrange an appointment.\n",
            "For Seniors Only\n",
            "Eat a meal with Harvard students\n",
            "During the academic year, high school seniors are our guests for one meal in Annenberg Hall, the first-year dining hall, or in one of the House dining halls if accompanied by a House resident.\n",
            "Stay overnight in one of the residence halls\n",
            "Our office can arrange for high school seniors to stay with volunteer student hosts for one night, Monday through Thursday, from October 1st through early March. We need to hear from you by phone (617-495-1551) or by mail at least three weeks in advance for us to be able to confirm your stay with a host.\n",
            "\n",
            "Question: Which of the following activities is NOT available  to all visitors?\n",
            "A. A meeting in the Admissions Office.\n",
            "B. An opportunity  to talk with a teacher.\n",
            "C. A tour of the university.\n",
            "D. A meal with Harvard students.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 1.0000\n",
            "Current Mean Accuracy: 1.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06146240234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.53955078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Tommy hated school and was always looking for excuses  not to go.If he sneezed, he asked his mother to write a note saying he had a cold.If he had a headache, he asked his mother to take him to the doctor during school hours.\n",
            "He spent more time at home than he did at school.On the days that he did go to school, he looked for excuses to come home early.One morning he came home when the lessons were only half finished.His father was surprised.\n",
            "\"You've come home early,\" he said. \"Is the school closed today?\"\n",
            "\"No, Dad, \" Tommy said - \"It's open. I came home early.\n",
            "\"How did you do that?\" his father asked him. \"What did you say to the teacher?\"\n",
            "\"I told her that I had a new baby brother and that I had to come home and help you . \"\n",
            "\"But your mother has had twins,\" his father said, \"a boy and a girl. You've got a baby brother and a baby sister.\"\n",
            "\"Yes, I know, Dad, \" Tommy said. \"I'm saving up my baby sister for next week \"\n",
            "\n",
            "Question: When he did go to school,he   _  .\n",
            "A. was always later\n",
            "B. tried to leave early\n",
            "C. was always sick\n",
            "D. was very happy\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.7500\n",
            "Current Mean Accuracy: 0.7500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7333984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
            "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
            "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
            "What could she do now?\n",
            "\n",
            "Question: What would happen if Celina told Joseph the truth?\n",
            "A. Joseph would go on the camping trip himself.\n",
            "B. Joseph's family would be angry with Celina.\n",
            "C. Celina might have trouble with her friends.\n",
            "D. Joseph would be thankful to his classmates.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.23486328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.40966796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
            "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
            "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
            "What could she do now?\n",
            "\n",
            "Question: If Joseph bought a sleeping bag,   _  .\n",
            "A. he would have it for no use.\n",
            "B. everyone else would also buy one\n",
            "C. it would be the best in the class\n",
            "D. Celina would pay for it\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.092529296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7529296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: A mother and her young son got into a bus in New York City and sat down. The bus conductor  came to them for their money. The mother said, \"I want one ticket  to Central Park, \"and gave him two dollars. The conductor looked at the small boy for a few seconds and then asked him, \"How old are you, young man?\"  The mother just began to speak, but the conductor stopped her, and the boy said, \"I'm four years old at home, and two and a half on buses and trains.\"  The mother felt shamed , so she took another dollar out of her bag and gave the money to the conductor. The conductor gave her one and a half tickets.\n",
            "\n",
            "Question: One day the mother took a bus   _  .\n",
            "A. to a small city\n",
            "B. to get some money\n",
            "C. with her son\n",
            "D. to school\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.7143\n",
            "Current Mean Accuracy: 0.7143\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.352294921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5849609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When you look up into the sky at night, have you ever felt that your eyes are playing tricks on   you? It seems that the stars are moving all the time.\n",
            "Actually, there is nothing wrong with your eyes. This twinkling effect is called scintillation  . Scintillation happens because of air movements in the earth's atmosphere  . Light is \"bent  \" when it travels through different parts of the earth's atmosphere. As the air in the earth's atmosphere is moving all the time, the light from the stars looks as if it is moving too.\n",
            "The same thing also happens to things on the ground. On a very hot and shiny day, if you look at the road, the image in the distance is not clear and things move slightly. You can also see the same effect if you drop a rock into water. The rock appears a little unclear under the moving water.\n",
            "This twinkling effect causes a lot of problems for astronomers   since they cannot _ the stars clearly. A telescope   was sent into space so that the air movements in the atmosphere could be avoided  . It took a long time to build the space telescope but finally in 1990, a huge space telescope called the Hubble Space Telescope was successfully sent into space. Since then, astronomers have many important observations that have helped people understand space better.\n",
            ",.  (10)\n",
            "\n",
            "Question: What can you see when you drop a rock into the water?\n",
            "A. The rock gets broken.\n",
            "B. The rock becomes unclear.\n",
            "C. The water becomes much polluted.\n",
            "D. The water does not move anymore.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.7500\n",
            "Current Mean Accuracy: 0.7500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10784912109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.70263671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: The Biggest and the Gentle\n",
            "The elephant is the biggest four-legged animal in the world.It is also the gentlest,but not always!\n",
            "Elephants are like us in some ways.They live for a long time--fifty or sixty years.They can remember things very well.They never forget great sadness or great happiness.When female elephant dies,her daughters and her granddaughters are sad for many months.They stay with the dead body.Then they carry a bit of it away with them.They never forget a dear friend.\n",
            "Elephants are like us,but they are also different.They live in families of females.There will be a few young males a few\"baby boys\".But the females will soon send them away.And elephant family keeps only its daughters,mothers and grandmothers.And its great-grandmothers.\n",
            "The females stay together for fifty,sixty...a hundred years.The older animals look after the younger ones.The mothers teach their daughters and set a good example.\n",
            "And what happens to male elephants?Well,the young males stay with their family.Then the females just send them away.A bull elephant does not often have a friend.He lives apart,away from the family,and often away from other bulls.\n",
            "Sometimes the females call a bull.He can visit them then,and stay for some time.But soon his\"wives\"and sisters send him away again.The females have a very happy family life.What do the bulls think about it?We don't know.\n",
            "\n",
            "Question: When a female elephant dies,the others  _  .\n",
            "A. leave its dead body there\n",
            "B. shed tears together\n",
            "C. take a bit of the dead body away sadly\n",
            "D. bury the dead\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.7778\n",
            "Current Mean Accuracy: 0.7778\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04583740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.191650390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Did you notice the number on the book in a library? That number is part of the system used by libraries to organize their collections of books. And it's used in many countries. The number on each book tells you exactly what kind of book it is. This system is also useful for knowing where to go in the library to find a book.\n",
            "In this system, there are ten large groups of books. Each of these groups has its own number, such as 100, 200, etc. So, for example, any books about language will have a number 400. On the other hand, any books about history will have a number 900. So, a number in the hundreds place tells you what general group a book is in. If you find a book that has a number in the 500s, you know it is a book about science.\n",
            "However, science is a big group, so the tens place is used to make a more detailed set of science books. For example, math books are included in the group of science books. Math books all have numbers between 510 and 519. Books about the history of Africa have numbers between 960 and 969.\n",
            "The system uses the ones place to give a more exact limit for the subject of a book. A book on the history of South Africa will have the number 968.\n",
            "As you can see, it is a simple system to use as long as you understand what the numbers mean. With this system, the library can keep its books well organized, and people can easily find the book that they want.\n",
            "\n",
            "Question: A book about math can be found in the same group of books as  _  .\n",
            "A. reference books\n",
            "B. school books\n",
            "C. science books\n",
            "D. art books\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.8000\n",
            "Current Mean Accuracy: 0.8000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 103983\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.029693603515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.52197265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: I am a Chinese boy. My name is Li Ming. I'm a student. In my class, some of the boys like playing football very much. Wu Jun and I are on school football team. And some of them like playing basketball. _ Han Mei and Zhang Hong are on school volleyball team. Each of them has a tennis racket. In a word  , everyone in our class likes sports very much.\n",
            "\n",
            "Question: The girls like playing   _  .\n",
            "A. tennis and basketball\n",
            "B. football and basketball\n",
            "C. tennis and volleyball\n",
            "D. volleyball and basketball\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.7273\n",
            "Current Mean Accuracy: 0.7273\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.58740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Would you like to adopt an animal? Although this sounds very unusual, some children have done just this. The Natural Zoo has given people the chance to adopt animals by paying for all of its food for one year. One of the animals that needed parents was a young tiger named Brocky. The people at the zoo said that it would cost about $900 a year for the food for Brocky.\n",
            "Not many boys and girls have $900 to spend. That is why several hundred children and grown-ups each have sent a little money to the zoo to help pay for Brocky's food. Some children sent in only a quarter because that was all the money they had. Other children sent in more money than that.\n",
            "Since so many people sent money to the zoo to help pay for Brocky's food, he now will be able to eat as much as he wants. Brocky surely must be a happy tiger to know that he has so many adopted parents. Many children must also be happy to know that they have helped to feed him. It really will be thrilling for those children to go to the Natural Zoo to visit their adopted tiger Brocky.\n",
            "\n",
            "Question: With so many people's money, Brocky now can   _  .\n",
            "A. play with many toys\n",
            "B. live without being hungry\n",
            "C. eat meat every day\n",
            "D. have an air-conditioned room to live in\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.7500\n",
            "Current Mean Accuracy: 0.7500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.28955078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1534423828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
            "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
            "\n",
            "Question: What colours does Nancy like?\n",
            "A. Red and blue.\n",
            "B. Red and yellow.\n",
            "C. Green and yellow.\n",
            "D. Green and blue.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6923\n",
            "Current Mean Accuracy: 0.6923\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.380859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.86865234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Snack time is a part of the day for children of all ages. But new research suggests that kids snacking in big groups could be at risk for _ .\n",
            "Scientists from American University looked at the eating behavior of 54 kids between the ages of 2 and 6. At snack time, the scientist watched the amount of food each child ate while they were in groups of either three or nine. According to the study, the more children there are in a group, the more likely they are to eat more. Those in the larger group ate nearly 30 percent more than those in the smaller group, and they actually ate faster.\n",
            "Since this is the first such study in children, scientists are quick to point out the importance of encouraging healthy habits in kids as early as possible.\n",
            "\"If you know kids eat more in large groups, it seems perfect to use this information to keep snack groups small or use small tables,\" says Dr. Jana Klauer, an expert in New York.\n",
            "Smaller groups would allow for a quiet and more relaxing environment-a perfect chance to teach children about food, manners and how to know when they feel full. \"This would have an effect on kids' eating,\" adds Klauer. \"They would slow down and eat less.\"\n",
            "\n",
            "Question: Why do children in smaller groups lose weight?\n",
            "A. Because children in smaller groups eat faster.\n",
            "B. Because children in smaller groups don't like eating.\n",
            "C. Because children in smaller groups don't know about food.\n",
            "D. Because children in smaller groups eat slowly and eat less.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6429\n",
            "Current Mean Accuracy: 0.6429\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8093\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.028076171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.47119140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
            "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
            "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
            "\n",
            "Question: What did the white lambs think of the black lamb?\n",
            "A. Friendly.\n",
            "B. Kind.\n",
            "C. Ugly.\n",
            "D. Beautiful.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.88720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.673828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: In a small village in England about 150 years ago, a mail coach (    ) was standing on the street . It didn't come to that village often  . People had to pay a lot to get a letter . The person who sent the letter didn't have to pay the postage (     )  , while the receiver had to .\n",
            "\"Here's a letter for Miss Alice Brown , \" said the mailman .\n",
            "\" I'm  Alice Brown , \" a girl of about 18 said in a low voice .\n",
            "Alice looked at the envelope  for a minute , and then handed it back to the mailman .\n",
            "\" I'm sorry I can't take it , I don't have enough money to pay it\", she said .\n",
            "A gentleman standing around were very sorry for her . Then he came up and paid the postage for her .\n",
            "When the gentleman gave the letter to her , she said with a smile , \" Thank you very much ,This letter is from Tom . I'm going to marry him . He went to London to look for work . I've waited a long time for this letter , but now I don't need it , there is nothing in it .\"\n",
            "\" Really ? How do you know that ? \" the gentleman said in surprise .\n",
            "\" He told me that he would put some signs on the envelope . Look ,sir ,this cross in the corner means that he is well and this circle means he has found work . That's good news .\"\n",
            "The gentleman was Sir Rowland Hill . He didn't forgot Alice and her letter .\n",
            "\" The postage to be paid by the receiver has to be changed ,\" he said to himself and had a good plan .\n",
            "\" The postage has to be much lower , what about a penny (    ) ? And the person who sends the letter pays the postage . He has to buy a stamp and put it on the envelope .\" he said .\n",
            "The government accepted his plan . Then the first stamp was put out in 1840 . It was called the \" Penny Black \" . It had a picture of the Queen on it .\n",
            "\n",
            "Question: The girl handed the letter back to the mailman because   _   .\n",
            "A. she didn't know whose letter it was\n",
            "B. she had no money to pay the postage\n",
            "C. she received the letter but she didn't want to open it\n",
            "D. she had already known what was written in the letter\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6250\n",
            "Current Mean Accuracy: 0.6250\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.097412109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
            "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
            "\n",
            "Question: Tony is from  _  .\n",
            "A. England\n",
            "B. America\n",
            "C. English\n",
            "D. American\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6471\n",
            "Current Mean Accuracy: 0.6471\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2237548828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.310302734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Just as \"Tiger Mom\" leaves, here comes the \"Wolf Daddy\" called Xiao Baiyou. He believes he's the best parent in the world. Some days ago, Xiao Baiyou's latest book about how to be a successful parent came out. He is pretty strict with his four children. Sometimes he even beat them. But the children don't hate their daddy at all. And all of them finally went to Pecking University, one of the top universities in China. So Xiao proudly tells others about his education idea that children need strict rules. In his microblog, he said, \"Come on, want your children to enter Peking University without rules? You must be joking.\" And, \"Leave your children more money, and strict rules at the same time.\"But the \"Wolf Daddy\" way was soon questioned by other parents. Some say that Xiao Baiyou just want to be famous by doing so. The \"Wolf Daddy\" Xiao Baiyou is a 47-year-old Guangdong businessman who deals in luxury goods  in Hong Kong. Unlike many other parents who usually have one child, Xiao has four children. Two of them were born in Hong Kong and two in the US. Some people on the Internet think the reason why his children were able to enter Peking University is because the exam is much easier taken from Hong Kong.\n",
            "\n",
            "Question: As for how to be a parent, Xiao Baiyu thinks   _  .\n",
            "A. children don't need rules\n",
            "B. children need strict rules\n",
            "C. children don't need money\n",
            "D. children need luxury goods\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.414794921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: In today's world many people seem to be hungry for money. Some of them even have lost their lives for it. Money does have a great effect on the poor, but if a person has a rich life, a lot more money doesn't mean more happiness.\n",
            "If money were everything, all millionaires would have true love, real friendship, health and a long life. However, this is not always true.\n",
            "Nothing else is more pleasant than the three words \"I love you\", but can love be bought? I'm afraid not. Love means \"give\", not \" take\". Health and a long life are precious things for every person. Well, can health and a long life be bought with money? The answer is \"No\". Of all the people who live longest in the world, few of them are millionaires. Real friendship can't be bought, either.\n",
            "In a word, where money is _ , money can cause brothers to quarrel, lovers to hate, strangers to fight and so on. No matter how much money you have, _ is still not enough to make you a happy person if you have no one to laugh with and no one to cry for.\n",
            ",\n",
            "\n",
            "Question: What does the passage mainly tell us?\n",
            "A. Money is as important as true love.\n",
            "B. Money isn't necessary.\n",
            "C. Money is important, but not the most important.\n",
            "D. Money can cause some problems.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6316\n",
            "Current Mean Accuracy: 0.6316\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.931640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.79052734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: In some places around China,the junior high school graduates have to take a P. E. test. The full marks are usually 30 points and it counts for much in the senior high school entrance exam.\n",
            "In Nanjing the test is held in April. Students have the test in their own schools. Each student is tested on three sports. They can choose long jump, basketball dribbling   or volleyball. The _ is for boys and girls can choose the sit-up. Both boys and girls must skip  in the test.\n",
            "Most students find the test easy and more than 90%of them can get full marks. That's because they have been training for it during the three whole years. Students in Junior Three usually do lots of practice in P. E. classes. The training makes the test easier than it seems to be.\n",
            "Students in Nanjing don't need to run a lot for the test, but students in Beijing must do lots of running for the test. Running is one of the sports in test. So in P. E. classes, they usually run a lot. Sometimes they have to run 3,000 meters in one class. Most teachers and parents welcome the P. E. test. They say it helps students build up their health and it's really useful.\n",
            ",.\n",
            "\n",
            "Question: The P. E. test in Nanjing includes all of these sports except   _  .\n",
            "A. skipping\n",
            "B. basketball\n",
            "C. football\n",
            "D. volleyball\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.60595703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Dear Boris,\n",
            "Thanks for your nice letter.\n",
            "After I had spent a week with my English family, I slowly began to understand their English a little better. It's very different from what I learned at school! Students in my group are from different cities of Britain and their dialects   are different too! Some of their accents   are quite strong and they also have their own words and expressions.\n",
            "But it's not the language that's different and surprising. Before I came to England I had thought that fish and chips were eaten every day. That's quite wrong! I get rather mad now when I hear all the foolish words about typical   English food.\n",
            "I had expected to see \"London fog\". Do you remember our texts about it? We had no idea that most of this 'thick fog' disappeared many years ago when people stopped using coal in their homes. But the idea to speak about the weather was very helpful. The weather in London is really changeable.\n",
            "On the other hand habits are different. People tell me what is typically British here in London is not always typical in Wales or Scotland. Local habits and traditions are not the same as what we knew.\n",
            "But what is ordinary for all British is that they follow traditions. Probably Britain has more living signs of its past than many other countries. And people have always been proud of having ancient buildings in capitals, big cities and the countryside.\n",
            "I will tell you more about Britain in my other letters.\n",
            "Love from Britain,\n",
            "Peter\n",
            "\n",
            "Question: The British people like to talk about weather because   _  .\n",
            "A. there is thick fog in London\n",
            "B. they like the weather in Britain\n",
            "C. the weather changes a lot\n",
            "D. it can be helpful\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5714\n",
            "Current Mean Accuracy: 0.5714\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11138916015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Once a traveller came into a village which was suffering from hunger. The villagers asked him to leave, for they feared he wanted them to give him food. They told him that there was no food. The traveller explained that he didn't need any food and that, in fact, he was planning to make a soup to share with them instead. The villagers watched suspiciously as he built a fire and filled a pot with water With great ceremony , he pulled a stone from a bag, and dropped the stone into the pot of water. After a moment, he smelt the soup and shouted with excitement, \"How delicious the soup is!\" As the villagers began to show interest, he mentioned how good the soup would be with just a little cabbage in it. A villager brought out a cabbage to share. This episode  repeated itself until the soup had cabbage, carrots, onions, and beets--indeed, a full pot of soup that could feed everyone in the village was ready. This story describes when there are not enough resources , humans will store things. We do not want to share. The story of stone soup helps us realize that, in doing so, we often prevent ourselves and everyone else from having a feast .The meaning of this story goes far beyond food. We keep to ourselves ideas, love, and energy, thinking we will be richer, but in fact we make the world, and ourselves, poorer. The traveller was able to see that the villagers were holding back, and he had the ability to inspire  them to give. In this way, they created a large meal that none of them could have created alone. Are you like one of the villagers? If you come forward and share your gifts, you will inspire others to do the same. The reward is a feast that can feed many.\n",
            "\n",
            "Question: The writer mainly wants to tell us that .\n",
            "A. storing things in hard times is human nature\n",
            "B. a good leader is very necessary in hard times\n",
            "C. skills are needed to inspire people to share with others\n",
            "D. sharing is more important than keeping things to oneself\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5909\n",
            "Current Mean Accuracy: 0.5909\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.90869140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 119714\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1297607421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Why do we come to school? Most of us may say we come to school to study. But to study needs a right way, or you either waste the time or the money. The following are the ways for studying.\n",
            "The best time for reading is morning. In the morning the air is fresh and the mind is clear. For that reason we can get good results.\n",
            "In studying we must have patience . If we have not known a text well, we must read it again. We should not read the next one until we have learned the first one well.\n",
            "When we are studying, we must put our hearts into the books, or we can get nothing from the books while we are reading.\n",
            "We must always ask \"whys\". If it is not well understood, write it down and ask our teachers or our parents, brothers or friends. In any possible way, we must know it completely and what we have learned can be used well and made better.\n",
            "Though there are many ways for studying, yet what I have said above will be enough if we can keep them in heart and do so.\n",
            "\n",
            "Question: While reading we can't get anything from the book if we   _  .\n",
            "A. read very fast\n",
            "B. read in the afternoon\n",
            "C. don't read it again\n",
            "D. can't put our hearts into it\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6087\n",
            "Current Mean Accuracy: 0.6087\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.6064453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13296\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07757568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
            "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
            "\n",
            "Question: Tony comes to China with  _  .\n",
            "A. his father\n",
            "B. his mother\n",
            "C. his father and mother\n",
            "D. his friends\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6250\n",
            "Current Mean Accuracy: 0.6250\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12333\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.87255859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: In many countries, holidays are important parts in people's life. Let's show some countries to you.\n",
            "America\n",
            "American people's holidays are flexible ( ). They can use up their holidays once, and they can also use them up a few times. During the holidays, they still get money.\n",
            "Canada\n",
            "Many people in Canada can rest three days a week. They have all kinds of activities   for holidays. They may go fishing, boating or mountain climbing. Also, they have long holidays. They may go to the beach to spend a sunny winter holiday. Like American people, Canadians also get money during the holidays.\n",
            "France\n",
            "People in France are very good at enjoying life. They have a 6-week holiday every year, and they work less than 40 hours a week.\n",
            "\n",
            "Question: Which of the following activities is not mentioned in the passage?\n",
            "A. Go fishing.\n",
            "B. Go boating.\n",
            "C. Go skating.\n",
            "D. Go mountain climbing.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6400\n",
            "Current Mean Accuracy: 0.6400\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.050567626953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
            "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
            "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
            "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
            "\n",
            "Question: What does the user mean by saying \"After 14 days of detention, Ko's acting skills grew a lot\"?\n",
            "A. He thinks Ko is still a good actor.\n",
            "B. He supports Ko no matter what happened.\n",
            "C. He doesn't trust what Ko said.\n",
            "D. He thinks Ko has trained hard and improved his acting skills.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6154\n",
            "Current Mean Accuracy: 0.6154\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 6927\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2100830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Usually, students are not encouraged to run or jump around in the corridor  . However, students in a British grammar school really enjoy running on the corridor tiles   and their teachers even encourage them to do that.\n",
            "Why? It is because the corridor was built with special kinetic   tiles. When students jump on the tiles, electricity will be produced. After one year, the electricity produced from the tiles can fully charge 853 mobile phones or power  an electric car to drive seven miles. It's amazing, isn't it?\n",
            "The corridor tiles are really a brilliant invention. Students can not only play on the corridor, but also help power the lights in their school corridors and other equipment in their classrooms. Besides, this is a good way to teach students to be creative. They will be _ to be scientists, inventors and engineers in the future to find clean energy for all humans.\n",
            "The inventor of the magic corridor tiles is Laurence Kemball-Cook. He was once a student in this school. Now, he is CEO of his own company. The corridor tiles are not Laurence's only invention. He has also invented a special dance floor, which can be used at music festivals. It allows dancers to charge their mobile phones while they are dancing on the dance floor.\n",
            "\n",
            "Question: After one year, the electricity produced from the tiles can provide enough energy for   _  .\n",
            "A. over 800 mobile phones\n",
            "B. all the lights of the school\n",
            "C. an electric car to drive 70 miles\n",
            "D. the lights and other equipment in their classrooms.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6296\n",
            "Current Mean Accuracy: 0.6296\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.6337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15144\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05419921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: There was a new maths teacher and some new students in the school. One of the new students named Karl was very _ . The other students tried to explain   numbers to him, but he didn't understand.\n",
            "Before Karl arrived, maths was the most boring lesson of all. Now it was great fun. The children would listen to Karl and correct his mistakes. They all wanted to be the first to find his mistakes, and then tried to think up the best ways to explain them.\n",
            "But little Lewis was sure that Karl felt sad and wanted to talk with him. So, one day, he decided to walk after Karl after school. Lewis was sure he would see him crying. On the way home, Karl walked a few minutes to a park, and there he waited for someone to meet him...\n",
            "It was the new teacher!\n",
            "They went off, hand in hand. Lewis could hear them talking about maths. And that stupid Karl knew everything about it, and even much more than anyone else in the class!\n",
            "\n",
            "Question: Which lesson was the most boring of all before Karl arrived?\n",
            "A. Chinese.\n",
            "B. English.\n",
            "C. Maths.\n",
            "D. Music.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6429\n",
            "Current Mean Accuracy: 0.6429\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4849\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.156494140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.329345703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Some women are talking about the problems of getting old.\n",
            "One woman says, \" Sometimes I stand in front of the bag with an egg. But I can't remember _ I need to put it in or get it out to make bread.\"\n",
            "\"Yes, I have the same problem,\" the second woman says. \"Sometimes I stand on the stairs . But I can't remember whether I am going on my way up or down.\"\n",
            "\"Well, I don't have that problem,\" the last woman says, keeping knocking  on the table.\n",
            "The other two women ask, \"Why are you knocking on the table?\"\n",
            "\"Sorry, I ?don't know. Someone is knocking at the door ,isn't\n",
            "It? Let me see who it is,\" the last woman says.\n",
            "\n",
            "Question: Whose problem is the most serious   in the story?\n",
            "A. The first woman.\n",
            "B. The second woman.\n",
            "C. The third woman.\n",
            "D. The fourth woman.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6207\n",
            "Current Mean Accuracy: 0.6207\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 28206\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01476287841796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3369140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
            "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
            "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
            "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
            "\n",
            "Question: Little Mike went to the park and   _  .\n",
            "A. played with pigeons\n",
            "B. met an old lady\n",
            "C. fed pigeons\n",
            "D. saw a friend of his grandma's\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6333\n",
            "Current Mean Accuracy: 0.6333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5224609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When someone says, \"Well, I guess I'll have to face the music\", it doesn't mean that he is going to hear a singer. It is something far less happy, as you are called in by your leader to explain why you did this and did that or why you did not do this or that.\n",
            "At some time or another, every one of us has to \"face the music\", especially as children. We can all remember father's angry words \"I want to talk to you.\" And only because we did not listen to him. What a bad thing it was!\n",
            "In the middle or at the end of every term, we students have to \"face the music\". The result of the exam will decide whether we will face the music or not. If you got a \"D\" in the exam, that means parents' cold faces and the contempt  of the classmates.\n",
            "\"To face the music\" is well-known to every American, young or old. It is at least 100 years old. It really means that you have to do something, no matter how terrible the whole thing might be, because you have no choice.\n",
            "\n",
            "Question: Which of the following is wrong?\n",
            "A. \"To face the music\" is well-known in the US.\n",
            "B. \"To face the music\" has a history of more than 100 years.\n",
            "C. The young Americans know the meaning of \"to face the music\".\n",
            "D. Only the old in the US know the meaning of \"to face the music\"\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6452\n",
            "Current Mean Accuracy: 0.6452\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.26708984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.74462890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: It is very important for children to get to school safely and on time every day. Luckily, there is a new program called Free Home to School Transport . It gives children free rides to school. But to enjoy the free trip. Children have to qualify .\n",
            "Children can take free home to school transport if they:\n",
            "*are between 5 and 16 years old\n",
            "*are going to the nearest school\n",
            "*live far away from school\n",
            "No matter how far away children live from school, they Can take the free transport if they have walking problems or there is no safe road for them. A safe road usually has crossings, lights and should be clean.\n",
            "Also, there are still free home to school _ for children in poor families and children with special educational needs, you can find out more on the Internet and see if your children are qualified.\n",
            "\n",
            "Question: According to the passage, it is very important for children not to be   _  for school every day.\n",
            "A. late\n",
            "B. away\n",
            "C. early\n",
            "D. ill\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6562\n",
            "Current Mean Accuracy: 0.6562\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2454833984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 73933\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.48388671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
            "\n",
            "Question: They work on   _  .\n",
            "A. weekends\n",
            "B. Friday\n",
            "C. Sundays\n",
            "D. weekdays\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.303955078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 78798\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1395263671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Kitesurfing as a water sport began in the 1980s, but didn't get popular until the end of last century. It is also known as kiteboarding, and in some European countries as flysurfing. Kitesurfing works through wind power  by using a large kite to pull a rider on the water at high speed.\n",
            "At first, kitesurfing was a difficult and dangerous sport. Now it is becoming easier and safer because of the safer kite design. For an able and strong person, kitesurfing can be a very fun, extremely exciting sport, just like skating on the water with a feeling of flying. It has become more and more popular.\n",
            "Compared with other water sports, kitesurfing is easier to learn. A beginner can understand how to operate the kite with 5--10 hours of training. And anybody aged from 13 to 65 can learn. It is not expensive to get the equipment for kitesurfing, which costs $1,000 to 82,500. Training lessons _ from $200 to $500 for two or three hours. With the development of its equipment progress, kitesurfing is becoming even safer. After some training, you can enjoy its excitement and challenging feeling.\n",
            "With the rising popularity of kitesurfing, most major seaside cities have kitesurfing clubs. In China, Xiamen is the only place that has the kitesurfing club, which provides professional kitesurfing training and equipments.\n",
            "\n",
            "Question: The most important reason for the popularity of kitesurfing is that   _  .\n",
            "A. its price is getting lower and lower\n",
            "B. more and more people are enjoying its excitement\n",
            "C. its equipment progress makes it easier and safer\n",
            "D. all people can learn and take part in it\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6765\n",
            "Current Mean Accuracy: 0.6765\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.57861328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7373046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
            "\n",
            "Question: In the south of China,many people go to work   _  .\n",
            "A. by plane\n",
            "B. on foot\n",
            "C. by boat\n",
            "D. by ropeway\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6571\n",
            "Current Mean Accuracy: 0.6571\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21938\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0477294921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.269287109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Where are the animals having the sports meeting?\n",
            "A. In the forest\n",
            "B. In a park\n",
            "C. In a zoo\n",
            "D. In a school.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6667\n",
            "Current Mean Accuracy: 0.6667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.93359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
            "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
            "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
            "\n",
            "Question: Why do people go and live in valleys near rives ?\n",
            "A. The temperature isn't too low in winter.\n",
            "B. The resources like oil can bring them much money.\n",
            "C. People can make their living by catching and selling fish.\n",
            "D. It's easier for people to grow plants or keep animals.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6757\n",
            "Current Mean Accuracy: 0.6757\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.43017578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.56298828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Last Sunday afternoon, I was having dinner in a restaurant when my friend Poor came in. Poor is working in a bank and is quite rich, but he is always borrowing money from his friends and never pays it back. Poor saw me and came to sit at my table. He had never borrowed any money from me. When he was eating, I asked him to lend me two dollars. To my surprise, he gave me the money at once.\"I have never borrowed any money from you,\"Poor said,\"So you can pay for my dinner.\"\n",
            "Read the passage and choose the best answers.(,. )\n",
            "\n",
            "Question: The story happened    _    .\n",
            "A. at home\n",
            "B. in a restaurant\n",
            "C. in a bank\n",
            "D. in an office\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6579\n",
            "Current Mean Accuracy: 0.6579\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.052581787109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello! My name is Zhang Fei. I am Chinese. I am twelve. I'm in No.1 Middle School in Nanjing. This is my friend. His name is Tony Green. He is an English boy .He is twelve. He and I are in the same  class. Our classroom is next to  the teachers' office .We have Chinese and English lessons  every day. Our English teacher is Mr. Read. He is English but he can speak Chinese. Our Chinese teacher is Mr. Ding. They are good teachers, and they are our friends, too\n",
            "\n",
            "Question: Mr. Read is Zhang Fei's  _\n",
            "A. English teacher\n",
            "B. Chinese teacher\n",
            "C. father\n",
            "D. classmate\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  A\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6410\n",
            "Current Mean Accuracy: 0.6410\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1969\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: South Korean stars shined brightly at the Opening Ceremony of the 17th Asian Games held here on Friday, Sept. 19 in Inchen .\n",
            "Many stars gave shows during the welcoming performance.The most famous K-pop boy group, EXO, performed two songs on stage.Famous actors followed to show up on stage, including Jang Dong-gun, Hyun Bin, and Kim Soo-hyun.Lee Young-ae, the South Korean actress known for volunteering, was the last torchbearer  and lighted the cauldron  with two children.\n",
            "After the lighting of the flame, 16 more minutes of other K-pop performances were held. JYJ sang the theme song 'Only One' and Psy and Chinese pianist Lang Lang finally performed \"Gangnam Style\" with the 60,000-strong audience.\n",
            "\n",
            "Question: _   lighted the cauldron at last.\n",
            "A. Jang Dong-gun\n",
            "B. Hyun Bin\n",
            "C. Kim Soo-hyun\n",
            "D. Lee Young-ae\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6500\n",
            "Current Mean Accuracy: 0.6500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2088623046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
            "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
            "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
            "She understood that she hadn't worn the hair clip to school at all.\n",
            "\n",
            "Question: Which of the following sentence is true?\n",
            "A. The girl is not as beautiful as other girls.\n",
            "B. Nobody liked the girl.\n",
            "C. The girl's classmates thought she was more beautiful than before with the hair clip.\n",
            "D. The girl wanted to be more beautiful, so she decided to wear the hair clip.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6341\n",
            "Current Mean Accuracy: 0.6341\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8093\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.82666015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When my wife left this world, I chose to travel in Antigua looking for a peaceful place to rest my old body. Not quite old and weak, I felt I wanted something more than the usual hotel room with 24-hour room service.\n",
            "I decided this year to try something completely new and booked myself a private holiday home in Antigua. This was the best decision I had ever made, as there was plenty to do, plenty to see and lots of lovely restaurants to visit. There was a private swimming pool, and a cool, wide yard where I ate my breakfast most mornings.\n",
            "Antigua has to be one of the loveliest places on earth to spend a holiday. The bright blue sea and the endless blue around the beach areas proved to be an excellent place for me to spend the long afternoons.\n",
            "I had to hurry to do what I wanted to do before the holiday came to an end. I managed to visit the Sugar Mill and Shirley Heights on my last two days and yet found myself wondering whether I could extend for a few more days.\n",
            "I rented a boat and came home after a day's sailing, refreshed, looking forward to dinner. Everything is so pleasant on these beautiful islands, swept by the trade winds and warmed by the sun for so many summer months. The food just tasted better to me, perhaps because I was having such a great holiday. There was always someone to have a drink with---- that's what I liked most.\n",
            "\n",
            "Question: The passage is most likely to be taken from a part of   _  .\n",
            "A. a tour guide\n",
            "B. a travel diary\n",
            "C. a student's report\n",
            "D. a health report\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6429\n",
            "Current Mean Accuracy: 0.6429\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21938\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1925048828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2509765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
            "\n",
            "Question: From the passage, we know   _   .\n",
            "A. Jim and Andy like seeing movies\n",
            "B. Jim and Andy like helping others\n",
            "C. Jim and Andy want to be actors\n",
            "D. the four people in the story become friends after that\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6512\n",
            "Current Mean Accuracy: 0.6512\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21938\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.56201171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Dr. Sharon M. Draper is an excellent teacher as well as a successful writer. She is a woman of achievements.\n",
            "She had been honored  as the National Teacher of the Year, is a five-time winner of the Coretta Scott King Literary Awards, and is a New York Times bestselling writer. Tears of a Tiger has received many awards. It was one of the top 100 books for young adults.\n",
            "She was chosen as Ohio's Outstanding High School Language Arts Educator, Ohio Teacher of the Year, and as a NCNW Excellence in Teaching Award winner.\n",
            "She is a Milken Family Foundation National Educator Award winner.\n",
            "She is a YWCA Career Woman of Achievement, and is the recipient  if the Dean's Award from Howard University School of Education.\n",
            "5 years ago she was named Ohio Pioneer in Education by the Ohio State Department of Education, and received the Beacon of Light Humanitarian Award, as well as the Doctor of Laws Degree from Pepperdine University.\n",
            "She has been honored at the White House six times, and was chosen as one of only four writers in the country to speak at National Book Festival Gala in Washington, D.C. Her book Copper Sun has been chosen by the US State Department and the International Reading Association as the United States novel for the international reading project. Students in the US, Nigeria, and Ghana are reading the book and sharing the ideas.\n",
            "She has worked all over the United States, as well as in Russia, Ghana, Togo, Kenya, Ethiopia, Bermuda, and Guam, spreading the word about the power of successful teaching and excellence in education.\n",
            "She became known when she won first prize in a literary  competition. She was given $5000 and her short story, One Small Torch, came out. Besides her short stories, poems, articles can often be read in literary journals . Her books are also very popular in America, too. Here are some:\n",
            "We Beat the Street (Dutton, 2005)\n",
            "Copper Sun (Simon and Schuster, 2006)\n",
            "Fire from the Rock (Dutton, 2007)\n",
            "Just Another Hero (Simon and Schuster, 2009)\n",
            "Out of my Mind (Simon and Schuster, 2010)\n",
            "\n",
            "Question: The passage is mainly about   _  .\n",
            "A. Draper's achievements\n",
            "B. Draper's experience\n",
            "C. Draper's character\n",
            "D. Draper's effort\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6364\n",
            "Current Mean Accuracy: 0.6364\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12042236328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.188232421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Music is an important part in our life. We may feel boring without music. Today when you go to stores, stations, restaurants and other places, do you notice music playing at any of these places? The answer must be \"Yes\". And you might even hear music in an office or on a farm.\n",
            "I like many kinds of music. Classical music is great. Rock music is fast. Light music is relaxing. But I like folk music best. It sounds very beautiful. It can bring me into the dream land. It can make me relax and forget all the problems. It makes me learn better and helps me to be more active. It is true that I learn better when I am relaxed.\n",
            "Music can also influence  people's behavior . Classical music makes people feel rich . When a restaurant plays classical music, people spend more money on food and drinks. When the restaurant plays modern music, people spend less money. Without music, people spend evenless. Restaurants can make more money in this way.\n",
            "\n",
            "Question: Which type of music below can make the writer relax?\n",
            "A. Light music.\n",
            "B. Folk music.\n",
            "C. Rock music.\n",
            "D. Pop music.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6444\n",
            "Current Mean Accuracy: 0.6444\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.57080078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12333\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Which of the following is NOT right?\n",
            "A. The elephants and lions are playing soccer.\n",
            "B. Some pandas are watching the soccer game.\n",
            "C. A dolphin and a penguin are swimming in the pool.\n",
            "D. A giraffe is eating apples under the trees\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6304\n",
            "Current Mean Accuracy: 0.6304\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.86181640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Kinsale may be one of the smallest towns in Southern Ireland, and it's also one of the most famous towns. It is well known for its wonderful fish restaurants. Some of the best known chiefs in the world have practiced in the restaurants there. The town itself is very beautiful in Southern Ireland by the sea. Here it is cooler in summer than other island towns. A big building overlooks the town and it is one of the most beautiful in the whole country. To the north of the town there is a high mountain standing in the country. The town is very beautiful, with its many craft shops and narrow cobbled streets. Most travelers visit Kinsale for its fish restaurants, which are family owned. This means that the service is better than that in other restaurants. People are more welcoming there than those anywhere else. The food may be expensive but you'll have one of the most pleasant evenings in your life there. So go ahead and visit Kinsale.\n",
            "\n",
            "Question: The food in the restaurants may be   _  .\n",
            "A. cheap\n",
            "B. expensive\n",
            "C. salty\n",
            "D. spicy\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6383\n",
            "Current Mean Accuracy: 0.6383\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.34912109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91569\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04437255859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   1%|          | 1/100 [00:01<01:43,  1.04s/it]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   2%|▏         | 2/100 [00:01<00:55,  1.75it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   3%|▎         | 3/100 [00:01<00:40,  2.39it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   4%|▍         | 4/100 [00:01<00:32,  2.98it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   5%|▌         | 5/100 [00:01<00:27,  3.40it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   6%|▌         | 6/100 [00:02<00:25,  3.71it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   7%|▋         | 7/100 [00:02<00:22,  4.11it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   8%|▊         | 8/100 [00:02<00:21,  4.30it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:   9%|▉         | 9/100 [00:02<00:20,  4.42it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  10%|█         | 10/100 [00:02<00:19,  4.61it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  11%|█         | 11/100 [00:03<00:18,  4.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  12%|█▏        | 12/100 [00:03<00:18,  4.79it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:03<00:17,  4.85it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  14%|█▍        | 14/100 [00:03<00:17,  4.88it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:03<00:17,  4.84it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  16%|█▌        | 16/100 [00:04<00:17,  4.71it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:04<00:17,  4.85it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  18%|█▊        | 18/100 [00:04<00:17,  4.82it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:04<00:17,  4.68it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  20%|██        | 20/100 [00:05<00:16,  4.80it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  21%|██        | 21/100 [00:05<00:16,  4.77it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  22%|██▏       | 22/100 [00:05<00:16,  4.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:05<00:16,  4.75it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  24%|██▍       | 24/100 [00:05<00:15,  4.91it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:06<00:15,  4.84it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  26%|██▌       | 26/100 [00:06<00:15,  4.70it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  27%|██▋       | 27/100 [00:06<00:15,  4.75it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  28%|██▊       | 28/100 [00:06<00:14,  4.89it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  29%|██▉       | 29/100 [00:06<00:14,  4.97it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  30%|███       | 30/100 [00:07<00:14,  4.93it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  31%|███       | 31/100 [00:07<00:13,  4.95it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  32%|███▏      | 32/100 [00:07<00:13,  4.88it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  33%|███▎      | 33/100 [00:07<00:13,  4.84it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  34%|███▍      | 34/100 [00:07<00:14,  4.70it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:08<00:13,  4.84it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  36%|███▌      | 36/100 [00:08<00:13,  4.91it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:08<00:13,  4.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  38%|███▊      | 38/100 [00:08<00:13,  4.64it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  39%|███▉      | 39/100 [00:09<00:12,  4.69it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  40%|████      | 40/100 [00:09<00:13,  4.61it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  41%|████      | 41/100 [00:09<00:12,  4.57it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  42%|████▏     | 42/100 [00:09<00:12,  4.55it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  43%|████▎     | 43/100 [00:09<00:12,  4.65it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  44%|████▍     | 44/100 [00:10<00:12,  4.47it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  45%|████▌     | 45/100 [00:10<00:12,  4.53it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  46%|████▌     | 46/100 [00:10<00:11,  4.61it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:10<00:11,  4.63it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  48%|████▊     | 48/100 [00:10<00:11,  4.69it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:11<00:11,  4.54it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  50%|█████     | 50/100 [00:11<00:10,  4.78it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  51%|█████     | 51/100 [00:11<00:10,  4.89it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  52%|█████▏    | 52/100 [00:11<00:09,  4.90it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:12<00:09,  4.80it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  54%|█████▍    | 54/100 [00:12<00:09,  4.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:12<00:09,  4.70it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  56%|█████▌    | 56/100 [00:12<00:09,  4.67it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:12<00:09,  4.71it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  58%|█████▊    | 58/100 [00:13<00:08,  4.82it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:13<00:08,  4.57it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  60%|██████    | 60/100 [00:13<00:08,  4.74it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  61%|██████    | 61/100 [00:13<00:08,  4.55it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  62%|██████▏   | 62/100 [00:13<00:08,  4.57it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:14<00:08,  4.56it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  64%|██████▍   | 64/100 [00:14<00:07,  4.69it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  65%|██████▌   | 65/100 [00:14<00:07,  4.75it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  66%|██████▌   | 66/100 [00:14<00:07,  4.38it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  67%|██████▋   | 67/100 [00:15<00:07,  4.55it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  68%|██████▊   | 68/100 [00:15<00:07,  4.50it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  69%|██████▉   | 69/100 [00:15<00:06,  4.63it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  70%|███████   | 70/100 [00:15<00:06,  4.50it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  71%|███████   | 71/100 [00:15<00:06,  4.27it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  72%|███████▏  | 72/100 [00:16<00:06,  4.20it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  73%|███████▎  | 73/100 [00:16<00:06,  4.17it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  74%|███████▍  | 74/100 [00:16<00:06,  4.18it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  75%|███████▌  | 75/100 [00:16<00:05,  4.18it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  76%|███████▌  | 76/100 [00:17<00:05,  4.30it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  77%|███████▋  | 77/100 [00:17<00:05,  4.38it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  78%|███████▊  | 78/100 [00:17<00:05,  4.33it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  79%|███████▉  | 79/100 [00:17<00:04,  4.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  80%|████████  | 80/100 [00:18<00:04,  4.51it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  81%|████████  | 81/100 [00:18<00:04,  4.69it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:18<00:03,  4.67it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  83%|████████▎ | 83/100 [00:18<00:03,  4.70it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:18<00:03,  4.78it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  85%|████████▌ | 85/100 [00:19<00:03,  4.56it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:19<00:03,  4.62it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  87%|████████▋ | 87/100 [00:19<00:02,  4.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  88%|████████▊ | 88/100 [00:19<00:02,  4.60it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  89%|████████▉ | 89/100 [00:19<00:02,  4.77it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  90%|█████████ | 90/100 [00:20<00:02,  4.85it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:20<00:01,  4.92it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  92%|█████████▏| 92/100 [00:20<00:01,  4.80it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  93%|█████████▎| 93/100 [00:20<00:01,  4.76it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  94%|█████████▍| 94/100 [00:20<00:01,  4.66it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  95%|█████████▌| 95/100 [00:21<00:01,  4.71it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  96%|█████████▌| 96/100 [00:21<00:00,  4.95it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  97%|█████████▋| 97/100 [00:21<00:00,  4.92it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  98%|█████████▊| 98/100 [00:21<00:00,  5.00it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M:  99%|█████████▉| 99/100 [00:21<00:00,  4.96it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_M: 100%|██████████| 100/100 [00:22<00:00,  4.94it/s]\n",
            "Benchmarking RACE_M: 100%|██████████| 100/100 [00:22<00:00,  4.51it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Article: Most People don't like mice, but they love one mouse -- Mickey Mouse. In their mind, this mouse is their favourite animal. About 70 years ago, an American man called Walt Disney created  a cartoon mouse for films. He named this mouse Mickey Mouse. From the beginning, Mickey Mouse is a clean mouse. He always does many interesting things. That's why many children and people love him. He makes them happy and _ . In the film, Mickey Mouse also has a lot of friends, for example, Donald Duck and Pluto. Donald can do many things that Mickey cannot. Pluto is a dog. He always does foolish things and makes foolish mistakes. Many children like these cartoon animals, but they like Mickey most because the mouse is a star of beauty and wisdom .\n",
            "\n",
            "Question: Many children and people like Mickey Mouse because  _  .\n",
            "A. He never makes mistakes\n",
            "B. He is like a real mouse.\n",
            "C. He always does many interesting things\n",
            "D. He has many friends.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6458\n",
            "Current Mean Accuracy: 0.6458\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4849\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.09967041015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.123291015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: October is getting closer and it also means that the year of 2014 is coming to an end. \"Hooray! It's a holiday!\" While you are thinking of putting textbooks aside and playing video games, let's take a look at what children in other continents usually do during their holidays.\n",
            "Children in America don't have much homework to do. They keep themselves busy by playing camp games. A parent says, \"My daughter Shirley usually attends different camps. We don't ask her to spend plenty of time on maths problems or spelling tests.\"\n",
            "Children in Australia take partin activities on over twenty different themes  . They learn painting, dancing, singing, history, culture and so on. Parents can _ their kids to enjoy the learning process and to build a closer relationship with them.\n",
            "These are what African kids do: build a boat, have a camel race, make a drum and make a rag   football. Don't you think it is interesting that kids in other places have no idea how to make a drum, but kids in Africa do?\n",
            "Plan your holiday well and try what you want to try. Make a good plan and you will have a lot of fun.\n",
            "\n",
            "Question: What is the purpose of this passage?\n",
            "A. To advise kids to make holiday plans.\n",
            "B. To introduce some good holiday camps.\n",
            "C. To encourage kids to make friends with parents.\n",
            "D. To show the importance of doing homework during holidays.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6327\n",
            "Current Mean Accuracy: 0.6327\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5791015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
            "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
            "\n",
            "Question: There are   _   classrooms in Betty's school?\n",
            "A. 12\n",
            "B. 14\n",
            "C. 24\n",
            "D. 34\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6400\n",
            "Current Mean Accuracy: 0.6400\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.262939453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12333\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.359619140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Mr. Yang is a doctor. He cares a lot about not only others' health but also his own. He controls( )his weight carefully. To him, _ is the most important thing to do if one wants to enjoy good health.\n",
            "Mr. Yang controls his weight in two ways: exercising and not eating much. As a doctor. Mr. Yang is too busy to go to the gym. He exercises by getting off the bus one or two stops early and walking the rest of the way to his office.\n",
            "Besides, he doesn't eat much. Mr. Yang has a special habit. When he buys a belt, he asks the salesperson to punch a hole in the belt at 90cm from the buckle end of the belt, so that he ca always remind  himself. He will stop eating if he feels the belt a little too tight . Mr. Yang thinks exercising doesn't work as well as eating less.\n",
            "\n",
            "Question: Which of the following is true?\n",
            "A. Mr. Yang takes exercise at the gym.\n",
            "B. Mr. Yang walks all the way to work.\n",
            "C. Mr. Yang uses a belt to control how much he eats.\n",
            "D. Mr. Yang thinks exercising is better than eating less in controlling wight.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6471\n",
            "Current Mean Accuracy: 0.6471\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.96337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15144\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Tony, 18. a member of an anti-tobacco group, he says, \"Kids feel that everyone around them smokes.\" Tony wants kids to realize that most people don't smoke. He also wants to tell them that smoking doesn't make one look cool. Two national studies show that teenage smoking is down. Still, there is work to be done.\n",
            "Smoking is an unhealthy habit. It can cause heart disease, lung cancer and other serious illnesses. Just being around cigarette smoke can make you sick.\n",
            "In the 1990s, all 50 states went to court to fight tobacco companies. The states won money from the companies. It helps to pay for anti-smoking groups, but the money is not enough.\n",
            "Each day, about 4,000 kids light up for the first time. \"We have to do a better job of stopping kids from smoking,\" says Husten. Ads that tell ugly facts about smoking help to change minds. Setting smoke-free areas in public places works too. Just this month, a California town _ smoking in all public places, such as schools, shopping malls and libraries. It may be bad news for smokers. Health experts say that they will fight until all Americans get the message.\n",
            ",.\n",
            "\n",
            "Question: The states use the money that they won from tobacco companies to  _  .\n",
            "A. pay for anti-smoking programs\n",
            "B. sell more cigarettes\n",
            "C. win more court cases\n",
            "D. build more schools\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6538\n",
            "Current Mean Accuracy: 0.6538\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 46968\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06231689453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello! My name is Kitty. I want to talk about my home town today.\n",
            "My home town is small but pretty. It's about two hours away from London by train. In the centre of the town there is a small lake. There are lots of trees and flowers around the lake. My parents often walk around the lake at the weekend. The air in my home town is very fresh   and clean.\n",
            "There are two schools in my home town, one primary school and one secondary school. I study in the secondary school and my younger sister studies in the primary school. I often ride my bike to school.\n",
            "I usually go to the youth centre to learn drawing with my sister on Friday afternoons. I like going shopping at the weekend. There are two big shopping malls there.[:Zxxk.Com]\n",
            "\n",
            "Question: There is  _  in the centre of the town.\n",
            "A. a primary school\n",
            "B. a secondary school\n",
            "C. a small lake\n",
            "D. a shopping mall\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6415\n",
            "Current Mean Accuracy: 0.6415\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.292236328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: On February 9 th,2013,Sarah Darling was walking along the street when she met a homeless man named Billy Ray Harris.She reached into her change purse,emptied out all the coins she had and gave them to the homeless man.Neither of them realized that this small generous act would change their lives.\n",
            "Sarah didn't realize that she had given Billy not only all her change but also her diamond ring that she had put in her change purse earlier until the following morning.She and her husband,Bill Krejci,rushed to see if they could find Billy.The homeless man was not only in the same place,he also immediately returned the ring.The grateful couple paid him back for his honesty by emptying out their pockets of all the money they had.\n",
            "Bill Krejci,a web designer,felt that he needed to do something more for this amazingly\n",
            "honest man.So on February 18th,he set up a special page to raise money for him.In just four days,Billy received over $ 85,000 and there seems to be no end yet.\n",
            "That is not enough.Billy is 1iving with a person who is generous instead of living in the streets.And that's not all--thanks to the news report,he got together again with his older brother,Edwin Harris who he had been unable to find for 27 years.\n",
            "All the good luck is just because Billy did the right thing--returning something that did not belong to him.\n",
            "\n",
            "Question: When did Sarah realize that she had also given Billy her diamond ring?\n",
            "A. On February 9 th,2013.\n",
            "B. On February 10th,2013.\n",
            "C. On February 18th,2013.\n",
            "D. On February 22nd,2013.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6296\n",
            "Current Mean Accuracy: 0.6296\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37689\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.25927734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Joe, an outgoing girl, is from a rich family. Therefore she can afford almost everything. But Joe's parents are too busy to spend enough time with her, which makes Joe more than lonely. So, she always goes to WeChat. On WeChat, she can do a lot of things like buying things, reading articles, and making friends with those she either knows or not.\n",
            "She uses the name Linda on WeChat and has made a lot of friends there. Last year Joe made a foreign friend on WeChat. Her name was Catherine and she lived in Sydney. Catherine once sent a picture of \"herself\": a tall, good-looking young woman with big eyes. Catherine and Joe were both interested in rock music and modern dance. So, they liked each other very much.\n",
            "When Joe's father told her that he was meeting a client in Sydney this summer, she went with him to give Catherine a surprise for her birthday. When Joe came to Catherine's house in Sydney, she found that her foreign \"girlfriend\" was a ten-year-old boy named Jim! What a surprise!\n",
            "\n",
            "Question: What is the real name of Joe's \"girlfriend\"?\n",
            "A. Catherine\n",
            "B. Joe\n",
            "C. Jim\n",
            "D. Linda\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6364\n",
            "Current Mean Accuracy: 0.6364\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1820068359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: More and more parents leave their homes and come into the big cities to make money. But their children can't go with them because their children have to go to school in their hometown. They are called home-left children. The problems of home-left children become more and more serious. And it becomes a big _ of our society. The main problem is that some home-left children become very lonely when they don't have their parents' love. And they are too young to tell right or wrong in many things. So they are fooled very easily by others.\n",
            "Xiao Mei , a 14-year-old girl, is a home-left child. Her parents are both in Shanghai. She is in her hometown with her grandpa. She likes playing games on the Internet. Her parents and grandpa only give her money and food. They hardly ever care for her studies. One day, she had no money to pay for the games in the Net bar. So she stole some money from her neighbor. Just at that time, Xiao Fang, a 9-year-old girl saw it. Xiao Mei was afraid that Xiao Fang would tell others about it. She cut Xiao Fang's throat with a knife, and then she went to school just like nothing happened. Luckily, Xiao Fang was saves by doctors. When she opened her eyes and wrote the fact to the policeman with a pencil, everybody was very surprised. This sad story reminds the parents to care for their children no matter how busy they are.\n",
            "Are you one of the home-left children? What do you need from your parents? Food, money or love? I think most children need love mostly. Let's care for the group together.\n",
            ",A, B, C, D,. 5,2,10\n",
            "\n",
            "Question: What does Xiao Mei only get from her parents?\n",
            "A. Clothes.\n",
            "B. Love.\n",
            "C. Money and food.\n",
            "D. Computers.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6429\n",
            "Current Mean Accuracy: 0.6429\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.68017578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5045\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1263427734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Have you heard of EXO? EXO is a Chinese-South Korean boy band with 12 people. They are in two teams: EXO-M and EXO-K. There's even a \"competition\" between the two teams. \"I will not call it a competition. It's always in good fun,\" said Sehun of EXO-K.\n",
            "Here comes the new superstar! His name is Austin Mahone. The 18-year-old is a pop singer in the US. His success story is just like that of Justin Bieber. Last month Mahone's new album The Secret came out. Maybe it's a good chance for us to know more about him and his music.\n",
            "Forget about Super Junior. We now have TFBOYS. TFBOYS is a popular Chinese boy band made up of three members. They are Wang Junkai, 14, Wang Yuan, 13, and Yi Yangqianxi, 13. The boys are all junior middle school students. Their songs are full of positive energy  . In their latest album, they call on teenagers not to be afraid of dreaming big.\n",
            "\n",
            "Question: Austin Mahone's success story is almost the same as   _  .\n",
            "A. TFBOY's\n",
            "B. Justin Bieber's\n",
            "C. EXO's\n",
            "D. Taylor Swift's\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6316\n",
            "Current Mean Accuracy: 0.6316\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.63720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 45999\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.460693359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
            "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
            "\n",
            "Question: Where is Wendy from?\n",
            "A. China.\n",
            "B. England.\n",
            "C. America.\n",
            "D. Australia.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6379\n",
            "Current Mean Accuracy: 0.6379\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.93798828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When you read an article you will understand and remember it better if you can work out how the writer has put the ideas together.Sometimes a writer puts ideas together by asking questions and then answering them.For example,if the article is about groundhogs ,the set of questions in the writer's head might be:\n",
            "What does a groundhog look like?\n",
            "Where do groundhogs live?\n",
            "What do they eat?...\n",
            "In the article,the author might answer those questions.\n",
            "Sometimes an author writes out her questions in the article.These questions give you signals.They tell you what the author is going to write next.Often an author has a question in her head but she doesn't write it out for you.You have to work out her question for yourself.Here's a sample reading for you to practice this method.\n",
            "Earthworms\n",
            "Do you know how many kinds of earthworms there are?There are about 1800 kinds in the world! They can be brown,purple,green.They can be as small as 3 cm long and as large as 3 m long.\n",
            "The best time to see earthworms is at night,especially a cool,damp night.That's when they come up from their burrows to hunt for food.Earthworms don't like to be in the sun.That's because they breathe through their skin,and they can't breathe if their skin gets too dry.Earthworms must come out of the earth if it rains a lot,because they can't breathe in their flooded burrows.What a dangerous life!\n",
            "Earthworms don't have eyes,so how can they tell when it's dark? They have special places on their skin that are sensitive to light.These spots tell whether it's light or dark.If you shine a flashlight on an earthworm at night,it will quickly disappear into the ground.\n",
            "Earthworms don't have ears either,but they can hear by feeling movements in the earth.If you want to hear like an earthworm,lie on the ground with your fingers in your ears.Then have a friend stamp his or her feet near you.This is how earthworms feel birds and people walking,and moles digging,near them.\n",
            "Earthworms are useful.Farmers and gardeners like having lots of earthworms in their land because the worms help to make better soil when they dig.That digging keeps the soil loose and airy .In one year earthworms can pile up as much as 23,000 kg of castings in an area about the size of a football field.\n",
            "\n",
            "Question: Which question CANNOT be answered in the passage?\n",
            "A. How do earthworms help with gardeners?\n",
            "B. What life are earthworms living with?\n",
            "C. When may people observe earthworms?\n",
            "D. Why can human listen like earthworms?\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6441\n",
            "Current Mean Accuracy: 0.6441\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.51904296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Kate is an American girl. Now she lives in New York with her parents. She lives in a community called Sunny Community. It's on Blue Street. There are five rows  of buildings in the community. Her house is in the first row. She lives on the third floor.\n",
            "There is a post office on Blue Street . Next to it ,there is a bank. Across from the bank ,there is a bookstore. The workers in the bookstore are very friendly to people. Mrs Green works in it. She is Kate's new neighbor. She has a son. His name is Bob. He is in the same class as Kate.\n",
            "Kate thinks the traffic here is very good, because she never meets any accidents here. She loves her community very much.\n",
            "\n",
            "Question: Where does Mrs Green work ?\n",
            "A. In a post office.\n",
            "B. In a bank.\n",
            "C. In a bookstore.\n",
            "D. In a school.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6500\n",
            "Current Mean Accuracy: 0.6500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 11687\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.58544921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Foreign visitors are often puzzled   in Japan because most streets there don't have names. In Japan, people use _ in their directions instead of street names. For example, the Japanese will say to travelers, \"Go straight down to the corner. Turn left at the big hotel and go pass a fruit market. The post office is across from the bus stop.\"\n",
            "In the countryside of the American Midwest, usually there are not many landmarks. There are no mountains, so the land is very flat  . In many places there are no towns or buildings within miles. Instead of landmarks, people will tell you directions and distance. In Kansas or lowa, for example, people will say, \"Go north two miles. Turn east, and then go another mile.\"\n",
            "People in Los Angeles, California, have no idea of distance on the map: the measure   distance by means of time, not miles. \"How far away is the post office?\" you ask. \"Oh,\" they answer, \"it's about five minutes from here.\" you say, \"Yes, but how many miles away is it?\" They don't know.\n",
            "People in Greece sometimes do not even try to give directions because visitors seldom understand the Greek language. Instead of giving you the direction, a Greek will often say, \"Follow me.\" Then he'll lead you through the streets of the city to the post office.\n",
            "Sometimes a person doesn't know the answer to your question. What happen in this situation? A New Yorker might say, \"sorry, I have no idea.\" But in Yucatan, Mexico, no one answer, \"I don't know.\" They think that it is impolite. They usually give an answer, often a wrong one. A visitor can get lost in Yucatan.\n",
            "One thing will help you everywhere. You might not understand a person's words, by maybe you can understand his body language. He or she will usually turn and then point in the correct direction.\n",
            "\n",
            "Question: What does the passage mainly talk about?\n",
            "A. we needn't carry a map for travel.\n",
            "B. There are not many landmarks in the American Midwest.\n",
            "C. There are different ways to give directions in different parts of the world.\n",
            "D. Americans and Japanese have different body languages when you ask for directions.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6557\n",
            "Current Mean Accuracy: 0.6557\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.70556640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 19447\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01073455810546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: Adult editors may invite   _   to the meeting to make the paper more popular with kids.\n",
            "A. a college student\n",
            "B. a middle school student\n",
            "C. an adult editor\n",
            "D. a reporter\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6452\n",
            "Current Mean Accuracy: 0.6452\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.92431640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47830\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1312255859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Tom was a farmer. He worked on the farm all day,but sometimes he went to the town market to sell fruit and vegetables. One day, a terrible sound attracted his attention in the town market. He saw a young bull for sale. The bull was white and yellow. It was looking at Tom in fear. Tom walked up and touched its head gently. Just at that time they both seemed to have known each other for a long time. How amazing!Tom bought it at once and called it Amba.\n",
            "From then on , Tom and Amba got on well with each other. But some friends told him that it was dangerous to have such a close relationship with an animal.\n",
            "One afternoon , Tom was walking through the forest with Amba. Suddenly , Amba stopped walking and kept pushing Tom with its head. Tom was very surprised and looked around. There was a big snake in front of him. It was beautiful but poisonous. Quickly Amba stepped on the snake's tail with its foot and at the same time Tom picked up a stick and hit the snake's head heavily. Soon the snake . died.\n",
            "Tom was very grateful for Amba's help. When people heard this, they were shocked at the bull's expression of love for Tom. But for Tom, Amba was not a bull but a member of his family.\n",
            "\n",
            "Question: Which of the following statements is NOT true?\n",
            "A. Tom went to the town market to sell fruit and vegetables.\n",
            "B. Tom's friends thought animals were safe.\n",
            "C. Tom hit the snake's head heavily with a stick.\n",
            "D. For Tom, Amba was a member of his family.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6349\n",
            "Current Mean Accuracy: 0.6349\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53645\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.091064453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.962890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: It was very late at night when Sam got off the train . He was tired and wanted to find a hotel to have a rest. He looked around and saw a hotel not far away. There were three floors in it. Then Sam went in.\n",
            "\"How much do I need to pay for a single  room a night?\" Sam asked.\n",
            "\"Well , sir,\"said the girl, \"a single room on the first floor is fifty dollars a night.\"\n",
            "\"What about the one on the second floor?\" asked Sam.\n",
            "\"Forty dollars.\"\n",
            "\"Then how about the one on the third floor?\"\n",
            "\"Thirty dollars.\"\n",
            "Sam picked up his suitcase  and wanted to go out.\n",
            "\"Don't you think our price is reasonable?\" The girl said.\n",
            "\"Yes,\" said Sam. \"Your price is of course _ , but I'm sure your hotel is not high enough.\"\n",
            "\n",
            "Question: How many floors were there in the hotel?\n",
            "A. One\n",
            "B. Two\n",
            "C. Three\n",
            "D. Four\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6406\n",
            "Current Mean Accuracy: 0.6406\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9638671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29667\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.266845703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: There are   _   people in Mike's family.\n",
            "A. four\n",
            "B. five\n",
            "C. six\n",
            "D. seven\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6462\n",
            "Current Mean Accuracy: 0.6462\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 13296\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.23193359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Autumn is the harvest season. There must be a lot for us to eat !Yes, autumn is a great time for fruit and vegetables. Let's find out about some of the best.\n",
            "Apples: You can eat apples all the year round, but they are better and cheaper in autumn. People say \"An apple a day keeps the doctor away\". Apples have a lot of vitamin C and fiber  in them. They are good for the heart and can make your mouth fresh.\n",
            "Pears: Pears are in season from autumn to mid winter. They have minerals and vitamins C and E in them. They are good for the heart and can keep cancer   away.\n",
            "Pumpkins: Pumpkin is a nice vegetable in autumn. They are rich in beta carotene  , which is turned into vitamin A in our bodies. Pumpkins also have calcium ,iron and vitamin C in them. Eating pumpkins can make us look young.\n",
            "Sweet corn  : Sweet corn is in season near the end of the year. It has minerals in it. It's good for the heart.\n",
            "Autumn weather is cold and dry. Try to eat as much fruit and vegetables as you can. They will make you healthy.\n",
            "\n",
            "Question: _   are /is in rich beta carotene.\n",
            "A. Pumpkins\n",
            "B. Sweet corn\n",
            "C. Apples\n",
            "D. Pears\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6364\n",
            "Current Mean Accuracy: 0.6364\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.250732421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Dan was the doorman of a club in a big city. Every day, thousands of people passed his door, and a lot of them stopped and asked him, \"What's the time, please?\"\n",
            "After a few months, Dan said to himself, \"I'm not going to answer all those stupid people any more. I'm going to buy a big clock and put it on the wall here.\" Then he did so.\n",
            "\"Now people aren't going to stop and ask me the time.\" He thought happily.\n",
            "But after that, a lot of people stopped, looked at the clock and asked Dan, \"Is that clock right?\"\n",
            "\n",
            "Question: What would be the best title for the passage?\n",
            "A. Hardworking Dan\n",
            "B. A Big Clock\n",
            "C. Stupid Question\n",
            "D. Boring People\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6269\n",
            "Current Mean Accuracy: 0.6269\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.77490234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.84765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When you were very young, you liked to play with your friends. Did you find that playtime was always more fun when everyone shared the toys? Everyone got a turn. No one was left out.\n",
            "That's a life lesson that changes as you get older. As you grow up, you begin to understand that others have less than you do - in China and in the world. And that those of us who \"have\" things should help those who \" have less\" than we do. The idea of sharing _ \n",
            "At your age, you can \"share\" with people in need in three ways.\n",
            "1. You can give them a part of your money. Many adults do that regularly.\n",
            "2. You can share items you no longer use, such as clothing and toys. You can pass them onto others who cannot buy them.\n",
            "3. You can help people by giving your time and your energy.\n",
            "The last one is also called volunteering. Volunteering is about giving your time to take part in activities that will help others. Every year, many thousands of volunteers in the world give the most valuable gift of all. They give their time. They give their talent. They give of themselves. And they are enjoying it. Volunteering isn't just about work. It's about fun too.\n",
            ",.\n",
            "\n",
            "Question: What's the best title for this passage?\n",
            "A. Work hard to have more than others.\n",
            "B. Be a volunteer.\n",
            "C. Make your playtime more enjoyable.\n",
            "D. Share your love with others.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6176\n",
            "Current Mean Accuracy: 0.6176\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9599609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7298\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.041839599609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: The largest number of people in a race\n",
            "The biggest race is in San Francisco, the USA. More than 100,000 people run the 12 kilometers in the race. Another famous race is in London every year. This race is longer and harder, it is more than 42 kilometers, but 25,000 people usually finish it. [:Zxxk.Com]\n",
            "The youngest international player\n",
            "The youngest international player in any sport was Jamaica. Her name was Joy Foster. She was the Jamaican table tennis champion   in1958 when she was 8 years old.\n",
            "The strongest superlative  \n",
            "Have you ever tried walking backwards? The world record for walking backwards is 12,875 kilometers. A man from Texas, the USA, walked backwards for 18 months in 1931--1032. Nobody else has ever broken this record  .\n",
            "The most popular sport\n",
            "The popular sport team game in the world is football. People play football in villages, streets and stadiums all over the world. The most famous football competition is the World Cup. It happens every four years, and nearly 2,000,000,000 people watch it on TV. The first Women's World Cup was in 1991.\n",
            "\n",
            "Question: _   walked more than 12,875 kilometers' backwards.\n",
            "A. Few people\n",
            "B. Nobody else\n",
            "C. One man has\n",
            "D. Many people\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6087\n",
            "Current Mean Accuracy: 0.6087\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.399169921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.238037109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: English breakfast is a very big meal--eggs, tomatoes, tea, coffee... For many people, lunch is a quick  meal. In cities there are a lot of sandwich  bars . People can buy sandwiches there. Students can have a hot meal at school, but many just take a sandwich, a drink and some fruit from home.\n",
            "\"Tea\" means two things. It is a drink and a meal! Some people have afternoon tea, with sandwiches, cakes and a cup of tea.\n",
            "They usually have dinner quite early , between 6:00 and 8:00(......), and often all the family eat together .\n",
            "People often get take-away  meals--they buy the food outside\n",
            "\n",
            "Question: When they get a take-away meal, they often eat it   _  .\n",
            "A. at home\n",
            "B. in the school\n",
            "C. outside\n",
            "D. in the bars\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1690673828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Once upon a time, there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day the feelings were told that the island would sink, so all built boats and left, except Love. Love was the only one who stayed. Love wanted to hold out  until the last possible moment.\n",
            "When the island had almost sunk, Love decided to ask for help.\n",
            "Richness was passing by Love in a big boat. Love said, \"Richness, can you take me with you?\"\n",
            "Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
            "Love decided to ask Vanity  who was also passing by in a beautiful ship.\"Vanity, please help me!\"\n",
            "\"I can't help you, Love. You are all wet and might damage  my boat, \"Vanity answered.\n",
            "Sadness was close by so Love asked, \"Sadness, let me go with you.\"\n",
            "\"Oh...Love, I am so sad that I need to be by myself!\"\n",
            "Happiness passed by Love, too, but she was so happy that she did not even hear when Love called her.\n",
            "Suddenly, there was a voice, \"Come, Love, I will take you.\"It was an elder. So thankful and happy, Love even forgot to ask the elder where they were going. When they arrived at dry land, the elder went her own way. Realizing how much was owed  the elder, Love asked Knowledge, another elder, \"Who helped me?\"\n",
            "\"It was Time, \"Knowledge answered.\n",
            "\"Time?\"asked Love.\"But why did Time help me?\"\n",
            "Knowledge smiled with deep wisdom  and answered, \"Because only Time is able to understand how valuable Love is.\"\n",
            "\n",
            "Question: Which of the following might be the best title of the passage?\n",
            "A. Love and Time\n",
            "B. An Accident\n",
            "C. A sinking island\n",
            "D. Different Feelings\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5915\n",
            "Current Mean Accuracy: 0.5915\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4892578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.057525634765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: If you won a lottery and had lots of money, what would you do? Most people start by buying themselves things, such as a new car or a bigger TV.\n",
            "Many people who win lots of money may suddenly find that they have a lot of socalled friends. The new friends they make may follow them for their money but they may also leave them when all the money is spent. Besides that, they can't decide what to do with the money, so they try to think what they want. In the end, most people usually decide to save the money.\n",
            "There are some lottery winners who decide to quit their jobs, because they think they have enough money and don't need to work any longer. Some big lottery winners make even bigger changes--they end their marriages. They think that winning a lot of money has suddenly made them more intelligent and more attractive .So they feel that they have to be with a younger or more attractive man or woman.\n",
            "They don't know their new money is just a bit of luck. _ can't change everything.\n",
            "Next time when you buy a lottery ticket, think about what you would like to do and what you wouldn't  like to do with the money if you won.\n",
            "\n",
            "Question: A lottery winner may suddenly find himself with many socalled  friends, probably because   _  .\n",
            "A. he wants to make lots of friends\n",
            "B. he doesn't  know what to do with all the money\n",
            "C. these new friends are usually kind to the lottery winner\n",
            "D. these new friends want the lottery winner to give them some money\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5833\n",
            "Current Mean Accuracy: 0.5833\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.89013671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8974609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Do you obey the rules in your school? What do you think of your school rules? Are you allowed to dye   hair? A lot of school rules are similar around the world, but some are different. Some students may enjoy more freedom in some countries. But freedom doesn't mean \"no rules\". Every school has its own rules.\n",
            "There are some rules in Japanese schools. The students are not allowed to dye their hair and are supposed to keep their hair black. They are not allowed to wear earrings either. Almost all schools used to require students to wear school uniforms but now half of the schools require uniforms. The students feel happy to wear all kinds of clothes. The students must get to school on time. If they are late, they cannot get into the school because the school gate is closed. In Japan, students are not allowed to have part-time jobs.\n",
            "American schools have their own rules too. For example, at Morton High School, students are not allowed to choose their own clothes. They must get to school or leave school on time. Food, drinks or snacks shouldn't be taken into the classroom. They must wear sports shoes in PE class. They are supposed to keep quiet on the school bus. In America, the students can have part-time jobs in their free time. (<<>> )\n",
            "\n",
            "Question: Which school rules have changed in some Japanese schools?\n",
            "A. About wearing earrings.\n",
            "B. About uniforms.\n",
            "C. About food and drinks.\n",
            "D. About part-time jobs.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5753\n",
            "Current Mean Accuracy: 0.5753\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15702\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.121337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.445556640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: My friends like different clothes. Sue likes red clothes. She is often in a red skirt and red shoes. Mina likes white clothes. She is in a white shirt. Her sister Emma likes to wear a green skirt. She looks nice. David often wears a white cap and black pants. Peter often wears a white coat and black pants.\n",
            ",.\n",
            "\n",
            "Question: What color does Sue like?\n",
            "A. White.\n",
            "B. Red.\n",
            "C. Yellow.\n",
            "D. Green.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5676\n",
            "Current Mean Accuracy: 0.5676\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.6650390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 395\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2481689453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: There is lots of junk  in space .Some of it is from rockets. In 1996, a rocket broke into about 300,000 small pieces. So far, scientists have found over 10,000 man-made pieces flying around in space. Only 6-7%of them are satellites and space probes  . Astronauts also lose small things while working in space. In 1965, during the first American spacewalk , astronaut Edward White lost a glove .For a month, the glove stayed in space, travelling at a speed of 28,000 kilometers per hour .It became the most dangerous piece of clothing for the Earth in history it flew away. Things move very fast in space. If they hit one another, it can be dangerous .A little piece of paint from a satellite once made a hole in a spacecraft window. Last year two US spacecraft dropped some bolts , and scientists on the Earth worried a lot. Luckily the bolts floated  away into space. They couldn't hit the spacecraft.\n",
            ",.\n",
            "\n",
            "Question: The glove in space may travel at a speed of    _    kilometers per hour.\n",
            "A. 300,000\n",
            "B. 28,000\n",
            "C. 10,000\n",
            "D. 21,000\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5600\n",
            "Current Mean Accuracy: 0.5600\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.26611328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: \"You know, these cups brings to my mind a story I heard,\" Mary said to her students.\n",
            "She poured some tea. There were four of them and there were four completely different cups on the tables.\n",
            "\"I heard there was a teacher who took all his students for tea. His students were surprised that all the cups on the table were different. They all took a cup and started drinking their tea, each looking at the cups of others. The teacher said, \"Did you notice your behavior? You are all looking at each other's tea cup and some of you even envy the finer cups of others.\"\n",
            "\"I put the different cups here on purpose. I want to say life is like this tea. You all have the same thing in your cups----tea. And yet you cannot truly enjoy it in your envy of another's cup. You forget to enjoy your own life when you envy someone else's life. We all have the same thing----life. We should care more about the tastes of your own life. So now, taste your own tea. Does it matter from which cup it came from?\" Mary finished telling her story and her students all sat in silence for a while, enjoying their tea. And it really did not matter a bit from which teacup they drank.\n",
            "\n",
            "Question: What should we learn from the story?\n",
            "A. Envy others and make progress.\n",
            "B. All the lives are the same.\n",
            "C. Work hard and catch up with others.\n",
            "D. Try to enjoy your own life.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5658\n",
            "Current Mean Accuracy: 0.5658\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 57014\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: If you think you are too shy and want to be a little outgoing, try the following. You can make it.\n",
            "Tell people you are shy. Just let people know that you are a shy kid. When they know that, they'll understand you better. This also helps you feel more at home when talking with others.\n",
            "Try to smile more. People think you are friendly and easy to talk to. Remember that most of us would like to talk to friendly people and we will stay away from an angry-looking face.\n",
            "Talk to others first. If you find it hard to do, say something nice about people around you. Think about how great you feel when someone says something nice to you. Doesn't it make you want to keep talking to those people?\n",
            "Turn your attention to somewhere else. Think more about ways to enjoy the party or the game. Don't worry about your looks or care if people like you.\n",
            "Reward  yourself. Each time after you say \"hi\" or smile at someone for the first time , say to yourself \"You did it!\" or buy yourself an ice cream.\n",
            "Keep trying and one day you won't be shy any more when you talk to others.\n",
            "\n",
            "Question: Which of the following is NOT true?\n",
            "A. People can understand you better when they know you are shy.\n",
            "B. Most people don't like to talk to those people with angry faces.\n",
            "C. Don't care what you look like at the party or the game.\n",
            "D. Each time after you smile at someone for the first time, you should buy yourself an ice cream.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5584\n",
            "Current Mean Accuracy: 0.5584\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.89013671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47830\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.85009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Many people think sports are just for winning and honor, but there is a lot more you can gain from (get out of) them. I have learned over the past years that sometimes when I lose, I get a lot more out of it than winning. Also, I find a lot of times in sports, people are getting too caught up in the game instead of just having fun. The real purpose of sports is to have fun and learn life lessons along the way.\n",
            "I greatly encourage you to be a part of the school sports. Even if you are not the best, you can still have fun. Sports give people a great and healthy way of spending an afternoon, instead of lying around playing video games or even getting into bad things. Sports also give us a sense of achievement. There isn't a better feeling than to have done something fun and productive for my day.\n",
            "I think that we all need sports to give us courage. If we try hard in sports, we usually do well. If we did the same in study, we would all be champions. Another reason why I encourage you to play sports is that it's just fun. Without sports, our lives would just be boring. So as you may be able to tell, sports are amazing!\n",
            "Our coaches not only teach us to play sports, but show class and good sportsmanship while playing them. It's never fun when you lose to have the competitor rub it in your face. That's why our coaches teach us to show class when we lose; also, when coaches _ , don't get down. They only want to see you improve and learn from what they say. When you do badly and they don't shout loudly is when you should start worrying because they are giving up on you.\n",
            "Overall, sports are great! They bring out the best and worst of a lot of us. However, we can' t let sports get too serious to where it brings down all the fun. So to have the most fun in sports, you just need try your best and not worry so much about the winning or losing.\n",
            "\n",
            "Question: Which of the following statements is TRUE according to the passage?\n",
            "A. Sports bring us great fun only if we have the talent.\n",
            "B. Sports give us the best way of spending free time.\n",
            "C. We can get more out of winning than losing.\n",
            "D. We should take pleasure in doing sports.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5513\n",
            "Current Mean Accuracy: 0.5513\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.140380859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: On May 1, a wildfire started in a forest near the Alberta town of Fort McMurray in Canada. Within two days, the fire grew larger and the people who lived in Fort McMurray had to leave their homes. While there have been very few people injured   by the large fire itself, it has been harmful to the community.\n",
            "Canadians in other places have been helping by sending money and _ to the Red Cross. Many people in Alberta have taken in people from Fort McMurray, letting them stay in their homes for free until the fire is put out. Many firefighters are needed to fight the fire and some of them have come from other parts of Canada to help. The brave firefighters were able to save 25,000 homes as well as the hospital and all of the town's schools, according to CBC news.\n",
            "There have been thousands of other acts of kindness towards the people of Fort McMurray. Some musicians, such as Great Big Sea's Alan Doyle, are holding special concerts, with the money going to Fort McMurray people. And companies have been helping, as well. Beer-maker Labatt filled thousands of cans with water--instead of beer--and sent them to the people in Fort McMurray.\n",
            "The fire is huge, spreading over more than 229,000 hectares  , but firefighters say they believe they are starting to get it under control--it is becoming smaller instead of spreading.\n",
            "\n",
            "Question: How many people have been injured by the large fire itself?\n",
            "A. 25,000.\n",
            "B. Very few.\n",
            "C. 229,000.\n",
            "D. Many.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5443\n",
            "Current Mean Accuracy: 0.5443\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.83544921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
            "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
            "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
            "\n",
            "Question: The writer thinks many people don't live near the north or south pole because  _  .\n",
            "A. they can't get enough food there\n",
            "B. the natural sights there don't arrract people\n",
            "C. the unpleasant weather keeps them away\n",
            "D. the length of nighttime keeps them away\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5500\n",
            "Current Mean Accuracy: 0.5500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Mr. and Mrs. Green lived in a big city. One summer they went to the country for their holiday. They enjoyed it very much because it was a quiet, clean place.\n",
            "One day they went for a walk early in the morning and met an old man. He lived on a farm, and he was sitting in the warm sun in front of his house. Mr. Green asked him, \"Do you like to live in this quiet place?\"\n",
            "The old man said, \"Yes, I do.\"\n",
            "Mr. Green then asked, \"What are the good things about it?\"\n",
            "The old man answered, \"Well, the people here know each other. They often come and visit me, and I often go and visit them. And there are also many children here.\" Mr. Green said, \"That's interesting, and what are the bad things?\"\n",
            "The old man thought for a moment and then said, \"Well, the same things, really.\"\n",
            "\n",
            "Question: The old man sometimes liked the people to   _  , but sometimes he didn't.\n",
            "A. ask him questions\n",
            "B. keep the place quiet and clean\n",
            "C. come and visit him\n",
            "D. make interesting things\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5432\n",
            "Current Mean Accuracy: 0.5432\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2451171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 395\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7158203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Do you know why different animals or pests have their special colours? Colours in them seem to be mainly used to protect themselves.\n",
            "Some birds like eating locusts , but birds cannot easily catch them. Why? It is because locusts change their colurs with the changes of the colours of crops .When crops are green, locusts look green .But as the harvest time comes, locusts change into the same brown colour as crops have .Some other pests whose colours are different from plants are easily found and eaten by others .So they have to hide themselves for lives and appear only at night.\n",
            "If you study the animals' life, you'll find the main use of colours is to protect themselves .Bears, lions and other animals move quietly through forests .They cannot be easily seen by hunters because their colours are much like the trees.\n",
            "Colours are useful not only on the land , but also in the sea .A kind of fish in the sea can give out a kind of black liquid when the fish face danger. The liquid spreads over quickly, so they cannot be found by their enemies and can quickly swim away. That is why they can live safely though they are not strong at all.\n",
            "\n",
            "Question: Bears and lions can keep safe because  _  .\n",
            "A. their colours are much like the trees\n",
            "B. they move quickly\n",
            "C. they are very strong\n",
            "D. they live in forests\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5488\n",
            "Current Mean Accuracy: 0.5488\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8093\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1441650390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: There are several ways you can find out about the countries and places you wish to visit. You can talk to friends who have traveled to the places, you can go and see a colour film about them, or you can read a travel book.\n",
            "It seems that there are three kinds of travel books. The first are those that give a personal, subjective  idea of travels which their writer has got himself. These books can be useful if the writers share their traveling experiences with others. The second kind are those books which give objective  information of things to be done and seen. If _ has written such a book about the facts of a place, then it is more useful. The third kind are those books which are called \"a guide\" to some place or other. If they are good, they will describe and explain the place in detail. Like the first kind , they can be interesting and exciting, but their main purpose is to help the reader plan his travel in the most practical way.\n",
            "Whatever kind of travel book you choose, you must make sure that the book does not describe everything as interesting, exciting or fantastic. You must also keep an open eyes on its date of publication  because travel is very practical matter and many things change quickly in the 21st century. Finally, you should make sure that it's easy to find the useful information for you travel.\n",
            "\n",
            "Question: The date of publication must be noticed because   _  .\n",
            "A. the prices of travel books may be different\n",
            "B. the writers of travel books may be different\n",
            "C. the information in travel books is always the same\n",
            "D. the information in travel books is always changing\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5422\n",
            "Current Mean Accuracy: 0.5422\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.313720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1368408203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
            "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
            "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
            "She understood that she hadn't worn the hair clip to school at all.\n",
            "\n",
            "Question: Her classmates wanted to know what had happened to the girl because  _\n",
            "A. she didn't tell her classmates about her beautiful hair clip.\n",
            "B. she was always unhappy but that day she was so happy.\n",
            "C. she looked more beautiful wearing the hair clip.\n",
            "D. she wanted to talk to others.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5357\n",
            "Current Mean Accuracy: 0.5357\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10772705078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77064\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4404296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When people talk about air pollution, they usually think of smog, acid rain ,and other forms  of outdoor air pollution. But did you know that air pollution also is inside homes, offices, hotels and other buildings?Indoor air pollution is more serious. The air in your home can be 2 to 100 times  more polluted than the air outdoors!In fact, some American doctors say that 50% of illnesses have something to do with polluted indoor air. Indoor air pollution is bad for our health in many ways. Young children and the old often suffer  more from air pollution. People with health problems may also suffer more when the air is polluted. Indoor air pollution can be bad for people's eyes, nose and throat. Air pollution, both indoor and outdoor, can also lead to cancer, heart disease, and even bad for the brain!In the great London fog in 1952, 4,000 people died in a few days because of air pollution!It is said that half a million young kids and women die each year in India because of indoor air pollution!\n",
            "There're many ways to reduce  indoor air pollution. Here are some of them and see if they can help you:\n",
            "Increase outdoor air coming indoors and open your windows for 15 to 30 minutes each day.\n",
            "Turn off all the lights and fans when you don't need them.\n",
            "Share your room with others when the air conditioner is running.\n",
            "Don't smoke and try to stop your family members from smoking. People who smoke are going to have trouble breathing and even die someday. If you're smart, don't ever start.\n",
            "Environment-friendly products, such as water-based paints pollute less and work well.\n",
            "\n",
            "Question: How many ways does the writer talk about to reduce indoor air pollution?\n",
            "A. Four.\n",
            "B. Five.\n",
            "C. Six.\n",
            "D. Seven.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5412\n",
            "Current Mean Accuracy: 0.5412\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.134765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.53515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: \"You know, these cups brings to my mind a story I heard,\" Mary said to her students.\n",
            "She poured some tea. There were four of them and there were four completely different cups on the tables.\n",
            "\"I heard there was a teacher who took all his students for tea. His students were surprised that all the cups on the table were different. They all took a cup and started drinking their tea, each looking at the cups of others. The teacher said, \"Did you notice your behavior? You are all looking at each other's tea cup and some of you even envy the finer cups of others.\"\n",
            "\"I put the different cups here on purpose. I want to say life is like this tea. You all have the same thing in your cups----tea. And yet you cannot truly enjoy it in your envy of another's cup. You forget to enjoy your own life when you envy someone else's life. We all have the same thing----life. We should care more about the tastes of your own life. So now, taste your own tea. Does it matter from which cup it came from?\" Mary finished telling her story and her students all sat in silence for a while, enjoying their tea. And it really did not matter a bit from which teacup they drank.\n",
            "\n",
            "Question: Which is the best title for the story?\n",
            "A. More than tea in a cup\n",
            "B. The same cups, the same tea\n",
            "C. The taste of the tea\n",
            "D. Different cups, different tea\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5349\n",
            "Current Mean Accuracy: 0.5349\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.91259765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.81298828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: The newspaper should not be   _\n",
            "A. simple\n",
            "B. interesting\n",
            "C. difficult\n",
            "D. easy\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5287\n",
            "Current Mean Accuracy: 0.5287\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 90486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.28466796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: At the age of sixteen, I went on my first volunteer program in West Virginia to repair or build homes for poor families. When we arrived, we discovered that the family we were going to help was living in a trailer that was in poor condition, no bigger than two parking spaces. A group of people had been working on it for two weeks, but every time they finished one problem, another appeared.\n",
            "We soon decided that the only way was to build a new house. It was something unusual because normally our goal was to repair old homes. The family was pleased with their new house that was 20 by 30 feet with three bedrooms, a bath and a kitchen.\n",
            "On Tuesday of that week, I asked the family's three boys, Josh, Eric and Ryan, \"What do you want for your new room?\" Kids in the families we had helped usually wanted toys or posters, so we were surprised when Josh, the oldest boy said, \"We just want beds.\" The boys had never slept in a bed. That night we had a meeting and decided that beds would be the perfect gift. On Thursday night, a few adults in our group drove to the nearest city and bought beds and new bedding.\n",
            "On Friday when we saw the truck coming, we told the family about the surprise. They were very excited.\n",
            "That afternoon, while we were setting up the beds, Eric ran into the house to watch us with wide eyes. As Maggie, a member of our group, put one of the pillows on the bed, Eric asked, \"What is that?\"\n",
            "\"A pillow,\" she replied.\n",
            "\"What do you do with it?\" Eric went on asking.\n",
            "\"When you go to sleep, you put your head on it,\" Maggie answered softly. Tears came to our eyes as she handed Eric the pillow.\n",
            "\"Oh . . . that's soft,\" he said, holding it tightly.\n",
            "Now, when my sister or I start to ask for something that seems very urgent , my dad always asks, \"Do you have a pillow?\" We know exactly what he means.\n",
            "\n",
            "Question: What can we learn from the story?\n",
            "A. The family needed two parking spaces.\n",
            "B. The boys of the family wanted toys and posters.\n",
            "C. The family were excited about the beds and bedding.\n",
            "D. The writer's group made some furniture for the family.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5341\n",
            "Current Mean Accuracy: 0.5341\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.14794921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: One day my wife and I went shopping at  the shop. We took the car as we had a lot of things to buy because my brother and his family were going to spend the weekend with us. We stopped the car in front of the shop. An hour later we came back to the car with a lot of things. Then the trouble started. We could not open the car door.\n",
            "\"Oh, dear,\" said my wife, \"What are you going to do?\"\n",
            "\"Let's ask that policeman,\" I said. The policeman was very kind and glad to help us. A few minutes later he got the door open. Just at that moment an angry man came up and shouted, \"What are you doing with my car?\"\n",
            "We looked at the number of the car and our faces turned very red.\n",
            "\n",
            "Question: How long did they spend in the shop doing their shopping?\n",
            "A. About half an hour.\n",
            "B. A whole morning.\n",
            "C. One hour or so.\n",
            "D. A whole day.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5281\n",
            "Current Mean Accuracy: 0.5281\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29667\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8642578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: Wang Hao is in   _   now.\n",
            "A. England\n",
            "B. the USA\n",
            "C. Jiangsu\n",
            "D. Beijing\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5222\n",
            "Current Mean Accuracy: 0.5222\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9072265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.67431640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
            "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
            "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
            "\n",
            "Question: Why does Victory work so hard? Because   _  .\n",
            "A. he is very strong\n",
            "B. he likes his work very much\n",
            "C. he is helping his parents\n",
            "D. he is saving up to buy a house\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5165\n",
            "Current Mean Accuracy: 0.5165\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.77490234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: The word, \"photography\", was first used in 1839. It comes from the Greek words that mean \"to write with light\". But photography could only give people _ pictures. So scientists were trying hard to find ways to make pictures that can move. They made lots of experiments, but failed again and again. It was Eadweard Muybridge who finally succeeded. He was the first photographer to try this successfully. But how did he make it? It was an interesting story.\n",
            "Back in 1872, people didn't know exactly whether all four of a horse's hooves   left the ground at the same time when it was running. A gentleman called Leland Stanford made a bet with his friend about it. Most people believed that a horse always had one hoof on the ground, or it would fall over. But Stanford didn't think so.\n",
            "At that time, it was hard to know who could win the bet, because a horse's legs move so fast that it is impossible to tell just by looking. So they needed a way to record the movement of a running horse. Then Stanford offered $25,000 to the famous photographer, Muybridge, to help find the answer. In the beginning, Muybridge failed to get clear images, but he didn't give up. He continued to improve his cameras. In 1878, after many experiments, he managed to get a sequence   of 12 photos. One of them clearly showed that all four of the horse's hooves were off the ground at the same time. And when the photos moved fast, people could see a horse running.\n",
            "Though is usually considered as the person who created the first movie in 1889, it was the work of Eadweard Muybridge and the bet that led to Edison's invention.\n",
            "\n",
            "Question: The passage mainly tells us   _  .\n",
            "A. that Thomas Edison created the first movie .\n",
            "B. that Eadweard Muybridge created the first static pictures\n",
            "C. how photography helped people know more about animals\n",
            "D. how Eadweard Muybridge got pictures of motion   successfully\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5217\n",
            "Current Mean Accuracy: 0.5217\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1990966796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Music education hasn't changed much since the 1970s. Students are still taught to read notation so they can recite compositions that they would never listen to on their MP3 players or play with friends. Playing music enriches life. The question is: Why do schools teach music in a way that _ so many young people rather than catch their imagination? Can we do a better job of using the power of music to get kids excited about school?\n",
            "The experience of an organization called Little Kids Rock suggests the answer is yes -- if we change the way music is taught. Little Kids Rock has helped music programs in over a thousand public schools and served 150,000 children. The organization has given 30,000 free instruments out, mainly guitars, and trained 1,500 teachers to run music classes in which students quickly experience the joys of playing their favorite songs, performing in bands , and writing their own music.\n",
            "The key to Little Kids Rock is that it teaches children to play music the way many musicians learn to play it -- not by notation, but by listening, imitation and meaningful experimentation. \"The knowledge you need to get started playing rock music is very limited,\" explains Dave Wish, the founder of Little Kids Rock. \"In high school, my friend Paul taught me a couple of chords and my life was changed forever. On the first day of class, Little Kids Rock teachers place guitars in the hands of their students and get them practicing chords that will enable them to play thousands of songs. The kids decide what songs they want to learn and the class is off and running. Their progress is surprising. Within a year, eight and nine-year-olds are playing musical instruments, and giving concerts, even performing their own songs.\n",
            "One of the biggest advantages that music offers is the ability to encourage students who are otherwise bored by school. \"I've had students start coming back to school because of this program,\" said Adkison Thomas, who heads up music for the Dallas Independent School District. He added, \"One of the best things is that the teachers discover a new side of their students. They see kids become successful who weren't before.\"\n",
            "\n",
            "Question: What does the writer want to tell us?\n",
            "A. Learning music is a good way to become successful.\n",
            "B. Teaching in a proper way does good to students' development.\n",
            "C. It's necessary for students to practice a lot in learning music.\n",
            "D. It's important for teachers to discover the new sides of students.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5161\n",
            "Current Mean Accuracy: 0.5161\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 120685\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1766357421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11688232421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Children in England mustn't work until they are 13. They need to have a work permit   to start working.\n",
            "The jobs teenagers can do\n",
            "Delivering   newspapers\n",
            "Many teenagers will get up early to deliver newspapers to houses in their local area before going to school. They are known as Paper-boys or Papergirls.\n",
            "Babysitting: Looking after young children in their home while their parents have gone out for the evening is a popular job for teenagers, as they get money for watching children and television all at the same time!\n",
            "Helping the Milkman: From the age of 14 some teenagers help the milkman deliver milk to houses.\n",
            "Other popular jobs : Working in a shop; Office work; Washing cars ; In a cafe or restaurant. The hours teenagers (13 and 14 year olds )can work:\n",
            "School Days\n",
            "Not more than 2 hours in one day during the following periods:\n",
            "Morning 7 a. m. --start of school or Evening\n",
            "close of school-- 7 p. m.\n",
            "Saturdays: Up to 5 hours between 7 a.m. and 7 p.m.\n",
            "Sundays\n",
            "Up to 2 hours between 7 a.m. and 11 a. m.\n",
            "Term time\n",
            "Up to 12 hours a week (Including weekends)\n",
            "\n",
            "Question: Teenagers in England can do all of the following except   _   .\n",
            "A. work in an office\n",
            "B. work in a night club\n",
            "C. look after young children\n",
            "D. deliver newspapers\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5106\n",
            "Current Mean Accuracy: 0.5106\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.51171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Are you always unwilling to do housework and cleaning for no reason? Well, you will be happy today. Today is No Housework Day. It's time to forget about housework and be relaxed.\n",
            "No Housework Day is always on April 7th. It is your chance to do anything, except housework. Better still, have someone else do housework for a day. Housework is a daily and endless job and most people think it's boring to do housework. I have many friends and their wish is to stay away from housework. In fact, their wish can never come true.\n",
            "Do you know how to celebrate No Housework Day? Well , there are two different ways.\n",
            "If you usually do the housework around the house, forget it on this day. Instead, kick back and enjoy the day. Relax and do anything, except housework.\n",
            "If you never do housework, you can do it for your family. It gives your parents a break from the housework. And, you just might get a chance to know how much housework your parents need to do every day.\n",
            "\n",
            "Question: The writer has many friends and their wish is   _  .\n",
            "A. not to do any housework any more\n",
            "B. to ask others to do their housework\n",
            "C. to celebrate No Housework Day\n",
            "D. to ask all the family members to do housework\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5053\n",
            "Current Mean Accuracy: 0.5053\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 64063\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.034423828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
            "\n",
            "Question: Andy and Jim think the tall man is   _   .\n",
            "A. an actor\n",
            "B. a thief\n",
            "C. a policeman\n",
            "D. the short man's friend.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5104\n",
            "Current Mean Accuracy: 0.5104\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9248046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Plants are very important living things. Life could not go on if there were no plants. This is because plants can make food from air, water and sunlight. Animals and man cannot make food from air, water and sunlight. Animals get their food by eating plants and other animals. Therefore animals and man need plants in order to live. This is why we find that there are so many plants around us.\n",
            "If you look carefully at the plants around you, you will find that there are two kinds of plants: flowering plants and non-flowering  plants.\n",
            "Flowering plants can make seeds . The seeds are protected by the fruits. Some fruits have one seed, some have two, three or four, and some have many seeds. But a few fruits have no seeds at all. An example of a fruit without seeds is the banana fruit.\n",
            "Most non-flowering plants do not grow from seeds. They grow from spores . Spores are very, very small. Some spores are so small and light that they can float in the air. We may say that spores are quite the same as seeds. When these spores fall on wet and shady  places, they usually grow into new plants.\n",
            "\n",
            "Question: This passage is most likely to be taken from   _  .\n",
            "A. a story book\n",
            "B. a novel\n",
            "C. a science magazine\n",
            "D. a laboratory report\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5052\n",
            "Current Mean Accuracy: 0.5052\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8310546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91591\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0278472900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: This is a special class. The students come from different countries. Some come from America. Others come from Canada, Japan, Australia and England. They speak different languages,but all of them can speak English. They are good friends. They study together, play together and live together. They help each other. All the teachers of this class are Chinese, but they can speak English. They are very kind and friendly. They work hard. The students in this class study Chinese cooking and Chinese gongfu.\n",
            "All the students like China. They say China is a great country and the Chinese people are very friendly. And they are happy in China.\n",
            ",.\n",
            "\n",
            "Question: What kind of class is this?\n",
            "A. A Chinese cooking class\n",
            "B. A Chinese gongfu class\n",
            "C. A foreign language class\n",
            "D. Both A and B\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.435302734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: We have twenty minutes' break time after the second class in the morning.  Look!  Most of us are playing during the break time. Some students are on the playground . They are playing basketball. Oh! A boy is running with the ball.  And another is stopping  him. They look so cool. And there are some girls watching the game. Some students are in the classroom. They are talking.  A few of them are reading and doing homework. Look! A girl is looking at the birds in the tree in front of the classroom. She must be thinking of something interesting because she is smiling .\n",
            "What are the teachers doing? Some of them are working in the office. And some are talking with students. Everyone is doing his or her things, busy but happy!\n",
            "\n",
            "Question: The passage is mainly about   _   .\n",
            "A. students\n",
            "B. a basketball game\n",
            "C. break time activities\n",
            "D. teachers\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4949\n",
            "Current Mean Accuracy: 0.4949\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.392333984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0260467529296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Before I left to meet Lynne, my friend told me that I had better take some money, but I didn't listen to him. I thought that Lynne would pay because she invited me.\n",
            "I arrived at the restaurant on time because I knew Americans like to be on time. Lynne and I sat at a table near the door and soon we began to enjoy ourselves there.\n",
            "The food there was very delicious. I talked a lot about Saudi Arabia and Lynne told me all about herself. After two hours the waiter came and asked if we wanted one check  or two. Lynne said two. Lynne paid her check, and the waiter gave me mine, I had no money. Then I had an idea, I called my friend. In a few minutes he arrived with some money. He laughed at me all the way home.\n",
            "Now, I think it's funny, but I guess you can understand how I felt at that time. So when you visit a foreign country, you have to learn their language and culture.\n",
            "\n",
            "Question: After the meal,  _  ,\n",
            "A. Lynne paid only for herself\n",
            "B. Lynne paid for both of us.\n",
            "C. I would like to pay for myself\n",
            "D. I paid for both of us.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4900\n",
            "Current Mean Accuracy: 0.4900\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (RACE_M) ---\n",
            "Final Exact Match Accuracy: 0.4900\n",
            "Final Mean Accuracy: 0.4900\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.49000000953674316, 'accuracy': 0.49}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.2206468677520752}, 'time_per_token': {'mean': 0.2206468677520752}, 'tokens_per_second': {'mean': 4.699063604474068}}\n",
            "Valid formats: ['chat_format', 'cnn_dm_summarization', 'cnn_dm_lm', 'xsum_summarization', 'human_eval', 'custom_jsonl', 'top_v2', 'mmlu', 'race_m', 'race_h']\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset race_m \\\n",
        "       --num_samples 100 \\\n",
        "       --generation_strategy self_speculative \\\n",
        "       --dropout_rate 0.2 \\\n",
        "       --layerdrop_seed 42 \\\n",
        "       --output_dir ./logs \\\n",
        "       --exit_layer 8 \\\n",
        "       --num_speculations 6 \\\n",
        "       --distributed False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: race_h\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on RACE_H with 100 samples...\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.68212890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
            "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
            "\n",
            "Question: We have   _   in the dining hall.\n",
            "A. breakfast\n",
            "B. lunch\n",
            "C. dinner\n",
            "D. supper\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.0000\n",
            "Current Mean Accuracy: 0.0000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9208984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Kids have unbelievable imaginations. We asked one hundred kids how robots might help them learn better. This is what they thought.\n",
            "Roberts can make learning fun\n",
            "Kids dreamed robots would make learning fun. One 9-year-old boy in Germany says, \"When I get home, my robot helps me with my homework. My mother and father came in and said 'no video games now, homework first'. When they saw that I had finished my homework, they'd be surprised\".\n",
            "Robots take care of the dirty work\n",
            "Dirty dishes? No problem. A quarter of kids surveyed imagined that their robots could do chores and boring work so that they might be freed up.\n",
            "Robots are our friends\n",
            "Two-thirds of the kids thought that their robots could be friends. One 10-year-old French boy describes his dream robot: \"He created books for me to read, we played with toy cars. He keeps my secrets. I can tell him anything, and he gives me suggestions.\"\n",
            "Robots are cool\n",
            "An 8-year-old girl in the U.S. imagines that her robot is \"really smart and everyone likes to talk to her. She has a funny voice, but we do not laugh at her.\"\n",
            "\n",
            "Question: The boy from Germany wanted his robot to  _  .\n",
            "A. help him with the homework\n",
            "B. play game spot with him\n",
            "C. surprise his parents\n",
            "D. make fun of him\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 1543\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.78564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.71044921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Visiting Harvard University\n",
            "For All Visitors\n",
            "Attend an hour-long group information meeting in the Admissions Office  \n",
            "Admissions officers give information and answer questions about the visit. No appointment or registration   is required for families or groups of 20 people or less who wish to visit the university. Groups of more than 20 people should email tours @ fas. Harvard. Edu to plan a visit.\n",
            "Take a tour\n",
            "Take a student-led tour of the university. But the dorms  , academic departments , athletic facilities  and libraries are not included on any of our tours.\n",
            "Attend a class\n",
            "The Admissions Office provides a list of the meeting times and locations of courses held during the academic year that visitors are welcome to attend.\n",
            "Speak with the Harvard teachers\n",
            "Teachers and other staff members are often glad to talk to people who have questions about our programs. It is best to write ahead directly to the office to arrange an appointment.\n",
            "For Seniors Only\n",
            "Eat a meal with Harvard students\n",
            "During the academic year, high school seniors are our guests for one meal in Annenberg Hall, the first-year dining hall, or in one of the House dining halls if accompanied by a House resident.\n",
            "Stay overnight in one of the residence halls\n",
            "Our office can arrange for high school seniors to stay with volunteer student hosts for one night, Monday through Thursday, from October 1st through early March. We need to hear from you by phone (617-495-1551) or by mail at least three weeks in advance for us to be able to confirm your stay with a host.\n",
            "\n",
            "Question: Which of the following activities is NOT available  to all visitors?\n",
            "A. A meeting in the Admissions Office.\n",
            "B. An opportunity  to talk with a teacher.\n",
            "C. A tour of the university.\n",
            "D. A meal with Harvard students.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.3333\n",
            "Current Mean Accuracy: 0.3333\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2357\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0299530029296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.26708984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Tommy hated school and was always looking for excuses  not to go.If he sneezed, he asked his mother to write a note saying he had a cold.If he had a headache, he asked his mother to take him to the doctor during school hours.\n",
            "He spent more time at home than he did at school.On the days that he did go to school, he looked for excuses to come home early.One morning he came home when the lessons were only half finished.His father was surprised.\n",
            "\"You've come home early,\" he said. \"Is the school closed today?\"\n",
            "\"No, Dad, \" Tommy said - \"It's open. I came home early.\n",
            "\"How did you do that?\" his father asked him. \"What did you say to the teacher?\"\n",
            "\"I told her that I had a new baby brother and that I had to come home and help you . \"\n",
            "\"But your mother has had twins,\" his father said, \"a boy and a girl. You've got a baby brother and a baby sister.\"\n",
            "\"Yes, I know, Dad, \" Tommy said. \"I'm saving up my baby sister for next week \"\n",
            "\n",
            "Question: When he did go to school,he   _  .\n",
            "A. was always later\n",
            "B. tried to leave early\n",
            "C. was always sick\n",
            "D. was very happy\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2500\n",
            "Current Mean Accuracy: 0.2500\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7333984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
            "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
            "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
            "What could she do now?\n",
            "\n",
            "Question: What would happen if Celina told Joseph the truth?\n",
            "A. Joseph would go on the camping trip himself.\n",
            "B. Joseph's family would be angry with Celina.\n",
            "C. Celina might have trouble with her friends.\n",
            "D. Joseph would be thankful to his classmates.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.2000\n",
            "Current Mean Accuracy: 0.2000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.23486328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 23976\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1046142578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
            "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
            "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
            "What could she do now?\n",
            "\n",
            "Question: If Joseph bought a sleeping bag,   _  .\n",
            "A. he would have it for no use.\n",
            "B. everyone else would also buy one\n",
            "C. it would be the best in the class\n",
            "D. Celina would pay for it\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.1667\n",
            "Current Mean Accuracy: 0.1667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 39720\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05975341796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7529296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: A mother and her young son got into a bus in New York City and sat down. The bus conductor  came to them for their money. The mother said, \"I want one ticket  to Central Park, \"and gave him two dollars. The conductor looked at the small boy for a few seconds and then asked him, \"How old are you, young man?\"  The mother just began to speak, but the conductor stopped her, and the boy said, \"I'm four years old at home, and two and a half on buses and trains.\"  The mother felt shamed , so she took another dollar out of her bag and gave the money to the conductor. The conductor gave her one and a half tickets.\n",
            "\n",
            "Question: One day the mother took a bus   _  .\n",
            "A. to a small city\n",
            "B. to get some money\n",
            "C. with her son\n",
            "D. to school\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.2857\n",
            "Current Mean Accuracy: 0.2857\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.352294921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 45999\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08966064453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When you look up into the sky at night, have you ever felt that your eyes are playing tricks on   you? It seems that the stars are moving all the time.\n",
            "Actually, there is nothing wrong with your eyes. This twinkling effect is called scintillation  . Scintillation happens because of air movements in the earth's atmosphere  . Light is \"bent  \" when it travels through different parts of the earth's atmosphere. As the air in the earth's atmosphere is moving all the time, the light from the stars looks as if it is moving too.\n",
            "The same thing also happens to things on the ground. On a very hot and shiny day, if you look at the road, the image in the distance is not clear and things move slightly. You can also see the same effect if you drop a rock into water. The rock appears a little unclear under the moving water.\n",
            "This twinkling effect causes a lot of problems for astronomers   since they cannot _ the stars clearly. A telescope   was sent into space so that the air movements in the atmosphere could be avoided  . It took a long time to build the space telescope but finally in 1990, a huge space telescope called the Hubble Space Telescope was successfully sent into space. Since then, astronomers have many important observations that have helped people understand space better.\n",
            ",.  (10)\n",
            "\n",
            "Question: What can you see when you drop a rock into the water?\n",
            "A. The rock gets broken.\n",
            "B. The rock becomes unclear.\n",
            "C. The water becomes much polluted.\n",
            "D. The water does not move anymore.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.3750\n",
            "Current Mean Accuracy: 0.3750\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5830078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.70263671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: The Biggest and the Gentle\n",
            "The elephant is the biggest four-legged animal in the world.It is also the gentlest,but not always!\n",
            "Elephants are like us in some ways.They live for a long time--fifty or sixty years.They can remember things very well.They never forget great sadness or great happiness.When female elephant dies,her daughters and her granddaughters are sad for many months.They stay with the dead body.Then they carry a bit of it away with them.They never forget a dear friend.\n",
            "Elephants are like us,but they are also different.They live in families of females.There will be a few young males a few\"baby boys\".But the females will soon send them away.And elephant family keeps only its daughters,mothers and grandmothers.And its great-grandmothers.\n",
            "The females stay together for fifty,sixty...a hundred years.The older animals look after the younger ones.The mothers teach their daughters and set a good example.\n",
            "And what happens to male elephants?Well,the young males stay with their family.Then the females just send them away.A bull elephant does not often have a friend.He lives apart,away from the family,and often away from other bulls.\n",
            "Sometimes the females call a bull.He can visit them then,and stay for some time.But soon his\"wives\"and sisters send him away again.The females have a very happy family life.What do the bulls think about it?We don't know.\n",
            "\n",
            "Question: When a female elephant dies,the others  _  .\n",
            "A. leave its dead body there\n",
            "B. shed tears together\n",
            "C. take a bit of the dead body away sadly\n",
            "D. bury the dead\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4444\n",
            "Current Mean Accuracy: 0.4444\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 3653\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04583740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 5045\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0811767578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Did you notice the number on the book in a library? That number is part of the system used by libraries to organize their collections of books. And it's used in many countries. The number on each book tells you exactly what kind of book it is. This system is also useful for knowing where to go in the library to find a book.\n",
            "In this system, there are ten large groups of books. Each of these groups has its own number, such as 100, 200, etc. So, for example, any books about language will have a number 400. On the other hand, any books about history will have a number 900. So, a number in the hundreds place tells you what general group a book is in. If you find a book that has a number in the 500s, you know it is a book about science.\n",
            "However, science is a big group, so the tens place is used to make a more detailed set of science books. For example, math books are included in the group of science books. Math books all have numbers between 510 and 519. Books about the history of Africa have numbers between 960 and 969.\n",
            "The system uses the ones place to give a more exact limit for the subject of a book. A book on the history of South Africa will have the number 968.\n",
            "As you can see, it is a simple system to use as long as you understand what the numbers mean. With this system, the library can keep its books well organized, and people can easily find the book that they want.\n",
            "\n",
            "Question: A book about math can be found in the same group of books as  _  .\n",
            "A. reference books\n",
            "B. school books\n",
            "C. science books\n",
            "D. art books\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 76790\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.268798828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.705078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: I am a Chinese boy. My name is Li Ming. I'm a student. In my class, some of the boys like playing football very much. Wu Jun and I are on school football team. And some of them like playing basketball. _ Han Mei and Zhang Hong are on school volleyball team. Each of them has a tennis racket. In a word  , everyone in our class likes sports very much.\n",
            "\n",
            "Question: The girls like playing   _  .\n",
            "A. tennis and basketball\n",
            "B. football and basketball\n",
            "C. tennis and volleyball\n",
            "D. volleyball and basketball\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4545\n",
            "Current Mean Accuracy: 0.4545\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1485595703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Would you like to adopt an animal? Although this sounds very unusual, some children have done just this. The Natural Zoo has given people the chance to adopt animals by paying for all of its food for one year. One of the animals that needed parents was a young tiger named Brocky. The people at the zoo said that it would cost about $900 a year for the food for Brocky.\n",
            "Not many boys and girls have $900 to spend. That is why several hundred children and grown-ups each have sent a little money to the zoo to help pay for Brocky's food. Some children sent in only a quarter because that was all the money they had. Other children sent in more money than that.\n",
            "Since so many people sent money to the zoo to help pay for Brocky's food, he now will be able to eat as much as he wants. Brocky surely must be a happy tiger to know that he has so many adopted parents. Many children must also be happy to know that they have helped to feed him. It really will be thrilling for those children to go to the Natural Zoo to visit their adopted tiger Brocky.\n",
            "\n",
            "Question: With so many people's money, Brocky now can   _  .\n",
            "A. play with many toys\n",
            "B. live without being hungry\n",
            "C. eat meat every day\n",
            "D. have an air-conditioned room to live in\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.477294921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7548828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
            "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
            "\n",
            "Question: What colours does Nancy like?\n",
            "A. Red and blue.\n",
            "B. Red and yellow.\n",
            "C. Green and yellow.\n",
            "D. Green and blue.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4615\n",
            "Current Mean Accuracy: 0.4615\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.41162109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.86865234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Snack time is a part of the day for children of all ages. But new research suggests that kids snacking in big groups could be at risk for _ .\n",
            "Scientists from American University looked at the eating behavior of 54 kids between the ages of 2 and 6. At snack time, the scientist watched the amount of food each child ate while they were in groups of either three or nine. According to the study, the more children there are in a group, the more likely they are to eat more. Those in the larger group ate nearly 30 percent more than those in the smaller group, and they actually ate faster.\n",
            "Since this is the first such study in children, scientists are quick to point out the importance of encouraging healthy habits in kids as early as possible.\n",
            "\"If you know kids eat more in large groups, it seems perfect to use this information to keep snack groups small or use small tables,\" says Dr. Jana Klauer, an expert in New York.\n",
            "Smaller groups would allow for a quiet and more relaxing environment-a perfect chance to teach children about food, manners and how to know when they feel full. \"This would have an effect on kids' eating,\" adds Klauer. \"They would slow down and eat less.\"\n",
            "\n",
            "Question: Why do children in smaller groups lose weight?\n",
            "A. Because children in smaller groups eat faster.\n",
            "B. Because children in smaller groups don't like eating.\n",
            "C. Because children in smaller groups don't know about food.\n",
            "D. Because children in smaller groups eat slowly and eat less.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4286\n",
            "Current Mean Accuracy: 0.4286\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.505859375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.47119140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
            "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
            "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
            "\n",
            "Question: What did the white lambs think of the black lamb?\n",
            "A. Friendly.\n",
            "B. Kind.\n",
            "C. Ugly.\n",
            "D. Beautiful.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4667\n",
            "Current Mean Accuracy: 0.4667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.88720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.748046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: In a small village in England about 150 years ago, a mail coach (    ) was standing on the street . It didn't come to that village often  . People had to pay a lot to get a letter . The person who sent the letter didn't have to pay the postage (     )  , while the receiver had to .\n",
            "\"Here's a letter for Miss Alice Brown , \" said the mailman .\n",
            "\" I'm  Alice Brown , \" a girl of about 18 said in a low voice .\n",
            "Alice looked at the envelope  for a minute , and then handed it back to the mailman .\n",
            "\" I'm sorry I can't take it , I don't have enough money to pay it\", she said .\n",
            "A gentleman standing around were very sorry for her . Then he came up and paid the postage for her .\n",
            "When the gentleman gave the letter to her , she said with a smile , \" Thank you very much ,This letter is from Tom . I'm going to marry him . He went to London to look for work . I've waited a long time for this letter , but now I don't need it , there is nothing in it .\"\n",
            "\" Really ? How do you know that ? \" the gentleman said in surprise .\n",
            "\" He told me that he would put some signs on the envelope . Look ,sir ,this cross in the corner means that he is well and this circle means he has found work . That's good news .\"\n",
            "The gentleman was Sir Rowland Hill . He didn't forgot Alice and her letter .\n",
            "\" The postage to be paid by the receiver has to be changed ,\" he said to himself and had a good plan .\n",
            "\" The postage has to be much lower , what about a penny (    ) ? And the person who sends the letter pays the postage . He has to buy a stamp and put it on the envelope .\" he said .\n",
            "The government accepted his plan . Then the first stamp was put out in 1840 . It was called the \" Penny Black \" . It had a picture of the Queen on it .\n",
            "\n",
            "Question: The girl handed the letter back to the mailman because   _   .\n",
            "A. she didn't know whose letter it was\n",
            "B. she had no money to pay the postage\n",
            "C. she received the letter but she didn't want to open it\n",
            "D. she had already known what was written in the letter\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.36767578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
            "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
            "\n",
            "Question: Tony is from  _  .\n",
            "A. England\n",
            "B. America\n",
            "C. English\n",
            "D. American\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5294\n",
            "Current Mean Accuracy: 0.5294\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.74560546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37689\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04071044921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Just as \"Tiger Mom\" leaves, here comes the \"Wolf Daddy\" called Xiao Baiyou. He believes he's the best parent in the world. Some days ago, Xiao Baiyou's latest book about how to be a successful parent came out. He is pretty strict with his four children. Sometimes he even beat them. But the children don't hate their daddy at all. And all of them finally went to Pecking University, one of the top universities in China. So Xiao proudly tells others about his education idea that children need strict rules. In his microblog, he said, \"Come on, want your children to enter Peking University without rules? You must be joking.\" And, \"Leave your children more money, and strict rules at the same time.\"But the \"Wolf Daddy\" way was soon questioned by other parents. Some say that Xiao Baiyou just want to be famous by doing so. The \"Wolf Daddy\" Xiao Baiyou is a 47-year-old Guangdong businessman who deals in luxury goods  in Hong Kong. Unlike many other parents who usually have one child, Xiao has four children. Two of them were born in Hong Kong and two in the US. Some people on the Internet think the reason why his children were able to enter Peking University is because the exam is much easier taken from Hong Kong.\n",
            "\n",
            "Question: As for how to be a parent, Xiao Baiyu thinks   _  .\n",
            "A. children don't need rules\n",
            "B. children need strict rules\n",
            "C. children don't need money\n",
            "D. children need luxury goods\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5556\n",
            "Current Mean Accuracy: 0.5556\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.5849609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: In today's world many people seem to be hungry for money. Some of them even have lost their lives for it. Money does have a great effect on the poor, but if a person has a rich life, a lot more money doesn't mean more happiness.\n",
            "If money were everything, all millionaires would have true love, real friendship, health and a long life. However, this is not always true.\n",
            "Nothing else is more pleasant than the three words \"I love you\", but can love be bought? I'm afraid not. Love means \"give\", not \" take\". Health and a long life are precious things for every person. Well, can health and a long life be bought with money? The answer is \"No\". Of all the people who live longest in the world, few of them are millionaires. Real friendship can't be bought, either.\n",
            "In a word, where money is _ , money can cause brothers to quarrel, lovers to hate, strangers to fight and so on. No matter how much money you have, _ is still not enough to make you a happy person if you have no one to laugh with and no one to cry for.\n",
            ",\n",
            "\n",
            "Question: What does the passage mainly tell us?\n",
            "A. Money is as important as true love.\n",
            "B. Money isn't necessary.\n",
            "C. Money is important, but not the most important.\n",
            "D. Money can cause some problems.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5263\n",
            "Current Mean Accuracy: 0.5263\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.931640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.439453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: In some places around China,the junior high school graduates have to take a P. E. test. The full marks are usually 30 points and it counts for much in the senior high school entrance exam.\n",
            "In Nanjing the test is held in April. Students have the test in their own schools. Each student is tested on three sports. They can choose long jump, basketball dribbling   or volleyball. The _ is for boys and girls can choose the sit-up. Both boys and girls must skip  in the test.\n",
            "Most students find the test easy and more than 90%of them can get full marks. That's because they have been training for it during the three whole years. Students in Junior Three usually do lots of practice in P. E. classes. The training makes the test easier than it seems to be.\n",
            "Students in Nanjing don't need to run a lot for the test, but students in Beijing must do lots of running for the test. Running is one of the sports in test. So in P. E. classes, they usually run a lot. Sometimes they have to run 3,000 meters in one class. Most teachers and parents welcome the P. E. test. They say it helps students build up their health and it's really useful.\n",
            ",.\n",
            "\n",
            "Question: The P. E. test in Nanjing includes all of these sports except   _  .\n",
            "A. skipping\n",
            "B. basketball\n",
            "C. football\n",
            "D. volleyball\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.29541015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Dear Boris,\n",
            "Thanks for your nice letter.\n",
            "After I had spent a week with my English family, I slowly began to understand their English a little better. It's very different from what I learned at school! Students in my group are from different cities of Britain and their dialects   are different too! Some of their accents   are quite strong and they also have their own words and expressions.\n",
            "But it's not the language that's different and surprising. Before I came to England I had thought that fish and chips were eaten every day. That's quite wrong! I get rather mad now when I hear all the foolish words about typical   English food.\n",
            "I had expected to see \"London fog\". Do you remember our texts about it? We had no idea that most of this 'thick fog' disappeared many years ago when people stopped using coal in their homes. But the idea to speak about the weather was very helpful. The weather in London is really changeable.\n",
            "On the other hand habits are different. People tell me what is typically British here in London is not always typical in Wales or Scotland. Local habits and traditions are not the same as what we knew.\n",
            "But what is ordinary for all British is that they follow traditions. Probably Britain has more living signs of its past than many other countries. And people have always been proud of having ancient buildings in capitals, big cities and the countryside.\n",
            "I will tell you more about Britain in my other letters.\n",
            "Love from Britain,\n",
            "Peter\n",
            "\n",
            "Question: The British people like to talk about weather because   _  .\n",
            "A. there is thick fog in London\n",
            "B. they like the weather in Britain\n",
            "C. the weather changes a lot\n",
            "D. it can be helpful\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5238\n",
            "Current Mean Accuracy: 0.5238\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11138916015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Once a traveller came into a village which was suffering from hunger. The villagers asked him to leave, for they feared he wanted them to give him food. They told him that there was no food. The traveller explained that he didn't need any food and that, in fact, he was planning to make a soup to share with them instead. The villagers watched suspiciously as he built a fire and filled a pot with water With great ceremony , he pulled a stone from a bag, and dropped the stone into the pot of water. After a moment, he smelt the soup and shouted with excitement, \"How delicious the soup is!\" As the villagers began to show interest, he mentioned how good the soup would be with just a little cabbage in it. A villager brought out a cabbage to share. This episode  repeated itself until the soup had cabbage, carrots, onions, and beets--indeed, a full pot of soup that could feed everyone in the village was ready. This story describes when there are not enough resources , humans will store things. We do not want to share. The story of stone soup helps us realize that, in doing so, we often prevent ourselves and everyone else from having a feast .The meaning of this story goes far beyond food. We keep to ourselves ideas, love, and energy, thinking we will be richer, but in fact we make the world, and ourselves, poorer. The traveller was able to see that the villagers were holding back, and he had the ability to inspire  them to give. In this way, they created a large meal that none of them could have created alone. Are you like one of the villagers? If you come forward and share your gifts, you will inspire others to do the same. The reward is a feast that can feed many.\n",
            "\n",
            "Question: The writer mainly wants to tell us that .\n",
            "A. storing things in hard times is human nature\n",
            "B. a good leader is very necessary in hard times\n",
            "C. skills are needed to inspire people to share with others\n",
            "D. sharing is more important than keeping things to oneself\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5455\n",
            "Current Mean Accuracy: 0.5455\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.90869140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.10760498046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Why do we come to school? Most of us may say we come to school to study. But to study needs a right way, or you either waste the time or the money. The following are the ways for studying.\n",
            "The best time for reading is morning. In the morning the air is fresh and the mind is clear. For that reason we can get good results.\n",
            "In studying we must have patience . If we have not known a text well, we must read it again. We should not read the next one until we have learned the first one well.\n",
            "When we are studying, we must put our hearts into the books, or we can get nothing from the books while we are reading.\n",
            "We must always ask \"whys\". If it is not well understood, write it down and ask our teachers or our parents, brothers or friends. In any possible way, we must know it completely and what we have learned can be used well and made better.\n",
            "Though there are many ways for studying, yet what I have said above will be enough if we can keep them in heart and do so.\n",
            "\n",
            "Question: While reading we can't get anything from the book if we   _  .\n",
            "A. read very fast\n",
            "B. read in the afternoon\n",
            "C. don't read it again\n",
            "D. can't put our hearts into it\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5652\n",
            "Current Mean Accuracy: 0.5652\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 64900\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07476806640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.71337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: I'm an American boy. My name is Tony. I'm thirteen this year. I come to China with my parents and study in a new school now. The name of my new school is Yingcai Middle School. It is the best  school in this city. There are nine hundred students in it. Many foreign students study here. We learn to speak Chinese. And many Chinese students can speak English well. I think Chinese is hard to study, but I like it.\n",
            "The students in the school are _ to me, and the teachers take good care of me. I feel very happy every day in my new school.\n",
            "\n",
            "Question: Tony comes to China with  _  .\n",
            "A. his father\n",
            "B. his mother\n",
            "C. his father and mother\n",
            "D. his friends\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5833\n",
            "Current Mean Accuracy: 0.5833\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.93798828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: In many countries, holidays are important parts in people's life. Let's show some countries to you.\n",
            "America\n",
            "American people's holidays are flexible ( ). They can use up their holidays once, and they can also use them up a few times. During the holidays, they still get money.\n",
            "Canada\n",
            "Many people in Canada can rest three days a week. They have all kinds of activities   for holidays. They may go fishing, boating or mountain climbing. Also, they have long holidays. They may go to the beach to spend a sunny winter holiday. Like American people, Canadians also get money during the holidays.\n",
            "France\n",
            "People in France are very good at enjoying life. They have a 6-week holiday every year, and they work less than 40 hours a week.\n",
            "\n",
            "Question: Which of the following activities is not mentioned in the passage?\n",
            "A. Go fishing.\n",
            "B. Go boating.\n",
            "C. Go skating.\n",
            "D. Go mountain climbing.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5600\n",
            "Current Mean Accuracy: 0.5600\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.181884765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
            "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
            "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
            "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
            "\n",
            "Question: What does the user mean by saying \"After 14 days of detention, Ko's acting skills grew a lot\"?\n",
            "A. He thinks Ko is still a good actor.\n",
            "B. He supports Ko no matter what happened.\n",
            "C. He doesn't trust what Ko said.\n",
            "D. He thinks Ko has trained hard and improved his acting skills.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5769\n",
            "Current Mean Accuracy: 0.5769\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 38731\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.03375244140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Usually, students are not encouraged to run or jump around in the corridor  . However, students in a British grammar school really enjoy running on the corridor tiles   and their teachers even encourage them to do that.\n",
            "Why? It is because the corridor was built with special kinetic   tiles. When students jump on the tiles, electricity will be produced. After one year, the electricity produced from the tiles can fully charge 853 mobile phones or power  an electric car to drive seven miles. It's amazing, isn't it?\n",
            "The corridor tiles are really a brilliant invention. Students can not only play on the corridor, but also help power the lights in their school corridors and other equipment in their classrooms. Besides, this is a good way to teach students to be creative. They will be _ to be scientists, inventors and engineers in the future to find clean energy for all humans.\n",
            "The inventor of the magic corridor tiles is Laurence Kemball-Cook. He was once a student in this school. Now, he is CEO of his own company. The corridor tiles are not Laurence's only invention. He has also invented a special dance floor, which can be used at music festivals. It allows dancers to charge their mobile phones while they are dancing on the dance floor.\n",
            "\n",
            "Question: After one year, the electricity produced from the tiles can provide enough energy for   _  .\n",
            "A. over 800 mobile phones\n",
            "B. all the lights of the school\n",
            "C. an electric car to drive 70 miles\n",
            "D. the lights and other equipment in their classrooms.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5926\n",
            "Current Mean Accuracy: 0.5926\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.181640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05767822265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: There was a new maths teacher and some new students in the school. One of the new students named Karl was very _ . The other students tried to explain   numbers to him, but he didn't understand.\n",
            "Before Karl arrived, maths was the most boring lesson of all. Now it was great fun. The children would listen to Karl and correct his mistakes. They all wanted to be the first to find his mistakes, and then tried to think up the best ways to explain them.\n",
            "But little Lewis was sure that Karl felt sad and wanted to talk with him. So, one day, he decided to walk after Karl after school. Lewis was sure he would see him crying. On the way home, Karl walked a few minutes to a park, and there he waited for someone to meet him...\n",
            "It was the new teacher!\n",
            "They went off, hand in hand. Lewis could hear them talking about maths. And that stupid Karl knew everything about it, and even much more than anyone else in the class!\n",
            "\n",
            "Question: Which lesson was the most boring of all before Karl arrived?\n",
            "A. Chinese.\n",
            "B. English.\n",
            "C. Maths.\n",
            "D. Music.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6071\n",
            "Current Mean Accuracy: 0.6071\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.701171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 80413\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.025390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Some women are talking about the problems of getting old.\n",
            "One woman says, \" Sometimes I stand in front of the bag with an egg. But I can't remember _ I need to put it in or get it out to make bread.\"\n",
            "\"Yes, I have the same problem,\" the second woman says. \"Sometimes I stand on the stairs . But I can't remember whether I am going on my way up or down.\"\n",
            "\"Well, I don't have that problem,\" the last woman says, keeping knocking  on the table.\n",
            "The other two women ask, \"Why are you knocking on the table?\"\n",
            "\"Sorry, I ?don't know. Someone is knocking at the door ,isn't\n",
            "It? Let me see who it is,\" the last woman says.\n",
            "\n",
            "Question: Whose problem is the most serious   in the story?\n",
            "A. The first woman.\n",
            "B. The second woman.\n",
            "C. The third woman.\n",
            "D. The fourth woman.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5862\n",
            "Current Mean Accuracy: 0.5862\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.305908203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3369140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
            "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
            "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
            "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
            "\n",
            "Question: Little Mike went to the park and   _  .\n",
            "A. played with pigeons\n",
            "B. met an old lady\n",
            "C. fed pigeons\n",
            "D. saw a friend of his grandma's\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4849\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06646728515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When someone says, \"Well, I guess I'll have to face the music\", it doesn't mean that he is going to hear a singer. It is something far less happy, as you are called in by your leader to explain why you did this and did that or why you did not do this or that.\n",
            "At some time or another, every one of us has to \"face the music\", especially as children. We can all remember father's angry words \"I want to talk to you.\" And only because we did not listen to him. What a bad thing it was!\n",
            "In the middle or at the end of every term, we students have to \"face the music\". The result of the exam will decide whether we will face the music or not. If you got a \"D\" in the exam, that means parents' cold faces and the contempt  of the classmates.\n",
            "\"To face the music\" is well-known to every American, young or old. It is at least 100 years old. It really means that you have to do something, no matter how terrible the whole thing might be, because you have no choice.\n",
            "\n",
            "Question: Which of the following is wrong?\n",
            "A. \"To face the music\" is well-known in the US.\n",
            "B. \"To face the music\" has a history of more than 100 years.\n",
            "C. The young Americans know the meaning of \"to face the music\".\n",
            "D. Only the old in the US know the meaning of \"to face the music\"\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6129\n",
            "Current Mean Accuracy: 0.6129\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.461181640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 64063\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12335205078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: It is very important for children to get to school safely and on time every day. Luckily, there is a new program called Free Home to School Transport . It gives children free rides to school. But to enjoy the free trip. Children have to qualify .\n",
            "Children can take free home to school transport if they:\n",
            "*are between 5 and 16 years old\n",
            "*are going to the nearest school\n",
            "*live far away from school\n",
            "No matter how far away children live from school, they Can take the free transport if they have walking problems or there is no safe road for them. A safe road usually has crossings, lights and should be clean.\n",
            "Also, there are still free home to school _ for children in poor families and children with special educational needs, you can find out more on the Internet and see if your children are qualified.\n",
            "\n",
            "Question: According to the passage, it is very important for children not to be   _  for school every day.\n",
            "A. late\n",
            "B. away\n",
            "C. early\n",
            "D. ill\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5938\n",
            "Current Mean Accuracy: 0.5938\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 30173\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.12152099609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.343017578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
            "\n",
            "Question: They work on   _  .\n",
            "A. weekends\n",
            "B. Friday\n",
            "C. Sundays\n",
            "D. weekdays\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6061\n",
            "Current Mean Accuracy: 0.6061\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21938\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.69580078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07012939453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Kitesurfing as a water sport began in the 1980s, but didn't get popular until the end of last century. It is also known as kiteboarding, and in some European countries as flysurfing. Kitesurfing works through wind power  by using a large kite to pull a rider on the water at high speed.\n",
            "At first, kitesurfing was a difficult and dangerous sport. Now it is becoming easier and safer because of the safer kite design. For an able and strong person, kitesurfing can be a very fun, extremely exciting sport, just like skating on the water with a feeling of flying. It has become more and more popular.\n",
            "Compared with other water sports, kitesurfing is easier to learn. A beginner can understand how to operate the kite with 5--10 hours of training. And anybody aged from 13 to 65 can learn. It is not expensive to get the equipment for kitesurfing, which costs $1,000 to 82,500. Training lessons _ from $200 to $500 for two or three hours. With the development of its equipment progress, kitesurfing is becoming even safer. After some training, you can enjoy its excitement and challenging feeling.\n",
            "With the rising popularity of kitesurfing, most major seaside cities have kitesurfing clubs. In China, Xiamen is the only place that has the kitesurfing club, which provides professional kitesurfing training and equipments.\n",
            "\n",
            "Question: The most important reason for the popularity of kitesurfing is that   _  .\n",
            "A. its price is getting lower and lower\n",
            "B. more and more people are enjoying its excitement\n",
            "C. its equipment progress makes it easier and safer\n",
            "D. all people can learn and take part in it\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6176\n",
            "Current Mean Accuracy: 0.6176\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.57861328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.262939453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: People go to work in different ways. They work from Monday to Friday.Some people go to work on foot because they live near their workplaces. Some people go to work by bike because they live far from their workplaces,or they like riding bikes. They think it's good for their health. Today more people have own cars,so they can go to work in their cars. In the south of China,many people even go to work by boat because water is around their houses. Will people go to work by plane? I think so,if necessary.\n",
            "\n",
            "Question: In the south of China,many people go to work   _  .\n",
            "A. by plane\n",
            "B. on foot\n",
            "C. by boat\n",
            "D. by ropeway\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4849\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.301513671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.345947265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Where are the animals having the sports meeting?\n",
            "A. In the forest\n",
            "B. In a park\n",
            "C. In a zoo\n",
            "D. In a school.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6111\n",
            "Current Mean Accuracy: 0.6111\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9345703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
            "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
            "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
            "\n",
            "Question: Why do people go and live in valleys near rives ?\n",
            "A. The temperature isn't too low in winter.\n",
            "B. The resources like oil can bring them much money.\n",
            "C. People can make their living by catching and selling fish.\n",
            "D. It's easier for people to grow plants or keep animals.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5946\n",
            "Current Mean Accuracy: 0.5946\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.56982421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1976318359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Last Sunday afternoon, I was having dinner in a restaurant when my friend Poor came in. Poor is working in a bank and is quite rich, but he is always borrowing money from his friends and never pays it back. Poor saw me and came to sit at my table. He had never borrowed any money from me. When he was eating, I asked him to lend me two dollars. To my surprise, he gave me the money at once.\"I have never borrowed any money from you,\"Poor said,\"So you can pay for my dinner.\"\n",
            "Read the passage and choose the best answers.(,. )\n",
            "\n",
            "Question: The story happened    _    .\n",
            "A. at home\n",
            "B. in a restaurant\n",
            "C. in a bank\n",
            "D. in an office\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5789\n",
            "Current Mean Accuracy: 0.5789\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7607421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello! My name is Zhang Fei. I am Chinese. I am twelve. I'm in No.1 Middle School in Nanjing. This is my friend. His name is Tony Green. He is an English boy .He is twelve. He and I are in the same  class. Our classroom is next to  the teachers' office .We have Chinese and English lessons  every day. Our English teacher is Mr. Read. He is English but he can speak Chinese. Our Chinese teacher is Mr. Ding. They are good teachers, and they are our friends, too\n",
            "\n",
            "Question: Mr. Read is Zhang Fei's  _\n",
            "A. English teacher\n",
            "B. Chinese teacher\n",
            "C. father\n",
            "D. classmate\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5897\n",
            "Current Mean Accuracy: 0.5897\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29667\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2344970703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: South Korean stars shined brightly at the Opening Ceremony of the 17th Asian Games held here on Friday, Sept. 19 in Inchen .\n",
            "Many stars gave shows during the welcoming performance.The most famous K-pop boy group, EXO, performed two songs on stage.Famous actors followed to show up on stage, including Jang Dong-gun, Hyun Bin, and Kim Soo-hyun.Lee Young-ae, the South Korean actress known for volunteering, was the last torchbearer  and lighted the cauldron  with two children.\n",
            "After the lighting of the flame, 16 more minutes of other K-pop performances were held. JYJ sang the theme song 'Only One' and Psy and Chinese pianist Lang Lang finally performed \"Gangnam Style\" with the 60,000-strong audience.\n",
            "\n",
            "Question: _   lighted the cauldron at last.\n",
            "A. Jang Dong-gun\n",
            "B. Hyun Bin\n",
            "C. Kim Soo-hyun\n",
            "D. Lee Young-ae\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2088623046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
            "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
            "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
            "She understood that she hadn't worn the hair clip to school at all.\n",
            "\n",
            "Question: Which of the following sentence is true?\n",
            "A. The girl is not as beautiful as other girls.\n",
            "B. Nobody liked the girl.\n",
            "C. The girl's classmates thought she was more beautiful than before with the hair clip.\n",
            "D. The girl wanted to be more beautiful, so she decided to wear the hair clip.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5854\n",
            "Current Mean Accuracy: 0.5854\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 8093\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.82666015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7216796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When my wife left this world, I chose to travel in Antigua looking for a peaceful place to rest my old body. Not quite old and weak, I felt I wanted something more than the usual hotel room with 24-hour room service.\n",
            "I decided this year to try something completely new and booked myself a private holiday home in Antigua. This was the best decision I had ever made, as there was plenty to do, plenty to see and lots of lovely restaurants to visit. There was a private swimming pool, and a cool, wide yard where I ate my breakfast most mornings.\n",
            "Antigua has to be one of the loveliest places on earth to spend a holiday. The bright blue sea and the endless blue around the beach areas proved to be an excellent place for me to spend the long afternoons.\n",
            "I had to hurry to do what I wanted to do before the holiday came to an end. I managed to visit the Sugar Mill and Shirley Heights on my last two days and yet found myself wondering whether I could extend for a few more days.\n",
            "I rented a boat and came home after a day's sailing, refreshed, looking forward to dinner. Everything is so pleasant on these beautiful islands, swept by the trade winds and warmed by the sun for so many summer months. The food just tasted better to me, perhaps because I was having such a great holiday. There was always someone to have a drink with---- that's what I liked most.\n",
            "\n",
            "Question: The passage is most likely to be taken from a part of   _  .\n",
            "A. a tour guide\n",
            "B. a travel diary\n",
            "C. a student's report\n",
            "D. a health report\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5952\n",
            "Current Mean Accuracy: 0.5952\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.359619140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47830\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.01517486572265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
            "\n",
            "Question: From the passage, we know   _   .\n",
            "A. Jim and Andy like seeing movies\n",
            "B. Jim and Andy like helping others\n",
            "C. Jim and Andy want to be actors\n",
            "D. the four people in the story become friends after that\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5814\n",
            "Current Mean Accuracy: 0.5814\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21938\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.405029296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Dr. Sharon M. Draper is an excellent teacher as well as a successful writer. She is a woman of achievements.\n",
            "She had been honored  as the National Teacher of the Year, is a five-time winner of the Coretta Scott King Literary Awards, and is a New York Times bestselling writer. Tears of a Tiger has received many awards. It was one of the top 100 books for young adults.\n",
            "She was chosen as Ohio's Outstanding High School Language Arts Educator, Ohio Teacher of the Year, and as a NCNW Excellence in Teaching Award winner.\n",
            "She is a Milken Family Foundation National Educator Award winner.\n",
            "She is a YWCA Career Woman of Achievement, and is the recipient  if the Dean's Award from Howard University School of Education.\n",
            "5 years ago she was named Ohio Pioneer in Education by the Ohio State Department of Education, and received the Beacon of Light Humanitarian Award, as well as the Doctor of Laws Degree from Pepperdine University.\n",
            "She has been honored at the White House six times, and was chosen as one of only four writers in the country to speak at National Book Festival Gala in Washington, D.C. Her book Copper Sun has been chosen by the US State Department and the International Reading Association as the United States novel for the international reading project. Students in the US, Nigeria, and Ghana are reading the book and sharing the ideas.\n",
            "She has worked all over the United States, as well as in Russia, Ghana, Togo, Kenya, Ethiopia, Bermuda, and Guam, spreading the word about the power of successful teaching and excellence in education.\n",
            "She became known when she won first prize in a literary  competition. She was given $5000 and her short story, One Small Torch, came out. Besides her short stories, poems, articles can often be read in literary journals . Her books are also very popular in America, too. Here are some:\n",
            "We Beat the Street (Dutton, 2005)\n",
            "Copper Sun (Simon and Schuster, 2006)\n",
            "Fire from the Rock (Dutton, 2007)\n",
            "Just Another Hero (Simon and Schuster, 2009)\n",
            "Out of my Mind (Simon and Schuster, 2010)\n",
            "\n",
            "Question: The passage is mainly about   _  .\n",
            "A. Draper's achievements\n",
            "B. Draper's experience\n",
            "C. Draper's character\n",
            "D. Draper's effort\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5909\n",
            "Current Mean Accuracy: 0.5909\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1185302734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.188232421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Music is an important part in our life. We may feel boring without music. Today when you go to stores, stations, restaurants and other places, do you notice music playing at any of these places? The answer must be \"Yes\". And you might even hear music in an office or on a farm.\n",
            "I like many kinds of music. Classical music is great. Rock music is fast. Light music is relaxing. But I like folk music best. It sounds very beautiful. It can bring me into the dream land. It can make me relax and forget all the problems. It makes me learn better and helps me to be more active. It is true that I learn better when I am relaxed.\n",
            "Music can also influence  people's behavior . Classical music makes people feel rich . When a restaurant plays classical music, people spend more money on food and drinks. When the restaurant plays modern music, people spend less money. Without music, people spend evenless. Restaurants can make more money in this way.\n",
            "\n",
            "Question: Which type of music below can make the writer relax?\n",
            "A. Light music.\n",
            "B. Folk music.\n",
            "C. Rock music.\n",
            "D. Pop music.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.57080078125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 12333\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
            "\n",
            "Question: Which of the following is NOT right?\n",
            "A. The elephants and lions are playing soccer.\n",
            "B. Some pandas are watching the soccer game.\n",
            "C. A dolphin and a penguin are swimming in the pool.\n",
            "D. A giraffe is eating apples under the trees\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5870\n",
            "Current Mean Accuracy: 0.5870\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0675048828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Kinsale may be one of the smallest towns in Southern Ireland, and it's also one of the most famous towns. It is well known for its wonderful fish restaurants. Some of the best known chiefs in the world have practiced in the restaurants there. The town itself is very beautiful in Southern Ireland by the sea. Here it is cooler in summer than other island towns. A big building overlooks the town and it is one of the most beautiful in the whole country. To the north of the town there is a high mountain standing in the country. The town is very beautiful, with its many craft shops and narrow cobbled streets. Most travelers visit Kinsale for its fish restaurants, which are family owned. This means that the service is better than that in other restaurants. People are more welcoming there than those anywhere else. The food may be expensive but you'll have one of the most pleasant evenings in your life there. So go ahead and visit Kinsale.\n",
            "\n",
            "Question: The food in the restaurants may be   _  .\n",
            "A. cheap\n",
            "B. expensive\n",
            "C. salty\n",
            "D. spicy\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5957\n",
            "Current Mean Accuracy: 0.5957\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 21938\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.303466796875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.096923828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Most People don't like mice, but they love one mouse -- Mickey Mouse. In their mind, this mouse is their favourite animal. About 70 years ago, an American man called Walt Disney created  a cartoon mouse for films. He named this mouse Mickey Mouse. From the beginning, Mickey Mouse is a clean mouse. He always does many interesting things. That's why many children and people love him. He makes them happy and _ . In the film, Mickey Mouse also has a lot of friends, for example, Donald Duck and Pluto. Donald can do many things that Mickey cannot. Pluto is a dog. He always does foolish things and makes foolish mistakes. Many children like these cartoon animals, but they like Mickey most because the mouse is a star of beauty and wisdom .\n",
            "\n",
            "Question: Many children and people like Mickey Mouse because  _  .\n",
            "A. He never makes mistakes\n",
            "B. He is like a real mouse.\n",
            "C. He always does many interesting things\n",
            "D. He has many friends.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6042\n",
            "Current Mean Accuracy: 0.6042\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.56494140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.779296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: October is getting closer and it also means that the year of 2014 is coming to an end. \"Hooray! It's a holiday!\" While you are thinking of putting textbooks aside and playing video games, let's take a look at what children in other continents usually do during their holidays.\n",
            "Children in America don't have much homework to do. They keep themselves busy by playing camp games. A parent says, \"My daughter Shirley usually attends different camps. We don't ask her to spend plenty of time on maths problems or spelling tests.\"\n",
            "Children in Australia take partin activities on over twenty different themes  . They learn painting, dancing, singing, history, culture and so on. Parents can _ their kids to enjoy the learning process and to build a closer relationship with them.\n",
            "These are what African kids do: build a boat, have a camel race, make a drum and make a rag   football. Don't you think it is interesting that kids in other places have no idea how to make a drum, but kids in Africa do?\n",
            "Plan your holiday well and try what you want to try. Make a good plan and you will have a lot of fun.\n",
            "\n",
            "Question: What is the purpose of this passage?\n",
            "A. To advise kids to make holiday plans.\n",
            "B. To introduce some good holiday camps.\n",
            "C. To encourage kids to make friends with parents.\n",
            "D. To show the importance of doing homework during holidays.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  A\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5918\n",
            "Current Mean Accuracy: 0.5918\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85156\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.324951171875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
            "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
            "\n",
            "Question: There are   _   classrooms in Betty's school?\n",
            "A. 12\n",
            "B. 14\n",
            "C. 24\n",
            "D. 34\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.6000\n",
            "Current Mean Accuracy: 0.6000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7373046875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 35386\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Mr. Yang is a doctor. He cares a lot about not only others' health but also his own. He controls( )his weight carefully. To him, _ is the most important thing to do if one wants to enjoy good health.\n",
            "Mr. Yang controls his weight in two ways: exercising and not eating much. As a doctor. Mr. Yang is too busy to go to the gym. He exercises by getting off the bus one or two stops early and walking the rest of the way to his office.\n",
            "Besides, he doesn't eat much. Mr. Yang has a special habit. When he buys a belt, he asks the salesperson to punch a hole in the belt at 90cm from the buckle end of the belt, so that he ca always remind  himself. He will stop eating if he feels the belt a little too tight . Mr. Yang thinks exercising doesn't work as well as eating less.\n",
            "\n",
            "Question: Which of the following is true?\n",
            "A. Mr. Yang takes exercise at the gym.\n",
            "B. Mr. Yang walks all the way to work.\n",
            "C. Mr. Yang uses a belt to control how much he eats.\n",
            "D. Mr. Yang thinks exercising is better than eating less in controlling wight.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  C\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5882\n",
            "Current Mean Accuracy: 0.5882\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.96337890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 15144\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Tony, 18. a member of an anti-tobacco group, he says, \"Kids feel that everyone around them smokes.\" Tony wants kids to realize that most people don't smoke. He also wants to tell them that smoking doesn't make one look cool. Two national studies show that teenage smoking is down. Still, there is work to be done.\n",
            "Smoking is an unhealthy habit. It can cause heart disease, lung cancer and other serious illnesses. Just being around cigarette smoke can make you sick.\n",
            "In the 1990s, all 50 states went to court to fight tobacco companies. The states won money from the companies. It helps to pay for anti-smoking groups, but the money is not enough.\n",
            "Each day, about 4,000 kids light up for the first time. \"We have to do a better job of stopping kids from smoking,\" says Husten. Ads that tell ugly facts about smoking help to change minds. Setting smoke-free areas in public places works too. Just this month, a California town _ smoking in all public places, such as schools, shopping malls and libraries. It may be bad news for smokers. Health experts say that they will fight until all Americans get the message.\n",
            ",.\n",
            "\n",
            "Question: The states use the money that they won from tobacco companies to  _  .\n",
            "A. pay for anti-smoking programs\n",
            "B. sell more cigarettes\n",
            "C. win more court cases\n",
            "D. build more schools\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5962\n",
            "Current Mean Accuracy: 0.5962\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3876953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello! My name is Kitty. I want to talk about my home town today.\n",
            "My home town is small but pretty. It's about two hours away from London by train. In the centre of the town there is a small lake. There are lots of trees and flowers around the lake. My parents often walk around the lake at the weekend. The air in my home town is very fresh   and clean.\n",
            "There are two schools in my home town, one primary school and one secondary school. I study in the secondary school and my younger sister studies in the primary school. I often ride my bike to school.\n",
            "I usually go to the youth centre to learn drawing with my sister on Friday afternoons. I like going shopping at the weekend. There are two big shopping malls there.[:Zxxk.Com]\n",
            "\n",
            "Question: There is  _  in the centre of the town.\n",
            "A. a primary school\n",
            "B. a secondary school\n",
            "C. a small lake\n",
            "D. a shopping mall\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5849\n",
            "Current Mean Accuracy: 0.5849\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.325927734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: On February 9 th,2013,Sarah Darling was walking along the street when she met a homeless man named Billy Ray Harris.She reached into her change purse,emptied out all the coins she had and gave them to the homeless man.Neither of them realized that this small generous act would change their lives.\n",
            "Sarah didn't realize that she had given Billy not only all her change but also her diamond ring that she had put in her change purse earlier until the following morning.She and her husband,Bill Krejci,rushed to see if they could find Billy.The homeless man was not only in the same place,he also immediately returned the ring.The grateful couple paid him back for his honesty by emptying out their pockets of all the money they had.\n",
            "Bill Krejci,a web designer,felt that he needed to do something more for this amazingly\n",
            "honest man.So on February 18th,he set up a special page to raise money for him.In just four days,Billy received over $ 85,000 and there seems to be no end yet.\n",
            "That is not enough.Billy is 1iving with a person who is generous instead of living in the streets.And that's not all--thanks to the news report,he got together again with his older brother,Edwin Harris who he had been unable to find for 27 years.\n",
            "All the good luck is just because Billy did the right thing--returning something that did not belong to him.\n",
            "\n",
            "Question: When did Sarah realize that she had also given Billy her diamond ring?\n",
            "A. On February 9 th,2013.\n",
            "B. On February 10th,2013.\n",
            "C. On February 18th,2013.\n",
            "D. On February 22nd,2013.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5741\n",
            "Current Mean Accuracy: 0.5741\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Joe, an outgoing girl, is from a rich family. Therefore she can afford almost everything. But Joe's parents are too busy to spend enough time with her, which makes Joe more than lonely. So, she always goes to WeChat. On WeChat, she can do a lot of things like buying things, reading articles, and making friends with those she either knows or not.\n",
            "She uses the name Linda on WeChat and has made a lot of friends there. Last year Joe made a foreign friend on WeChat. Her name was Catherine and she lived in Sydney. Catherine once sent a picture of \"herself\": a tall, good-looking young woman with big eyes. Catherine and Joe were both interested in rock music and modern dance. So, they liked each other very much.\n",
            "When Joe's father told her that he was meeting a client in Sydney this summer, she went with him to give Catherine a surprise for her birthday. When Joe came to Catherine's house in Sydney, she found that her foreign \"girlfriend\" was a ten-year-old boy named Jim! What a surprise!\n",
            "\n",
            "Question: What is the real name of Joe's \"girlfriend\"?\n",
            "A. Catherine\n",
            "B. Joe\n",
            "C. Jim\n",
            "D. Linda\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5636\n",
            "Current Mean Accuracy: 0.5636\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.67626953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: More and more parents leave their homes and come into the big cities to make money. But their children can't go with them because their children have to go to school in their hometown. They are called home-left children. The problems of home-left children become more and more serious. And it becomes a big _ of our society. The main problem is that some home-left children become very lonely when they don't have their parents' love. And they are too young to tell right or wrong in many things. So they are fooled very easily by others.\n",
            "Xiao Mei , a 14-year-old girl, is a home-left child. Her parents are both in Shanghai. She is in her hometown with her grandpa. She likes playing games on the Internet. Her parents and grandpa only give her money and food. They hardly ever care for her studies. One day, she had no money to pay for the games in the Net bar. So she stole some money from her neighbor. Just at that time, Xiao Fang, a 9-year-old girl saw it. Xiao Mei was afraid that Xiao Fang would tell others about it. She cut Xiao Fang's throat with a knife, and then she went to school just like nothing happened. Luckily, Xiao Fang was saves by doctors. When she opened her eyes and wrote the fact to the policeman with a pencil, everybody was very surprised. This sad story reminds the parents to care for their children no matter how busy they are.\n",
            "Are you one of the home-left children? What do you need from your parents? Food, money or love? I think most children need love mostly. Let's care for the group together.\n",
            ",A, B, C, D,. 5,2,10\n",
            "\n",
            "Question: What does Xiao Mei only get from her parents?\n",
            "A. Clothes.\n",
            "B. Love.\n",
            "C. Money and food.\n",
            "D. Computers.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5536\n",
            "Current Mean Accuracy: 0.5536\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.68017578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.236083984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Have you heard of EXO? EXO is a Chinese-South Korean boy band with 12 people. They are in two teams: EXO-M and EXO-K. There's even a \"competition\" between the two teams. \"I will not call it a competition. It's always in good fun,\" said Sehun of EXO-K.\n",
            "Here comes the new superstar! His name is Austin Mahone. The 18-year-old is a pop singer in the US. His success story is just like that of Justin Bieber. Last month Mahone's new album The Secret came out. Maybe it's a good chance for us to know more about him and his music.\n",
            "Forget about Super Junior. We now have TFBOYS. TFBOYS is a popular Chinese boy band made up of three members. They are Wang Junkai, 14, Wang Yuan, 13, and Yi Yangqianxi, 13. The boys are all junior middle school students. Their songs are full of positive energy  . In their latest album, they call on teenagers not to be afraid of dreaming big.\n",
            "\n",
            "Question: Austin Mahone's success story is almost the same as   _  .\n",
            "A. TFBOY's\n",
            "B. Justin Bieber's\n",
            "C. EXO's\n",
            "D. Taylor Swift's\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5439\n",
            "Current Mean Accuracy: 0.5439\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.63720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.41943359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
            "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
            "\n",
            "Question: Where is Wendy from?\n",
            "A. China.\n",
            "B. England.\n",
            "C. America.\n",
            "D. Australia.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5517\n",
            "Current Mean Accuracy: 0.5517\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.93798828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When you read an article you will understand and remember it better if you can work out how the writer has put the ideas together.Sometimes a writer puts ideas together by asking questions and then answering them.For example,if the article is about groundhogs ,the set of questions in the writer's head might be:\n",
            "What does a groundhog look like?\n",
            "Where do groundhogs live?\n",
            "What do they eat?...\n",
            "In the article,the author might answer those questions.\n",
            "Sometimes an author writes out her questions in the article.These questions give you signals.They tell you what the author is going to write next.Often an author has a question in her head but she doesn't write it out for you.You have to work out her question for yourself.Here's a sample reading for you to practice this method.\n",
            "Earthworms\n",
            "Do you know how many kinds of earthworms there are?There are about 1800 kinds in the world! They can be brown,purple,green.They can be as small as 3 cm long and as large as 3 m long.\n",
            "The best time to see earthworms is at night,especially a cool,damp night.That's when they come up from their burrows to hunt for food.Earthworms don't like to be in the sun.That's because they breathe through their skin,and they can't breathe if their skin gets too dry.Earthworms must come out of the earth if it rains a lot,because they can't breathe in their flooded burrows.What a dangerous life!\n",
            "Earthworms don't have eyes,so how can they tell when it's dark? They have special places on their skin that are sensitive to light.These spots tell whether it's light or dark.If you shine a flashlight on an earthworm at night,it will quickly disappear into the ground.\n",
            "Earthworms don't have ears either,but they can hear by feeling movements in the earth.If you want to hear like an earthworm,lie on the ground with your fingers in your ears.Then have a friend stamp his or her feet near you.This is how earthworms feel birds and people walking,and moles digging,near them.\n",
            "Earthworms are useful.Farmers and gardeners like having lots of earthworms in their land because the worms help to make better soil when they dig.That digging keeps the soil loose and airy .In one year earthworms can pile up as much as 23,000 kg of castings in an area about the size of a football field.\n",
            "\n",
            "Question: Which question CANNOT be answered in the passage?\n",
            "A. How do earthworms help with gardeners?\n",
            "B. What life are earthworms living with?\n",
            "C. When may people observe earthworms?\n",
            "D. Why can human listen like earthworms?\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5593\n",
            "Current Mean Accuracy: 0.5593\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.51904296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Kate is an American girl. Now she lives in New York with her parents. She lives in a community called Sunny Community. It's on Blue Street. There are five rows  of buildings in the community. Her house is in the first row. She lives on the third floor.\n",
            "There is a post office on Blue Street . Next to it ,there is a bank. Across from the bank ,there is a bookstore. The workers in the bookstore are very friendly to people. Mrs Green works in it. She is Kate's new neighbor. She has a son. His name is Bob. He is in the same class as Kate.\n",
            "Kate thinks the traffic here is very good, because she never meets any accidents here. She loves her community very much.\n",
            "\n",
            "Question: Where does Mrs Green work ?\n",
            "A. In a post office.\n",
            "B. In a bank.\n",
            "C. In a bookstore.\n",
            "D. In a school.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5667\n",
            "Current Mean Accuracy: 0.5667\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 11687\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.58544921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Foreign visitors are often puzzled   in Japan because most streets there don't have names. In Japan, people use _ in their directions instead of street names. For example, the Japanese will say to travelers, \"Go straight down to the corner. Turn left at the big hotel and go pass a fruit market. The post office is across from the bus stop.\"\n",
            "In the countryside of the American Midwest, usually there are not many landmarks. There are no mountains, so the land is very flat  . In many places there are no towns or buildings within miles. Instead of landmarks, people will tell you directions and distance. In Kansas or lowa, for example, people will say, \"Go north two miles. Turn east, and then go another mile.\"\n",
            "People in Los Angeles, California, have no idea of distance on the map: the measure   distance by means of time, not miles. \"How far away is the post office?\" you ask. \"Oh,\" they answer, \"it's about five minutes from here.\" you say, \"Yes, but how many miles away is it?\" They don't know.\n",
            "People in Greece sometimes do not even try to give directions because visitors seldom understand the Greek language. Instead of giving you the direction, a Greek will often say, \"Follow me.\" Then he'll lead you through the streets of the city to the post office.\n",
            "Sometimes a person doesn't know the answer to your question. What happen in this situation? A New Yorker might say, \"sorry, I have no idea.\" But in Yucatan, Mexico, no one answer, \"I don't know.\" They think that it is impolite. They usually give an answer, often a wrong one. A visitor can get lost in Yucatan.\n",
            "One thing will help you everywhere. You might not understand a person's words, by maybe you can understand his body language. He or she will usually turn and then point in the correct direction.\n",
            "\n",
            "Question: What does the passage mainly talk about?\n",
            "A. we needn't carry a map for travel.\n",
            "B. There are not many landmarks in the American Midwest.\n",
            "C. There are different ways to give directions in different parts of the world.\n",
            "D. Americans and Japanese have different body languages when you ask for directions.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5738\n",
            "Current Mean Accuracy: 0.5738\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.70556640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 42946\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.07568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: Adult editors may invite   _   to the meeting to make the paper more popular with kids.\n",
            "A. a college student\n",
            "B. a middle school student\n",
            "C. an adult editor\n",
            "D. a reporter\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  B\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5645\n",
            "Current Mean Accuracy: 0.5645\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.92431640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 98421\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.06842041015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Tom was a farmer. He worked on the farm all day,but sometimes he went to the town market to sell fruit and vegetables. One day, a terrible sound attracted his attention in the town market. He saw a young bull for sale. The bull was white and yellow. It was looking at Tom in fear. Tom walked up and touched its head gently. Just at that time they both seemed to have known each other for a long time. How amazing!Tom bought it at once and called it Amba.\n",
            "From then on , Tom and Amba got on well with each other. But some friends told him that it was dangerous to have such a close relationship with an animal.\n",
            "One afternoon , Tom was walking through the forest with Amba. Suddenly , Amba stopped walking and kept pushing Tom with its head. Tom was very surprised and looked around. There was a big snake in front of him. It was beautiful but poisonous. Quickly Amba stepped on the snake's tail with its foot and at the same time Tom picked up a stick and hit the snake's head heavily. Soon the snake . died.\n",
            "Tom was very grateful for Amba's help. When people heard this, they were shocked at the bull's expression of love for Tom. But for Tom, Amba was not a bull but a member of his family.\n",
            "\n",
            "Question: Which of the following statements is NOT true?\n",
            "A. Tom went to the town market to sell fruit and vegetables.\n",
            "B. Tom's friends thought animals were safe.\n",
            "C. Tom hit the snake's head heavily with a stick.\n",
            "D. For Tom, Amba was a member of his family.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5556\n",
            "Current Mean Accuracy: 0.5556\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53645\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.091064453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 68195\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.962890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: It was very late at night when Sam got off the train . He was tired and wanted to find a hotel to have a rest. He looked around and saw a hotel not far away. There were three floors in it. Then Sam went in.\n",
            "\"How much do I need to pay for a single  room a night?\" Sam asked.\n",
            "\"Well , sir,\"said the girl, \"a single room on the first floor is fifty dollars a night.\"\n",
            "\"What about the one on the second floor?\" asked Sam.\n",
            "\"Forty dollars.\"\n",
            "\"Then how about the one on the third floor?\"\n",
            "\"Thirty dollars.\"\n",
            "Sam picked up his suitcase  and wanted to go out.\n",
            "\"Don't you think our price is reasonable?\" The girl said.\n",
            "\"Yes,\" said Sam. \"Your price is of course _ , but I'm sure your hotel is not high enough.\"\n",
            "\n",
            "Question: How many floors were there in the hotel?\n",
            "A. One\n",
            "B. Two\n",
            "C. Three\n",
            "D. Four\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5625\n",
            "Current Mean Accuracy: 0.5625\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 227\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9638671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 27523\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7041015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: There are   _   people in Mike's family.\n",
            "A. four\n",
            "B. five\n",
            "C. six\n",
            "D. seven\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5538\n",
            "Current Mean Accuracy: 0.5538\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 91591\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1497802734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Autumn is the harvest season. There must be a lot for us to eat !Yes, autumn is a great time for fruit and vegetables. Let's find out about some of the best.\n",
            "Apples: You can eat apples all the year round, but they are better and cheaper in autumn. People say \"An apple a day keeps the doctor away\". Apples have a lot of vitamin C and fiber  in them. They are good for the heart and can make your mouth fresh.\n",
            "Pears: Pears are in season from autumn to mid winter. They have minerals and vitamins C and E in them. They are good for the heart and can keep cancer   away.\n",
            "Pumpkins: Pumpkin is a nice vegetable in autumn. They are rich in beta carotene  , which is turned into vitamin A in our bodies. Pumpkins also have calcium ,iron and vitamin C in them. Eating pumpkins can make us look young.\n",
            "Sweet corn  : Sweet corn is in season near the end of the year. It has minerals in it. It's good for the heart.\n",
            "Autumn weather is cold and dry. Try to eat as much fruit and vegetables as you can. They will make you healthy.\n",
            "\n",
            "Question: _   are /is in rich beta carotene.\n",
            "A. Pumpkins\n",
            "B. Sweet corn\n",
            "C. Apples\n",
            "D. Pears\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5455\n",
            "Current Mean Accuracy: 0.5455\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 45999\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.028564453125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Dan was the doorman of a club in a big city. Every day, thousands of people passed his door, and a lot of them stopped and asked him, \"What's the time, please?\"\n",
            "After a few months, Dan said to himself, \"I'm not going to answer all those stupid people any more. I'm going to buy a big clock and put it on the wall here.\" Then he did so.\n",
            "\"Now people aren't going to stop and ask me the time.\" He thought happily.\n",
            "But after that, a lot of people stopped, looked at the clock and asked Dan, \"Is that clock right?\"\n",
            "\n",
            "Question: What would be the best title for the passage?\n",
            "A. Hardworking Dan\n",
            "B. A Big Clock\n",
            "C. Stupid Question\n",
            "D. Boring People\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5373\n",
            "Current Mean Accuracy: 0.5373\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.77490234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.84765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When you were very young, you liked to play with your friends. Did you find that playtime was always more fun when everyone shared the toys? Everyone got a turn. No one was left out.\n",
            "That's a life lesson that changes as you get older. As you grow up, you begin to understand that others have less than you do - in China and in the world. And that those of us who \"have\" things should help those who \" have less\" than we do. The idea of sharing _ \n",
            "At your age, you can \"share\" with people in need in three ways.\n",
            "1. You can give them a part of your money. Many adults do that regularly.\n",
            "2. You can share items you no longer use, such as clothing and toys. You can pass them onto others who cannot buy them.\n",
            "3. You can help people by giving your time and your energy.\n",
            "The last one is also called volunteering. Volunteering is about giving your time to take part in activities that will help others. Every year, many thousands of volunteers in the world give the most valuable gift of all. They give their time. They give their talent. They give of themselves. And they are enjoying it. Volunteering isn't just about work. It's about fun too.\n",
            ",.\n",
            "\n",
            "Question: What's the best title for this passage?\n",
            "A. Work hard to have more than others.\n",
            "B. Be a volunteer.\n",
            "C. Make your playtime more enjoyable.\n",
            "D. Share your love with others.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5294\n",
            "Current Mean Accuracy: 0.5294\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9599609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 73933\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.95751953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: The largest number of people in a race\n",
            "The biggest race is in San Francisco, the USA. More than 100,000 people run the 12 kilometers in the race. Another famous race is in London every year. This race is longer and harder, it is more than 42 kilometers, but 25,000 people usually finish it. [:Zxxk.Com]\n",
            "The youngest international player\n",
            "The youngest international player in any sport was Jamaica. Her name was Joy Foster. She was the Jamaican table tennis champion   in1958 when she was 8 years old.\n",
            "The strongest superlative  \n",
            "Have you ever tried walking backwards? The world record for walking backwards is 12,875 kilometers. A man from Texas, the USA, walked backwards for 18 months in 1931--1032. Nobody else has ever broken this record  .\n",
            "The most popular sport\n",
            "The popular sport team game in the world is football. People play football in villages, streets and stadiums all over the world. The most famous football competition is the World Cup. It happens every four years, and nearly 2,000,000,000 people watch it on TV. The first Women's World Cup was in 1991.\n",
            "\n",
            "Question: _   walked more than 12,875 kilometers' backwards.\n",
            "A. Few people\n",
            "B. Nobody else\n",
            "C. One man has\n",
            "D. Many people\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5217\n",
            "Current Mean Accuracy: 0.5217\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.431640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.71044921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: English breakfast is a very big meal--eggs, tomatoes, tea, coffee... For many people, lunch is a quick  meal. In cities there are a lot of sandwich  bars . People can buy sandwiches there. Students can have a hot meal at school, but many just take a sandwich, a drink and some fruit from home.\n",
            "\"Tea\" means two things. It is a drink and a meal! Some people have afternoon tea, with sandwiches, cakes and a cup of tea.\n",
            "They usually have dinner quite early , between 6:00 and 8:00(......), and often all the family eat together .\n",
            "People often get take-away  meals--they buy the food outside\n",
            "\n",
            "Question: When they get a take-away meal, they often eat it   _  .\n",
            "A. at home\n",
            "B. in the school\n",
            "C. outside\n",
            "D. in the bars\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5143\n",
            "Current Mean Accuracy: 0.5143\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1690673828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Once upon a time, there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day the feelings were told that the island would sink, so all built boats and left, except Love. Love was the only one who stayed. Love wanted to hold out  until the last possible moment.\n",
            "When the island had almost sunk, Love decided to ask for help.\n",
            "Richness was passing by Love in a big boat. Love said, \"Richness, can you take me with you?\"\n",
            "Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
            "Love decided to ask Vanity  who was also passing by in a beautiful ship.\"Vanity, please help me!\"\n",
            "\"I can't help you, Love. You are all wet and might damage  my boat, \"Vanity answered.\n",
            "Sadness was close by so Love asked, \"Sadness, let me go with you.\"\n",
            "\"Oh...Love, I am so sad that I need to be by myself!\"\n",
            "Happiness passed by Love, too, but she was so happy that she did not even hear when Love called her.\n",
            "Suddenly, there was a voice, \"Come, Love, I will take you.\"It was an elder. So thankful and happy, Love even forgot to ask the elder where they were going. When they arrived at dry land, the elder went her own way. Realizing how much was owed  the elder, Love asked Knowledge, another elder, \"Who helped me?\"\n",
            "\"It was Time, \"Knowledge answered.\n",
            "\"Time?\"asked Love.\"But why did Time help me?\"\n",
            "Knowledge smiled with deep wisdom  and answered, \"Because only Time is able to understand how valuable Love is.\"\n",
            "\n",
            "Question: Which of the following might be the best title of the passage?\n",
            "A. Love and Time\n",
            "B. An Accident\n",
            "C. A sinking island\n",
            "D. Different Feelings\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  D\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5070\n",
            "Current Mean Accuracy: 0.5070\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4892578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.057525634765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: If you won a lottery and had lots of money, what would you do? Most people start by buying themselves things, such as a new car or a bigger TV.\n",
            "Many people who win lots of money may suddenly find that they have a lot of socalled friends. The new friends they make may follow them for their money but they may also leave them when all the money is spent. Besides that, they can't decide what to do with the money, so they try to think what they want. In the end, most people usually decide to save the money.\n",
            "There are some lottery winners who decide to quit their jobs, because they think they have enough money and don't need to work any longer. Some big lottery winners make even bigger changes--they end their marriages. They think that winning a lot of money has suddenly made them more intelligent and more attractive .So they feel that they have to be with a younger or more attractive man or woman.\n",
            "They don't know their new money is just a bit of luck. _ can't change everything.\n",
            "Next time when you buy a lottery ticket, think about what you would like to do and what you wouldn't  like to do with the money if you won.\n",
            "\n",
            "Question: A lottery winner may suddenly find himself with many socalled  friends, probably because   _  .\n",
            "A. he wants to make lots of friends\n",
            "B. he doesn't  know what to do with all the money\n",
            "C. these new friends are usually kind to the lottery winner\n",
            "D. these new friends want the lottery winner to give them some money\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.89013671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8974609375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Do you obey the rules in your school? What do you think of your school rules? Are you allowed to dye   hair? A lot of school rules are similar around the world, but some are different. Some students may enjoy more freedom in some countries. But freedom doesn't mean \"no rules\". Every school has its own rules.\n",
            "There are some rules in Japanese schools. The students are not allowed to dye their hair and are supposed to keep their hair black. They are not allowed to wear earrings either. Almost all schools used to require students to wear school uniforms but now half of the schools require uniforms. The students feel happy to wear all kinds of clothes. The students must get to school on time. If they are late, they cannot get into the school because the school gate is closed. In Japan, students are not allowed to have part-time jobs.\n",
            "American schools have their own rules too. For example, at Morton High School, students are not allowed to choose their own clothes. They must get to school or leave school on time. Food, drinks or snacks shouldn't be taken into the classroom. They must wear sports shoes in PE class. They are supposed to keep quiet on the school bus. In America, the students can have part-time jobs in their free time. (<<>> )\n",
            "\n",
            "Question: Which school rules have changed in some Japanese schools?\n",
            "A. About wearing earrings.\n",
            "B. About uniforms.\n",
            "C. About food and drinks.\n",
            "D. About part-time jobs.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4932\n",
            "Current Mean Accuracy: 0.4932\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.52685546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.685546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: My friends like different clothes. Sue likes red clothes. She is often in a red skirt and red shoes. Mina likes white clothes. She is in a white shirt. Her sister Emma likes to wear a green skirt. She looks nice. David often wears a white cap and black pants. Peter often wears a white coat and black pants.\n",
            ",.\n",
            "\n",
            "Question: What color does Sue like?\n",
            "A. White.\n",
            "B. Red.\n",
            "C. Yellow.\n",
            "D. Green.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 2357\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1507568359375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29667\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9306640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: There is lots of junk  in space .Some of it is from rockets. In 1996, a rocket broke into about 300,000 small pieces. So far, scientists have found over 10,000 man-made pieces flying around in space. Only 6-7%of them are satellites and space probes  . Astronauts also lose small things while working in space. In 1965, during the first American spacewalk , astronaut Edward White lost a glove .For a month, the glove stayed in space, travelling at a speed of 28,000 kilometers per hour .It became the most dangerous piece of clothing for the Earth in history it flew away. Things move very fast in space. If they hit one another, it can be dangerous .A little piece of paint from a satellite once made a hole in a spacecraft window. Last year two US spacecraft dropped some bolts , and scientists on the Earth worried a lot. Luckily the bolts floated  away into space. They couldn't hit the spacecraft.\n",
            ",.\n",
            "\n",
            "Question: The glove in space may travel at a speed of    _    kilometers per hour.\n",
            "A. 300,000\n",
            "B. 28,000\n",
            "C. 10,000\n",
            "D. 21,000\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5067\n",
            "Current Mean Accuracy: 0.5067\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 71166\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.083740234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: \"You know, these cups brings to my mind a story I heard,\" Mary said to her students.\n",
            "She poured some tea. There were four of them and there were four completely different cups on the tables.\n",
            "\"I heard there was a teacher who took all his students for tea. His students were surprised that all the cups on the table were different. They all took a cup and started drinking their tea, each looking at the cups of others. The teacher said, \"Did you notice your behavior? You are all looking at each other's tea cup and some of you even envy the finer cups of others.\"\n",
            "\"I put the different cups here on purpose. I want to say life is like this tea. You all have the same thing in your cups----tea. And yet you cannot truly enjoy it in your envy of another's cup. You forget to enjoy your own life when you envy someone else's life. We all have the same thing----life. We should care more about the tastes of your own life. So now, taste your own tea. Does it matter from which cup it came from?\" Mary finished telling her story and her students all sat in silence for a while, enjoying their tea. And it really did not matter a bit from which teacup they drank.\n",
            "\n",
            "Question: What should we learn from the story?\n",
            "A. Envy others and make progress.\n",
            "B. All the lives are the same.\n",
            "C. Work hard and catch up with others.\n",
            "D. Try to enjoy your own life.\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5132\n",
            "Current Mean Accuracy: 0.5132\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 39530\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: If you think you are too shy and want to be a little outgoing, try the following. You can make it.\n",
            "Tell people you are shy. Just let people know that you are a shy kid. When they know that, they'll understand you better. This also helps you feel more at home when talking with others.\n",
            "Try to smile more. People think you are friendly and easy to talk to. Remember that most of us would like to talk to friendly people and we will stay away from an angry-looking face.\n",
            "Talk to others first. If you find it hard to do, say something nice about people around you. Think about how great you feel when someone says something nice to you. Doesn't it make you want to keep talking to those people?\n",
            "Turn your attention to somewhere else. Think more about ways to enjoy the party or the game. Don't worry about your looks or care if people like you.\n",
            "Reward  yourself. Each time after you say \"hi\" or smile at someone for the first time , say to yourself \"You did it!\" or buy yourself an ice cream.\n",
            "Keep trying and one day you won't be shy any more when you talk to others.\n",
            "\n",
            "Question: Which of the following is NOT true?\n",
            "A. People can understand you better when they know you are shy.\n",
            "B. Most people don't like to talk to those people with angry faces.\n",
            "C. Don't care what you look like at the party or the game.\n",
            "D. Each time after you smile at someone for the first time, you should buy yourself an ice cream.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5065\n",
            "Current Mean Accuracy: 0.5065\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.89013671875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 47830\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.85009765625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Many people think sports are just for winning and honor, but there is a lot more you can gain from (get out of) them. I have learned over the past years that sometimes when I lose, I get a lot more out of it than winning. Also, I find a lot of times in sports, people are getting too caught up in the game instead of just having fun. The real purpose of sports is to have fun and learn life lessons along the way.\n",
            "I greatly encourage you to be a part of the school sports. Even if you are not the best, you can still have fun. Sports give people a great and healthy way of spending an afternoon, instead of lying around playing video games or even getting into bad things. Sports also give us a sense of achievement. There isn't a better feeling than to have done something fun and productive for my day.\n",
            "I think that we all need sports to give us courage. If we try hard in sports, we usually do well. If we did the same in study, we would all be champions. Another reason why I encourage you to play sports is that it's just fun. Without sports, our lives would just be boring. So as you may be able to tell, sports are amazing!\n",
            "Our coaches not only teach us to play sports, but show class and good sportsmanship while playing them. It's never fun when you lose to have the competitor rub it in your face. That's why our coaches teach us to show class when we lose; also, when coaches _ , don't get down. They only want to see you improve and learn from what they say. When you do badly and they don't shout loudly is when you should start worrying because they are giving up on you.\n",
            "Overall, sports are great! They bring out the best and worst of a lot of us. However, we can' t let sports get too serious to where it brings down all the fun. So to have the most fun in sports, you just need try your best and not worry so much about the winning or losing.\n",
            "\n",
            "Question: Which of the following statements is TRUE according to the passage?\n",
            "A. Sports bring us great fun only if we have the talent.\n",
            "B. Sports give us the best way of spending free time.\n",
            "C. We can get more out of winning than losing.\n",
            "D. We should take pleasure in doing sports.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 50858\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.3642578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: On May 1, a wildfire started in a forest near the Alberta town of Fort McMurray in Canada. Within two days, the fire grew larger and the people who lived in Fort McMurray had to leave their homes. While there have been very few people injured   by the large fire itself, it has been harmful to the community.\n",
            "Canadians in other places have been helping by sending money and _ to the Red Cross. Many people in Alberta have taken in people from Fort McMurray, letting them stay in their homes for free until the fire is put out. Many firefighters are needed to fight the fire and some of them have come from other parts of Canada to help. The brave firefighters were able to save 25,000 homes as well as the hospital and all of the town's schools, according to CBC news.\n",
            "There have been thousands of other acts of kindness towards the people of Fort McMurray. Some musicians, such as Great Big Sea's Alan Doyle, are holding special concerts, with the money going to Fort McMurray people. And companies have been helping, as well. Beer-maker Labatt filled thousands of cans with water--instead of beer--and sent them to the people in Fort McMurray.\n",
            "The fire is huge, spreading over more than 229,000 hectares  , but firefighters say they believe they are starting to get it under control--it is becoming smaller instead of spreading.\n",
            "\n",
            "Question: How many people have been injured by the large fire itself?\n",
            "A. 25,000.\n",
            "B. Very few.\n",
            "C. 229,000.\n",
            "D. Many.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4937\n",
            "Current Mean Accuracy: 0.4937\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 85460\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.83544921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
            "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
            "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
            "\n",
            "Question: The writer thinks many people don't live near the north or south pole because  _  .\n",
            "A. they can't get enough food there\n",
            "B. the natural sights there don't arrract people\n",
            "C. the unpleasant weather keeps them away\n",
            "D. the length of nighttime keeps them away\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Mr. and Mrs. Green lived in a big city. One summer they went to the country for their holiday. They enjoyed it very much because it was a quiet, clean place.\n",
            "One day they went for a walk early in the morning and met an old man. He lived on a farm, and he was sitting in the warm sun in front of his house. Mr. Green asked him, \"Do you like to live in this quiet place?\"\n",
            "The old man said, \"Yes, I do.\"\n",
            "Mr. Green then asked, \"What are the good things about it?\"\n",
            "The old man answered, \"Well, the people here know each other. They often come and visit me, and I often go and visit them. And there are also many children here.\" Mr. Green said, \"That's interesting, and what are the bad things?\"\n",
            "The old man thought for a moment and then said, \"Well, the same things, really.\"\n",
            "\n",
            "Question: The old man sometimes liked the people to   _  , but sometimes he didn't.\n",
            "A. ask him questions\n",
            "B. keep the place quiet and clean\n",
            "C. come and visit him\n",
            "D. make interesting things\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  C\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4938\n",
            "Current Mean Accuracy: 0.4938\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7548828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 395\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7158203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Do you know why different animals or pests have their special colours? Colours in them seem to be mainly used to protect themselves.\n",
            "Some birds like eating locusts , but birds cannot easily catch them. Why? It is because locusts change their colurs with the changes of the colours of crops .When crops are green, locusts look green .But as the harvest time comes, locusts change into the same brown colour as crops have .Some other pests whose colours are different from plants are easily found and eaten by others .So they have to hide themselves for lives and appear only at night.\n",
            "If you study the animals' life, you'll find the main use of colours is to protect themselves .Bears, lions and other animals move quietly through forests .They cannot be easily seen by hunters because their colours are much like the trees.\n",
            "Colours are useful not only on the land , but also in the sea .A kind of fish in the sea can give out a kind of black liquid when the fish face danger. The liquid spreads over quickly, so they cannot be found by their enemies and can quickly swim away. That is why they can live safely though they are not strong at all.\n",
            "\n",
            "Question: Bears and lions can keep safe because  _  .\n",
            "A. their colours are much like the trees\n",
            "B. they move quickly\n",
            "C. they are very strong\n",
            "D. they live in forests\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  A\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.85595703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 17465\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: There are several ways you can find out about the countries and places you wish to visit. You can talk to friends who have traveled to the places, you can go and see a colour film about them, or you can read a travel book.\n",
            "It seems that there are three kinds of travel books. The first are those that give a personal, subjective  idea of travels which their writer has got himself. These books can be useful if the writers share their traveling experiences with others. The second kind are those books which give objective  information of things to be done and seen. If _ has written such a book about the facts of a place, then it is more useful. The third kind are those books which are called \"a guide\" to some place or other. If they are good, they will describe and explain the place in detail. Like the first kind , they can be interesting and exciting, but their main purpose is to help the reader plan his travel in the most practical way.\n",
            "Whatever kind of travel book you choose, you must make sure that the book does not describe everything as interesting, exciting or fantastic. You must also keep an open eyes on its date of publication  because travel is very practical matter and many things change quickly in the 21st century. Finally, you should make sure that it's easy to find the useful information for you travel.\n",
            "\n",
            "Question: The date of publication must be noticed because   _  .\n",
            "A. the prices of travel books may be different\n",
            "B. the writers of travel books may be different\n",
            "C. the information in travel books is always the same\n",
            "D. the information in travel books is always changing\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4940\n",
            "Current Mean Accuracy: 0.4940\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 7759\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.313720703125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 127587\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.109619140625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
            "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
            "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
            "She understood that she hadn't worn the hair clip to school at all.\n",
            "\n",
            "Question: Her classmates wanted to know what had happened to the girl because  _\n",
            "A. she didn't tell her classmates about her beautiful hair clip.\n",
            "B. she was always unhappy but that day she was so happy.\n",
            "C. she looked more beautiful wearing the hair clip.\n",
            "D. she wanted to talk to others.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4749\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.33203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 77064\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.4404296875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: When people talk about air pollution, they usually think of smog, acid rain ,and other forms  of outdoor air pollution. But did you know that air pollution also is inside homes, offices, hotels and other buildings?Indoor air pollution is more serious. The air in your home can be 2 to 100 times  more polluted than the air outdoors!In fact, some American doctors say that 50% of illnesses have something to do with polluted indoor air. Indoor air pollution is bad for our health in many ways. Young children and the old often suffer  more from air pollution. People with health problems may also suffer more when the air is polluted. Indoor air pollution can be bad for people's eyes, nose and throat. Air pollution, both indoor and outdoor, can also lead to cancer, heart disease, and even bad for the brain!In the great London fog in 1952, 4,000 people died in a few days because of air pollution!It is said that half a million young kids and women die each year in India because of indoor air pollution!\n",
            "There're many ways to reduce  indoor air pollution. Here are some of them and see if they can help you:\n",
            "Increase outdoor air coming indoors and open your windows for 15 to 30 minutes each day.\n",
            "Turn off all the lights and fans when you don't need them.\n",
            "Share your room with others when the air conditioner is running.\n",
            "Don't smoke and try to stop your family members from smoking. People who smoke are going to have trouble breathing and even die someday. If you're smart, don't ever start.\n",
            "Environment-friendly products, such as water-based paints pollute less and work well.\n",
            "\n",
            "Question: How many ways does the writer talk about to reduce indoor air pollution?\n",
            "A. Four.\n",
            "B. Five.\n",
            "C. Six.\n",
            "D. Seven.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5059\n",
            "Current Mean Accuracy: 0.5059\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.865234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53774\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.53515625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: \"You know, these cups brings to my mind a story I heard,\" Mary said to her students.\n",
            "She poured some tea. There were four of them and there were four completely different cups on the tables.\n",
            "\"I heard there was a teacher who took all his students for tea. His students were surprised that all the cups on the table were different. They all took a cup and started drinking their tea, each looking at the cups of others. The teacher said, \"Did you notice your behavior? You are all looking at each other's tea cup and some of you even envy the finer cups of others.\"\n",
            "\"I put the different cups here on purpose. I want to say life is like this tea. You all have the same thing in your cups----tea. And yet you cannot truly enjoy it in your envy of another's cup. You forget to enjoy your own life when you envy someone else's life. We all have the same thing----life. We should care more about the tastes of your own life. So now, taste your own tea. Does it matter from which cup it came from?\" Mary finished telling her story and her students all sat in silence for a while, enjoying their tea. And it really did not matter a bit from which teacup they drank.\n",
            "\n",
            "Question: Which is the best title for the story?\n",
            "A. More than tea in a cup\n",
            "B. The same cups, the same tea\n",
            "C. The taste of the tea\n",
            "D. Different cups, different tea\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  B\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.08758544921875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 70178\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.81298828125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
            "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
            "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
            "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
            "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
            "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
            "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
            "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
            "\n",
            "Question: The newspaper should not be   _\n",
            "A. simple\n",
            "B. interesting\n",
            "C. difficult\n",
            "D. easy\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4943\n",
            "Current Mean Accuracy: 0.4943\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 53709\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.11865234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: At the age of sixteen, I went on my first volunteer program in West Virginia to repair or build homes for poor families. When we arrived, we discovered that the family we were going to help was living in a trailer that was in poor condition, no bigger than two parking spaces. A group of people had been working on it for two weeks, but every time they finished one problem, another appeared.\n",
            "We soon decided that the only way was to build a new house. It was something unusual because normally our goal was to repair old homes. The family was pleased with their new house that was 20 by 30 feet with three bedrooms, a bath and a kitchen.\n",
            "On Tuesday of that week, I asked the family's three boys, Josh, Eric and Ryan, \"What do you want for your new room?\" Kids in the families we had helped usually wanted toys or posters, so we were surprised when Josh, the oldest boy said, \"We just want beds.\" The boys had never slept in a bed. That night we had a meeting and decided that beds would be the perfect gift. On Thursday night, a few adults in our group drove to the nearest city and bought beds and new bedding.\n",
            "On Friday when we saw the truck coming, we told the family about the surprise. They were very excited.\n",
            "That afternoon, while we were setting up the beds, Eric ran into the house to watch us with wide eyes. As Maggie, a member of our group, put one of the pillows on the bed, Eric asked, \"What is that?\"\n",
            "\"A pillow,\" she replied.\n",
            "\"What do you do with it?\" Eric went on asking.\n",
            "\"When you go to sleep, you put your head on it,\" Maggie answered softly. Tears came to our eyes as she handed Eric the pillow.\n",
            "\"Oh . . . that's soft,\" he said, holding it tightly.\n",
            "Now, when my sister or I start to ask for something that seems very urgent , my dad always asks, \"Do you have a pillow?\" We know exactly what he means.\n",
            "\n",
            "Question: What can we learn from the story?\n",
            "A. The family needed two parking spaces.\n",
            "B. The boys of the family wanted toys and posters.\n",
            "C. The family were excited about the beds and bedding.\n",
            "D. The writer's group made some furniture for the family.\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.5000\n",
            "Current Mean Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 4849\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.05792236328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1097412109375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: One day my wife and I went shopping at  the shop. We took the car as we had a lot of things to buy because my brother and his family were going to spend the weekend with us. We stopped the car in front of the shop. An hour later we came back to the car with a lot of things. Then the trouble started. We could not open the car door.\n",
            "\"Oh, dear,\" said my wife, \"What are you going to do?\"\n",
            "\"Let's ask that policeman,\" I said. The policeman was very kind and glad to help us. A few minutes later he got the door open. Just at that moment an angry man came up and shouted, \"What are you doing with my car?\"\n",
            "We looked at the number of the car and our faces turned very red.\n",
            "\n",
            "Question: How long did they spend in the shop doing their shopping?\n",
            "A. About half an hour.\n",
            "B. A whole morning.\n",
            "C. One hour or so.\n",
            "D. A whole day.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  C\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4944\n",
            "Current Mean Accuracy: 0.4944\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29667\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.8642578125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Hello! My name is Amy.I'm from the USA.I'm in Beijing Sunshine Secondary School.I have some good penfriends.They are Mike, Mary and Wang Hao.\n",
            "Mike is from the USA.He is fourteen years old.He lives with his parents and his two sisters in New York.He likes Chinese music very much.\n",
            "Mary is from England.There are four people in her family--her parents, her brother and Mary.Mary's mother is an English teacher and her father is a doctor.Mary's brother, Jim, is a student.\n",
            "Wang Hao is a Chinese boy.He is from Jiangsu, China.But now he is in Beijing with his parents.He often visits his grandparents with his sister at the weekend.\n",
            "\n",
            "Question: Wang Hao is in   _   now.\n",
            "A. England\n",
            "B. the USA\n",
            "C. Jiangsu\n",
            "D. Beijing\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4889\n",
            "Current Mean Accuracy: 0.4889\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.9072265625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.67431640625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
            "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
            "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
            "\n",
            "Question: Why does Victory work so hard? Because   _  .\n",
            "A. he is very strong\n",
            "B. he likes his work very much\n",
            "C. he is helping his parents\n",
            "D. he is saving up to buy a house\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  D\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4835\n",
            "Current Mean Accuracy: 0.4835\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.77490234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 34486\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: The word, \"photography\", was first used in 1839. It comes from the Greek words that mean \"to write with light\". But photography could only give people _ pictures. So scientists were trying hard to find ways to make pictures that can move. They made lots of experiments, but failed again and again. It was Eadweard Muybridge who finally succeeded. He was the first photographer to try this successfully. But how did he make it? It was an interesting story.\n",
            "Back in 1872, people didn't know exactly whether all four of a horse's hooves   left the ground at the same time when it was running. A gentleman called Leland Stanford made a bet with his friend about it. Most people believed that a horse always had one hoof on the ground, or it would fall over. But Stanford didn't think so.\n",
            "At that time, it was hard to know who could win the bet, because a horse's legs move so fast that it is impossible to tell just by looking. So they needed a way to record the movement of a running horse. Then Stanford offered $25,000 to the famous photographer, Muybridge, to help find the answer. In the beginning, Muybridge failed to get clear images, but he didn't give up. He continued to improve his cameras. In 1878, after many experiments, he managed to get a sequence   of 12 photos. One of them clearly showed that all four of the horse's hooves were off the ground at the same time. And when the photos moved fast, people could see a horse running.\n",
            "Though is usually considered as the person who created the first movie in 1889, it was the work of Eadweard Muybridge and the bet that led to Edison's invention.\n",
            "\n",
            "Question: The passage mainly tells us   _  .\n",
            "A. that Thomas Edison created the first movie .\n",
            "B. that Eadweard Muybridge created the first static pictures\n",
            "C. how photography helped people know more about animals\n",
            "D. how Eadweard Muybridge got pictures of motion   successfully\n",
            "Answer:\n",
            "Predicted: D\n",
            "Expected:  D\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4891\n",
            "Current Mean Accuracy: 0.4891\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 25417\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.2861328125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Music education hasn't changed much since the 1970s. Students are still taught to read notation so they can recite compositions that they would never listen to on their MP3 players or play with friends. Playing music enriches life. The question is: Why do schools teach music in a way that _ so many young people rather than catch their imagination? Can we do a better job of using the power of music to get kids excited about school?\n",
            "The experience of an organization called Little Kids Rock suggests the answer is yes -- if we change the way music is taught. Little Kids Rock has helped music programs in over a thousand public schools and served 150,000 children. The organization has given 30,000 free instruments out, mainly guitars, and trained 1,500 teachers to run music classes in which students quickly experience the joys of playing their favorite songs, performing in bands , and writing their own music.\n",
            "The key to Little Kids Rock is that it teaches children to play music the way many musicians learn to play it -- not by notation, but by listening, imitation and meaningful experimentation. \"The knowledge you need to get started playing rock music is very limited,\" explains Dave Wish, the founder of Little Kids Rock. \"In high school, my friend Paul taught me a couple of chords and my life was changed forever. On the first day of class, Little Kids Rock teachers place guitars in the hands of their students and get them practicing chords that will enable them to play thousands of songs. The kids decide what songs they want to learn and the class is off and running. Their progress is surprising. Within a year, eight and nine-year-olds are playing musical instruments, and giving concerts, even performing their own songs.\n",
            "One of the biggest advantages that music offers is the ability to encourage students who are otherwise bored by school. \"I've had students start coming back to school because of this program,\" said Adkison Thomas, who heads up music for the Dallas Independent School District. He added, \"One of the best things is that the teachers discover a new side of their students. They see kids become successful who weren't before.\"\n",
            "\n",
            "Question: What does the writer want to tell us?\n",
            "A. Learning music is a good way to become successful.\n",
            "B. Teaching in a proper way does good to students' development.\n",
            "C. It's necessary for students to practice a lot in learning music.\n",
            "D. It's important for teachers to discover the new sides of students.\n",
            "Answer:\n",
            "Predicted: A\n",
            "Expected:  B\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4839\n",
            "Current Mean Accuracy: 0.4839\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 120685\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1766357421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04571533203125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Children in England mustn't work until they are 13. They need to have a work permit   to start working.\n",
            "The jobs teenagers can do\n",
            "Delivering   newspapers\n",
            "Many teenagers will get up early to deliver newspapers to houses in their local area before going to school. They are known as Paper-boys or Papergirls.\n",
            "Babysitting: Looking after young children in their home while their parents have gone out for the evening is a popular job for teenagers, as they get money for watching children and television all at the same time!\n",
            "Helping the Milkman: From the age of 14 some teenagers help the milkman deliver milk to houses.\n",
            "Other popular jobs : Working in a shop; Office work; Washing cars ; In a cafe or restaurant. The hours teenagers (13 and 14 year olds )can work:\n",
            "School Days\n",
            "Not more than 2 hours in one day during the following periods:\n",
            "Morning 7 a. m. --start of school or Evening\n",
            "close of school-- 7 p. m.\n",
            "Saturdays: Up to 5 hours between 7 a.m. and 7 p.m.\n",
            "Sundays\n",
            "Up to 2 hours between 7 a.m. and 11 a. m.\n",
            "Term time\n",
            "Up to 12 hours a week (Including weekends)\n",
            "\n",
            "Question: Teenagers in England can do all of the following except   _   .\n",
            "A. work in an office\n",
            "B. work in a night club\n",
            "C. look after young children\n",
            "D. deliver newspapers\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4894\n",
            "Current Mean Accuracy: 0.4894\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 37689\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0565185546875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Are you always unwilling to do housework and cleaning for no reason? Well, you will be happy today. Today is No Housework Day. It's time to forget about housework and be relaxed.\n",
            "No Housework Day is always on April 7th. It is your chance to do anything, except housework. Better still, have someone else do housework for a day. Housework is a daily and endless job and most people think it's boring to do housework. I have many friends and their wish is to stay away from housework. In fact, their wish can never come true.\n",
            "Do you know how to celebrate No Housework Day? Well , there are two different ways.\n",
            "If you usually do the housework around the house, forget it on this day. Instead, kick back and enjoy the day. Relax and do anything, except housework.\n",
            "If you never do housework, you can do it for your family. It gives your parents a break from the housework. And, you just might get a chance to know how much housework your parents need to do every day.\n",
            "\n",
            "Question: The writer has many friends and their wish is   _  .\n",
            "A. not to do any housework any more\n",
            "B. to ask others to do their housework\n",
            "C. to celebrate No Housework Day\n",
            "D. to ask all the family members to do housework\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  A\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4842\n",
            "Current Mean Accuracy: 0.4842\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.7587890625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 29667\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0157623291015625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
            "\n",
            "Question: Andy and Jim think the tall man is   _   .\n",
            "A. an actor\n",
            "B. a thief\n",
            "C. a policeman\n",
            "D. the short man's friend.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  B\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4896\n",
            "Current Mean Accuracy: 0.4896\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 1.0\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.19677734375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Plants are very important living things. Life could not go on if there were no plants. This is because plants can make food from air, water and sunlight. Animals and man cannot make food from air, water and sunlight. Animals get their food by eating plants and other animals. Therefore animals and man need plants in order to live. This is why we find that there are so many plants around us.\n",
            "If you look carefully at the plants around you, you will find that there are two kinds of plants: flowering plants and non-flowering  plants.\n",
            "Flowering plants can make seeds . The seeds are protected by the fruits. Some fruits have one seed, some have two, three or four, and some have many seeds. But a few fruits have no seeds at all. An example of a fruit without seeds is the banana fruit.\n",
            "Most non-flowering plants do not grow from seeds. They grow from spores . Spores are very, very small. Some spores are so small and light that they can float in the air. We may say that spores are quite the same as seeds. When these spores fall on wet and shady  places, they usually grow into new plants.\n",
            "\n",
            "Question: This passage is most likely to be taken from   _  .\n",
            "A. a story book\n",
            "B. a novel\n",
            "C. a science magazine\n",
            "D. a laboratory report\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4948\n",
            "Current Mean Accuracy: 0.4948\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 75675\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.1688232421875\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 22073\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.0504150390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: This is a special class. The students come from different countries. Some come from America. Others come from Canada, Japan, Australia and England. They speak different languages,but all of them can speak English. They are good friends. They study together, play together and live together. They help each other. All the teachers of this class are Chinese, but they can speak English. They are very kind and friendly. They work hard. The students in this class study Chinese cooking and Chinese gongfu.\n",
            "All the students like China. They say China is a great country and the Chinese people are very friendly. And they are happy in China.\n",
            ",.\n",
            "\n",
            "Question: What kind of class is this?\n",
            "A. A Chinese cooking class\n",
            "B. A Chinese gongfu class\n",
            "C. A foreign language class\n",
            "D. Both A and B\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  D\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4898\n",
            "Current Mean Accuracy: 0.4898\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 20328\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.615234375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 67324\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.900390625\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: We have twenty minutes' break time after the second class in the morning.  Look!  Most of us are playing during the break time. Some students are on the playground . They are playing basketball. Oh! A boy is running with the ball.  And another is stopping  him. They look so cool. And there are some girls watching the game. Some students are in the classroom. They are talking.  A few of them are reading and doing homework. Look! A girl is looking at the birds in the tree in front of the classroom. She must be thinking of something interesting because she is smiling .\n",
            "What are the teachers doing? Some of them are working in the office. And some are talking with students. Everyone is doing his or her things, busy but happy!\n",
            "\n",
            "Question: The passage is mainly about   _   .\n",
            "A. students\n",
            "B. a basketball game\n",
            "C. break time activities\n",
            "D. teachers\n",
            "Answer:\n",
            "Predicted: C\n",
            "Expected:  C\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "Current Exact Match Accuracy: 0.4949\n",
            "Current Mean Accuracy: 0.4949\n",
            "--------------------------------------------------\n",
            "Type:  <class 'data.EvaluationExample'>\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 46525\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.04833984375\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "\n",
            "[DEBUG] Speculation Step 0\n",
            "  Draft Output Token: 99688\n",
            "  Verified Probability: 0.0\n",
            "  Draft Probability: 0.489501953125\n",
            "\n",
            "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
            "\n",
            "[SUMMARY] Zero-Division Cases Encountered: 0\n",
            "Input: Article: Before I left to meet Lynne, my friend told me that I had better take some money, but I didn't listen to him. I thought that Lynne would pay because she invited me.\n",
            "I arrived at the restaurant on time because I knew Americans like to be on time. Lynne and I sat at a table near the door and soon we began to enjoy ourselves there.\n",
            "The food there was very delicious. I talked a lot about Saudi Arabia and Lynne told me all about herself. After two hours the waiter came and asked if we wanted one check  or two. Lynne said two. Lynne paid her check, and the waiter gave me mine, I had no money. Then I had an idea, I called my friend. In a few minutes he arrived with some money. He laughed at me all the way home.\n",
            "Now, I think it's funny, but I guess you can understand how I felt at that time. So when you visit a foreign country, you have to learn their language and culture.\n",
            "\n",
            "Question: After the meal,  _  ,\n",
            "A. Lynne paid only for herself\n",
            "B. Lynne paid for both of us.\n",
            "C. I would like to pay for myself\n",
            "D. I paid for both of us.\n",
            "Answer:\n",
            "Predicted: B\n",
            "Expected:  A\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "Current Exact Match Accuracy: 0.4900\n",
            "Current Mean Accuracy: 0.4900\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (RACE_H) ---\n",
            "Final Exact Match Accuracy: 0.4900\n",
            "Final Mean Accuracy: 0.4900\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.49000000953674316, 'accuracy': 0.49}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.2417721152305603}, 'time_per_token': {'mean': 0.2417721152305603}, 'tokens_per_second': {'mean': 4.388556629419327}}\n",
            "Valid formats: ['chat_format', 'cnn_dm_summarization', 'cnn_dm_lm', 'xsum_summarization', 'human_eval', 'custom_jsonl', 'top_v2', 'mmlu', 'race_m', 'race_h']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking RACE_H:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   1%|          | 1/100 [00:01<02:23,  1.44s/it]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   2%|▏         | 2/100 [00:01<01:10,  1.40it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   3%|▎         | 3/100 [00:01<00:47,  2.05it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   4%|▍         | 4/100 [00:02<00:36,  2.65it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   5%|▌         | 5/100 [00:02<00:29,  3.23it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   6%|▌         | 6/100 [00:02<00:25,  3.67it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   7%|▋         | 7/100 [00:02<00:22,  4.10it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   8%|▊         | 8/100 [00:02<00:21,  4.18it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:   9%|▉         | 9/100 [00:03<00:21,  4.30it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  10%|█         | 10/100 [00:03<00:20,  4.48it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  11%|█         | 11/100 [00:03<00:18,  4.75it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  12%|█▏        | 12/100 [00:03<00:18,  4.86it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  13%|█▎        | 13/100 [00:03<00:17,  4.89it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  14%|█▍        | 14/100 [00:04<00:17,  4.89it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  15%|█▌        | 15/100 [00:04<00:16,  5.06it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  16%|█▌        | 16/100 [00:04<00:17,  4.81it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  17%|█▋        | 17/100 [00:04<00:16,  5.01it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  18%|█▊        | 18/100 [00:04<00:16,  4.96it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  19%|█▉        | 19/100 [00:05<00:16,  4.85it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  20%|██        | 20/100 [00:05<00:16,  4.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  21%|██        | 21/100 [00:05<00:17,  4.51it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  22%|██▏       | 22/100 [00:05<00:17,  4.36it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  23%|██▎       | 23/100 [00:06<00:17,  4.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  24%|██▍       | 24/100 [00:06<00:16,  4.52it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  25%|██▌       | 25/100 [00:06<00:16,  4.67it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  26%|██▌       | 26/100 [00:06<00:16,  4.50it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  27%|██▋       | 27/100 [00:06<00:16,  4.49it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  28%|██▊       | 28/100 [00:07<00:15,  4.53it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  29%|██▉       | 29/100 [00:07<00:17,  4.09it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  30%|███       | 30/100 [00:07<00:16,  4.12it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  31%|███       | 31/100 [00:07<00:16,  4.19it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  32%|███▏      | 32/100 [00:08<00:15,  4.25it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  33%|███▎      | 33/100 [00:08<00:16,  4.14it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  34%|███▍      | 34/100 [00:08<00:18,  3.62it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  35%|███▌      | 35/100 [00:08<00:17,  3.73it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  36%|███▌      | 36/100 [00:09<00:17,  3.67it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  37%|███▋      | 37/100 [00:09<00:16,  3.83it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  38%|███▊      | 38/100 [00:09<00:15,  3.95it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  39%|███▉      | 39/100 [00:09<00:14,  4.16it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  40%|████      | 40/100 [00:10<00:13,  4.31it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  41%|████      | 41/100 [00:10<00:13,  4.45it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  42%|████▏     | 42/100 [00:10<00:13,  4.46it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  43%|████▎     | 43/100 [00:10<00:12,  4.57it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  44%|████▍     | 44/100 [00:11<00:12,  4.32it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  45%|████▌     | 45/100 [00:11<00:12,  4.49it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  46%|████▌     | 46/100 [00:11<00:12,  4.32it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  47%|████▋     | 47/100 [00:11<00:12,  4.15it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  48%|████▊     | 48/100 [00:11<00:12,  4.29it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  49%|████▉     | 49/100 [00:12<00:11,  4.35it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  50%|█████     | 50/100 [00:12<00:11,  4.50it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  51%|█████     | 51/100 [00:12<00:10,  4.48it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  52%|█████▏    | 52/100 [00:12<00:11,  4.20it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  53%|█████▎    | 53/100 [00:13<00:11,  4.18it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  54%|█████▍    | 54/100 [00:13<00:10,  4.32it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  55%|█████▌    | 55/100 [00:13<00:10,  4.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  56%|█████▌    | 56/100 [00:13<00:09,  4.41it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  57%|█████▋    | 57/100 [00:14<00:10,  4.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  58%|█████▊    | 58/100 [00:14<00:10,  3.95it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  59%|█████▉    | 59/100 [00:14<00:11,  3.57it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  60%|██████    | 60/100 [00:14<00:10,  3.78it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  61%|██████    | 61/100 [00:15<00:10,  3.76it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  62%|██████▏   | 62/100 [00:15<00:09,  3.95it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  63%|██████▎   | 63/100 [00:15<00:09,  4.06it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  64%|██████▍   | 64/100 [00:15<00:08,  4.14it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  65%|██████▌   | 65/100 [00:16<00:08,  4.31it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  66%|██████▌   | 66/100 [00:16<00:08,  4.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  67%|██████▋   | 67/100 [00:16<00:08,  4.09it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  68%|██████▊   | 68/100 [00:16<00:08,  3.98it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  69%|██████▉   | 69/100 [00:17<00:07,  3.90it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  70%|███████   | 70/100 [00:17<00:07,  4.10it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  71%|███████   | 71/100 [00:17<00:07,  3.95it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  72%|███████▏  | 72/100 [00:17<00:07,  3.79it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  73%|███████▎  | 73/100 [00:18<00:06,  3.86it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  74%|███████▍  | 74/100 [00:18<00:06,  4.04it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  75%|███████▌  | 75/100 [00:18<00:05,  4.18it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  76%|███████▌  | 76/100 [00:18<00:05,  4.32it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  77%|███████▋  | 77/100 [00:19<00:05,  4.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  78%|███████▊  | 78/100 [00:19<00:05,  4.07it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  79%|███████▉  | 79/100 [00:19<00:04,  4.24it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  80%|████████  | 80/100 [00:19<00:04,  4.44it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  81%|████████  | 81/100 [00:19<00:04,  4.43it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  82%|████████▏ | 82/100 [00:20<00:03,  4.56it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  83%|████████▎ | 83/100 [00:20<00:03,  4.68it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  84%|████████▍ | 84/100 [00:20<00:03,  4.71it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  85%|████████▌ | 85/100 [00:20<00:03,  4.51it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  86%|████████▌ | 86/100 [00:21<00:03,  4.58it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  87%|████████▋ | 87/100 [00:21<00:02,  4.41it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  88%|████████▊ | 88/100 [00:21<00:02,  4.11it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  89%|████████▉ | 89/100 [00:21<00:02,  4.16it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  90%|█████████ | 90/100 [00:22<00:02,  4.34it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  91%|█████████ | 91/100 [00:22<00:02,  4.34it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  92%|█████████▏| 92/100 [00:22<00:01,  4.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  93%|█████████▎| 93/100 [00:22<00:01,  4.02it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  94%|█████████▍| 94/100 [00:23<00:01,  4.21it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  95%|█████████▌| 95/100 [00:23<00:01,  4.03it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  96%|█████████▌| 96/100 [00:23<00:00,  4.18it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  97%|█████████▋| 97/100 [00:23<00:00,  4.16it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  98%|█████████▊| 98/100 [00:23<00:00,  4.36it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H:  99%|█████████▉| 99/100 [00:24<00:00,  4.41it/s]WARNING:root:No calls to update() have been made - returning 0.0\n",
            "\n",
            "Benchmarking RACE_H: 100%|██████████| 100/100 [00:24<00:00,  4.55it/s]\n",
            "Benchmarking RACE_H: 100%|██████████| 100/100 [00:24<00:00,  4.10it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset race_h \\\n",
        "       --num_samples 100 \\\n",
        "       --generation_strategy self_speculative \\\n",
        "       --output_dir ./logs \\\n",
        "       --exit_layer 8 \\\n",
        "       --num_speculations 6 \\\n",
        "       --distributed False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9fbbSXdhbMI"
      },
      "source": [
        "## Baseline Results\n",
        "\n",
        "! torchrun benchmark.py --model facebook/layerskip-llama3.2-1B \\\n",
        "    --dataset cnn_dm_summarization \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy self_speculative \\\n",
        "    --exit_layer 8 \\\n",
        "    --num_speculations 6 \\\n",
        "    --output_dir ./logs\n",
        "\n",
        "{'predicted_text': {'rouge-l': 0.09527777880430222, 'rouge-1': 0.1348915547132492, 'rouge-2': 0.05371306464076042, 'rouge-3': 0.027781713753938675, 'bleu_score': 0.0, 'exact_match': 2145.550048828125}, 'acceptance_rate': {'mean': 0.7760123947262764}, 'total_time': {'mean': 11.370401830673218}, 'time_per_token': {'mean': 0.02220781607553363}, 'tokens_per_second': {'mean': 46.37881397247315}}\n",
        "\n",
        "<br/>\n",
        "\n",
        "--- Final Metrics (RACE_H) ---\n",
        "Final Exact Match Accuracy: 0.2800\n",
        "Final Mean Accuracy: 0.2800\n",
        "Total Questions: 100\n",
        "{'predicted_text': {'exact_match': 0.2800000011920929, 'accuracy': 0.28}, 'acceptance_rate': {'mean': 0.4039061892032623}, 'total_time': {'mean': 0.756118540763855}, 'time_per_token': {'mean': 0.03780592691153288}, 'tokens_per_second': {'mean': 28.28859375}}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: mmlu\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on MMLU with 100 samples...\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Error during generation: 'NoneType' object has no attribute 'shape'\n",
            "Extracted: prediction=None, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (MMLU) ---\n",
            "exact_match: 0.0000\n",
            "accuracy: 0.0000\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.0, 'accuracy': 0.0}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.0}, 'time_per_token': {'mean': 0.0}, 'tokens_per_second': {'mean': 0.0}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "\n",
            "Benchmarking MMLU:   1%|          | 1/100 [00:00<00:35,  2.78it/s]\n",
            "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:00<00:00, 260.47it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:00<00:00, 214.19it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        }
      ],
      "source": [
        "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "    --dataset mmlu \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy depth_adaptive_token \\\n",
        "    --halting_threshold 0.99 \\\n",
        "    --min_layers 4 \\\n",
        "    --max_layers 32 \\\n",
        "    --exit_layer 8 \\\n",
        "    --num_speculations 6 \\\n",
        "    --output_dir ./logs \\\n",
        "    --distributed False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: mmlu\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on MMLU with 100 samples...\n",
            "Layer 4/16: Halt prob: 0.1820, Accumulated: 0.1820, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0904, Accumulated: 0.2724, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0632, Accumulated: 0.3356, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0405, Accumulated: 0.3761, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0343, Accumulated: 0.4104, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0439, Accumulated: 0.4542, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0531, Accumulated: 0.5073, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1060, Accumulated: 0.6134, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1333, Accumulated: 0.7466, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1109, Accumulated: 0.8576, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0773, Accumulated: 0.9348, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0152, Accumulated: 0.0152, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0126, Accumulated: 0.0277, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0148, Accumulated: 0.0426, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0153, Accumulated: 0.0579, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0129, Accumulated: 0.0708, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0074, Accumulated: 0.0782, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0240, Accumulated: 0.1022, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0297, Accumulated: 0.1320, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0341, Accumulated: 0.1661, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8286, Accumulated: 0.9947, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2434, Accumulated: 0.2434, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.1040, Accumulated: 0.3474, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0723, Accumulated: 0.4197, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0576, Accumulated: 0.4773, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0463, Accumulated: 0.5235, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0454, Accumulated: 0.5689, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0417, Accumulated: 0.6106, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0609, Accumulated: 0.6716, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0790, Accumulated: 0.7506, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0865, Accumulated: 0.8371, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0776, Accumulated: 0.9147, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0175, Accumulated: 0.0175, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0114, Accumulated: 0.0289, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0158, Accumulated: 0.0447, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0138, Accumulated: 0.0585, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0196, Accumulated: 0.0781, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0136, Accumulated: 0.0917, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0357, Accumulated: 0.1275, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0861, Accumulated: 0.2135, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0963, Accumulated: 0.3098, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6831, Accumulated: 0.9929, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1768, Accumulated: 0.1768, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0702, Accumulated: 0.2470, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0294, Accumulated: 0.2763, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0251, Accumulated: 0.3015, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0171, Accumulated: 0.3185, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0192, Accumulated: 0.3378, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0358, Accumulated: 0.3735, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0838, Accumulated: 0.4574, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1400, Accumulated: 0.5974, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1350, Accumulated: 0.7323, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1233, Accumulated: 0.8557, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0962, Accumulated: 0.9519, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0170, Accumulated: 0.0170, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0074, Accumulated: 0.0245, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0155, Accumulated: 0.0400, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0302, Accumulated: 0.0702, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0078, Accumulated: 0.0781, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0143, Accumulated: 0.0924, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0070, Accumulated: 0.0994, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0340, Accumulated: 0.1334, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0193, Accumulated: 0.1527, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7993, Accumulated: 0.9520, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1069, Accumulated: 0.1069, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0585, Accumulated: 0.1655, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0174, Accumulated: 0.1829, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0166, Accumulated: 0.1996, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0167, Accumulated: 0.2163, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0231, Accumulated: 0.2394, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0224, Accumulated: 0.2618, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0604, Accumulated: 0.3222, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1154, Accumulated: 0.4376, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1374, Accumulated: 0.5751, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1642, Accumulated: 0.7393, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1514, Accumulated: 0.8906, Threshold: 0.9000\n",
            "Layer 4/16: Halt prob: 0.0085, Accumulated: 0.0085, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0102, Accumulated: 0.0187, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0113, Accumulated: 0.0300, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0438, Accumulated: 0.0737, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0131, Accumulated: 0.0868, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.1008, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0121, Accumulated: 0.1129, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1576, Accumulated: 0.2704, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0954, Accumulated: 0.3658, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6221, Accumulated: 0.9879, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2274, Accumulated: 0.2274, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0851, Accumulated: 0.3125, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0564, Accumulated: 0.3689, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0304, Accumulated: 0.3993, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0249, Accumulated: 0.4242, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0357, Accumulated: 0.4599, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0445, Accumulated: 0.5044, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1070, Accumulated: 0.6115, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1371, Accumulated: 0.7485, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1153, Accumulated: 0.8638, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0804, Accumulated: 0.9442, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0115, Accumulated: 0.0115, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0420, Accumulated: 0.0535, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0076, Accumulated: 0.0610, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0125, Accumulated: 0.0735, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0105, Accumulated: 0.0840, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0294, Accumulated: 0.1133, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0210, Accumulated: 0.1344, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1012, Accumulated: 0.2356, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.2268, Accumulated: 0.4623, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5361, Accumulated: 0.9984, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1356, Accumulated: 0.1356, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0582, Accumulated: 0.1939, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0331, Accumulated: 0.2270, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0311, Accumulated: 0.2581, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0233, Accumulated: 0.2814, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0314, Accumulated: 0.3128, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0379, Accumulated: 0.3507, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0976, Accumulated: 0.4483, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1362, Accumulated: 0.5846, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1547, Accumulated: 0.7392, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1341, Accumulated: 0.8733, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0797, Accumulated: 0.9530, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0119, Accumulated: 0.0119, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0344, Accumulated: 0.0463, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0088, Accumulated: 0.0551, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0084, Accumulated: 0.0635, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0062, Accumulated: 0.0698, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0083, Accumulated: 0.0781, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0061, Accumulated: 0.0842, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0704, Accumulated: 0.1546, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1179, Accumulated: 0.2724, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7251, Accumulated: 0.9975, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0526, Accumulated: 0.0526, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0296, Accumulated: 0.0821, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0163, Accumulated: 0.0985, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0179, Accumulated: 0.1164, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0143, Accumulated: 0.1307, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0186, Accumulated: 0.1493, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0234, Accumulated: 0.1727, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0798, Accumulated: 0.2525, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0556, Accumulated: 0.3081, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1008, Accumulated: 0.4089, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1927, Accumulated: 0.6015, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.2471, Accumulated: 0.8486, Threshold: 0.9000\n",
            "Layer 4/16: Halt prob: 0.0180, Accumulated: 0.0180, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0122, Accumulated: 0.0302, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0256, Accumulated: 0.0558, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0231, Accumulated: 0.0788, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0089, Accumulated: 0.0878, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0433, Accumulated: 0.1310, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0122, Accumulated: 0.1432, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0332, Accumulated: 0.1764, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0220, Accumulated: 0.1984, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7883, Accumulated: 0.9867, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2006, Accumulated: 0.2006, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0791, Accumulated: 0.2797, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0489, Accumulated: 0.3286, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0403, Accumulated: 0.3689, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0303, Accumulated: 0.3992, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0345, Accumulated: 0.4337, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0586, Accumulated: 0.4922, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0999, Accumulated: 0.5921, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1330, Accumulated: 0.7252, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1174, Accumulated: 0.8426, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0857, Accumulated: 0.9283, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0254, Accumulated: 0.0254, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0206, Accumulated: 0.0460, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0063, Accumulated: 0.0523, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0138, Accumulated: 0.0661, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0047, Accumulated: 0.0708, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0087, Accumulated: 0.0795, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0100, Accumulated: 0.0895, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0175, Accumulated: 0.1071, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0248, Accumulated: 0.1319, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8626, Accumulated: 0.9945, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1727, Accumulated: 0.1727, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0899, Accumulated: 0.2626, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0505, Accumulated: 0.3131, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0370, Accumulated: 0.3502, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0302, Accumulated: 0.3803, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0357, Accumulated: 0.4160, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0407, Accumulated: 0.4567, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1000, Accumulated: 0.5566, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1169, Accumulated: 0.6735, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1231, Accumulated: 0.7966, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1150, Accumulated: 0.9116, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0088, Accumulated: 0.0088, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0210, Accumulated: 0.0298, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0168, Accumulated: 0.0466, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0311, Accumulated: 0.0777, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0155, Accumulated: 0.0932, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0065, Accumulated: 0.0997, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0419, Accumulated: 0.1416, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0107, Accumulated: 0.1522, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0153, Accumulated: 0.1676, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8255, Accumulated: 0.9931, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1526, Accumulated: 0.1526, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0705, Accumulated: 0.2231, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0347, Accumulated: 0.2578, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0323, Accumulated: 0.2901, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0197, Accumulated: 0.3098, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0231, Accumulated: 0.3330, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0254, Accumulated: 0.3584, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0530, Accumulated: 0.4114, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0903, Accumulated: 0.5017, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1357, Accumulated: 0.6373, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1613, Accumulated: 0.7987, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1216, Accumulated: 0.9203, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0136, Accumulated: 0.0136, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0076, Accumulated: 0.0212, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0083, Accumulated: 0.0296, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0413, Accumulated: 0.0709, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0048, Accumulated: 0.0757, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0129, Accumulated: 0.0886, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0259, Accumulated: 0.1145, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.6036, Accumulated: 0.7181, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1090, Accumulated: 0.8271, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1720, Accumulated: 0.9991, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1877, Accumulated: 0.1877, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0712, Accumulated: 0.2589, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0443, Accumulated: 0.3032, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0381, Accumulated: 0.3413, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0353, Accumulated: 0.3767, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0385, Accumulated: 0.4151, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0493, Accumulated: 0.4644, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0962, Accumulated: 0.5606, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1280, Accumulated: 0.6886, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1192, Accumulated: 0.8078, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1025, Accumulated: 0.9103, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0220, Accumulated: 0.0220, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0190, Accumulated: 0.0411, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0144, Accumulated: 0.0554, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0060, Accumulated: 0.0615, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0113, Accumulated: 0.0727, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0067, Accumulated: 0.0794, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0334, Accumulated: 0.1128, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.2105, Accumulated: 0.3233, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1736, Accumulated: 0.4970, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.4971, Accumulated: 0.9941, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1887, Accumulated: 0.1887, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0825, Accumulated: 0.2712, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0550, Accumulated: 0.3262, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0452, Accumulated: 0.3714, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0402, Accumulated: 0.4116, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0452, Accumulated: 0.4568, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0535, Accumulated: 0.5103, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1008, Accumulated: 0.6111, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1445, Accumulated: 0.7556, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1169, Accumulated: 0.8726, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0674, Accumulated: 0.9400, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0110, Accumulated: 0.0110, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0282, Accumulated: 0.0392, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0233, Accumulated: 0.0624, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0531, Accumulated: 0.1155, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0090, Accumulated: 0.1245, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0156, Accumulated: 0.1401, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.1439, Accumulated: 0.2840, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0425, Accumulated: 0.3266, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0134, Accumulated: 0.3400, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6571, Accumulated: 0.9971, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1750, Accumulated: 0.1750, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0571, Accumulated: 0.2321, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0368, Accumulated: 0.2690, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0220, Accumulated: 0.2910, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0183, Accumulated: 0.3093, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0301, Accumulated: 0.3393, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0463, Accumulated: 0.3856, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0818, Accumulated: 0.4674, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0962, Accumulated: 0.5636, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1408, Accumulated: 0.7045, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1412, Accumulated: 0.8457, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1019, Accumulated: 0.9476, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0272, Accumulated: 0.0272, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0230, Accumulated: 0.0503, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0135, Accumulated: 0.0638, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0043, Accumulated: 0.0681, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0202, Accumulated: 0.0883, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0216, Accumulated: 0.1100, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0254, Accumulated: 0.1354, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0969, Accumulated: 0.2323, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0802, Accumulated: 0.3125, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6703, Accumulated: 0.9829, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1711, Accumulated: 0.1711, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0843, Accumulated: 0.2554, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0573, Accumulated: 0.3127, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0469, Accumulated: 0.3595, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0315, Accumulated: 0.3910, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0310, Accumulated: 0.4220, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0415, Accumulated: 0.4635, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0639, Accumulated: 0.5274, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1059, Accumulated: 0.6333, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0935, Accumulated: 0.7268, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1006, Accumulated: 0.8274, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1010, Accumulated: 0.9285, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0104, Accumulated: 0.0104, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0090, Accumulated: 0.0193, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0097, Accumulated: 0.0291, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0425, Accumulated: 0.0716, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0060, Accumulated: 0.0776, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0115, Accumulated: 0.0891, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0315, Accumulated: 0.1207, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0543, Accumulated: 0.1750, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0584, Accumulated: 0.2333, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7592, Accumulated: 0.9925, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1980, Accumulated: 0.1980, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0752, Accumulated: 0.2732, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0423, Accumulated: 0.3155, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0280, Accumulated: 0.3435, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0277, Accumulated: 0.3712, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0309, Accumulated: 0.4021, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0535, Accumulated: 0.4556, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1107, Accumulated: 0.5663, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1347, Accumulated: 0.7010, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1224, Accumulated: 0.8234, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0994, Accumulated: 0.9228, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0177, Accumulated: 0.0177, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0269, Accumulated: 0.0446, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0257, Accumulated: 0.0702, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0071, Accumulated: 0.0774, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0177, Accumulated: 0.0951, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0059, Accumulated: 0.1010, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0143, Accumulated: 0.1153, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1418, Accumulated: 0.2571, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.2013, Accumulated: 0.4584, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5403, Accumulated: 0.9987, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1725, Accumulated: 0.1725, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0761, Accumulated: 0.2486, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0329, Accumulated: 0.2815, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0298, Accumulated: 0.3113, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0287, Accumulated: 0.3400, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0397, Accumulated: 0.3797, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0569, Accumulated: 0.4367, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0848, Accumulated: 0.5215, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1023, Accumulated: 0.6237, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1154, Accumulated: 0.7391, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1341, Accumulated: 0.8733, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0837, Accumulated: 0.9570, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0138, Accumulated: 0.0138, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0098, Accumulated: 0.0236, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0098, Accumulated: 0.0334, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0546, Accumulated: 0.0880, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0076, Accumulated: 0.0956, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0114, Accumulated: 0.1070, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0111, Accumulated: 0.1181, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0469, Accumulated: 0.1650, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0542, Accumulated: 0.2192, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7690, Accumulated: 0.9882, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1907, Accumulated: 0.1907, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0895, Accumulated: 0.2801, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0438, Accumulated: 0.3240, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0375, Accumulated: 0.3615, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0388, Accumulated: 0.4003, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0419, Accumulated: 0.4422, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0469, Accumulated: 0.4891, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1003, Accumulated: 0.5894, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1340, Accumulated: 0.7234, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1114, Accumulated: 0.8348, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0814, Accumulated: 0.9162, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0150, Accumulated: 0.0150, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0095, Accumulated: 0.0245, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0076, Accumulated: 0.0321, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0130, Accumulated: 0.0451, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0062, Accumulated: 0.0512, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0099, Accumulated: 0.0611, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0110, Accumulated: 0.0722, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0269, Accumulated: 0.0991, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0211, Accumulated: 0.1202, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8682, Accumulated: 0.9884, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1487, Accumulated: 0.1487, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0533, Accumulated: 0.2019, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0346, Accumulated: 0.2365, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0339, Accumulated: 0.2704, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0274, Accumulated: 0.2978, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0378, Accumulated: 0.3356, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0385, Accumulated: 0.3742, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0816, Accumulated: 0.4557, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1014, Accumulated: 0.5571, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1256, Accumulated: 0.6828, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1438, Accumulated: 0.8266, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1067, Accumulated: 0.9333, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0110, Accumulated: 0.0110, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0077, Accumulated: 0.0188, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0071, Accumulated: 0.0259, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0476, Accumulated: 0.0735, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0087, Accumulated: 0.0821, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0499, Accumulated: 0.1320, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0113, Accumulated: 0.1433, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0296, Accumulated: 0.1730, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0586, Accumulated: 0.2315, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7523, Accumulated: 0.9839, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0693, Accumulated: 0.0693, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0318, Accumulated: 0.1012, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0304, Accumulated: 0.1316, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0276, Accumulated: 0.1592, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0237, Accumulated: 0.1829, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0226, Accumulated: 0.2055, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0283, Accumulated: 0.2338, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1068, Accumulated: 0.3406, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0911, Accumulated: 0.4317, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1256, Accumulated: 0.5574, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1719, Accumulated: 0.7293, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1897, Accumulated: 0.9190, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0106, Accumulated: 0.0106, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0214, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0073, Accumulated: 0.0287, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0191, Accumulated: 0.0478, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0044, Accumulated: 0.0521, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0356, Accumulated: 0.0877, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0121, Accumulated: 0.0998, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0551, Accumulated: 0.1549, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0647, Accumulated: 0.2197, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7727, Accumulated: 0.9924, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2135, Accumulated: 0.2135, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0595, Accumulated: 0.2730, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0419, Accumulated: 0.3149, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0308, Accumulated: 0.3457, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0314, Accumulated: 0.3772, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0344, Accumulated: 0.4116, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0436, Accumulated: 0.4552, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0720, Accumulated: 0.5272, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0923, Accumulated: 0.6195, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1269, Accumulated: 0.7464, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1219, Accumulated: 0.8683, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0845, Accumulated: 0.9528, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0115, Accumulated: 0.0115, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0075, Accumulated: 0.0190, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0092, Accumulated: 0.0281, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0346, Accumulated: 0.0627, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0107, Accumulated: 0.0734, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0153, Accumulated: 0.0887, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0116, Accumulated: 0.1003, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1233, Accumulated: 0.2237, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1788, Accumulated: 0.4025, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5949, Accumulated: 0.9974, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2285, Accumulated: 0.2285, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0968, Accumulated: 0.3253, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0524, Accumulated: 0.3777, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0365, Accumulated: 0.4142, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0311, Accumulated: 0.4453, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0360, Accumulated: 0.4813, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0564, Accumulated: 0.5377, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1085, Accumulated: 0.6462, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1349, Accumulated: 0.7811, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1018, Accumulated: 0.8830, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0635, Accumulated: 0.9465, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0107, Accumulated: 0.0107, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0187, Accumulated: 0.0295, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0100, Accumulated: 0.0395, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0183, Accumulated: 0.0578, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0056, Accumulated: 0.0634, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0093, Accumulated: 0.0727, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0501, Accumulated: 0.1228, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0565, Accumulated: 0.1793, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0368, Accumulated: 0.2161, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7758, Accumulated: 0.9920, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2145, Accumulated: 0.2145, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0917, Accumulated: 0.3061, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0522, Accumulated: 0.3584, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0419, Accumulated: 0.4003, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0343, Accumulated: 0.4346, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0392, Accumulated: 0.4738, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0514, Accumulated: 0.5253, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1153, Accumulated: 0.6406, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1308, Accumulated: 0.7714, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1077, Accumulated: 0.8791, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0659, Accumulated: 0.9450, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0122, Accumulated: 0.0122, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0175, Accumulated: 0.0298, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0193, Accumulated: 0.0491, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0599, Accumulated: 0.1090, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0183, Accumulated: 0.1272, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0109, Accumulated: 0.1382, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0196, Accumulated: 0.1578, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0100, Accumulated: 0.1677, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0067, Accumulated: 0.1745, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8122, Accumulated: 0.9867, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0988, Accumulated: 0.0988, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0510, Accumulated: 0.1498, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0401, Accumulated: 0.1898, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0177, Accumulated: 0.2075, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0152, Accumulated: 0.2227, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0283, Accumulated: 0.2510, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0246, Accumulated: 0.2756, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0444, Accumulated: 0.3200, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0911, Accumulated: 0.4111, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1490, Accumulated: 0.5600, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.2196, Accumulated: 0.7796, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1569, Accumulated: 0.9365, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0191, Accumulated: 0.0191, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0118, Accumulated: 0.0309, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0069, Accumulated: 0.0378, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0318, Accumulated: 0.0696, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0087, Accumulated: 0.0783, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0257, Accumulated: 0.1039, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0171, Accumulated: 0.1211, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.7219, Accumulated: 0.8429, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0913, Accumulated: 0.9343, Threshold: 0.9000\n",
            "Early exit at layer 12/16\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1693, Accumulated: 0.1693, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0840, Accumulated: 0.2533, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0559, Accumulated: 0.3092, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0405, Accumulated: 0.3497, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0259, Accumulated: 0.3756, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0435, Accumulated: 0.4192, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0494, Accumulated: 0.4686, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1114, Accumulated: 0.5800, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1487, Accumulated: 0.7287, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1160, Accumulated: 0.8447, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0827, Accumulated: 0.9273, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0197, Accumulated: 0.0197, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0067, Accumulated: 0.0264, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0066, Accumulated: 0.0330, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0194, Accumulated: 0.0524, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0103, Accumulated: 0.0627, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0169, Accumulated: 0.0796, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0362, Accumulated: 0.1158, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0146, Accumulated: 0.1304, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0127, Accumulated: 0.1431, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8393, Accumulated: 0.9824, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1340, Accumulated: 0.1340, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0491, Accumulated: 0.1832, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0454, Accumulated: 0.2286, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0254, Accumulated: 0.2540, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0199, Accumulated: 0.2739, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0306, Accumulated: 0.3045, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0317, Accumulated: 0.3362, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0573, Accumulated: 0.3935, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1193, Accumulated: 0.5128, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1537, Accumulated: 0.6665, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1523, Accumulated: 0.8188, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1083, Accumulated: 0.9271, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0077, Accumulated: 0.0077, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0054, Accumulated: 0.0131, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0103, Accumulated: 0.0234, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0444, Accumulated: 0.0678, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0087, Accumulated: 0.0765, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0114, Accumulated: 0.0878, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0149, Accumulated: 0.1028, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1677, Accumulated: 0.2704, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1030, Accumulated: 0.3735, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6204, Accumulated: 0.9939, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2019, Accumulated: 0.2019, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0664, Accumulated: 0.2683, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0410, Accumulated: 0.3093, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0346, Accumulated: 0.3440, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0285, Accumulated: 0.3724, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0270, Accumulated: 0.3994, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0332, Accumulated: 0.4326, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0789, Accumulated: 0.5115, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1212, Accumulated: 0.6327, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1266, Accumulated: 0.7593, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1139, Accumulated: 0.8732, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0831, Accumulated: 0.9563, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0165, Accumulated: 0.0165, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0072, Accumulated: 0.0237, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0080, Accumulated: 0.0317, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0545, Accumulated: 0.0862, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0052, Accumulated: 0.0913, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0216, Accumulated: 0.1129, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0268, Accumulated: 0.1396, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.2577, Accumulated: 0.3974, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0944, Accumulated: 0.4918, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5048, Accumulated: 0.9965, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1743, Accumulated: 0.1743, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0545, Accumulated: 0.2288, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0295, Accumulated: 0.2584, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0215, Accumulated: 0.2799, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0208, Accumulated: 0.3007, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0273, Accumulated: 0.3280, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0298, Accumulated: 0.3577, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0995, Accumulated: 0.4572, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1292, Accumulated: 0.5864, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1537, Accumulated: 0.7401, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1332, Accumulated: 0.8734, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0806, Accumulated: 0.9540, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0088, Accumulated: 0.0088, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0330, Accumulated: 0.0419, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0061, Accumulated: 0.0480, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0081, Accumulated: 0.0561, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0198, Accumulated: 0.0759, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0301, Accumulated: 0.1061, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0093, Accumulated: 0.1154, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.4306, Accumulated: 0.5461, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.2222, Accumulated: 0.7683, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.2314, Accumulated: 0.9997, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1794, Accumulated: 0.1794, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0550, Accumulated: 0.2345, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0261, Accumulated: 0.2606, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0231, Accumulated: 0.2837, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0218, Accumulated: 0.3055, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0210, Accumulated: 0.3265, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0334, Accumulated: 0.3598, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0688, Accumulated: 0.4287, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1411, Accumulated: 0.5698, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1447, Accumulated: 0.7145, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1415, Accumulated: 0.8560, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0809, Accumulated: 0.9369, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0203, Accumulated: 0.0203, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0266, Accumulated: 0.0469, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0144, Accumulated: 0.0614, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0090, Accumulated: 0.0704, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0087, Accumulated: 0.0790, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0094, Accumulated: 0.0884, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0132, Accumulated: 0.1016, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.4095, Accumulated: 0.5111, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1879, Accumulated: 0.6990, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.3002, Accumulated: 0.9991, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1476, Accumulated: 0.1476, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0627, Accumulated: 0.2103, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0372, Accumulated: 0.2475, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0358, Accumulated: 0.2833, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0250, Accumulated: 0.3083, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0363, Accumulated: 0.3446, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0302, Accumulated: 0.3748, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0980, Accumulated: 0.4728, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1353, Accumulated: 0.6081, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1358, Accumulated: 0.7438, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1188, Accumulated: 0.8627, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0865, Accumulated: 0.9492, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0120, Accumulated: 0.0120, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0100, Accumulated: 0.0220, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0075, Accumulated: 0.0295, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0232, Accumulated: 0.0527, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0056, Accumulated: 0.0583, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0167, Accumulated: 0.0750, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0199, Accumulated: 0.0948, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0946, Accumulated: 0.1894, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0701, Accumulated: 0.2595, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7372, Accumulated: 0.9967, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1860, Accumulated: 0.1860, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0863, Accumulated: 0.2724, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0622, Accumulated: 0.3346, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0569, Accumulated: 0.3915, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0470, Accumulated: 0.4385, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0507, Accumulated: 0.4891, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0556, Accumulated: 0.5447, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1084, Accumulated: 0.6531, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1248, Accumulated: 0.7779, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0976, Accumulated: 0.8756, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0653, Accumulated: 0.9409, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0166, Accumulated: 0.0166, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0096, Accumulated: 0.0263, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0077, Accumulated: 0.0340, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0200, Accumulated: 0.0541, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0057, Accumulated: 0.0597, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0093, Accumulated: 0.0690, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0084, Accumulated: 0.0773, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0189, Accumulated: 0.0963, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0261, Accumulated: 0.1223, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8699, Accumulated: 0.9923, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1088, Accumulated: 0.1088, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0370, Accumulated: 0.1458, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0194, Accumulated: 0.1651, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0170, Accumulated: 0.1821, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0165, Accumulated: 0.1987, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0202, Accumulated: 0.2189, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0233, Accumulated: 0.2422, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0914, Accumulated: 0.3336, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1200, Accumulated: 0.4536, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1595, Accumulated: 0.6131, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1835, Accumulated: 0.7967, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1378, Accumulated: 0.9345, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0174, Accumulated: 0.0174, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0068, Accumulated: 0.0242, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0147, Accumulated: 0.0389, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0653, Accumulated: 0.1042, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0120, Accumulated: 0.1162, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0082, Accumulated: 0.1244, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0158, Accumulated: 0.1403, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0296, Accumulated: 0.1699, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0258, Accumulated: 0.1957, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7627, Accumulated: 0.9584, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1554, Accumulated: 0.1554, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0959, Accumulated: 0.2513, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0730, Accumulated: 0.3243, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0541, Accumulated: 0.3785, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0415, Accumulated: 0.4200, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0505, Accumulated: 0.4705, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0432, Accumulated: 0.5137, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0774, Accumulated: 0.5911, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1140, Accumulated: 0.7051, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1019, Accumulated: 0.8071, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1001, Accumulated: 0.9072, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0146, Accumulated: 0.0146, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0103, Accumulated: 0.0249, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0154, Accumulated: 0.0403, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0609, Accumulated: 0.1012, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0047, Accumulated: 0.1059, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0115, Accumulated: 0.1173, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0194, Accumulated: 0.1367, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1413, Accumulated: 0.2781, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0533, Accumulated: 0.3314, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6347, Accumulated: 0.9660, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2020, Accumulated: 0.2020, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0934, Accumulated: 0.2954, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0639, Accumulated: 0.3593, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0534, Accumulated: 0.4127, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0413, Accumulated: 0.4540, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0460, Accumulated: 0.5000, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0487, Accumulated: 0.5488, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0907, Accumulated: 0.6395, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1142, Accumulated: 0.7537, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0896, Accumulated: 0.8434, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0766, Accumulated: 0.9200, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0137, Accumulated: 0.0137, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0270, Accumulated: 0.0406, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0138, Accumulated: 0.0544, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0311, Accumulated: 0.0856, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0223, Accumulated: 0.1079, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0091, Accumulated: 0.1170, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0408, Accumulated: 0.1578, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.2457, Accumulated: 0.4035, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1145, Accumulated: 0.5180, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.4792, Accumulated: 0.9972, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1276, Accumulated: 0.1276, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0527, Accumulated: 0.1803, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0366, Accumulated: 0.2169, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0219, Accumulated: 0.2388, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0195, Accumulated: 0.2584, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0262, Accumulated: 0.2846, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0339, Accumulated: 0.3185, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0648, Accumulated: 0.3833, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1152, Accumulated: 0.4985, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1425, Accumulated: 0.6410, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1561, Accumulated: 0.7971, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1294, Accumulated: 0.9265, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0097, Accumulated: 0.0097, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0106, Accumulated: 0.0203, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0065, Accumulated: 0.0268, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0323, Accumulated: 0.0591, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0156, Accumulated: 0.0747, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0090, Accumulated: 0.0837, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0180, Accumulated: 0.1017, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0163, Accumulated: 0.1179, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0269, Accumulated: 0.1448, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8515, Accumulated: 0.9962, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2205, Accumulated: 0.2205, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0824, Accumulated: 0.3028, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0519, Accumulated: 0.3547, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0550, Accumulated: 0.4097, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0371, Accumulated: 0.4469, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0439, Accumulated: 0.4908, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0515, Accumulated: 0.5423, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0919, Accumulated: 0.6341, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1250, Accumulated: 0.7591, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1058, Accumulated: 0.8648, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0710, Accumulated: 0.9359, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0244, Accumulated: 0.0244, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0141, Accumulated: 0.0385, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0040, Accumulated: 0.0425, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0129, Accumulated: 0.0553, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0088, Accumulated: 0.0642, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0089, Accumulated: 0.0731, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0133, Accumulated: 0.0863, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0168, Accumulated: 0.1031, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0228, Accumulated: 0.1259, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8711, Accumulated: 0.9970, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2111, Accumulated: 0.2111, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0984, Accumulated: 0.3095, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0571, Accumulated: 0.3666, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0441, Accumulated: 0.4107, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0363, Accumulated: 0.4470, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0478, Accumulated: 0.4948, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0488, Accumulated: 0.5437, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0999, Accumulated: 0.6436, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1182, Accumulated: 0.7619, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1035, Accumulated: 0.8653, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0720, Accumulated: 0.9373, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0324, Accumulated: 0.0324, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0133, Accumulated: 0.0457, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0143, Accumulated: 0.0599, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0113, Accumulated: 0.0712, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0081, Accumulated: 0.0793, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0073, Accumulated: 0.0866, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0117, Accumulated: 0.0983, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0446, Accumulated: 0.1429, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0442, Accumulated: 0.1871, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8106, Accumulated: 0.9976, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0991, Accumulated: 0.0991, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0344, Accumulated: 0.1335, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0214, Accumulated: 0.1549, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0190, Accumulated: 0.1739, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0223, Accumulated: 0.1962, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0215, Accumulated: 0.2178, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0410, Accumulated: 0.2588, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0936, Accumulated: 0.3523, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1391, Accumulated: 0.4914, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1568, Accumulated: 0.6482, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.2099, Accumulated: 0.8581, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1053, Accumulated: 0.9634, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0138, Accumulated: 0.0138, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0136, Accumulated: 0.0273, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0066, Accumulated: 0.0339, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0186, Accumulated: 0.0525, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0157, Accumulated: 0.0683, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0330, Accumulated: 0.1013, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0113, Accumulated: 0.1126, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0231, Accumulated: 0.1358, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0065, Accumulated: 0.1422, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8226, Accumulated: 0.9648, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1105, Accumulated: 0.1105, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0445, Accumulated: 0.1550, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0256, Accumulated: 0.1806, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0253, Accumulated: 0.2059, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0215, Accumulated: 0.2274, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0240, Accumulated: 0.2514, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0516, Accumulated: 0.3030, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1325, Accumulated: 0.4355, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1295, Accumulated: 0.5650, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1412, Accumulated: 0.7061, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1491, Accumulated: 0.8552, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0913, Accumulated: 0.9465, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0162, Accumulated: 0.0162, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0245, Accumulated: 0.0406, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0110, Accumulated: 0.0517, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0094, Accumulated: 0.0611, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0116, Accumulated: 0.0727, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0112, Accumulated: 0.0839, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0084, Accumulated: 0.0923, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0243, Accumulated: 0.1165, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0147, Accumulated: 0.1312, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8391, Accumulated: 0.9703, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1907, Accumulated: 0.1907, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0943, Accumulated: 0.2850, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0645, Accumulated: 0.3495, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0463, Accumulated: 0.3958, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0290, Accumulated: 0.4248, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0343, Accumulated: 0.4591, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0359, Accumulated: 0.4950, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0840, Accumulated: 0.5789, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1312, Accumulated: 0.7101, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1169, Accumulated: 0.8270, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0886, Accumulated: 0.9156, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0132, Accumulated: 0.0132, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0121, Accumulated: 0.0253, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0146, Accumulated: 0.0399, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0214, Accumulated: 0.0613, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0206, Accumulated: 0.0820, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0143, Accumulated: 0.0962, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0350, Accumulated: 0.1312, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0432, Accumulated: 0.1744, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0457, Accumulated: 0.2201, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7723, Accumulated: 0.9924, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1177, Accumulated: 0.1177, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0482, Accumulated: 0.1660, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0490, Accumulated: 0.2150, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0282, Accumulated: 0.2432, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0218, Accumulated: 0.2650, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0287, Accumulated: 0.2937, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0480, Accumulated: 0.3417, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0797, Accumulated: 0.4214, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1155, Accumulated: 0.5369, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1393, Accumulated: 0.6762, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1415, Accumulated: 0.8177, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1043, Accumulated: 0.9220, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0131, Accumulated: 0.0131, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0232, Accumulated: 0.0363, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0116, Accumulated: 0.0478, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0192, Accumulated: 0.0670, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0126, Accumulated: 0.0796, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0117, Accumulated: 0.0914, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0218, Accumulated: 0.1132, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3507, Accumulated: 0.4639, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1510, Accumulated: 0.6150, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.3828, Accumulated: 0.9977, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1969, Accumulated: 0.1969, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0752, Accumulated: 0.2721, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0468, Accumulated: 0.3189, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0406, Accumulated: 0.3596, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0293, Accumulated: 0.3888, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0379, Accumulated: 0.4268, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0417, Accumulated: 0.4684, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0834, Accumulated: 0.5518, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1122, Accumulated: 0.6640, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1152, Accumulated: 0.7791, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1023, Accumulated: 0.8814, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0640, Accumulated: 0.9455, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0138, Accumulated: 0.0138, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0423, Accumulated: 0.0562, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0145, Accumulated: 0.0707, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0138, Accumulated: 0.0845, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0233, Accumulated: 0.1079, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0063, Accumulated: 0.1142, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0134, Accumulated: 0.1276, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3448, Accumulated: 0.4724, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.2400, Accumulated: 0.7124, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.2873, Accumulated: 0.9997, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0944, Accumulated: 0.0944, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0272, Accumulated: 0.1216, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0212, Accumulated: 0.1429, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0154, Accumulated: 0.1582, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0101, Accumulated: 0.1683, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0233, Accumulated: 0.1916, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0319, Accumulated: 0.2236, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0581, Accumulated: 0.2816, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1314, Accumulated: 0.4130, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1509, Accumulated: 0.5639, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.2009, Accumulated: 0.7648, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1591, Accumulated: 0.9239, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0141, Accumulated: 0.0141, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0117, Accumulated: 0.0258, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0082, Accumulated: 0.0340, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0304, Accumulated: 0.0644, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0055, Accumulated: 0.0699, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0252, Accumulated: 0.0952, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0045, Accumulated: 0.0996, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0882, Accumulated: 0.1878, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1276, Accumulated: 0.3154, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6789, Accumulated: 0.9943, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0444, Accumulated: 0.0444, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0268, Accumulated: 0.0712, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0215, Accumulated: 0.0927, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0250, Accumulated: 0.1177, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0179, Accumulated: 0.1356, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0241, Accumulated: 0.1598, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0252, Accumulated: 0.1849, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0493, Accumulated: 0.2342, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0790, Accumulated: 0.3132, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1052, Accumulated: 0.4184, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1807, Accumulated: 0.5992, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.2182, Accumulated: 0.8174, Threshold: 0.9000\n",
            "Layer 4/16: Halt prob: 0.0194, Accumulated: 0.0194, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0096, Accumulated: 0.0290, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0112, Accumulated: 0.0402, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0067, Accumulated: 0.0469, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0086, Accumulated: 0.0556, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0100, Accumulated: 0.0655, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0214, Accumulated: 0.0869, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.4169, Accumulated: 0.5038, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.2937, Accumulated: 0.7974, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.2023, Accumulated: 0.9997, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1503, Accumulated: 0.1503, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0532, Accumulated: 0.2035, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0355, Accumulated: 0.2390, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0331, Accumulated: 0.2721, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0224, Accumulated: 0.2945, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0314, Accumulated: 0.3259, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0368, Accumulated: 0.3627, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1139, Accumulated: 0.4766, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1406, Accumulated: 0.6172, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1471, Accumulated: 0.7643, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1103, Accumulated: 0.8746, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0801, Accumulated: 0.9547, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0138, Accumulated: 0.0138, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0095, Accumulated: 0.0233, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0116, Accumulated: 0.0349, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0329, Accumulated: 0.0678, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0097, Accumulated: 0.0775, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0120, Accumulated: 0.0895, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0088, Accumulated: 0.0983, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0240, Accumulated: 0.1223, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0205, Accumulated: 0.1428, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8510, Accumulated: 0.9937, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1252, Accumulated: 0.1252, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0450, Accumulated: 0.1703, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0354, Accumulated: 0.2057, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0288, Accumulated: 0.2344, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0267, Accumulated: 0.2611, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0344, Accumulated: 0.2955, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0331, Accumulated: 0.3287, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0704, Accumulated: 0.3991, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1149, Accumulated: 0.5139, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1297, Accumulated: 0.6436, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1330, Accumulated: 0.7767, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1297, Accumulated: 0.9063, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0188, Accumulated: 0.0188, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0193, Accumulated: 0.0380, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0227, Accumulated: 0.0607, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0074, Accumulated: 0.0681, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0582, Accumulated: 0.1263, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0134, Accumulated: 0.1397, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0270, Accumulated: 0.1666, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1777, Accumulated: 0.3443, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1586, Accumulated: 0.5030, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.4902, Accumulated: 0.9932, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1372, Accumulated: 0.1372, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0699, Accumulated: 0.2071, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0532, Accumulated: 0.2604, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0446, Accumulated: 0.3050, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0381, Accumulated: 0.3431, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0575, Accumulated: 0.4006, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0727, Accumulated: 0.4733, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1213, Accumulated: 0.5945, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1419, Accumulated: 0.7364, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1228, Accumulated: 0.8592, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0769, Accumulated: 0.9361, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0098, Accumulated: 0.0098, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0086, Accumulated: 0.0184, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0073, Accumulated: 0.0257, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0500, Accumulated: 0.0757, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0053, Accumulated: 0.0809, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0157, Accumulated: 0.0966, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0294, Accumulated: 0.1259, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0367, Accumulated: 0.1626, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0207, Accumulated: 0.1833, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8087, Accumulated: 0.9920, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2040, Accumulated: 0.2040, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0771, Accumulated: 0.2810, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0563, Accumulated: 0.3373, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0561, Accumulated: 0.3934, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0405, Accumulated: 0.4339, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0521, Accumulated: 0.4860, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0426, Accumulated: 0.5287, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0636, Accumulated: 0.5923, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0865, Accumulated: 0.6788, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0884, Accumulated: 0.7673, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0989, Accumulated: 0.8662, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0679, Accumulated: 0.9341, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0115, Accumulated: 0.0115, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0201, Accumulated: 0.0316, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0081, Accumulated: 0.0398, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0234, Accumulated: 0.0631, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0064, Accumulated: 0.0695, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0111, Accumulated: 0.0806, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0300, Accumulated: 0.1107, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1131, Accumulated: 0.2238, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0627, Accumulated: 0.2865, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7086, Accumulated: 0.9951, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2157, Accumulated: 0.2157, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0952, Accumulated: 0.3109, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0580, Accumulated: 0.3688, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0413, Accumulated: 0.4102, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0357, Accumulated: 0.4458, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0411, Accumulated: 0.4869, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0490, Accumulated: 0.5359, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0870, Accumulated: 0.6230, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1163, Accumulated: 0.7392, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0981, Accumulated: 0.8373, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0768, Accumulated: 0.9141, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0075, Accumulated: 0.0075, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0176, Accumulated: 0.0251, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0506, Accumulated: 0.0756, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0215, Accumulated: 0.0971, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0142, Accumulated: 0.1113, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0109, Accumulated: 0.1222, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0261, Accumulated: 0.1482, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0817, Accumulated: 0.2300, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1521, Accumulated: 0.3821, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6158, Accumulated: 0.9979, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1815, Accumulated: 0.1815, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0866, Accumulated: 0.2681, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0465, Accumulated: 0.3146, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0457, Accumulated: 0.3603, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0349, Accumulated: 0.3952, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0435, Accumulated: 0.4387, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0458, Accumulated: 0.4845, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0866, Accumulated: 0.5712, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1371, Accumulated: 0.7083, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1143, Accumulated: 0.8226, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0883, Accumulated: 0.9110, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0121, Accumulated: 0.0121, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0101, Accumulated: 0.0222, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0136, Accumulated: 0.0357, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0176, Accumulated: 0.0533, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0605, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0165, Accumulated: 0.0770, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0135, Accumulated: 0.0905, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0980, Accumulated: 0.1886, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0651, Accumulated: 0.2537, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7438, Accumulated: 0.9974, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1744, Accumulated: 0.1744, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0777, Accumulated: 0.2522, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0392, Accumulated: 0.2914, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0336, Accumulated: 0.3250, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0216, Accumulated: 0.3465, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0321, Accumulated: 0.3786, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0498, Accumulated: 0.4285, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0834, Accumulated: 0.5119, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1373, Accumulated: 0.6492, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1244, Accumulated: 0.7736, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1073, Accumulated: 0.8809, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0750, Accumulated: 0.9559, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0155, Accumulated: 0.0155, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0196, Accumulated: 0.0351, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0172, Accumulated: 0.0523, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0082, Accumulated: 0.0605, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0741, Accumulated: 0.1346, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0087, Accumulated: 0.1433, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0126, Accumulated: 0.1559, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.2286, Accumulated: 0.3844, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1679, Accumulated: 0.5523, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.4427, Accumulated: 0.9950, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1901, Accumulated: 0.1901, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0555, Accumulated: 0.2455, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0561, Accumulated: 0.3017, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0339, Accumulated: 0.3355, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0293, Accumulated: 0.3649, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0333, Accumulated: 0.3982, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0426, Accumulated: 0.4408, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0912, Accumulated: 0.5320, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1258, Accumulated: 0.6578, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1373, Accumulated: 0.7951, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1029, Accumulated: 0.8979, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0591, Accumulated: 0.9570, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0129, Accumulated: 0.0129, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0097, Accumulated: 0.0226, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0129, Accumulated: 0.0355, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0173, Accumulated: 0.0528, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0109, Accumulated: 0.0637, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0227, Accumulated: 0.0864, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0242, Accumulated: 0.1106, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0388, Accumulated: 0.1495, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0295, Accumulated: 0.1789, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7946, Accumulated: 0.9735, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1785, Accumulated: 0.1785, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0745, Accumulated: 0.2529, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0519, Accumulated: 0.3048, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0410, Accumulated: 0.3458, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0307, Accumulated: 0.3765, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0431, Accumulated: 0.4196, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0469, Accumulated: 0.4665, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0981, Accumulated: 0.5646, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1371, Accumulated: 0.7017, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1161, Accumulated: 0.8178, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0910, Accumulated: 0.9088, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0187, Accumulated: 0.0187, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0099, Accumulated: 0.0286, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0083, Accumulated: 0.0369, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0211, Accumulated: 0.0580, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0105, Accumulated: 0.0686, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0102, Accumulated: 0.0787, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0234, Accumulated: 0.1022, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0897, Accumulated: 0.1919, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0638, Accumulated: 0.2557, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7399, Accumulated: 0.9956, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2025, Accumulated: 0.2025, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0912, Accumulated: 0.2937, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0607, Accumulated: 0.3545, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0430, Accumulated: 0.3975, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0299, Accumulated: 0.4274, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0263, Accumulated: 0.4537, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0365, Accumulated: 0.4903, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0895, Accumulated: 0.5797, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1322, Accumulated: 0.7119, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1121, Accumulated: 0.8239, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1026, Accumulated: 0.9265, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0103, Accumulated: 0.0182, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0163, Accumulated: 0.0345, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0429, Accumulated: 0.0774, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0131, Accumulated: 0.0905, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0268, Accumulated: 0.1173, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0144, Accumulated: 0.1317, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0236, Accumulated: 0.1553, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0427, Accumulated: 0.1979, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7978, Accumulated: 0.9957, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0829, Accumulated: 0.0829, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0374, Accumulated: 0.1203, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0205, Accumulated: 0.1408, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0238, Accumulated: 0.1646, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0252, Accumulated: 0.1898, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0223, Accumulated: 0.2120, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0371, Accumulated: 0.2491, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0931, Accumulated: 0.3423, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1539, Accumulated: 0.4962, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1925, Accumulated: 0.6887, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1539, Accumulated: 0.8426, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0989, Accumulated: 0.9415, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0187, Accumulated: 0.0187, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0066, Accumulated: 0.0253, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0059, Accumulated: 0.0312, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0114, Accumulated: 0.0426, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0225, Accumulated: 0.0651, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0093, Accumulated: 0.0744, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0087, Accumulated: 0.0831, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3036, Accumulated: 0.3866, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1071, Accumulated: 0.4938, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5045, Accumulated: 0.9983, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1364, Accumulated: 0.1364, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0572, Accumulated: 0.1936, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0354, Accumulated: 0.2290, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0240, Accumulated: 0.2530, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0195, Accumulated: 0.2725, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0203, Accumulated: 0.2928, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0426, Accumulated: 0.3354, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0853, Accumulated: 0.4208, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1778, Accumulated: 0.5985, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1441, Accumulated: 0.7426, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1254, Accumulated: 0.8680, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0742, Accumulated: 0.9423, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0098, Accumulated: 0.0098, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0348, Accumulated: 0.0446, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0085, Accumulated: 0.0531, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0082, Accumulated: 0.0613, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0071, Accumulated: 0.0683, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0053, Accumulated: 0.0736, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0092, Accumulated: 0.0828, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1230, Accumulated: 0.2059, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1190, Accumulated: 0.3249, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6692, Accumulated: 0.9941, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1600, Accumulated: 0.1600, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0520, Accumulated: 0.2120, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0343, Accumulated: 0.2464, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0300, Accumulated: 0.2763, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0256, Accumulated: 0.3020, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0355, Accumulated: 0.3375, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0328, Accumulated: 0.3703, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1256, Accumulated: 0.4959, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1310, Accumulated: 0.6268, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1175, Accumulated: 0.7444, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1128, Accumulated: 0.8571, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0729, Accumulated: 0.9300, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0145, Accumulated: 0.0145, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0299, Accumulated: 0.0444, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0083, Accumulated: 0.0527, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0123, Accumulated: 0.0650, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.0741, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0103, Accumulated: 0.0844, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0153, Accumulated: 0.0997, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1946, Accumulated: 0.2943, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1286, Accumulated: 0.4229, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5700, Accumulated: 0.9930, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1041, Accumulated: 0.1041, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0550, Accumulated: 0.1590, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0360, Accumulated: 0.1950, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0254, Accumulated: 0.2204, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0178, Accumulated: 0.2383, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0253, Accumulated: 0.2636, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0292, Accumulated: 0.2928, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0900, Accumulated: 0.3828, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1047, Accumulated: 0.4875, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1389, Accumulated: 0.6264, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1855, Accumulated: 0.8119, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1330, Accumulated: 0.9449, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0090, Accumulated: 0.0090, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0076, Accumulated: 0.0166, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0114, Accumulated: 0.0280, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.1128, Accumulated: 0.1408, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0063, Accumulated: 0.1471, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0102, Accumulated: 0.1573, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0309, Accumulated: 0.1882, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0925, Accumulated: 0.2807, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0444, Accumulated: 0.3251, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6640, Accumulated: 0.9891, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1705, Accumulated: 0.1705, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0936, Accumulated: 0.2641, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0513, Accumulated: 0.3154, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0329, Accumulated: 0.3483, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0256, Accumulated: 0.3739, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0305, Accumulated: 0.4044, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0384, Accumulated: 0.4428, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0926, Accumulated: 0.5354, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1516, Accumulated: 0.6871, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1339, Accumulated: 0.8210, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1016, Accumulated: 0.9226, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0093, Accumulated: 0.0093, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0114, Accumulated: 0.0207, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0097, Accumulated: 0.0304, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0631, Accumulated: 0.0935, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0128, Accumulated: 0.1063, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0093, Accumulated: 0.1156, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0267, Accumulated: 0.1423, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0263, Accumulated: 0.1686, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0506, Accumulated: 0.2193, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7754, Accumulated: 0.9947, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1936, Accumulated: 0.1936, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0968, Accumulated: 0.2904, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0596, Accumulated: 0.3500, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0519, Accumulated: 0.4019, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0383, Accumulated: 0.4402, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0443, Accumulated: 0.4846, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0456, Accumulated: 0.5301, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0665, Accumulated: 0.5967, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1049, Accumulated: 0.7015, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0997, Accumulated: 0.8012, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0835, Accumulated: 0.8847, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0637, Accumulated: 0.9484, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0396, Accumulated: 0.0396, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0071, Accumulated: 0.0467, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0069, Accumulated: 0.0537, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0073, Accumulated: 0.0609, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0088, Accumulated: 0.0697, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0067, Accumulated: 0.0764, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0293, Accumulated: 0.1057, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.5279, Accumulated: 0.6337, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1303, Accumulated: 0.7640, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.2351, Accumulated: 0.9991, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1469, Accumulated: 0.1469, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0690, Accumulated: 0.2158, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0389, Accumulated: 0.2548, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0320, Accumulated: 0.2867, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0314, Accumulated: 0.3182, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0447, Accumulated: 0.3629, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0667, Accumulated: 0.4295, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0848, Accumulated: 0.5143, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1054, Accumulated: 0.6196, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1205, Accumulated: 0.7402, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1129, Accumulated: 0.8531, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0851, Accumulated: 0.9382, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0135, Accumulated: 0.0135, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0182, Accumulated: 0.0317, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0262, Accumulated: 0.0579, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0093, Accumulated: 0.0672, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0253, Accumulated: 0.0925, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0086, Accumulated: 0.1011, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0360, Accumulated: 0.1372, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0803, Accumulated: 0.2174, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.2463, Accumulated: 0.4637, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5295, Accumulated: 0.9932, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1434, Accumulated: 0.1434, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0383, Accumulated: 0.1818, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0254, Accumulated: 0.2072, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0206, Accumulated: 0.2277, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0219, Accumulated: 0.2496, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0421, Accumulated: 0.2917, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0434, Accumulated: 0.3351, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0677, Accumulated: 0.4028, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1267, Accumulated: 0.5295, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1435, Accumulated: 0.6730, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1792, Accumulated: 0.8521, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0948, Accumulated: 0.9469, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0242, Accumulated: 0.0242, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0109, Accumulated: 0.0351, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0108, Accumulated: 0.0459, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0087, Accumulated: 0.0546, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0069, Accumulated: 0.0615, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0447, Accumulated: 0.1062, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0209, Accumulated: 0.1271, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0145, Accumulated: 0.1415, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1384, Accumulated: 0.2800, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7137, Accumulated: 0.9937, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0482, Accumulated: 0.0482, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0258, Accumulated: 0.0740, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0152, Accumulated: 0.0892, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0175, Accumulated: 0.1067, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0189, Accumulated: 0.1256, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0234, Accumulated: 0.1490, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0248, Accumulated: 0.1738, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0506, Accumulated: 0.2244, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0830, Accumulated: 0.3073, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.2090, Accumulated: 0.5164, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.2143, Accumulated: 0.7307, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1835, Accumulated: 0.9141, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0156, Accumulated: 0.0156, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0088, Accumulated: 0.0244, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0091, Accumulated: 0.0335, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0303, Accumulated: 0.0638, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0326, Accumulated: 0.0964, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0162, Accumulated: 0.1126, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0198, Accumulated: 0.1323, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3163, Accumulated: 0.4486, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0935, Accumulated: 0.5421, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.4546, Accumulated: 0.9966, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2179, Accumulated: 0.2179, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0752, Accumulated: 0.2931, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0489, Accumulated: 0.3420, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0433, Accumulated: 0.3853, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0309, Accumulated: 0.4162, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0372, Accumulated: 0.4534, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0471, Accumulated: 0.5005, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0959, Accumulated: 0.5964, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1537, Accumulated: 0.7501, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1152, Accumulated: 0.8654, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0759, Accumulated: 0.9413, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0231, Accumulated: 0.0231, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0116, Accumulated: 0.0346, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0064, Accumulated: 0.0410, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0157, Accumulated: 0.0567, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0155, Accumulated: 0.0723, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0115, Accumulated: 0.0838, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0085, Accumulated: 0.0923, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0137, Accumulated: 0.1060, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0405, Accumulated: 0.1465, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8469, Accumulated: 0.9933, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1996, Accumulated: 0.1996, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0715, Accumulated: 0.2711, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0433, Accumulated: 0.3144, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0352, Accumulated: 0.3496, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0330, Accumulated: 0.3826, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0382, Accumulated: 0.4207, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0463, Accumulated: 0.4670, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0991, Accumulated: 0.5661, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1216, Accumulated: 0.6877, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1086, Accumulated: 0.7964, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0929, Accumulated: 0.8893, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0657, Accumulated: 0.9550, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0101, Accumulated: 0.0101, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0067, Accumulated: 0.0168, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0117, Accumulated: 0.0285, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0153, Accumulated: 0.0438, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0101, Accumulated: 0.0539, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0177, Accumulated: 0.0716, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0142, Accumulated: 0.0857, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.4500, Accumulated: 0.5357, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0856, Accumulated: 0.6213, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.3770, Accumulated: 0.9983, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1956, Accumulated: 0.1956, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0694, Accumulated: 0.2649, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0350, Accumulated: 0.3000, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0267, Accumulated: 0.3266, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0237, Accumulated: 0.3503, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0307, Accumulated: 0.3810, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0512, Accumulated: 0.4322, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1191, Accumulated: 0.5512, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1538, Accumulated: 0.7051, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1275, Accumulated: 0.8325, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0898, Accumulated: 0.9223, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0093, Accumulated: 0.0093, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0193, Accumulated: 0.0286, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0129, Accumulated: 0.0415, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0261, Accumulated: 0.0676, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0188, Accumulated: 0.0865, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0125, Accumulated: 0.0989, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0155, Accumulated: 0.1144, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0104, Accumulated: 0.1248, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0171, Accumulated: 0.1419, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8551, Accumulated: 0.9971, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1270, Accumulated: 0.1270, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0623, Accumulated: 0.1892, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0325, Accumulated: 0.2217, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0272, Accumulated: 0.2489, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0184, Accumulated: 0.2673, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0304, Accumulated: 0.2977, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0329, Accumulated: 0.3307, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0793, Accumulated: 0.4100, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1277, Accumulated: 0.5377, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1335, Accumulated: 0.6712, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1416, Accumulated: 0.8128, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1038, Accumulated: 0.9166, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0164, Accumulated: 0.0164, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0081, Accumulated: 0.0244, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0083, Accumulated: 0.0327, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0146, Accumulated: 0.0473, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0053, Accumulated: 0.0526, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0200, Accumulated: 0.0726, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0059, Accumulated: 0.0785, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0094, Accumulated: 0.0879, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0229, Accumulated: 0.1108, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8388, Accumulated: 0.9496, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1418, Accumulated: 0.1418, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0688, Accumulated: 0.2106, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0490, Accumulated: 0.2596, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0347, Accumulated: 0.2943, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0311, Accumulated: 0.3254, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0316, Accumulated: 0.3570, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0439, Accumulated: 0.4008, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1178, Accumulated: 0.5187, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1424, Accumulated: 0.6611, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1354, Accumulated: 0.7965, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1044, Accumulated: 0.9008, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0075, Accumulated: 0.0075, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0120, Accumulated: 0.0195, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0066, Accumulated: 0.0261, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0901, Accumulated: 0.1162, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0212, Accumulated: 0.1374, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0129, Accumulated: 0.1503, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0149, Accumulated: 0.1652, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0068, Accumulated: 0.1720, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0093, Accumulated: 0.1813, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8043, Accumulated: 0.9856, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0816, Accumulated: 0.0816, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0332, Accumulated: 0.1148, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0201, Accumulated: 0.1348, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0188, Accumulated: 0.1536, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0161, Accumulated: 0.1697, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0212, Accumulated: 0.1910, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0438, Accumulated: 0.2348, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0501, Accumulated: 0.2849, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0842, Accumulated: 0.3691, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.2047, Accumulated: 0.5738, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.2437, Accumulated: 0.8175, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1393, Accumulated: 0.9568, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0087, Accumulated: 0.0087, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0107, Accumulated: 0.0193, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0112, Accumulated: 0.0305, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0194, Accumulated: 0.0499, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0083, Accumulated: 0.0582, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0376, Accumulated: 0.0958, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0107, Accumulated: 0.1065, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3907, Accumulated: 0.4972, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1592, Accumulated: 0.6564, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.3416, Accumulated: 0.9980, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2274, Accumulated: 0.2274, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.1097, Accumulated: 0.3371, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0649, Accumulated: 0.4020, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0533, Accumulated: 0.4554, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0425, Accumulated: 0.4978, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0433, Accumulated: 0.5412, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0569, Accumulated: 0.5981, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0931, Accumulated: 0.6912, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1125, Accumulated: 0.8037, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0725, Accumulated: 0.8761, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0579, Accumulated: 0.9341, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0129, Accumulated: 0.0129, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0188, Accumulated: 0.0317, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0075, Accumulated: 0.0393, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0107, Accumulated: 0.0499, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0384, Accumulated: 0.0884, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0068, Accumulated: 0.0951, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0127, Accumulated: 0.1078, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0348, Accumulated: 0.1427, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0325, Accumulated: 0.1752, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8187, Accumulated: 0.9940, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1172, Accumulated: 0.1172, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0669, Accumulated: 0.1841, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0472, Accumulated: 0.2313, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0399, Accumulated: 0.2713, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0332, Accumulated: 0.3044, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0395, Accumulated: 0.3440, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0434, Accumulated: 0.3874, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0974, Accumulated: 0.4848, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1140, Accumulated: 0.5988, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1237, Accumulated: 0.7225, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1497, Accumulated: 0.8722, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0855, Accumulated: 0.9578, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0153, Accumulated: 0.0153, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0278, Accumulated: 0.0432, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0049, Accumulated: 0.0481, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0076, Accumulated: 0.0556, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0037, Accumulated: 0.0593, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0138, Accumulated: 0.0731, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0615, Accumulated: 0.1346, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.8426, Accumulated: 0.9772, Threshold: 0.9000\n",
            "Early exit at layer 11/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0852, Accumulated: 0.0852, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0354, Accumulated: 0.1206, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0175, Accumulated: 0.1381, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0193, Accumulated: 0.1574, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0168, Accumulated: 0.1742, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0236, Accumulated: 0.1978, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0225, Accumulated: 0.2203, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0542, Accumulated: 0.2745, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1098, Accumulated: 0.3843, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1765, Accumulated: 0.5608, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1929, Accumulated: 0.7537, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1593, Accumulated: 0.9131, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0106, Accumulated: 0.0106, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0117, Accumulated: 0.0223, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0075, Accumulated: 0.0298, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0340, Accumulated: 0.0638, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.0730, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0141, Accumulated: 0.0871, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0431, Accumulated: 0.1302, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1959, Accumulated: 0.3261, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0694, Accumulated: 0.3955, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5998, Accumulated: 0.9953, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2158, Accumulated: 0.2158, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0970, Accumulated: 0.3128, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0575, Accumulated: 0.3703, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0409, Accumulated: 0.4112, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0329, Accumulated: 0.4441, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0430, Accumulated: 0.4871, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0431, Accumulated: 0.5302, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0887, Accumulated: 0.6189, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1168, Accumulated: 0.7356, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1035, Accumulated: 0.8392, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0721, Accumulated: 0.9113, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0072, Accumulated: 0.0072, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0103, Accumulated: 0.0175, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0104, Accumulated: 0.0279, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0372, Accumulated: 0.0651, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0334, Accumulated: 0.0985, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0302, Accumulated: 0.1287, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0229, Accumulated: 0.1516, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0525, Accumulated: 0.2041, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0504, Accumulated: 0.2545, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7368, Accumulated: 0.9913, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1418, Accumulated: 0.1418, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0550, Accumulated: 0.1968, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0298, Accumulated: 0.2266, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0303, Accumulated: 0.2569, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0249, Accumulated: 0.2818, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0267, Accumulated: 0.3084, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0330, Accumulated: 0.3414, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0801, Accumulated: 0.4216, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1388, Accumulated: 0.5604, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1612, Accumulated: 0.7216, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1464, Accumulated: 0.8680, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0869, Accumulated: 0.9549, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0145, Accumulated: 0.0145, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0132, Accumulated: 0.0276, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0146, Accumulated: 0.0423, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0102, Accumulated: 0.0525, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0158, Accumulated: 0.0683, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0063, Accumulated: 0.0745, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0135, Accumulated: 0.0880, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0283, Accumulated: 0.1163, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0376, Accumulated: 0.1540, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8282, Accumulated: 0.9822, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0760, Accumulated: 0.0760, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0310, Accumulated: 0.1070, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0203, Accumulated: 0.1273, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0209, Accumulated: 0.1482, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0159, Accumulated: 0.1641, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0372, Accumulated: 0.2013, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0405, Accumulated: 0.2418, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0974, Accumulated: 0.3392, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1094, Accumulated: 0.4486, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1803, Accumulated: 0.6288, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1883, Accumulated: 0.8171, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1380, Accumulated: 0.9551, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0161, Accumulated: 0.0161, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0070, Accumulated: 0.0231, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0051, Accumulated: 0.0282, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0746, Accumulated: 0.1028, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0075, Accumulated: 0.1102, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0086, Accumulated: 0.1189, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0211, Accumulated: 0.1400, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.2148, Accumulated: 0.3548, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0502, Accumulated: 0.4050, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5860, Accumulated: 0.9910, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0703, Accumulated: 0.0703, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0239, Accumulated: 0.0941, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0183, Accumulated: 0.1124, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0151, Accumulated: 0.1275, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0180, Accumulated: 0.1455, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0202, Accumulated: 0.1657, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0276, Accumulated: 0.1932, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0458, Accumulated: 0.2391, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0939, Accumulated: 0.3329, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1079, Accumulated: 0.4408, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1848, Accumulated: 0.6257, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.2330, Accumulated: 0.8587, Threshold: 0.9000\n",
            "Layer 4/16: Halt prob: 0.0088, Accumulated: 0.0088, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0057, Accumulated: 0.0146, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0098, Accumulated: 0.0243, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0787, Accumulated: 0.1031, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0227, Accumulated: 0.1258, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0187, Accumulated: 0.1444, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0150, Accumulated: 0.1594, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3300, Accumulated: 0.4894, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1014, Accumulated: 0.5908, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.4038, Accumulated: 0.9946, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1947, Accumulated: 0.1947, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0852, Accumulated: 0.2799, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0510, Accumulated: 0.3309, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0410, Accumulated: 0.3719, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0355, Accumulated: 0.4074, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0429, Accumulated: 0.4503, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0490, Accumulated: 0.4992, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0934, Accumulated: 0.5926, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1168, Accumulated: 0.7094, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1051, Accumulated: 0.8145, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0815, Accumulated: 0.8960, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0548, Accumulated: 0.9508, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0077, Accumulated: 0.0077, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0188, Accumulated: 0.0266, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0133, Accumulated: 0.0398, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0134, Accumulated: 0.0532, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0127, Accumulated: 0.0659, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0081, Accumulated: 0.0740, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0167, Accumulated: 0.0907, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0085, Accumulated: 0.0992, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0115, Accumulated: 0.1107, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8624, Accumulated: 0.9731, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1290, Accumulated: 0.1290, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0402, Accumulated: 0.1693, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0265, Accumulated: 0.1957, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0228, Accumulated: 0.2186, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0221, Accumulated: 0.2407, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0350, Accumulated: 0.2757, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0244, Accumulated: 0.3001, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0681, Accumulated: 0.3682, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1106, Accumulated: 0.4788, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1339, Accumulated: 0.6127, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1512, Accumulated: 0.7639, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1392, Accumulated: 0.9030, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0108, Accumulated: 0.0108, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0130, Accumulated: 0.0238, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0166, Accumulated: 0.0404, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0430, Accumulated: 0.0834, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0069, Accumulated: 0.0903, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0155, Accumulated: 0.1058, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0113, Accumulated: 0.1172, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0452, Accumulated: 0.1623, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0631, Accumulated: 0.2255, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7681, Accumulated: 0.9936, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1124, Accumulated: 0.1124, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0484, Accumulated: 0.1608, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0238, Accumulated: 0.1846, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0177, Accumulated: 0.2023, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0150, Accumulated: 0.2173, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0197, Accumulated: 0.2370, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0304, Accumulated: 0.2674, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0988, Accumulated: 0.3662, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1297, Accumulated: 0.4960, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1455, Accumulated: 0.6414, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1802, Accumulated: 0.8216, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1236, Accumulated: 0.9452, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0133, Accumulated: 0.0133, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0249, Accumulated: 0.0382, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0141, Accumulated: 0.0523, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0055, Accumulated: 0.0578, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0099, Accumulated: 0.0678, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0117, Accumulated: 0.0795, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0169, Accumulated: 0.0964, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3583, Accumulated: 0.4547, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.2588, Accumulated: 0.7135, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.2857, Accumulated: 0.9992, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2052, Accumulated: 0.2052, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0591, Accumulated: 0.2643, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0304, Accumulated: 0.2947, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0222, Accumulated: 0.3169, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0228, Accumulated: 0.3398, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0295, Accumulated: 0.3693, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0390, Accumulated: 0.4083, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0806, Accumulated: 0.4889, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1310, Accumulated: 0.6199, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1392, Accumulated: 0.7591, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1112, Accumulated: 0.8703, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0731, Accumulated: 0.9434, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0104, Accumulated: 0.0104, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0118, Accumulated: 0.0222, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0072, Accumulated: 0.0294, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0166, Accumulated: 0.0460, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0153, Accumulated: 0.0613, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0143, Accumulated: 0.0756, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0098, Accumulated: 0.0854, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0713, Accumulated: 0.1568, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0608, Accumulated: 0.2176, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7649, Accumulated: 0.9824, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1638, Accumulated: 0.1638, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0801, Accumulated: 0.2439, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0398, Accumulated: 0.2837, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0302, Accumulated: 0.3140, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0264, Accumulated: 0.3403, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0421, Accumulated: 0.3824, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0426, Accumulated: 0.4251, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0984, Accumulated: 0.5235, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1119, Accumulated: 0.6353, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1127, Accumulated: 0.7480, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1139, Accumulated: 0.8620, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0805, Accumulated: 0.9424, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0117, Accumulated: 0.0117, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0093, Accumulated: 0.0210, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0078, Accumulated: 0.0287, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0183, Accumulated: 0.0470, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0053, Accumulated: 0.0523, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0131, Accumulated: 0.0654, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0048, Accumulated: 0.0702, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0073, Accumulated: 0.0775, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0258, Accumulated: 0.1033, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8499, Accumulated: 0.9531, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1887, Accumulated: 0.1887, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0602, Accumulated: 0.2489, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0520, Accumulated: 0.3009, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0458, Accumulated: 0.3467, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0325, Accumulated: 0.3792, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0337, Accumulated: 0.4130, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0400, Accumulated: 0.4529, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0665, Accumulated: 0.5194, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1022, Accumulated: 0.6216, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1148, Accumulated: 0.7364, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1076, Accumulated: 0.8441, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0824, Accumulated: 0.9265, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0076, Accumulated: 0.0076, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0081, Accumulated: 0.0157, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0090, Accumulated: 0.0247, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0148, Accumulated: 0.0395, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0226, Accumulated: 0.0620, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0338, Accumulated: 0.0958, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0078, Accumulated: 0.1037, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1867, Accumulated: 0.2903, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1127, Accumulated: 0.4030, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5937, Accumulated: 0.9968, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1058, Accumulated: 0.1058, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0308, Accumulated: 0.1365, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0386, Accumulated: 0.1752, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0290, Accumulated: 0.2042, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0266, Accumulated: 0.2308, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0263, Accumulated: 0.2570, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0540, Accumulated: 0.3111, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0865, Accumulated: 0.3976, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1096, Accumulated: 0.5072, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1153, Accumulated: 0.6225, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1621, Accumulated: 0.7846, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1288, Accumulated: 0.9134, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0122, Accumulated: 0.0122, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0070, Accumulated: 0.0192, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0049, Accumulated: 0.0240, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.1916, Accumulated: 0.2156, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0118, Accumulated: 0.2274, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0663, Accumulated: 0.2937, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0081, Accumulated: 0.3018, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0296, Accumulated: 0.3314, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0201, Accumulated: 0.3515, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6298, Accumulated: 0.9813, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2303, Accumulated: 0.2303, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0885, Accumulated: 0.3189, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0653, Accumulated: 0.3842, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0501, Accumulated: 0.4343, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0420, Accumulated: 0.4763, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0500, Accumulated: 0.5263, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0528, Accumulated: 0.5791, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0922, Accumulated: 0.6713, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1202, Accumulated: 0.7915, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0931, Accumulated: 0.8846, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0622, Accumulated: 0.9467, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0217, Accumulated: 0.0217, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0129, Accumulated: 0.0346, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0064, Accumulated: 0.0410, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0200, Accumulated: 0.0610, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0080, Accumulated: 0.0690, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0285, Accumulated: 0.0975, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0207, Accumulated: 0.1182, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0268, Accumulated: 0.1450, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0342, Accumulated: 0.1792, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8136, Accumulated: 0.9928, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1736, Accumulated: 0.1736, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0653, Accumulated: 0.2389, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0416, Accumulated: 0.2805, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0493, Accumulated: 0.3298, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0332, Accumulated: 0.3630, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0394, Accumulated: 0.4024, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0385, Accumulated: 0.4410, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0629, Accumulated: 0.5038, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1044, Accumulated: 0.6082, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1146, Accumulated: 0.7228, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1222, Accumulated: 0.8450, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0875, Accumulated: 0.9325, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0328, Accumulated: 0.0328, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0160, Accumulated: 0.0489, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0123, Accumulated: 0.0611, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0045, Accumulated: 0.0657, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0142, Accumulated: 0.0799, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0086, Accumulated: 0.0885, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0524, Accumulated: 0.1409, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3303, Accumulated: 0.4712, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1819, Accumulated: 0.6531, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.3440, Accumulated: 0.9971, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1901, Accumulated: 0.1901, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0552, Accumulated: 0.2452, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0290, Accumulated: 0.2742, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0425, Accumulated: 0.3168, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0339, Accumulated: 0.3507, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0346, Accumulated: 0.3852, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0290, Accumulated: 0.4142, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0975, Accumulated: 0.5117, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1698, Accumulated: 0.6814, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1365, Accumulated: 0.8179, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1077, Accumulated: 0.9256, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0104, Accumulated: 0.0104, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0117, Accumulated: 0.0222, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0192, Accumulated: 0.0413, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.1429, Accumulated: 0.1842, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0121, Accumulated: 0.1963, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0058, Accumulated: 0.2022, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0143, Accumulated: 0.2164, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0160, Accumulated: 0.2325, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0248, Accumulated: 0.2572, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7239, Accumulated: 0.9811, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0966, Accumulated: 0.0966, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0379, Accumulated: 0.1345, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0265, Accumulated: 0.1610, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0202, Accumulated: 0.1812, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0187, Accumulated: 0.1999, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0253, Accumulated: 0.2252, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0255, Accumulated: 0.2507, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1064, Accumulated: 0.3571, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1968, Accumulated: 0.5539, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1431, Accumulated: 0.6970, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1305, Accumulated: 0.8275, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1107, Accumulated: 0.9382, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0126, Accumulated: 0.0126, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0106, Accumulated: 0.0232, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0163, Accumulated: 0.0395, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0077, Accumulated: 0.0472, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0142, Accumulated: 0.0614, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0117, Accumulated: 0.0731, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0196, Accumulated: 0.0927, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.5684, Accumulated: 0.6611, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0916, Accumulated: 0.7527, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.2430, Accumulated: 0.9957, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1274, Accumulated: 0.1274, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0461, Accumulated: 0.1735, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0253, Accumulated: 0.1988, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0246, Accumulated: 0.2234, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0189, Accumulated: 0.2423, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0360, Accumulated: 0.2783, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0435, Accumulated: 0.3217, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1186, Accumulated: 0.4403, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1252, Accumulated: 0.5655, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1310, Accumulated: 0.6965, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1282, Accumulated: 0.8248, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0907, Accumulated: 0.9155, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0117, Accumulated: 0.0117, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0191, Accumulated: 0.0308, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0115, Accumulated: 0.0423, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0468, Accumulated: 0.0891, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0102, Accumulated: 0.0993, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0078, Accumulated: 0.1071, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0282, Accumulated: 0.1353, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1241, Accumulated: 0.2594, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0841, Accumulated: 0.3435, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6517, Accumulated: 0.9952, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2162, Accumulated: 0.2162, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0796, Accumulated: 0.2958, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0481, Accumulated: 0.3438, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0362, Accumulated: 0.3800, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0295, Accumulated: 0.4096, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0359, Accumulated: 0.4455, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0381, Accumulated: 0.4836, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0760, Accumulated: 0.5596, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1514, Accumulated: 0.7110, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1247, Accumulated: 0.8358, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0906, Accumulated: 0.9264, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0138, Accumulated: 0.0138, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0454, Accumulated: 0.0592, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0123, Accumulated: 0.0715, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0096, Accumulated: 0.0811, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0108, Accumulated: 0.0918, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0080, Accumulated: 0.0998, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0098, Accumulated: 0.1096, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1121, Accumulated: 0.2217, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1043, Accumulated: 0.3260, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6658, Accumulated: 0.9918, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1796, Accumulated: 0.1796, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0985, Accumulated: 0.2781, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0688, Accumulated: 0.3469, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0567, Accumulated: 0.4036, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0482, Accumulated: 0.4517, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0585, Accumulated: 0.5103, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0551, Accumulated: 0.5654, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0893, Accumulated: 0.6547, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0978, Accumulated: 0.7525, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0902, Accumulated: 0.8426, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0835, Accumulated: 0.9262, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0177, Accumulated: 0.0177, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0285, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0053, Accumulated: 0.0338, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0298, Accumulated: 0.0636, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0074, Accumulated: 0.0710, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0260, Accumulated: 0.0971, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0291, Accumulated: 0.1262, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.2221, Accumulated: 0.3483, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0955, Accumulated: 0.4438, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.5510, Accumulated: 0.9948, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1274, Accumulated: 0.1274, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0769, Accumulated: 0.2043, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0536, Accumulated: 0.2579, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0461, Accumulated: 0.3040, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0298, Accumulated: 0.3339, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0467, Accumulated: 0.3806, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0412, Accumulated: 0.4218, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0676, Accumulated: 0.4893, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0902, Accumulated: 0.5795, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1000, Accumulated: 0.6796, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1644, Accumulated: 0.8440, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1001, Accumulated: 0.9441, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0092, Accumulated: 0.0092, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0054, Accumulated: 0.0146, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0097, Accumulated: 0.0243, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.1732, Accumulated: 0.1975, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0153, Accumulated: 0.2128, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0118, Accumulated: 0.2246, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0165, Accumulated: 0.2411, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0336, Accumulated: 0.2747, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0204, Accumulated: 0.2951, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6822, Accumulated: 0.9773, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1599, Accumulated: 0.1599, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0514, Accumulated: 0.2113, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0311, Accumulated: 0.2425, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0168, Accumulated: 0.2593, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0164, Accumulated: 0.2756, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0225, Accumulated: 0.2981, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0247, Accumulated: 0.3228, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1190, Accumulated: 0.4418, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1491, Accumulated: 0.5909, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1653, Accumulated: 0.7562, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1251, Accumulated: 0.8813, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0776, Accumulated: 0.9589, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0078, Accumulated: 0.0078, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0754, Accumulated: 0.0832, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0113, Accumulated: 0.0946, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0054, Accumulated: 0.1000, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0170, Accumulated: 0.1170, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0104, Accumulated: 0.1274, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0148, Accumulated: 0.1422, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3328, Accumulated: 0.4750, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1920, Accumulated: 0.6670, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.3319, Accumulated: 0.9989, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1787, Accumulated: 0.1787, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0752, Accumulated: 0.2539, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0495, Accumulated: 0.3034, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0449, Accumulated: 0.3483, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0361, Accumulated: 0.3843, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0363, Accumulated: 0.4206, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0388, Accumulated: 0.4594, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1002, Accumulated: 0.5596, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1199, Accumulated: 0.6795, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1276, Accumulated: 0.8071, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1087, Accumulated: 0.9158, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0146, Accumulated: 0.0146, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0120, Accumulated: 0.0266, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0096, Accumulated: 0.0362, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0352, Accumulated: 0.0715, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0049, Accumulated: 0.0764, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0121, Accumulated: 0.0885, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0131, Accumulated: 0.1017, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0241, Accumulated: 0.1258, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0096, Accumulated: 0.1354, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8422, Accumulated: 0.9776, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1945, Accumulated: 0.1945, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0655, Accumulated: 0.2599, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0348, Accumulated: 0.2947, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0313, Accumulated: 0.3260, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0241, Accumulated: 0.3501, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0283, Accumulated: 0.3784, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0450, Accumulated: 0.4234, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0736, Accumulated: 0.4970, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1154, Accumulated: 0.6125, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1442, Accumulated: 0.7567, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1192, Accumulated: 0.8759, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0759, Accumulated: 0.9518, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0124, Accumulated: 0.0124, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0107, Accumulated: 0.0231, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0154, Accumulated: 0.0385, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0316, Accumulated: 0.0701, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0088, Accumulated: 0.0789, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0111, Accumulated: 0.0900, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0258, Accumulated: 0.1158, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0657, Accumulated: 0.1815, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1134, Accumulated: 0.2949, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7030, Accumulated: 0.9979, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1946, Accumulated: 0.1946, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0561, Accumulated: 0.2507, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0295, Accumulated: 0.2801, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0205, Accumulated: 0.3006, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0268, Accumulated: 0.3274, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0250, Accumulated: 0.3524, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0382, Accumulated: 0.3906, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1098, Accumulated: 0.5004, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1366, Accumulated: 0.6370, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1276, Accumulated: 0.7646, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1095, Accumulated: 0.8741, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0736, Accumulated: 0.9477, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0132, Accumulated: 0.0132, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0843, Accumulated: 0.0975, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0139, Accumulated: 0.1114, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0101, Accumulated: 0.1215, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0096, Accumulated: 0.1311, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0098, Accumulated: 0.1408, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0535, Accumulated: 0.1944, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.4378, Accumulated: 0.6322, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1943, Accumulated: 0.8265, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1730, Accumulated: 0.9995, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1641, Accumulated: 0.1641, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0698, Accumulated: 0.2339, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0423, Accumulated: 0.2762, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0389, Accumulated: 0.3151, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0277, Accumulated: 0.3428, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0367, Accumulated: 0.3794, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0479, Accumulated: 0.4274, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1151, Accumulated: 0.5424, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1506, Accumulated: 0.6930, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1260, Accumulated: 0.8190, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1060, Accumulated: 0.9250, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0221, Accumulated: 0.0221, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0080, Accumulated: 0.0301, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0104, Accumulated: 0.0405, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0140, Accumulated: 0.0545, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0052, Accumulated: 0.0597, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0125, Accumulated: 0.0722, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0200, Accumulated: 0.0923, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0262, Accumulated: 0.1184, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0239, Accumulated: 0.1423, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8439, Accumulated: 0.9862, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1420, Accumulated: 0.1420, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0538, Accumulated: 0.1958, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0349, Accumulated: 0.2307, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0385, Accumulated: 0.2692, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0312, Accumulated: 0.3004, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0368, Accumulated: 0.3373, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0483, Accumulated: 0.3856, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1189, Accumulated: 0.5045, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1488, Accumulated: 0.6533, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1389, Accumulated: 0.7922, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1070, Accumulated: 0.8991, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0689, Accumulated: 0.9681, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0088, Accumulated: 0.0088, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0089, Accumulated: 0.0177, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0054, Accumulated: 0.0231, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0129, Accumulated: 0.0360, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0101, Accumulated: 0.0462, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0161, Accumulated: 0.0623, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0099, Accumulated: 0.0722, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.3554, Accumulated: 0.4276, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1537, Accumulated: 0.5813, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.4179, Accumulated: 0.9992, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1250, Accumulated: 0.1250, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0647, Accumulated: 0.1897, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0316, Accumulated: 0.2214, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0421, Accumulated: 0.2635, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0311, Accumulated: 0.2945, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0413, Accumulated: 0.3358, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0417, Accumulated: 0.3776, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0953, Accumulated: 0.4728, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1245, Accumulated: 0.5973, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1442, Accumulated: 0.7415, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1396, Accumulated: 0.8811, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.0806, Accumulated: 0.9617, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0112, Accumulated: 0.0112, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0091, Accumulated: 0.0203, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0164, Accumulated: 0.0367, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0184, Accumulated: 0.0551, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0115, Accumulated: 0.0666, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0184, Accumulated: 0.0850, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0149, Accumulated: 0.0999, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0800, Accumulated: 0.1799, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1433, Accumulated: 0.3233, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.6737, Accumulated: 0.9970, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0845, Accumulated: 0.0845, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0420, Accumulated: 0.1266, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0210, Accumulated: 0.1475, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0181, Accumulated: 0.1656, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0198, Accumulated: 0.1854, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0251, Accumulated: 0.2105, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0299, Accumulated: 0.2404, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0704, Accumulated: 0.3109, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1719, Accumulated: 0.4827, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1671, Accumulated: 0.6498, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.1606, Accumulated: 0.8104, Threshold: 0.9000\n",
            "Layer 15/16: Halt prob: 0.1314, Accumulated: 0.9418, Threshold: 0.9000\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0135, Accumulated: 0.0135, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0165, Accumulated: 0.0300, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0087, Accumulated: 0.0386, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0592, Accumulated: 0.0978, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0042, Accumulated: 0.1021, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0122, Accumulated: 0.1143, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0141, Accumulated: 0.1283, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0581, Accumulated: 0.1865, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0397, Accumulated: 0.2262, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7560, Accumulated: 0.9822, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2664, Accumulated: 0.2664, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.1482, Accumulated: 0.4146, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0886, Accumulated: 0.5032, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0703, Accumulated: 0.5735, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0459, Accumulated: 0.6195, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0518, Accumulated: 0.6713, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0361, Accumulated: 0.7073, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0465, Accumulated: 0.7538, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0634, Accumulated: 0.8172, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.0478, Accumulated: 0.8650, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0486, Accumulated: 0.9136, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0102, Accumulated: 0.0102, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0104, Accumulated: 0.0206, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0055, Accumulated: 0.0260, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0624, Accumulated: 0.0885, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0105, Accumulated: 0.0989, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0337, Accumulated: 0.1326, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0082, Accumulated: 0.1408, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0151, Accumulated: 0.1559, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0176, Accumulated: 0.1736, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.8079, Accumulated: 0.9814, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1648, Accumulated: 0.1648, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0806, Accumulated: 0.2454, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0400, Accumulated: 0.2854, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0389, Accumulated: 0.3243, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0263, Accumulated: 0.3506, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0344, Accumulated: 0.3850, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0466, Accumulated: 0.4316, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.1209, Accumulated: 0.5525, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.1663, Accumulated: 0.7188, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.1276, Accumulated: 0.8463, Threshold: 0.9000\n",
            "Layer 14/16: Halt prob: 0.0850, Accumulated: 0.9313, Threshold: 0.9000\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0083, Accumulated: 0.0083, Threshold: 0.9000\n",
            "Layer 5/16: Halt prob: 0.0099, Accumulated: 0.0181, Threshold: 0.9000\n",
            "Layer 6/16: Halt prob: 0.0102, Accumulated: 0.0284, Threshold: 0.9000\n",
            "Layer 7/16: Halt prob: 0.0234, Accumulated: 0.0518, Threshold: 0.9000\n",
            "Layer 8/16: Halt prob: 0.0235, Accumulated: 0.0753, Threshold: 0.9000\n",
            "Layer 9/16: Halt prob: 0.0109, Accumulated: 0.0862, Threshold: 0.9000\n",
            "Layer 10/16: Halt prob: 0.0294, Accumulated: 0.1156, Threshold: 0.9000\n",
            "Layer 11/16: Halt prob: 0.0877, Accumulated: 0.2032, Threshold: 0.9000\n",
            "Layer 12/16: Halt prob: 0.0756, Accumulated: 0.2789, Threshold: 0.9000\n",
            "Layer 13/16: Halt prob: 0.7123, Accumulated: 0.9912, Threshold: 0.9000\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (MMLU) ---\n",
            "exact_match: 0.4100\n",
            "accuracy: 0.4100\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.4099999964237213, 'accuracy': 0.41}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.13020119190216065}, 'time_per_token': {'mean': 0.13020119190216065}, 'tokens_per_second': {'mean': 8.382073322534561}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking MMLU:   1%|          | 1/100 [00:00<01:04,  1.54it/s]\n",
            "Benchmarking MMLU:   2%|▏         | 2/100 [00:00<00:33,  2.97it/s]\n",
            "Benchmarking MMLU:   3%|▎         | 3/100 [00:00<00:23,  4.15it/s]\n",
            "Benchmarking MMLU:   4%|▍         | 4/100 [00:00<00:17,  5.35it/s]\n",
            "Benchmarking MMLU:   5%|▌         | 5/100 [00:01<00:14,  6.42it/s]\n",
            "Benchmarking MMLU:   6%|▌         | 6/100 [00:01<00:14,  6.46it/s]\n",
            "Benchmarking MMLU:   7%|▋         | 7/100 [00:01<00:12,  7.20it/s]\n",
            "Benchmarking MMLU:   8%|▊         | 8/100 [00:01<00:14,  6.49it/s]\n",
            "Benchmarking MMLU:   9%|▉         | 9/100 [00:01<00:13,  6.54it/s]\n",
            "Benchmarking MMLU:  10%|█         | 10/100 [00:01<00:12,  7.05it/s]\n",
            "Benchmarking MMLU:  11%|█         | 11/100 [00:01<00:11,  7.53it/s]\n",
            "Benchmarking MMLU:  12%|█▏        | 12/100 [00:02<00:13,  6.39it/s]\n",
            "Benchmarking MMLU:  13%|█▎        | 13/100 [00:02<00:12,  7.00it/s]\n",
            "Benchmarking MMLU:  14%|█▍        | 14/100 [00:02<00:11,  7.59it/s]\n",
            "Benchmarking MMLU:  15%|█▌        | 15/100 [00:02<00:10,  8.18it/s]\n",
            "Benchmarking MMLU:  16%|█▌        | 16/100 [00:02<00:09,  8.57it/s]\n",
            "Benchmarking MMLU:  17%|█▋        | 17/100 [00:02<00:11,  7.39it/s]\n",
            "Benchmarking MMLU:  19%|█▉        | 19/100 [00:02<00:09,  8.37it/s]\n",
            "Benchmarking MMLU:  20%|██        | 20/100 [00:03<00:09,  8.72it/s]\n",
            "Benchmarking MMLU:  21%|██        | 21/100 [00:03<00:10,  7.68it/s]\n",
            "Benchmarking MMLU:  22%|██▏       | 22/100 [00:03<00:15,  4.98it/s]\n",
            "Benchmarking MMLU:  23%|██▎       | 23/100 [00:03<00:13,  5.65it/s]\n",
            "Benchmarking MMLU:  24%|██▍       | 24/100 [00:03<00:12,  5.89it/s]\n",
            "Benchmarking MMLU:  25%|██▌       | 25/100 [00:03<00:11,  6.62it/s]\n",
            "Benchmarking MMLU:  26%|██▌       | 26/100 [00:04<00:10,  7.31it/s]\n",
            "Benchmarking MMLU:  27%|██▋       | 27/100 [00:04<00:09,  7.52it/s]\n",
            "Benchmarking MMLU:  28%|██▊       | 28/100 [00:04<00:09,  7.74it/s]\n",
            "Benchmarking MMLU:  29%|██▉       | 29/100 [00:04<00:08,  8.01it/s]\n",
            "Benchmarking MMLU:  30%|███       | 30/100 [00:04<00:10,  6.81it/s]\n",
            "Benchmarking MMLU:  31%|███       | 31/100 [00:04<00:09,  7.28it/s]\n",
            "Benchmarking MMLU:  33%|███▎      | 33/100 [00:04<00:08,  8.02it/s]\n",
            "Benchmarking MMLU:  34%|███▍      | 34/100 [00:05<00:08,  8.22it/s]\n",
            "Benchmarking MMLU:  35%|███▌      | 35/100 [00:05<00:08,  7.59it/s]\n",
            "Benchmarking MMLU:  36%|███▌      | 36/100 [00:05<00:09,  6.90it/s]\n",
            "Benchmarking MMLU:  37%|███▋      | 37/100 [00:05<00:08,  7.31it/s]\n",
            "Benchmarking MMLU:  38%|███▊      | 38/100 [00:05<00:08,  7.48it/s]\n",
            "Benchmarking MMLU:  39%|███▉      | 39/100 [00:05<00:08,  7.32it/s]\n",
            "Benchmarking MMLU:  40%|████      | 40/100 [00:05<00:07,  7.75it/s]\n",
            "Benchmarking MMLU:  41%|████      | 41/100 [00:06<00:07,  8.09it/s]\n",
            "Benchmarking MMLU:  42%|████▏     | 42/100 [00:06<00:06,  8.32it/s]\n",
            "Benchmarking MMLU:  43%|████▎     | 43/100 [00:06<00:06,  8.31it/s]\n",
            "Benchmarking MMLU:  44%|████▍     | 44/100 [00:06<00:06,  8.44it/s]\n",
            "Benchmarking MMLU:  45%|████▌     | 45/100 [00:06<00:06,  8.71it/s]\n",
            "Benchmarking MMLU:  46%|████▌     | 46/100 [00:06<00:06,  8.95it/s]\n",
            "Benchmarking MMLU:  47%|████▋     | 47/100 [00:06<00:06,  8.32it/s]\n",
            "Benchmarking MMLU:  48%|████▊     | 48/100 [00:06<00:07,  6.82it/s]\n",
            "Benchmarking MMLU:  49%|████▉     | 49/100 [00:07<00:07,  6.62it/s]\n",
            "Benchmarking MMLU:  50%|█████     | 50/100 [00:07<00:06,  7.17it/s]\n",
            "Benchmarking MMLU:  51%|█████     | 51/100 [00:07<00:06,  7.68it/s]\n",
            "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:07<00:06,  7.63it/s]\n",
            "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:07<00:05,  8.14it/s]\n",
            "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:07<00:05,  8.58it/s]\n",
            "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:07<00:05,  8.42it/s]\n",
            "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:07<00:05,  8.73it/s]\n",
            "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:07<00:04,  9.00it/s]\n",
            "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:08<00:04,  9.26it/s]\n",
            "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:08<00:04,  9.33it/s]\n",
            "Benchmarking MMLU:  60%|██████    | 60/100 [00:08<00:04,  9.49it/s]\n",
            "Benchmarking MMLU:  61%|██████    | 61/100 [00:08<00:04,  9.61it/s]\n",
            "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:08<00:03,  9.68it/s]\n",
            "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:08<00:04,  8.74it/s]\n",
            "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:08<00:04,  8.90it/s]\n",
            "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:08<00:03,  9.01it/s]\n",
            "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:08<00:03,  8.94it/s]\n",
            "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:09<00:03,  9.03it/s]\n",
            "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:09<00:03,  9.22it/s]\n",
            "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:09<00:04,  7.35it/s]\n",
            "Benchmarking MMLU:  70%|███████   | 70/100 [00:09<00:03,  7.69it/s]\n",
            "Benchmarking MMLU:  71%|███████   | 71/100 [00:09<00:03,  8.09it/s]\n",
            "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:09<00:03,  7.07it/s]\n",
            "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:09<00:03,  7.36it/s]\n",
            "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:10<00:03,  7.95it/s]\n",
            "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:10<00:02,  8.44it/s]\n",
            "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:10<00:03,  7.21it/s]\n",
            "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:10<00:03,  7.34it/s]\n",
            "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:10<00:02,  7.94it/s]\n",
            "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:10<00:02,  8.34it/s]\n",
            "Benchmarking MMLU:  80%|████████  | 80/100 [00:10<00:02,  8.14it/s]\n",
            "Benchmarking MMLU:  81%|████████  | 81/100 [00:10<00:02,  8.23it/s]\n",
            "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:10<00:02,  8.40it/s]\n",
            "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:11<00:02,  7.95it/s]\n",
            "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:11<00:01,  8.44it/s]\n",
            "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:11<00:01,  8.71it/s]\n",
            "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:11<00:01,  8.72it/s]\n",
            "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:11<00:01,  8.57it/s]\n",
            "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:11<00:01,  8.83it/s]\n",
            "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:11<00:01,  8.99it/s]\n",
            "Benchmarking MMLU:  90%|█████████ | 90/100 [00:11<00:01,  9.05it/s]\n",
            "Benchmarking MMLU:  91%|█████████ | 91/100 [00:12<00:00,  9.18it/s]\n",
            "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:12<00:00,  9.34it/s]\n",
            "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:12<00:00,  9.39it/s]\n",
            "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:12<00:00,  9.40it/s]\n",
            "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:12<00:00,  7.39it/s]\n",
            "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:12<00:00,  7.21it/s]\n",
            "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:12<00:00,  7.53it/s]\n",
            "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:12<00:00,  8.09it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:13<00:00,  8.59it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:13<00:00,  7.63it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        }
      ],
      "source": [
        "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "    --dataset mmlu \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy depth_adaptive_sequence \\\n",
        "    --halting_threshold 0.90 \\\n",
        "    --min_layers 4 \\\n",
        "    --max_layers 15 \\\n",
        "    --output_dir ./logs \\\n",
        "    --distributed False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: mmlu\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on MMLU with 100 samples...\n",
            "Layer 4/16: Halt prob: 0.1323, Accumulated: 0.1323, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0548, Accumulated: 0.1871, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0201, Accumulated: 0.2072, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0317, Accumulated: 0.2389, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0202, Accumulated: 0.2591, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0397, Accumulated: 0.2988, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0293, Accumulated: 0.3281, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0747, Accumulated: 0.4028, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1233, Accumulated: 0.5261, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1405, Accumulated: 0.6666, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1434, Accumulated: 0.8099, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1114, Accumulated: 0.9213, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0109, Accumulated: 0.0109, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0069, Accumulated: 0.0178, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0135, Accumulated: 0.0314, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0294, Accumulated: 0.0607, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0079, Accumulated: 0.0686, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0292, Accumulated: 0.0978, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0140, Accumulated: 0.1118, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1611, Accumulated: 0.2729, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1083, Accumulated: 0.3812, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6164, Accumulated: 0.9976, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2030, Accumulated: 0.2030, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0872, Accumulated: 0.2902, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0481, Accumulated: 0.3383, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0402, Accumulated: 0.3786, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0356, Accumulated: 0.4141, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0401, Accumulated: 0.4542, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0459, Accumulated: 0.5001, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1021, Accumulated: 0.6022, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1427, Accumulated: 0.7449, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1048, Accumulated: 0.8496, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0783, Accumulated: 0.9279, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0150, Accumulated: 0.0150, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0089, Accumulated: 0.0239, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0076, Accumulated: 0.0315, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0120, Accumulated: 0.0435, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0064, Accumulated: 0.0499, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0108, Accumulated: 0.0607, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0086, Accumulated: 0.0693, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0327, Accumulated: 0.1020, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0350, Accumulated: 0.1371, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8583, Accumulated: 0.9954, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2527, Accumulated: 0.2527, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0958, Accumulated: 0.3485, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0495, Accumulated: 0.3979, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0378, Accumulated: 0.4357, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0293, Accumulated: 0.4650, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0313, Accumulated: 0.4963, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0408, Accumulated: 0.5371, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0912, Accumulated: 0.6282, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1310, Accumulated: 0.7592, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1023, Accumulated: 0.8615, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.0119, Accumulated: 0.0119, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0219, Accumulated: 0.0337, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0061, Accumulated: 0.0398, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0148, Accumulated: 0.0546, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0252, Accumulated: 0.0798, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0066, Accumulated: 0.0864, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0123, Accumulated: 0.0988, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0092, Accumulated: 0.1079, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0149, Accumulated: 0.1228, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8442, Accumulated: 0.9670, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1841, Accumulated: 0.1841, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0912, Accumulated: 0.2753, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0493, Accumulated: 0.3245, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0363, Accumulated: 0.3608, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0274, Accumulated: 0.3882, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0419, Accumulated: 0.4300, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0406, Accumulated: 0.4706, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0785, Accumulated: 0.5491, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1081, Accumulated: 0.6573, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1077, Accumulated: 0.7650, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1042, Accumulated: 0.8692, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0118, Accumulated: 0.0118, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0087, Accumulated: 0.0205, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0073, Accumulated: 0.0278, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0214, Accumulated: 0.0492, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0070, Accumulated: 0.0562, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0169, Accumulated: 0.0731, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0055, Accumulated: 0.0786, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0098, Accumulated: 0.0884, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0340, Accumulated: 0.1223, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8125, Accumulated: 0.9349, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1091, Accumulated: 0.1091, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0299, Accumulated: 0.1390, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0174, Accumulated: 0.1564, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0166, Accumulated: 0.1729, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0134, Accumulated: 0.1863, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0184, Accumulated: 0.2047, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0261, Accumulated: 0.2308, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0774, Accumulated: 0.3082, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1312, Accumulated: 0.4395, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1472, Accumulated: 0.5867, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1840, Accumulated: 0.7708, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1424, Accumulated: 0.9131, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0143, Accumulated: 0.0143, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0251, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0075, Accumulated: 0.0326, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0425, Accumulated: 0.0752, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0071, Accumulated: 0.0823, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0077, Accumulated: 0.0900, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0195, Accumulated: 0.1095, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1332, Accumulated: 0.2426, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0575, Accumulated: 0.3001, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6777, Accumulated: 0.9778, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2573, Accumulated: 0.2573, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1094, Accumulated: 0.3667, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0803, Accumulated: 0.4471, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0637, Accumulated: 0.5107, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0498, Accumulated: 0.5606, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0468, Accumulated: 0.6074, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0491, Accumulated: 0.6564, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0697, Accumulated: 0.7262, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0763, Accumulated: 0.8025, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0756, Accumulated: 0.8781, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.0178, Accumulated: 0.0178, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0095, Accumulated: 0.0273, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0053, Accumulated: 0.0326, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0156, Accumulated: 0.0482, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0118, Accumulated: 0.0600, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0108, Accumulated: 0.0708, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0093, Accumulated: 0.0801, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0202, Accumulated: 0.1003, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0149, Accumulated: 0.1151, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8399, Accumulated: 0.9551, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1692, Accumulated: 0.1692, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0738, Accumulated: 0.2430, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0490, Accumulated: 0.2920, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0539, Accumulated: 0.3459, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0325, Accumulated: 0.3784, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0383, Accumulated: 0.4167, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0504, Accumulated: 0.4671, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0976, Accumulated: 0.5647, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1085, Accumulated: 0.6732, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0910, Accumulated: 0.7642, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0998, Accumulated: 0.8640, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0152, Accumulated: 0.0152, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0211, Accumulated: 0.0363, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0060, Accumulated: 0.0423, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0952, Accumulated: 0.1375, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0204, Accumulated: 0.1579, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0090, Accumulated: 0.1669, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0189, Accumulated: 0.1858, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0335, Accumulated: 0.2194, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0665, Accumulated: 0.2859, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7054, Accumulated: 0.9913, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1473, Accumulated: 0.1473, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0638, Accumulated: 0.2111, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0333, Accumulated: 0.2444, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0393, Accumulated: 0.2837, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0279, Accumulated: 0.3117, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0382, Accumulated: 0.3499, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0295, Accumulated: 0.3794, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0684, Accumulated: 0.4478, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1021, Accumulated: 0.5498, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0961, Accumulated: 0.6459, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1342, Accumulated: 0.7801, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1182, Accumulated: 0.8983, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0158, Accumulated: 0.0158, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0301, Accumulated: 0.0458, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0186, Accumulated: 0.0644, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0067, Accumulated: 0.0711, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0834, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0069, Accumulated: 0.0903, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0243, Accumulated: 0.1146, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.2769, Accumulated: 0.3915, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1185, Accumulated: 0.5100, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.4869, Accumulated: 0.9969, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1945, Accumulated: 0.1945, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0716, Accumulated: 0.2661, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0401, Accumulated: 0.3062, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0369, Accumulated: 0.3432, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0281, Accumulated: 0.3713, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0424, Accumulated: 0.4137, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0530, Accumulated: 0.4667, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1121, Accumulated: 0.5788, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1364, Accumulated: 0.7153, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1222, Accumulated: 0.8375, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0878, Accumulated: 0.9252, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0134, Accumulated: 0.0134, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0133, Accumulated: 0.0266, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0094, Accumulated: 0.0360, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0085, Accumulated: 0.0446, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0107, Accumulated: 0.0552, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0246, Accumulated: 0.0798, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0327, Accumulated: 0.1124, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0177, Accumulated: 0.1301, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0359, Accumulated: 0.1660, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8319, Accumulated: 0.9980, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1660, Accumulated: 0.1660, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0723, Accumulated: 0.2383, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0495, Accumulated: 0.2879, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0387, Accumulated: 0.3266, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0335, Accumulated: 0.3601, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0457, Accumulated: 0.4058, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0528, Accumulated: 0.4586, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1006, Accumulated: 0.5592, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1544, Accumulated: 0.7136, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1175, Accumulated: 0.8311, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0882, Accumulated: 0.9193, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0104, Accumulated: 0.0104, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0196, Accumulated: 0.0301, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0164, Accumulated: 0.0465, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0253, Accumulated: 0.0718, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.0809, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0191, Accumulated: 0.1001, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0689, Accumulated: 0.1689, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0331, Accumulated: 0.2021, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0158, Accumulated: 0.2179, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7657, Accumulated: 0.9836, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1527, Accumulated: 0.1527, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0785, Accumulated: 0.2312, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0318, Accumulated: 0.2629, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0244, Accumulated: 0.2874, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0202, Accumulated: 0.3075, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0357, Accumulated: 0.3432, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0367, Accumulated: 0.3800, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0734, Accumulated: 0.4534, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1080, Accumulated: 0.5613, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1263, Accumulated: 0.6876, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1374, Accumulated: 0.8250, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.0965, Accumulated: 0.9215, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0151, Accumulated: 0.0151, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0081, Accumulated: 0.0232, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0081, Accumulated: 0.0313, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0199, Accumulated: 0.0512, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0063, Accumulated: 0.0576, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.0715, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0049, Accumulated: 0.0764, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0086, Accumulated: 0.0850, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0232, Accumulated: 0.1082, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8317, Accumulated: 0.9399, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1835, Accumulated: 0.1835, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0820, Accumulated: 0.2655, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0540, Accumulated: 0.3195, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0379, Accumulated: 0.3574, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0341, Accumulated: 0.3915, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0343, Accumulated: 0.4258, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0389, Accumulated: 0.4647, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0916, Accumulated: 0.5562, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1317, Accumulated: 0.6880, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1199, Accumulated: 0.8079, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1013, Accumulated: 0.9092, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0063, Accumulated: 0.0063, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0164, Accumulated: 0.0227, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0184, Accumulated: 0.0411, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0645, Accumulated: 0.1056, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0167, Accumulated: 0.1223, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.1362, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0700, Accumulated: 0.2062, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0705, Accumulated: 0.2767, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0536, Accumulated: 0.3303, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6628, Accumulated: 0.9931, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1423, Accumulated: 0.1423, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0705, Accumulated: 0.2128, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0466, Accumulated: 0.2594, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0336, Accumulated: 0.2930, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0289, Accumulated: 0.3220, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0295, Accumulated: 0.3514, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0326, Accumulated: 0.3840, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0755, Accumulated: 0.4595, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1178, Accumulated: 0.5773, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1228, Accumulated: 0.7001, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1158, Accumulated: 0.8159, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.0977, Accumulated: 0.9136, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0175, Accumulated: 0.0175, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0518, Accumulated: 0.0693, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0163, Accumulated: 0.0855, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0154, Accumulated: 0.1010, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0099, Accumulated: 0.1109, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0166, Accumulated: 0.1275, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0152, Accumulated: 0.1427, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.2937, Accumulated: 0.4363, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1221, Accumulated: 0.5584, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.4369, Accumulated: 0.9953, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1688, Accumulated: 0.1688, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0856, Accumulated: 0.2544, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0454, Accumulated: 0.2998, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0370, Accumulated: 0.3367, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0368, Accumulated: 0.3735, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0414, Accumulated: 0.4149, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0347, Accumulated: 0.4496, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0796, Accumulated: 0.5292, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1277, Accumulated: 0.6569, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1420, Accumulated: 0.7989, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1133, Accumulated: 0.9122, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0118, Accumulated: 0.0118, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0151, Accumulated: 0.0270, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0123, Accumulated: 0.0393, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.1091, Accumulated: 0.1484, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0080, Accumulated: 0.1565, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0065, Accumulated: 0.1630, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0130, Accumulated: 0.1760, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1410, Accumulated: 0.3170, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1045, Accumulated: 0.4215, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.5746, Accumulated: 0.9960, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1182, Accumulated: 0.1182, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0376, Accumulated: 0.1557, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0260, Accumulated: 0.1817, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0314, Accumulated: 0.2131, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0274, Accumulated: 0.2405, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0328, Accumulated: 0.2733, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0364, Accumulated: 0.3097, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1108, Accumulated: 0.4205, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1329, Accumulated: 0.5534, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1366, Accumulated: 0.6900, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1482, Accumulated: 0.8382, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.0952, Accumulated: 0.9334, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0125, Accumulated: 0.0125, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0158, Accumulated: 0.0284, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0198, Accumulated: 0.0482, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0331, Accumulated: 0.0813, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0108, Accumulated: 0.0921, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0259, Accumulated: 0.1180, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0143, Accumulated: 0.1323, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1545, Accumulated: 0.2868, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0689, Accumulated: 0.3557, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6376, Accumulated: 0.9934, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2800, Accumulated: 0.2800, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1234, Accumulated: 0.4034, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0805, Accumulated: 0.4839, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0589, Accumulated: 0.5428, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0476, Accumulated: 0.5904, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0450, Accumulated: 0.6355, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0526, Accumulated: 0.6881, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0846, Accumulated: 0.7727, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0926, Accumulated: 0.8653, Threshold: 0.8500\n",
            "Early exit at layer 12/16\n",
            "Layer 4/16: Halt prob: 0.2998, Accumulated: 0.2998, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1687, Accumulated: 0.4685, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.1134, Accumulated: 0.5819, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0140, Accumulated: 0.5960, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0270, Accumulated: 0.6229, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0762, Accumulated: 0.6991, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0328, Accumulated: 0.7319, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0577, Accumulated: 0.7896, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0684, Accumulated: 0.8580, Threshold: 0.8500\n",
            "Early exit at layer 12/16\n",
            "Layer 4/16: Halt prob: 0.3191, Accumulated: 0.3191, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1667, Accumulated: 0.4858, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0135, Accumulated: 0.4993, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0079, Accumulated: 0.5072, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0211, Accumulated: 0.5283, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0252, Accumulated: 0.5535, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0367, Accumulated: 0.5902, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0493, Accumulated: 0.6396, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0390, Accumulated: 0.6786, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0148, Accumulated: 0.6933, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0569, Accumulated: 0.7502, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.0932, Accumulated: 0.8434, Threshold: 0.8500\n",
            "Layer 16/16: Halt prob: 0.0309, Accumulated: 0.8744, Threshold: 0.8500\n",
            "Early exit at layer 16/16\n",
            "Layer 4/16: Halt prob: 0.3376, Accumulated: 0.3376, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0329, Accumulated: 0.3705, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0320, Accumulated: 0.4026, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0325, Accumulated: 0.4350, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0107, Accumulated: 0.4457, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0093, Accumulated: 0.4550, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0059, Accumulated: 0.4609, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0500, Accumulated: 0.5108, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0649, Accumulated: 0.5758, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0382, Accumulated: 0.6139, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1084, Accumulated: 0.7223, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1893, Accumulated: 0.9116, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1234, Accumulated: 0.1234, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0311, Accumulated: 0.1545, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0158, Accumulated: 0.1703, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0138, Accumulated: 0.1841, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0193, Accumulated: 0.2034, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0255, Accumulated: 0.2289, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0295, Accumulated: 0.2583, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0579, Accumulated: 0.3162, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1124, Accumulated: 0.4286, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1309, Accumulated: 0.5594, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1910, Accumulated: 0.7504, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1499, Accumulated: 0.9003, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0071, Accumulated: 0.0071, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0116, Accumulated: 0.0187, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0063, Accumulated: 0.0250, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0169, Accumulated: 0.0418, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0148, Accumulated: 0.0566, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0168, Accumulated: 0.0734, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0818, Accumulated: 0.1552, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.5581, Accumulated: 0.7133, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1042, Accumulated: 0.8175, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1820, Accumulated: 0.9996, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1404, Accumulated: 0.1404, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0368, Accumulated: 0.1772, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0184, Accumulated: 0.1956, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0203, Accumulated: 0.2159, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0171, Accumulated: 0.2330, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0223, Accumulated: 0.2553, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0304, Accumulated: 0.2857, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1230, Accumulated: 0.4086, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1627, Accumulated: 0.5713, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1474, Accumulated: 0.7187, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1551, Accumulated: 0.8738, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0102, Accumulated: 0.0102, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0085, Accumulated: 0.0187, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0125, Accumulated: 0.0312, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0973, Accumulated: 0.1286, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0193, Accumulated: 0.1479, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0101, Accumulated: 0.1579, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0080, Accumulated: 0.1659, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0549, Accumulated: 0.2208, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0805, Accumulated: 0.3014, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6905, Accumulated: 0.9918, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0999, Accumulated: 0.0999, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0465, Accumulated: 0.1464, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0257, Accumulated: 0.1722, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0251, Accumulated: 0.1973, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0206, Accumulated: 0.2179, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0195, Accumulated: 0.2373, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0225, Accumulated: 0.2599, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0672, Accumulated: 0.3270, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1368, Accumulated: 0.4638, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1724, Accumulated: 0.6362, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1927, Accumulated: 0.8289, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1250, Accumulated: 0.9539, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0125, Accumulated: 0.0125, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0160, Accumulated: 0.0286, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0063, Accumulated: 0.0349, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0205, Accumulated: 0.0554, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0126, Accumulated: 0.0681, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0111, Accumulated: 0.0791, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0240, Accumulated: 0.1032, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0654, Accumulated: 0.1685, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0725, Accumulated: 0.2410, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7408, Accumulated: 0.9818, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0410, Accumulated: 0.0410, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0371, Accumulated: 0.0782, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0218, Accumulated: 0.1000, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0176, Accumulated: 0.1176, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0187, Accumulated: 0.1363, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0248, Accumulated: 0.1611, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0239, Accumulated: 0.1849, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0769, Accumulated: 0.2618, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0782, Accumulated: 0.3400, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1312, Accumulated: 0.4713, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1890, Accumulated: 0.6602, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.2200, Accumulated: 0.8802, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0132, Accumulated: 0.0132, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0054, Accumulated: 0.0186, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0073, Accumulated: 0.0259, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0157, Accumulated: 0.0416, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0068, Accumulated: 0.0484, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0174, Accumulated: 0.0657, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0184, Accumulated: 0.0842, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.5621, Accumulated: 0.6463, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1611, Accumulated: 0.8073, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1924, Accumulated: 0.9997, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2676, Accumulated: 0.2676, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1070, Accumulated: 0.3746, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0608, Accumulated: 0.4354, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0499, Accumulated: 0.4853, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0387, Accumulated: 0.5239, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0462, Accumulated: 0.5701, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0449, Accumulated: 0.6150, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0799, Accumulated: 0.6948, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0923, Accumulated: 0.7871, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0814, Accumulated: 0.8686, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.0123, Accumulated: 0.0123, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0053, Accumulated: 0.0175, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0153, Accumulated: 0.0328, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0215, Accumulated: 0.0543, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0329, Accumulated: 0.0872, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0111, Accumulated: 0.0983, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0066, Accumulated: 0.1049, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0323, Accumulated: 0.1372, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0207, Accumulated: 0.1579, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8356, Accumulated: 0.9934, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2448, Accumulated: 0.2448, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1127, Accumulated: 0.3574, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0755, Accumulated: 0.4330, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0560, Accumulated: 0.4890, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0431, Accumulated: 0.5321, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0432, Accumulated: 0.5753, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0543, Accumulated: 0.6296, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0928, Accumulated: 0.7224, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1078, Accumulated: 0.8301, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0787, Accumulated: 0.9089, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.3684, Accumulated: 0.3684, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0712, Accumulated: 0.4396, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0173, Accumulated: 0.4570, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0288, Accumulated: 0.4858, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0125, Accumulated: 0.4983, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0101, Accumulated: 0.5084, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0086, Accumulated: 0.5170, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0845, Accumulated: 0.6016, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0462, Accumulated: 0.6477, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1156, Accumulated: 0.7633, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0139, Accumulated: 0.7772, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.0887, Accumulated: 0.8659, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.3162, Accumulated: 0.3162, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0794, Accumulated: 0.3955, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0092, Accumulated: 0.4048, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0274, Accumulated: 0.4322, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0235, Accumulated: 0.4557, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0086, Accumulated: 0.4643, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0115, Accumulated: 0.4759, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0240, Accumulated: 0.4999, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0211, Accumulated: 0.5209, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1319, Accumulated: 0.6529, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0267, Accumulated: 0.6796, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1354, Accumulated: 0.8150, Threshold: 0.8500\n",
            "Layer 16/16: Halt prob: 0.0321, Accumulated: 0.8471, Threshold: 0.8500\n",
            "Layer 4/16: Halt prob: 0.2139, Accumulated: 0.2139, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0344, Accumulated: 0.2483, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0334, Accumulated: 0.2817, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0452, Accumulated: 0.3269, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0063, Accumulated: 0.3331, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.3471, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0119, Accumulated: 0.3590, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0169, Accumulated: 0.3759, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0539, Accumulated: 0.4297, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1162, Accumulated: 0.5459, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0963, Accumulated: 0.6422, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.2481, Accumulated: 0.8903, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0540, Accumulated: 0.0540, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0192, Accumulated: 0.0732, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0310, Accumulated: 0.1042, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0133, Accumulated: 0.1175, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0171, Accumulated: 0.1346, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0103, Accumulated: 0.1449, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0041, Accumulated: 0.1490, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0278, Accumulated: 0.1767, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0960, Accumulated: 0.2727, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1987, Accumulated: 0.4714, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1067, Accumulated: 0.5781, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.2311, Accumulated: 0.8093, Threshold: 0.8500\n",
            "Layer 16/16: Halt prob: 0.0677, Accumulated: 0.8769, Threshold: 0.8500\n",
            "Early exit at layer 16/16\n",
            "Layer 4/16: Halt prob: 0.0211, Accumulated: 0.0211, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0195, Accumulated: 0.0406, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0252, Accumulated: 0.0658, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0157, Accumulated: 0.0815, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0940, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0046, Accumulated: 0.0985, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0114, Accumulated: 0.1099, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0970, Accumulated: 0.2069, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1985, Accumulated: 0.4054, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.2230, Accumulated: 0.6283, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0678, Accumulated: 0.6962, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1589, Accumulated: 0.8551, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Extracted: prediction=None, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2220, Accumulated: 0.2220, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1054, Accumulated: 0.3275, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0564, Accumulated: 0.3839, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0535, Accumulated: 0.4374, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0461, Accumulated: 0.4835, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0506, Accumulated: 0.5341, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0550, Accumulated: 0.5891, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0892, Accumulated: 0.6783, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1065, Accumulated: 0.7848, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0917, Accumulated: 0.8765, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.0147, Accumulated: 0.0147, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0105, Accumulated: 0.0252, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0070, Accumulated: 0.0322, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0123, Accumulated: 0.0445, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0109, Accumulated: 0.0554, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0091, Accumulated: 0.0645, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0160, Accumulated: 0.0805, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0802, Accumulated: 0.1607, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0768, Accumulated: 0.2376, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7595, Accumulated: 0.9970, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1671, Accumulated: 0.1671, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0561, Accumulated: 0.2232, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0242, Accumulated: 0.2474, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0256, Accumulated: 0.2730, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0285, Accumulated: 0.3015, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0310, Accumulated: 0.3325, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0257, Accumulated: 0.3582, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0910, Accumulated: 0.4491, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1138, Accumulated: 0.5630, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1613, Accumulated: 0.7243, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1320, Accumulated: 0.8563, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0078, Accumulated: 0.0078, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0299, Accumulated: 0.0377, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0286, Accumulated: 0.0662, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0122, Accumulated: 0.0784, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0061, Accumulated: 0.0845, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0102, Accumulated: 0.0947, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0194, Accumulated: 0.1141, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0984, Accumulated: 0.2125, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1063, Accumulated: 0.3189, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6725, Accumulated: 0.9914, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0439, Accumulated: 0.0439, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0195, Accumulated: 0.0634, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0178, Accumulated: 0.0811, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0202, Accumulated: 0.1014, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0191, Accumulated: 0.1205, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0214, Accumulated: 0.1419, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0191, Accumulated: 0.1610, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0490, Accumulated: 0.2100, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0554, Accumulated: 0.2653, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1132, Accumulated: 0.3785, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.2023, Accumulated: 0.5808, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.2778, Accumulated: 0.8585, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0149, Accumulated: 0.0149, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0079, Accumulated: 0.0229, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0083, Accumulated: 0.0312, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0141, Accumulated: 0.0453, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0054, Accumulated: 0.0507, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0159, Accumulated: 0.0666, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0226, Accumulated: 0.0892, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0962, Accumulated: 0.1854, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0612, Accumulated: 0.2466, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7486, Accumulated: 0.9952, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1697, Accumulated: 0.1697, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0401, Accumulated: 0.2098, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0290, Accumulated: 0.2388, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0166, Accumulated: 0.2554, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0156, Accumulated: 0.2710, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0190, Accumulated: 0.2900, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0271, Accumulated: 0.3171, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1051, Accumulated: 0.4222, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1280, Accumulated: 0.5502, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1348, Accumulated: 0.6851, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1429, Accumulated: 0.8279, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1022, Accumulated: 0.9301, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0228, Accumulated: 0.0228, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0200, Accumulated: 0.0428, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0214, Accumulated: 0.0642, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0090, Accumulated: 0.0732, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0804, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0076, Accumulated: 0.0880, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0168, Accumulated: 0.1048, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0466, Accumulated: 0.1514, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0816, Accumulated: 0.2331, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7587, Accumulated: 0.9918, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1724, Accumulated: 0.1724, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0618, Accumulated: 0.2341, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0339, Accumulated: 0.2681, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0292, Accumulated: 0.2973, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0182, Accumulated: 0.3154, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0244, Accumulated: 0.3398, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0311, Accumulated: 0.3710, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0771, Accumulated: 0.4481, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1342, Accumulated: 0.5823, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1622, Accumulated: 0.7445, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1211, Accumulated: 0.8657, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0158, Accumulated: 0.0158, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0184, Accumulated: 0.0342, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0184, Accumulated: 0.0525, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0721, Accumulated: 0.1246, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.1338, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0086, Accumulated: 0.1423, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0107, Accumulated: 0.1530, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0321, Accumulated: 0.1852, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0332, Accumulated: 0.2184, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7728, Accumulated: 0.9912, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1246, Accumulated: 0.1246, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0471, Accumulated: 0.1717, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0353, Accumulated: 0.2070, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0141, Accumulated: 0.2211, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0156, Accumulated: 0.2367, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0280, Accumulated: 0.2647, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0311, Accumulated: 0.2958, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1001, Accumulated: 0.3958, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1191, Accumulated: 0.5149, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1611, Accumulated: 0.6760, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1531, Accumulated: 0.8291, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1250, Accumulated: 0.9541, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0137, Accumulated: 0.0137, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0093, Accumulated: 0.0230, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0075, Accumulated: 0.0305, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0672, Accumulated: 0.0977, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0078, Accumulated: 0.1055, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0118, Accumulated: 0.1174, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0275, Accumulated: 0.1448, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.3808, Accumulated: 0.5256, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1102, Accumulated: 0.6358, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.3626, Accumulated: 0.9984, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0359, Accumulated: 0.0359, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0263, Accumulated: 0.0622, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0144, Accumulated: 0.0766, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0165, Accumulated: 0.0931, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0137, Accumulated: 0.1068, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0160, Accumulated: 0.1227, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0296, Accumulated: 0.1524, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0544, Accumulated: 0.2068, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0579, Accumulated: 0.2647, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1049, Accumulated: 0.3696, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.3444, Accumulated: 0.7141, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.2231, Accumulated: 0.9372, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0103, Accumulated: 0.0103, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0077, Accumulated: 0.0180, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0044, Accumulated: 0.0224, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0974, Accumulated: 0.1199, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0034, Accumulated: 0.1232, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0210, Accumulated: 0.1442, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0232, Accumulated: 0.1673, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0815, Accumulated: 0.2489, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0474, Accumulated: 0.2962, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6959, Accumulated: 0.9921, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1032, Accumulated: 0.1032, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0335, Accumulated: 0.1367, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0299, Accumulated: 0.1667, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0152, Accumulated: 0.1818, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0139, Accumulated: 0.1957, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0173, Accumulated: 0.2130, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0242, Accumulated: 0.2371, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0675, Accumulated: 0.3046, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0869, Accumulated: 0.3915, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1399, Accumulated: 0.5314, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1860, Accumulated: 0.7174, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1835, Accumulated: 0.9009, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0174, Accumulated: 0.0174, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0314, Accumulated: 0.0488, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0084, Accumulated: 0.0572, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0115, Accumulated: 0.0687, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0092, Accumulated: 0.0778, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0110, Accumulated: 0.0889, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0119, Accumulated: 0.1007, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0212, Accumulated: 0.1220, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0105, Accumulated: 0.1324, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8519, Accumulated: 0.9843, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1283, Accumulated: 0.1283, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0640, Accumulated: 0.1923, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0633, Accumulated: 0.2556, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0466, Accumulated: 0.3023, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0375, Accumulated: 0.3398, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0415, Accumulated: 0.3813, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0396, Accumulated: 0.4209, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0903, Accumulated: 0.5112, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1459, Accumulated: 0.6572, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1423, Accumulated: 0.7995, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1075, Accumulated: 0.9070, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0091, Accumulated: 0.0091, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0060, Accumulated: 0.0150, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0101, Accumulated: 0.0252, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0470, Accumulated: 0.0722, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0047, Accumulated: 0.0769, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0182, Accumulated: 0.0951, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0148, Accumulated: 0.1099, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1190, Accumulated: 0.2289, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0567, Accumulated: 0.2855, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7061, Accumulated: 0.9916, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0646, Accumulated: 0.0646, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0368, Accumulated: 0.1015, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0307, Accumulated: 0.1321, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0170, Accumulated: 0.1491, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0187, Accumulated: 0.1678, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0199, Accumulated: 0.1877, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0195, Accumulated: 0.2073, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0512, Accumulated: 0.2585, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1283, Accumulated: 0.3869, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1527, Accumulated: 0.5396, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1981, Accumulated: 0.7376, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1769, Accumulated: 0.9145, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0166, Accumulated: 0.0166, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0074, Accumulated: 0.0240, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0138, Accumulated: 0.0378, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0455, Accumulated: 0.0832, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0055, Accumulated: 0.0887, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0088, Accumulated: 0.0975, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0417, Accumulated: 0.1391, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0381, Accumulated: 0.1773, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0179, Accumulated: 0.1952, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7875, Accumulated: 0.9827, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2020, Accumulated: 0.2020, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0934, Accumulated: 0.2954, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0639, Accumulated: 0.3593, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0534, Accumulated: 0.4127, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0413, Accumulated: 0.4540, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0460, Accumulated: 0.5000, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0487, Accumulated: 0.5488, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0907, Accumulated: 0.6395, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1142, Accumulated: 0.7537, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0896, Accumulated: 0.8434, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0766, Accumulated: 0.9200, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0137, Accumulated: 0.0137, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0270, Accumulated: 0.0406, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0138, Accumulated: 0.0544, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0311, Accumulated: 0.0856, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0223, Accumulated: 0.1079, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0091, Accumulated: 0.1170, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0408, Accumulated: 0.1578, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.2457, Accumulated: 0.4035, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1145, Accumulated: 0.5180, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.4792, Accumulated: 0.9972, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1753, Accumulated: 0.1753, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0753, Accumulated: 0.2505, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0575, Accumulated: 0.3080, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0503, Accumulated: 0.3583, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0404, Accumulated: 0.3987, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0461, Accumulated: 0.4448, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0489, Accumulated: 0.4936, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0930, Accumulated: 0.5867, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1114, Accumulated: 0.6981, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1189, Accumulated: 0.8170, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1109, Accumulated: 0.9279, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0117, Accumulated: 0.0117, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0069, Accumulated: 0.0186, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0105, Accumulated: 0.0291, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0767, Accumulated: 0.1058, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0088, Accumulated: 0.1147, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0063, Accumulated: 0.1210, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0099, Accumulated: 0.1308, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0410, Accumulated: 0.1718, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0311, Accumulated: 0.2030, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7811, Accumulated: 0.9840, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1569, Accumulated: 0.1569, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0407, Accumulated: 0.1975, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0236, Accumulated: 0.2211, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0205, Accumulated: 0.2416, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0192, Accumulated: 0.2607, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0265, Accumulated: 0.2872, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0243, Accumulated: 0.3115, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0558, Accumulated: 0.3673, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0880, Accumulated: 0.4554, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1046, Accumulated: 0.5600, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1855, Accumulated: 0.7455, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1361, Accumulated: 0.8816, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0109, Accumulated: 0.0109, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0116, Accumulated: 0.0225, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0072, Accumulated: 0.0297, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0271, Accumulated: 0.0568, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0111, Accumulated: 0.0679, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0163, Accumulated: 0.0842, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0083, Accumulated: 0.0924, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1068, Accumulated: 0.1992, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0693, Accumulated: 0.2685, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7218, Accumulated: 0.9904, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0473, Accumulated: 0.0473, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0248, Accumulated: 0.0721, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0220, Accumulated: 0.0941, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0170, Accumulated: 0.1111, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0194, Accumulated: 0.1306, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0160, Accumulated: 0.1466, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0219, Accumulated: 0.1685, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0491, Accumulated: 0.2176, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0861, Accumulated: 0.3037, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1631, Accumulated: 0.4668, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.2181, Accumulated: 0.6848, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.2165, Accumulated: 0.9014, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0148, Accumulated: 0.0148, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0098, Accumulated: 0.0245, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0177, Accumulated: 0.0422, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0458, Accumulated: 0.0881, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0084, Accumulated: 0.0965, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0068, Accumulated: 0.1033, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0116, Accumulated: 0.1149, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0413, Accumulated: 0.1562, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0298, Accumulated: 0.1860, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8049, Accumulated: 0.9909, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2173, Accumulated: 0.2173, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0891, Accumulated: 0.3064, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0685, Accumulated: 0.3749, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0463, Accumulated: 0.4212, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0436, Accumulated: 0.4649, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0419, Accumulated: 0.5067, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0319, Accumulated: 0.5386, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0720, Accumulated: 0.6106, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0945, Accumulated: 0.7051, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0968, Accumulated: 0.8019, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0974, Accumulated: 0.8993, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0093, Accumulated: 0.0093, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0072, Accumulated: 0.0165, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0140, Accumulated: 0.0305, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0798, Accumulated: 0.1103, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0144, Accumulated: 0.1248, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0156, Accumulated: 0.1403, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0369, Accumulated: 0.1772, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0170, Accumulated: 0.1942, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0174, Accumulated: 0.2116, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7595, Accumulated: 0.9711, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0615, Accumulated: 0.0615, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0379, Accumulated: 0.0994, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0300, Accumulated: 0.1294, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0188, Accumulated: 0.1482, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0256, Accumulated: 0.1738, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0370, Accumulated: 0.2108, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0392, Accumulated: 0.2500, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0831, Accumulated: 0.3332, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1047, Accumulated: 0.4378, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1574, Accumulated: 0.5953, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1956, Accumulated: 0.7909, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1506, Accumulated: 0.9415, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0186, Accumulated: 0.0186, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0408, Accumulated: 0.0594, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0211, Accumulated: 0.0805, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0070, Accumulated: 0.0875, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0128, Accumulated: 0.1003, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0144, Accumulated: 0.1147, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0098, Accumulated: 0.1245, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0410, Accumulated: 0.1655, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0461, Accumulated: 0.2116, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7765, Accumulated: 0.9881, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2172, Accumulated: 0.2172, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0753, Accumulated: 0.2925, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0484, Accumulated: 0.3408, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0385, Accumulated: 0.3793, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0348, Accumulated: 0.4141, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0440, Accumulated: 0.4581, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0585, Accumulated: 0.5166, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1010, Accumulated: 0.6176, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1338, Accumulated: 0.7514, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1002, Accumulated: 0.8516, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.0194, Accumulated: 0.0194, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0105, Accumulated: 0.0300, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0043, Accumulated: 0.0343, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0129, Accumulated: 0.0471, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0146, Accumulated: 0.0618, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0178, Accumulated: 0.0795, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0151, Accumulated: 0.0946, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0136, Accumulated: 0.1082, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0144, Accumulated: 0.1227, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8568, Accumulated: 0.9794, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1770, Accumulated: 0.1770, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0668, Accumulated: 0.2438, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0433, Accumulated: 0.2871, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0416, Accumulated: 0.3287, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0310, Accumulated: 0.3597, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0329, Accumulated: 0.3926, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0488, Accumulated: 0.4414, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0968, Accumulated: 0.5382, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1378, Accumulated: 0.6760, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1259, Accumulated: 0.8019, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0972, Accumulated: 0.8991, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0181, Accumulated: 0.0181, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0116, Accumulated: 0.0297, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0085, Accumulated: 0.0382, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0146, Accumulated: 0.0528, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0085, Accumulated: 0.0613, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0238, Accumulated: 0.0851, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0117, Accumulated: 0.0968, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0269, Accumulated: 0.1237, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0176, Accumulated: 0.1413, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8406, Accumulated: 0.9820, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1757, Accumulated: 0.1757, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0751, Accumulated: 0.2508, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0614, Accumulated: 0.3122, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0399, Accumulated: 0.3521, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0439, Accumulated: 0.3959, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0473, Accumulated: 0.4432, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0522, Accumulated: 0.4954, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1016, Accumulated: 0.5970, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1128, Accumulated: 0.7097, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0875, Accumulated: 0.7972, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0851, Accumulated: 0.8824, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0094, Accumulated: 0.0094, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0118, Accumulated: 0.0212, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0075, Accumulated: 0.0287, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.2183, Accumulated: 0.2470, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0118, Accumulated: 0.2588, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0079, Accumulated: 0.2668, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0181, Accumulated: 0.2848, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1083, Accumulated: 0.3931, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0806, Accumulated: 0.4737, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.5214, Accumulated: 0.9951, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0517, Accumulated: 0.0517, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0331, Accumulated: 0.0848, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0285, Accumulated: 0.1133, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0216, Accumulated: 0.1350, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0235, Accumulated: 0.1585, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0290, Accumulated: 0.1875, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0235, Accumulated: 0.2110, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0611, Accumulated: 0.2720, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0565, Accumulated: 0.3285, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1271, Accumulated: 0.4557, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.2089, Accumulated: 0.6646, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.2363, Accumulated: 0.9009, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0111, Accumulated: 0.0111, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0081, Accumulated: 0.0191, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0062, Accumulated: 0.0253, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.1012, Accumulated: 0.1265, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0137, Accumulated: 0.1402, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0089, Accumulated: 0.1491, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0092, Accumulated: 0.1583, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0158, Accumulated: 0.1741, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0123, Accumulated: 0.1864, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7878, Accumulated: 0.9742, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0920, Accumulated: 0.0920, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0480, Accumulated: 0.1400, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0236, Accumulated: 0.1636, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0220, Accumulated: 0.1856, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0196, Accumulated: 0.2052, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0220, Accumulated: 0.2272, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0299, Accumulated: 0.2572, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0724, Accumulated: 0.3295, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1089, Accumulated: 0.4384, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1233, Accumulated: 0.5617, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.2143, Accumulated: 0.7760, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1494, Accumulated: 0.9254, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0110, Accumulated: 0.0110, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0289, Accumulated: 0.0400, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0162, Accumulated: 0.0561, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0104, Accumulated: 0.0665, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0107, Accumulated: 0.0772, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0098, Accumulated: 0.0870, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0513, Accumulated: 0.1383, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.3814, Accumulated: 0.5197, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1076, Accumulated: 0.6274, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.3701, Accumulated: 0.9975, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1284, Accumulated: 0.1284, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0441, Accumulated: 0.1725, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0276, Accumulated: 0.2001, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0320, Accumulated: 0.2320, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0233, Accumulated: 0.2553, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0299, Accumulated: 0.2852, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0307, Accumulated: 0.3160, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1223, Accumulated: 0.4383, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1587, Accumulated: 0.5970, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1486, Accumulated: 0.7455, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1288, Accumulated: 0.8744, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0122, Accumulated: 0.0122, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0077, Accumulated: 0.0198, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0098, Accumulated: 0.0297, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0164, Accumulated: 0.0460, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0081, Accumulated: 0.0542, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0093, Accumulated: 0.0635, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0133, Accumulated: 0.0768, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0217, Accumulated: 0.0985, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0317, Accumulated: 0.1302, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8630, Accumulated: 0.9932, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0919, Accumulated: 0.0919, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0542, Accumulated: 0.1461, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0176, Accumulated: 0.1637, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0150, Accumulated: 0.1787, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0135, Accumulated: 0.1922, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0201, Accumulated: 0.2122, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0251, Accumulated: 0.2374, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0637, Accumulated: 0.3011, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0755, Accumulated: 0.3765, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1445, Accumulated: 0.5211, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1780, Accumulated: 0.6990, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1714, Accumulated: 0.8704, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0149, Accumulated: 0.0149, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0081, Accumulated: 0.0230, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0063, Accumulated: 0.0293, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0672, Accumulated: 0.0965, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.1056, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0182, Accumulated: 0.1238, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0116, Accumulated: 0.1354, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0129, Accumulated: 0.1483, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0089, Accumulated: 0.1572, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8057, Accumulated: 0.9630, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2028, Accumulated: 0.2028, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0864, Accumulated: 0.2891, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0450, Accumulated: 0.3342, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0345, Accumulated: 0.3686, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0244, Accumulated: 0.3931, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0321, Accumulated: 0.4252, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0498, Accumulated: 0.4750, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1078, Accumulated: 0.5828, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1430, Accumulated: 0.7258, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1147, Accumulated: 0.8405, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0846, Accumulated: 0.9251, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0122, Accumulated: 0.0122, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0122, Accumulated: 0.0245, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0093, Accumulated: 0.0337, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0148, Accumulated: 0.0486, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0039, Accumulated: 0.0525, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0136, Accumulated: 0.0661, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0098, Accumulated: 0.0759, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0354, Accumulated: 0.1113, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0383, Accumulated: 0.1497, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8482, Accumulated: 0.9979, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0925, Accumulated: 0.0925, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0372, Accumulated: 0.1296, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0317, Accumulated: 0.1613, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0315, Accumulated: 0.1928, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0287, Accumulated: 0.2216, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0385, Accumulated: 0.2600, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0697, Accumulated: 0.3298, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1010, Accumulated: 0.4307, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1193, Accumulated: 0.5500, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1370, Accumulated: 0.6870, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1369, Accumulated: 0.8240, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1090, Accumulated: 0.9330, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0111, Accumulated: 0.0111, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0056, Accumulated: 0.0167, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0098, Accumulated: 0.0265, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0164, Accumulated: 0.0429, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0097, Accumulated: 0.0526, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0197, Accumulated: 0.0722, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0084, Accumulated: 0.0806, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0242, Accumulated: 0.1049, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0384, Accumulated: 0.1433, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8500, Accumulated: 0.9933, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1333, Accumulated: 0.1333, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0499, Accumulated: 0.1832, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0471, Accumulated: 0.2303, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0262, Accumulated: 0.2565, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0249, Accumulated: 0.2814, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0243, Accumulated: 0.3057, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0425, Accumulated: 0.3482, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0848, Accumulated: 0.4331, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1203, Accumulated: 0.5533, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1369, Accumulated: 0.6902, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1324, Accumulated: 0.8226, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1197, Accumulated: 0.9423, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0112, Accumulated: 0.0112, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0087, Accumulated: 0.0200, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0169, Accumulated: 0.0368, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0130, Accumulated: 0.0499, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0190, Accumulated: 0.0689, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0134, Accumulated: 0.0823, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0101, Accumulated: 0.0923, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0180, Accumulated: 0.1104, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0222, Accumulated: 0.1326, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8636, Accumulated: 0.9962, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1881, Accumulated: 0.1881, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0726, Accumulated: 0.2608, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0481, Accumulated: 0.3089, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0467, Accumulated: 0.3556, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0379, Accumulated: 0.3935, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0520, Accumulated: 0.4454, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0584, Accumulated: 0.5039, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1036, Accumulated: 0.6074, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1351, Accumulated: 0.7426, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0997, Accumulated: 0.8422, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0723, Accumulated: 0.9145, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0120, Accumulated: 0.0120, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0278, Accumulated: 0.0399, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0108, Accumulated: 0.0507, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0154, Accumulated: 0.0661, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.0752, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0156, Accumulated: 0.0908, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0066, Accumulated: 0.0974, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0195, Accumulated: 0.1169, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0170, Accumulated: 0.1339, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8568, Accumulated: 0.9907, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2006, Accumulated: 0.2006, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0803, Accumulated: 0.2809, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0688, Accumulated: 0.3497, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0510, Accumulated: 0.4007, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0369, Accumulated: 0.4376, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0482, Accumulated: 0.4858, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0382, Accumulated: 0.5240, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0795, Accumulated: 0.6036, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1086, Accumulated: 0.7122, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0918, Accumulated: 0.8039, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0956, Accumulated: 0.8996, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0114, Accumulated: 0.0114, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0110, Accumulated: 0.0224, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0196, Accumulated: 0.0420, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.1133, Accumulated: 0.1552, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0116, Accumulated: 0.1668, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0080, Accumulated: 0.1749, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0282, Accumulated: 0.2031, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0398, Accumulated: 0.2429, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0722, Accumulated: 0.3151, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6815, Accumulated: 0.9967, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2172, Accumulated: 0.2172, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1034, Accumulated: 0.3206, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0529, Accumulated: 0.3734, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0377, Accumulated: 0.4111, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0316, Accumulated: 0.4427, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0423, Accumulated: 0.4850, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0479, Accumulated: 0.5329, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0932, Accumulated: 0.6260, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1317, Accumulated: 0.7578, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1057, Accumulated: 0.8635, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.0108, Accumulated: 0.0108, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0073, Accumulated: 0.0182, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0061, Accumulated: 0.0243, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0120, Accumulated: 0.0362, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0122, Accumulated: 0.0484, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0060, Accumulated: 0.0544, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0089, Accumulated: 0.0633, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0137, Accumulated: 0.0770, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0277, Accumulated: 0.1047, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8769, Accumulated: 0.9816, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1953, Accumulated: 0.1953, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0825, Accumulated: 0.2778, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0413, Accumulated: 0.3191, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0401, Accumulated: 0.3592, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0345, Accumulated: 0.3937, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0348, Accumulated: 0.4285, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0517, Accumulated: 0.4802, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1053, Accumulated: 0.5854, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1271, Accumulated: 0.7126, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1061, Accumulated: 0.8187, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0895, Accumulated: 0.9081, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0212, Accumulated: 0.0212, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0185, Accumulated: 0.0397, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0095, Accumulated: 0.0492, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0107, Accumulated: 0.0599, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0062, Accumulated: 0.0660, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0134, Accumulated: 0.0794, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0168, Accumulated: 0.0963, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1808, Accumulated: 0.2771, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1052, Accumulated: 0.3823, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6162, Accumulated: 0.9985, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1207, Accumulated: 0.1207, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0735, Accumulated: 0.1942, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0255, Accumulated: 0.2197, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0176, Accumulated: 0.2373, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0164, Accumulated: 0.2536, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0307, Accumulated: 0.2843, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0305, Accumulated: 0.3148, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0767, Accumulated: 0.3915, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1503, Accumulated: 0.5418, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1483, Accumulated: 0.6901, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1462, Accumulated: 0.8364, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.0952, Accumulated: 0.9316, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0100, Accumulated: 0.0100, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0079, Accumulated: 0.0179, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0084, Accumulated: 0.0262, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0307, Accumulated: 0.0569, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0067, Accumulated: 0.0637, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0181, Accumulated: 0.0818, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0151, Accumulated: 0.0969, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.3916, Accumulated: 0.4885, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1511, Accumulated: 0.6396, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.3593, Accumulated: 0.9989, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2139, Accumulated: 0.2139, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1082, Accumulated: 0.3221, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0716, Accumulated: 0.3937, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0662, Accumulated: 0.4600, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0521, Accumulated: 0.5121, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0574, Accumulated: 0.5695, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0452, Accumulated: 0.6147, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0592, Accumulated: 0.6738, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0661, Accumulated: 0.7400, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0708, Accumulated: 0.8108, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0810, Accumulated: 0.8917, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0121, Accumulated: 0.0121, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0067, Accumulated: 0.0189, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0085, Accumulated: 0.0274, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0662, Accumulated: 0.0935, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0091, Accumulated: 0.1027, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0181, Accumulated: 0.1208, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0098, Accumulated: 0.1306, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0347, Accumulated: 0.1653, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0399, Accumulated: 0.2052, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7878, Accumulated: 0.9930, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1514, Accumulated: 0.1514, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0641, Accumulated: 0.2154, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0316, Accumulated: 0.2470, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0252, Accumulated: 0.2722, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0192, Accumulated: 0.2915, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0303, Accumulated: 0.3218, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0287, Accumulated: 0.3506, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0784, Accumulated: 0.4289, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1143, Accumulated: 0.5432, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1335, Accumulated: 0.6767, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1442, Accumulated: 0.8209, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1041, Accumulated: 0.9250, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0157, Accumulated: 0.0157, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0249, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0069, Accumulated: 0.0319, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0155, Accumulated: 0.0473, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0067, Accumulated: 0.0541, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0143, Accumulated: 0.0683, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0054, Accumulated: 0.0737, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0064, Accumulated: 0.0801, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0274, Accumulated: 0.1075, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8102, Accumulated: 0.9176, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1678, Accumulated: 0.1678, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0538, Accumulated: 0.2216, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0543, Accumulated: 0.2760, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0312, Accumulated: 0.3072, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0253, Accumulated: 0.3325, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0253, Accumulated: 0.3578, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0373, Accumulated: 0.3951, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1195, Accumulated: 0.5145, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1522, Accumulated: 0.6667, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1144, Accumulated: 0.7811, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1007, Accumulated: 0.8819, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0170, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0058, Accumulated: 0.0228, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0391, Accumulated: 0.0619, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0075, Accumulated: 0.0694, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0186, Accumulated: 0.0880, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0174, Accumulated: 0.1054, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0475, Accumulated: 0.1528, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0148, Accumulated: 0.1676, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8117, Accumulated: 0.9793, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1333, Accumulated: 0.1333, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0599, Accumulated: 0.1932, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0412, Accumulated: 0.2344, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0310, Accumulated: 0.2654, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0300, Accumulated: 0.2954, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0340, Accumulated: 0.3294, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0323, Accumulated: 0.3617, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0489, Accumulated: 0.4106, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1144, Accumulated: 0.5250, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1392, Accumulated: 0.6642, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1507, Accumulated: 0.8149, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1076, Accumulated: 0.9224, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0158, Accumulated: 0.0158, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0119, Accumulated: 0.0277, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0048, Accumulated: 0.0324, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.1168, Accumulated: 0.1492, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0053, Accumulated: 0.1545, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0448, Accumulated: 0.1993, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0099, Accumulated: 0.2092, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0812, Accumulated: 0.2904, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0582, Accumulated: 0.3486, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6422, Accumulated: 0.9908, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2139, Accumulated: 0.2139, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0562, Accumulated: 0.2701, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0210, Accumulated: 0.2911, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0236, Accumulated: 0.3147, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0148, Accumulated: 0.3295, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0269, Accumulated: 0.3564, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0628, Accumulated: 0.4192, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1205, Accumulated: 0.5397, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1197, Accumulated: 0.6594, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1272, Accumulated: 0.7865, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1078, Accumulated: 0.8943, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0134, Accumulated: 0.0134, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0491, Accumulated: 0.0625, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0176, Accumulated: 0.0800, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0054, Accumulated: 0.0854, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0168, Accumulated: 0.1022, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0071, Accumulated: 0.1094, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0099, Accumulated: 0.1192, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1337, Accumulated: 0.2530, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0815, Accumulated: 0.3345, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6502, Accumulated: 0.9847, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1088, Accumulated: 0.1088, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0407, Accumulated: 0.1495, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0187, Accumulated: 0.1682, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0176, Accumulated: 0.1858, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0189, Accumulated: 0.2047, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0240, Accumulated: 0.2287, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0259, Accumulated: 0.2546, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0652, Accumulated: 0.3198, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1108, Accumulated: 0.4307, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1540, Accumulated: 0.5847, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1790, Accumulated: 0.7636, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1440, Accumulated: 0.9077, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0153, Accumulated: 0.0153, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0066, Accumulated: 0.0218, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0070, Accumulated: 0.0288, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0477, Accumulated: 0.0766, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0076, Accumulated: 0.0842, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0195, Accumulated: 0.1037, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0074, Accumulated: 0.1111, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1977, Accumulated: 0.3088, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0696, Accumulated: 0.3784, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6022, Accumulated: 0.9806, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1650, Accumulated: 0.1650, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0671, Accumulated: 0.2321, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0333, Accumulated: 0.2654, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0244, Accumulated: 0.2898, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0158, Accumulated: 0.3056, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0376, Accumulated: 0.3432, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0457, Accumulated: 0.3889, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1076, Accumulated: 0.4966, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1277, Accumulated: 0.6243, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1302, Accumulated: 0.7544, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1137, Accumulated: 0.8681, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0113, Accumulated: 0.0113, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0088, Accumulated: 0.0201, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0095, Accumulated: 0.0296, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.1468, Accumulated: 0.1764, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0064, Accumulated: 0.1828, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0109, Accumulated: 0.1937, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0114, Accumulated: 0.2050, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.2096, Accumulated: 0.4147, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1961, Accumulated: 0.6107, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.3889, Accumulated: 0.9996, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1282, Accumulated: 0.1282, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0504, Accumulated: 0.1786, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0207, Accumulated: 0.1993, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0178, Accumulated: 0.2171, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0134, Accumulated: 0.2305, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0228, Accumulated: 0.2533, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0329, Accumulated: 0.2862, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1040, Accumulated: 0.3901, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1423, Accumulated: 0.5325, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1364, Accumulated: 0.6689, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1555, Accumulated: 0.8244, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1150, Accumulated: 0.9394, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0093, Accumulated: 0.0093, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0093, Accumulated: 0.0186, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0091, Accumulated: 0.0276, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0242, Accumulated: 0.0518, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0135, Accumulated: 0.0653, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0219, Accumulated: 0.0873, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0286, Accumulated: 0.1158, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1236, Accumulated: 0.2394, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0663, Accumulated: 0.3057, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6818, Accumulated: 0.9875, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2142, Accumulated: 0.2142, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0755, Accumulated: 0.2898, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0458, Accumulated: 0.3355, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0364, Accumulated: 0.3719, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0306, Accumulated: 0.4026, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0333, Accumulated: 0.4358, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0373, Accumulated: 0.4732, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0657, Accumulated: 0.5389, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0903, Accumulated: 0.6292, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1275, Accumulated: 0.7566, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0961, Accumulated: 0.8527, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0155, Accumulated: 0.0155, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0247, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0173, Accumulated: 0.0420, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0285, Accumulated: 0.0705, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0097, Accumulated: 0.0803, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0324, Accumulated: 0.1126, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0108, Accumulated: 0.1235, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0177, Accumulated: 0.1411, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0163, Accumulated: 0.1574, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8344, Accumulated: 0.9918, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1440, Accumulated: 0.1440, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0741, Accumulated: 0.2182, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0565, Accumulated: 0.2747, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0446, Accumulated: 0.3192, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0477, Accumulated: 0.3669, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0396, Accumulated: 0.4065, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0498, Accumulated: 0.4563, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0813, Accumulated: 0.5376, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1153, Accumulated: 0.6529, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1233, Accumulated: 0.7762, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1310, Accumulated: 0.9072, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0173, Accumulated: 0.0173, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0064, Accumulated: 0.0236, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0060, Accumulated: 0.0297, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0255, Accumulated: 0.0552, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0067, Accumulated: 0.0618, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0151, Accumulated: 0.0769, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0154, Accumulated: 0.0923, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0280, Accumulated: 0.1204, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0301, Accumulated: 0.1505, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8475, Accumulated: 0.9979, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0776, Accumulated: 0.0776, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0551, Accumulated: 0.1328, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0415, Accumulated: 0.1743, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0423, Accumulated: 0.2166, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0320, Accumulated: 0.2486, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0369, Accumulated: 0.2854, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0390, Accumulated: 0.3244, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0508, Accumulated: 0.3752, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0619, Accumulated: 0.4371, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0986, Accumulated: 0.5357, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1408, Accumulated: 0.6765, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.2330, Accumulated: 0.9095, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0280, Accumulated: 0.0280, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0229, Accumulated: 0.0509, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0141, Accumulated: 0.0650, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0109, Accumulated: 0.0758, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0119, Accumulated: 0.0877, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0088, Accumulated: 0.0965, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0111, Accumulated: 0.1076, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1891, Accumulated: 0.2967, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1317, Accumulated: 0.4284, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.5699, Accumulated: 0.9983, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1744, Accumulated: 0.1744, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0495, Accumulated: 0.2239, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0270, Accumulated: 0.2509, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0317, Accumulated: 0.2827, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0254, Accumulated: 0.3080, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0384, Accumulated: 0.3464, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0398, Accumulated: 0.3862, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0753, Accumulated: 0.4615, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1127, Accumulated: 0.5742, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1181, Accumulated: 0.6923, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1405, Accumulated: 0.8328, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1022, Accumulated: 0.9349, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0167, Accumulated: 0.0167, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0106, Accumulated: 0.0273, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0105, Accumulated: 0.0378, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0073, Accumulated: 0.0452, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0050, Accumulated: 0.0502, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0070, Accumulated: 0.0572, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0137, Accumulated: 0.0709, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0257, Accumulated: 0.0966, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0355, Accumulated: 0.1321, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8451, Accumulated: 0.9771, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1709, Accumulated: 0.1709, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0732, Accumulated: 0.2441, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0423, Accumulated: 0.2864, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0314, Accumulated: 0.3178, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0220, Accumulated: 0.3398, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0280, Accumulated: 0.3677, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0362, Accumulated: 0.4039, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1065, Accumulated: 0.5104, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1419, Accumulated: 0.6523, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1324, Accumulated: 0.7847, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1136, Accumulated: 0.8984, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0100, Accumulated: 0.0100, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0152, Accumulated: 0.0252, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0076, Accumulated: 0.0328, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0176, Accumulated: 0.0504, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0105, Accumulated: 0.0610, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0084, Accumulated: 0.0693, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0256, Accumulated: 0.0949, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0460, Accumulated: 0.1409, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0507, Accumulated: 0.1917, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8016, Accumulated: 0.9933, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0942, Accumulated: 0.0942, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0298, Accumulated: 0.1240, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0202, Accumulated: 0.1442, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0198, Accumulated: 0.1640, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0151, Accumulated: 0.1792, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0280, Accumulated: 0.2072, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0263, Accumulated: 0.2334, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0896, Accumulated: 0.3231, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1136, Accumulated: 0.4367, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1439, Accumulated: 0.5805, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.2087, Accumulated: 0.7892, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1408, Accumulated: 0.9300, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0150, Accumulated: 0.0150, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0093, Accumulated: 0.0243, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0186, Accumulated: 0.0429, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0457, Accumulated: 0.0886, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0065, Accumulated: 0.0951, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0123, Accumulated: 0.1074, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0073, Accumulated: 0.1147, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0176, Accumulated: 0.1322, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0350, Accumulated: 0.1672, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8263, Accumulated: 0.9935, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2002, Accumulated: 0.2002, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0698, Accumulated: 0.2700, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0435, Accumulated: 0.3135, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0342, Accumulated: 0.3477, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0264, Accumulated: 0.3741, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0326, Accumulated: 0.4067, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0299, Accumulated: 0.4365, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1196, Accumulated: 0.5562, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1158, Accumulated: 0.6720, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1285, Accumulated: 0.8005, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1056, Accumulated: 0.9061, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0260, Accumulated: 0.0260, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0171, Accumulated: 0.0431, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0097, Accumulated: 0.0528, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0098, Accumulated: 0.0626, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0246, Accumulated: 0.0873, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0083, Accumulated: 0.0956, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0320, Accumulated: 0.1276, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.5602, Accumulated: 0.6878, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1830, Accumulated: 0.8707, Threshold: 0.8500\n",
            "Early exit at layer 12/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1418, Accumulated: 0.1418, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0630, Accumulated: 0.2049, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0316, Accumulated: 0.2365, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0263, Accumulated: 0.2627, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0187, Accumulated: 0.2814, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0305, Accumulated: 0.3120, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0301, Accumulated: 0.3421, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0738, Accumulated: 0.4159, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1118, Accumulated: 0.5277, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1287, Accumulated: 0.6564, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1531, Accumulated: 0.8095, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1069, Accumulated: 0.9164, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0145, Accumulated: 0.0145, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0084, Accumulated: 0.0230, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0085, Accumulated: 0.0315, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0179, Accumulated: 0.0494, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0066, Accumulated: 0.0560, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0138, Accumulated: 0.0698, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0049, Accumulated: 0.0748, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0068, Accumulated: 0.0816, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0247, Accumulated: 0.1062, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8174, Accumulated: 0.9236, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2186, Accumulated: 0.2186, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0617, Accumulated: 0.2803, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0378, Accumulated: 0.3182, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0270, Accumulated: 0.3452, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0228, Accumulated: 0.3680, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0412, Accumulated: 0.4092, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0426, Accumulated: 0.4518, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0867, Accumulated: 0.5386, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1145, Accumulated: 0.6530, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0961, Accumulated: 0.7492, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1114, Accumulated: 0.8606, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0245, Accumulated: 0.0245, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0082, Accumulated: 0.0327, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0122, Accumulated: 0.0450, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0279, Accumulated: 0.0729, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0568, Accumulated: 0.1297, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0084, Accumulated: 0.1381, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0164, Accumulated: 0.1545, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1320, Accumulated: 0.2865, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1088, Accumulated: 0.3953, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.5991, Accumulated: 0.9944, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1633, Accumulated: 0.1633, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0708, Accumulated: 0.2342, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0346, Accumulated: 0.2688, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0273, Accumulated: 0.2961, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0207, Accumulated: 0.3168, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0327, Accumulated: 0.3495, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0282, Accumulated: 0.3776, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0770, Accumulated: 0.4547, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1226, Accumulated: 0.5772, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1317, Accumulated: 0.7089, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1305, Accumulated: 0.8394, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.0878, Accumulated: 0.9271, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0135, Accumulated: 0.0135, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0098, Accumulated: 0.0232, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0084, Accumulated: 0.0316, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0219, Accumulated: 0.0535, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0056, Accumulated: 0.0591, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0164, Accumulated: 0.0755, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0051, Accumulated: 0.0806, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0129, Accumulated: 0.0935, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0194, Accumulated: 0.1129, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8404, Accumulated: 0.9532, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1526, Accumulated: 0.1526, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0745, Accumulated: 0.2271, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0387, Accumulated: 0.2658, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0345, Accumulated: 0.3003, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0287, Accumulated: 0.3290, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0445, Accumulated: 0.3735, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0454, Accumulated: 0.4189, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0786, Accumulated: 0.4975, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1164, Accumulated: 0.6139, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1167, Accumulated: 0.7306, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1189, Accumulated: 0.8494, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.0848, Accumulated: 0.9342, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0138, Accumulated: 0.0138, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0091, Accumulated: 0.0228, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0081, Accumulated: 0.0309, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0166, Accumulated: 0.0475, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0061, Accumulated: 0.0536, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0131, Accumulated: 0.0667, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0069, Accumulated: 0.0737, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0071, Accumulated: 0.0808, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0257, Accumulated: 0.1065, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7796, Accumulated: 0.8861, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1285, Accumulated: 0.1285, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0653, Accumulated: 0.1939, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0494, Accumulated: 0.2433, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0403, Accumulated: 0.2836, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0340, Accumulated: 0.3176, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0411, Accumulated: 0.3587, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0449, Accumulated: 0.4036, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0861, Accumulated: 0.4897, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1205, Accumulated: 0.6102, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1309, Accumulated: 0.7411, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1171, Accumulated: 0.8581, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0280, Accumulated: 0.0280, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0080, Accumulated: 0.0360, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0139, Accumulated: 0.0499, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0108, Accumulated: 0.0607, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0093, Accumulated: 0.0700, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0224, Accumulated: 0.0924, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0188, Accumulated: 0.1112, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0371, Accumulated: 0.1483, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0364, Accumulated: 0.1847, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8042, Accumulated: 0.9889, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2365, Accumulated: 0.2365, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0863, Accumulated: 0.3228, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0644, Accumulated: 0.3871, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0479, Accumulated: 0.4350, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0352, Accumulated: 0.4702, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0406, Accumulated: 0.5108, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0469, Accumulated: 0.5576, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0887, Accumulated: 0.6463, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0950, Accumulated: 0.7413, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0860, Accumulated: 0.8272, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0685, Accumulated: 0.8957, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0164, Accumulated: 0.0164, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0094, Accumulated: 0.0258, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0118, Accumulated: 0.0376, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0220, Accumulated: 0.0596, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0202, Accumulated: 0.0797, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0108, Accumulated: 0.0906, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0105, Accumulated: 0.1011, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0225, Accumulated: 0.1237, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0243, Accumulated: 0.1480, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8312, Accumulated: 0.9792, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1523, Accumulated: 0.1523, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0331, Accumulated: 0.1855, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0191, Accumulated: 0.2046, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0198, Accumulated: 0.2243, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0170, Accumulated: 0.2413, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0240, Accumulated: 0.2654, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0479, Accumulated: 0.3133, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0998, Accumulated: 0.4131, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1126, Accumulated: 0.5256, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1236, Accumulated: 0.6492, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1525, Accumulated: 0.8016, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1309, Accumulated: 0.9325, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0080, Accumulated: 0.0080, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0246, Accumulated: 0.0326, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0095, Accumulated: 0.0421, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.1210, Accumulated: 0.1631, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0187, Accumulated: 0.1819, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0129, Accumulated: 0.1948, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0082, Accumulated: 0.2030, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0112, Accumulated: 0.2142, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0213, Accumulated: 0.2355, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7507, Accumulated: 0.9862, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1334, Accumulated: 0.1334, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0461, Accumulated: 0.1796, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0246, Accumulated: 0.2042, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0214, Accumulated: 0.2255, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0256, Accumulated: 0.2512, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0353, Accumulated: 0.2865, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0396, Accumulated: 0.3260, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0724, Accumulated: 0.3984, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0896, Accumulated: 0.4880, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1426, Accumulated: 0.6306, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1752, Accumulated: 0.8058, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1236, Accumulated: 0.9295, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0158, Accumulated: 0.0158, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0105, Accumulated: 0.0264, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0099, Accumulated: 0.0363, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.1596, Accumulated: 0.1959, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0086, Accumulated: 0.2045, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0164, Accumulated: 0.2209, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0069, Accumulated: 0.2278, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1097, Accumulated: 0.3375, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0368, Accumulated: 0.3743, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6043, Accumulated: 0.9786, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1543, Accumulated: 0.1543, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1007, Accumulated: 0.2550, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0632, Accumulated: 0.3182, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0672, Accumulated: 0.3853, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0352, Accumulated: 0.4205, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0496, Accumulated: 0.4701, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0478, Accumulated: 0.5179, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0766, Accumulated: 0.5946, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0989, Accumulated: 0.6934, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0938, Accumulated: 0.7872, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0922, Accumulated: 0.8794, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0162, Accumulated: 0.0162, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0192, Accumulated: 0.0354, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0068, Accumulated: 0.0422, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0385, Accumulated: 0.0807, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0080, Accumulated: 0.0887, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0245, Accumulated: 0.1132, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0184, Accumulated: 0.1316, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0361, Accumulated: 0.1677, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0128, Accumulated: 0.1805, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6046, Accumulated: 0.7851, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.2127, Accumulated: 0.9978, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0896, Accumulated: 0.0896, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0346, Accumulated: 0.1242, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0307, Accumulated: 0.1549, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0244, Accumulated: 0.1793, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0153, Accumulated: 0.1946, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0268, Accumulated: 0.2214, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0293, Accumulated: 0.2507, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0732, Accumulated: 0.3239, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1571, Accumulated: 0.4810, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1831, Accumulated: 0.6641, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1852, Accumulated: 0.8493, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1013, Accumulated: 0.9506, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0173, Accumulated: 0.0173, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0307, Accumulated: 0.0480, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0113, Accumulated: 0.0592, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0077, Accumulated: 0.0669, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0124, Accumulated: 0.0793, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0108, Accumulated: 0.0902, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0176, Accumulated: 0.1078, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.4674, Accumulated: 0.5752, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.2725, Accumulated: 0.8478, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1519, Accumulated: 0.9996, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1958, Accumulated: 0.1958, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0456, Accumulated: 0.2414, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0309, Accumulated: 0.2723, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0249, Accumulated: 0.2972, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0229, Accumulated: 0.3201, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0227, Accumulated: 0.3428, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0330, Accumulated: 0.3758, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0901, Accumulated: 0.4659, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1301, Accumulated: 0.5961, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1311, Accumulated: 0.7271, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1338, Accumulated: 0.8609, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0116, Accumulated: 0.0116, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0093, Accumulated: 0.0209, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0155, Accumulated: 0.0364, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0864, Accumulated: 0.1228, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0112, Accumulated: 0.1340, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0100, Accumulated: 0.1440, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0135, Accumulated: 0.1575, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1354, Accumulated: 0.2928, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0783, Accumulated: 0.3711, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6230, Accumulated: 0.9942, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1602, Accumulated: 0.1602, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0637, Accumulated: 0.2238, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0266, Accumulated: 0.2504, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0277, Accumulated: 0.2780, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0208, Accumulated: 0.2989, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0278, Accumulated: 0.3266, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0339, Accumulated: 0.3605, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0920, Accumulated: 0.4526, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1665, Accumulated: 0.6191, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1476, Accumulated: 0.7667, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1194, Accumulated: 0.8861, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0113, Accumulated: 0.0113, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0092, Accumulated: 0.0205, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0114, Accumulated: 0.0319, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0467, Accumulated: 0.0787, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0156, Accumulated: 0.0943, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0118, Accumulated: 0.1060, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0530, Accumulated: 0.1591, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0764, Accumulated: 0.2355, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0781, Accumulated: 0.3136, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6764, Accumulated: 0.9899, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1797, Accumulated: 0.1797, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0785, Accumulated: 0.2581, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0355, Accumulated: 0.2936, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0404, Accumulated: 0.3340, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0294, Accumulated: 0.3634, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0368, Accumulated: 0.4001, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0540, Accumulated: 0.4541, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0966, Accumulated: 0.5507, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1525, Accumulated: 0.7031, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1297, Accumulated: 0.8329, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0922, Accumulated: 0.9251, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0119, Accumulated: 0.0119, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0277, Accumulated: 0.0396, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0115, Accumulated: 0.0511, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0625, Accumulated: 0.1136, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0143, Accumulated: 0.1279, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0192, Accumulated: 0.1471, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0750, Accumulated: 0.2221, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0244, Accumulated: 0.2465, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0361, Accumulated: 0.2826, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7115, Accumulated: 0.9940, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1725, Accumulated: 0.1725, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0636, Accumulated: 0.2361, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0333, Accumulated: 0.2694, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0372, Accumulated: 0.3066, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0307, Accumulated: 0.3373, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0430, Accumulated: 0.3803, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0412, Accumulated: 0.4215, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0715, Accumulated: 0.4929, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0997, Accumulated: 0.5926, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1106, Accumulated: 0.7032, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1171, Accumulated: 0.8203, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1132, Accumulated: 0.9335, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0302, Accumulated: 0.0302, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0082, Accumulated: 0.0384, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0064, Accumulated: 0.0448, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0344, Accumulated: 0.0792, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0086, Accumulated: 0.0878, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0126, Accumulated: 0.1004, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0093, Accumulated: 0.1097, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.3271, Accumulated: 0.4368, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1010, Accumulated: 0.5378, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.4568, Accumulated: 0.9946, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1927, Accumulated: 0.1927, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0743, Accumulated: 0.2671, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0468, Accumulated: 0.3139, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0388, Accumulated: 0.3527, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0324, Accumulated: 0.3851, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0372, Accumulated: 0.4223, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0440, Accumulated: 0.4663, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0685, Accumulated: 0.5349, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1138, Accumulated: 0.6487, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1164, Accumulated: 0.7651, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1013, Accumulated: 0.8664, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0080, Accumulated: 0.0080, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0084, Accumulated: 0.0164, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0108, Accumulated: 0.0272, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0248, Accumulated: 0.0520, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0111, Accumulated: 0.0632, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0274, Accumulated: 0.0905, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0229, Accumulated: 0.1135, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0151, Accumulated: 0.1285, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0285, Accumulated: 0.1570, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8335, Accumulated: 0.9905, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2019, Accumulated: 0.2019, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0664, Accumulated: 0.2683, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0410, Accumulated: 0.3093, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0346, Accumulated: 0.3440, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0285, Accumulated: 0.3724, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0270, Accumulated: 0.3994, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0332, Accumulated: 0.4326, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0789, Accumulated: 0.5115, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1212, Accumulated: 0.6327, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1266, Accumulated: 0.7593, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1139, Accumulated: 0.8732, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0165, Accumulated: 0.0165, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0072, Accumulated: 0.0237, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0080, Accumulated: 0.0317, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0545, Accumulated: 0.0862, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0052, Accumulated: 0.0913, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0216, Accumulated: 0.1129, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0268, Accumulated: 0.1396, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.2577, Accumulated: 0.3974, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0944, Accumulated: 0.4918, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.5048, Accumulated: 0.9965, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1768, Accumulated: 0.1768, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0767, Accumulated: 0.2535, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0517, Accumulated: 0.3052, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0429, Accumulated: 0.3481, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0391, Accumulated: 0.3872, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0567, Accumulated: 0.4439, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0562, Accumulated: 0.5001, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0973, Accumulated: 0.5974, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1100, Accumulated: 0.7074, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0998, Accumulated: 0.8072, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0847, Accumulated: 0.8919, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0077, Accumulated: 0.0077, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0126, Accumulated: 0.0203, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0071, Accumulated: 0.0274, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0231, Accumulated: 0.0505, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0109, Accumulated: 0.0614, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0130, Accumulated: 0.0744, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0328, Accumulated: 0.1072, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0155, Accumulated: 0.1227, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0180, Accumulated: 0.1407, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8551, Accumulated: 0.9958, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1202, Accumulated: 0.1202, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0576, Accumulated: 0.1779, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0259, Accumulated: 0.2037, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0253, Accumulated: 0.2290, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0125, Accumulated: 0.2415, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0209, Accumulated: 0.2624, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0257, Accumulated: 0.2881, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1078, Accumulated: 0.3959, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1630, Accumulated: 0.5589, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1595, Accumulated: 0.7184, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1196, Accumulated: 0.8380, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1093, Accumulated: 0.9473, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0130, Accumulated: 0.0130, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0067, Accumulated: 0.0197, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0102, Accumulated: 0.0298, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0321, Accumulated: 0.0620, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0130, Accumulated: 0.0750, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0096, Accumulated: 0.0846, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0165, Accumulated: 0.1011, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0437, Accumulated: 0.1448, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0282, Accumulated: 0.1730, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8008, Accumulated: 0.9738, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1633, Accumulated: 0.1633, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0442, Accumulated: 0.2076, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0246, Accumulated: 0.2322, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0276, Accumulated: 0.2599, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0227, Accumulated: 0.2826, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0311, Accumulated: 0.3136, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0420, Accumulated: 0.3556, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1045, Accumulated: 0.4601, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1092, Accumulated: 0.5693, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1160, Accumulated: 0.6853, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1269, Accumulated: 0.8121, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1182, Accumulated: 0.9303, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0167, Accumulated: 0.0167, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0168, Accumulated: 0.0336, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0126, Accumulated: 0.0462, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0220, Accumulated: 0.0682, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0123, Accumulated: 0.0805, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0324, Accumulated: 0.1129, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0218, Accumulated: 0.1347, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0238, Accumulated: 0.1585, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0566, Accumulated: 0.2150, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7773, Accumulated: 0.9923, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1113, Accumulated: 0.1113, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0643, Accumulated: 0.1755, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0467, Accumulated: 0.2222, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0329, Accumulated: 0.2551, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0294, Accumulated: 0.2845, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0373, Accumulated: 0.3217, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0393, Accumulated: 0.3611, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1026, Accumulated: 0.4636, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1214, Accumulated: 0.5850, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1137, Accumulated: 0.6987, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1243, Accumulated: 0.8230, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1085, Accumulated: 0.9316, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0079, Accumulated: 0.0079, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0130, Accumulated: 0.0209, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0081, Accumulated: 0.0290, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0283, Accumulated: 0.0573, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0120, Accumulated: 0.0693, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0147, Accumulated: 0.0840, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0144, Accumulated: 0.0985, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.2106, Accumulated: 0.3091, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1217, Accumulated: 0.4308, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.5667, Accumulated: 0.9975, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0748, Accumulated: 0.0748, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0223, Accumulated: 0.0972, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0205, Accumulated: 0.1177, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0169, Accumulated: 0.1346, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0156, Accumulated: 0.1502, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0223, Accumulated: 0.1725, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0239, Accumulated: 0.1964, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0431, Accumulated: 0.2395, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1184, Accumulated: 0.3579, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1298, Accumulated: 0.4877, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1704, Accumulated: 0.6580, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1792, Accumulated: 0.8372, Threshold: 0.8500\n",
            "Layer 16/16: Halt prob: 0.1089, Accumulated: 0.9461, Threshold: 0.8500\n",
            "Early exit at layer 16/16\n",
            "Layer 4/16: Halt prob: 0.0110, Accumulated: 0.0110, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0208, Accumulated: 0.0318, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0058, Accumulated: 0.0377, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0258, Accumulated: 0.0635, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0133, Accumulated: 0.0768, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.0907, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0170, Accumulated: 0.1076, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.4924, Accumulated: 0.6000, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1593, Accumulated: 0.7593, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.2398, Accumulated: 0.9991, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2120, Accumulated: 0.2120, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0700, Accumulated: 0.2820, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0310, Accumulated: 0.3130, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0326, Accumulated: 0.3456, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0255, Accumulated: 0.3710, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0389, Accumulated: 0.4100, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0471, Accumulated: 0.4570, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.1099, Accumulated: 0.5669, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1536, Accumulated: 0.7206, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1309, Accumulated: 0.8515, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.0155, Accumulated: 0.0155, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0106, Accumulated: 0.0261, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0065, Accumulated: 0.0326, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0139, Accumulated: 0.0465, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0093, Accumulated: 0.0558, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0083, Accumulated: 0.0641, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0503, Accumulated: 0.1144, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0954, Accumulated: 0.2098, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0650, Accumulated: 0.2748, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7149, Accumulated: 0.9897, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.0976, Accumulated: 0.0976, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0313, Accumulated: 0.1289, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0224, Accumulated: 0.1513, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0152, Accumulated: 0.1665, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0177, Accumulated: 0.1842, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0152, Accumulated: 0.1994, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0225, Accumulated: 0.2219, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0975, Accumulated: 0.3195, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1198, Accumulated: 0.4393, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.2070, Accumulated: 0.6463, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1964, Accumulated: 0.8426, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1232, Accumulated: 0.9659, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0127, Accumulated: 0.0127, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0241, Accumulated: 0.0367, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0128, Accumulated: 0.0495, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0104, Accumulated: 0.0599, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0100, Accumulated: 0.0699, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0206, Accumulated: 0.0905, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0085, Accumulated: 0.0990, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.3544, Accumulated: 0.4534, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.2500, Accumulated: 0.7033, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.2961, Accumulated: 0.9994, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2125, Accumulated: 0.2125, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.1020, Accumulated: 0.3145, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0672, Accumulated: 0.3817, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0493, Accumulated: 0.4310, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0417, Accumulated: 0.4727, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0477, Accumulated: 0.5204, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0538, Accumulated: 0.5742, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0873, Accumulated: 0.6615, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1144, Accumulated: 0.7759, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.0917, Accumulated: 0.8676, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Layer 4/16: Halt prob: 0.0103, Accumulated: 0.0103, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0391, Accumulated: 0.0494, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0110, Accumulated: 0.0604, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0116, Accumulated: 0.0720, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0058, Accumulated: 0.0779, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0122, Accumulated: 0.0901, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0230, Accumulated: 0.1131, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0173, Accumulated: 0.1304, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0342, Accumulated: 0.1646, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8333, Accumulated: 0.9980, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1726, Accumulated: 0.1726, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0869, Accumulated: 0.2595, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0481, Accumulated: 0.3076, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0331, Accumulated: 0.3407, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0211, Accumulated: 0.3618, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0359, Accumulated: 0.3977, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0362, Accumulated: 0.4339, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0782, Accumulated: 0.5121, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1122, Accumulated: 0.6243, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1207, Accumulated: 0.7450, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1175, Accumulated: 0.8625, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0130, Accumulated: 0.0130, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0083, Accumulated: 0.0213, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0073, Accumulated: 0.0287, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0176, Accumulated: 0.0463, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0065, Accumulated: 0.0528, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0140, Accumulated: 0.0668, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0050, Accumulated: 0.0718, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0105, Accumulated: 0.0823, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0256, Accumulated: 0.1079, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8481, Accumulated: 0.9560, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1322, Accumulated: 0.1322, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0348, Accumulated: 0.1670, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0201, Accumulated: 0.1871, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0180, Accumulated: 0.2052, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0162, Accumulated: 0.2213, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0201, Accumulated: 0.2415, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0225, Accumulated: 0.2639, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0552, Accumulated: 0.3191, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1175, Accumulated: 0.4366, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1635, Accumulated: 0.6002, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1572, Accumulated: 0.7573, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1483, Accumulated: 0.9057, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0129, Accumulated: 0.0129, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0086, Accumulated: 0.0215, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0077, Accumulated: 0.0292, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0414, Accumulated: 0.0706, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0097, Accumulated: 0.0802, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0273, Accumulated: 0.1075, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0112, Accumulated: 0.1187, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.6154, Accumulated: 0.7341, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0853, Accumulated: 0.8194, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1798, Accumulated: 0.9992, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1844, Accumulated: 0.1844, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0701, Accumulated: 0.2546, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0528, Accumulated: 0.3074, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0364, Accumulated: 0.3438, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0328, Accumulated: 0.3766, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0367, Accumulated: 0.4133, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0501, Accumulated: 0.4634, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0994, Accumulated: 0.5628, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1269, Accumulated: 0.6897, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1169, Accumulated: 0.8066, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.0963, Accumulated: 0.9029, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0145, Accumulated: 0.0145, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0540, Accumulated: 0.0684, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0061, Accumulated: 0.0745, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0116, Accumulated: 0.0861, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0111, Accumulated: 0.0972, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0127, Accumulated: 0.1099, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0235, Accumulated: 0.1334, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0836, Accumulated: 0.2170, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0788, Accumulated: 0.2958, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.6939, Accumulated: 0.9897, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.2169, Accumulated: 0.2169, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0771, Accumulated: 0.2940, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0379, Accumulated: 0.3319, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0217, Accumulated: 0.3536, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0194, Accumulated: 0.3730, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0384, Accumulated: 0.4114, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0437, Accumulated: 0.4551, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0809, Accumulated: 0.5361, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1138, Accumulated: 0.6499, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1030, Accumulated: 0.7529, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1013, Accumulated: 0.8542, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0163, Accumulated: 0.0163, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0273, Accumulated: 0.0436, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0395, Accumulated: 0.0831, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0102, Accumulated: 0.0933, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0130, Accumulated: 0.1063, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0052, Accumulated: 0.1115, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0144, Accumulated: 0.1259, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0111, Accumulated: 0.1371, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0560, Accumulated: 0.1931, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8014, Accumulated: 0.9945, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1035, Accumulated: 0.1035, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0416, Accumulated: 0.1450, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0280, Accumulated: 0.1731, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0280, Accumulated: 0.2011, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0214, Accumulated: 0.2224, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0241, Accumulated: 0.2465, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0267, Accumulated: 0.2732, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0867, Accumulated: 0.3599, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1271, Accumulated: 0.4870, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1824, Accumulated: 0.6694, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1612, Accumulated: 0.8306, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1148, Accumulated: 0.9453, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0132, Accumulated: 0.0132, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0108, Accumulated: 0.0240, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0075, Accumulated: 0.0315, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0186, Accumulated: 0.0501, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0072, Accumulated: 0.0573, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0139, Accumulated: 0.0712, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0323, Accumulated: 0.1035, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0245, Accumulated: 0.1280, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0145, Accumulated: 0.1426, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8499, Accumulated: 0.9925, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1501, Accumulated: 0.1501, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0581, Accumulated: 0.2082, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0365, Accumulated: 0.2448, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0300, Accumulated: 0.2748, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0274, Accumulated: 0.3022, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0375, Accumulated: 0.3397, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0341, Accumulated: 0.3739, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0938, Accumulated: 0.4676, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1461, Accumulated: 0.6137, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1390, Accumulated: 0.7527, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1229, Accumulated: 0.8756, Threshold: 0.8500\n",
            "Early exit at layer 14/16\n",
            "Layer 4/16: Halt prob: 0.0137, Accumulated: 0.0137, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0073, Accumulated: 0.0211, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0063, Accumulated: 0.0274, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0291, Accumulated: 0.0565, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0056, Accumulated: 0.0621, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0073, Accumulated: 0.0694, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0273, Accumulated: 0.0967, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0179, Accumulated: 0.1147, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0205, Accumulated: 0.1352, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.8357, Accumulated: 0.9709, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1348, Accumulated: 0.1348, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0723, Accumulated: 0.2071, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0366, Accumulated: 0.2436, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0285, Accumulated: 0.2721, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0185, Accumulated: 0.2906, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0313, Accumulated: 0.3219, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0328, Accumulated: 0.3546, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0838, Accumulated: 0.4384, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1136, Accumulated: 0.5520, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1308, Accumulated: 0.6828, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1394, Accumulated: 0.8222, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1013, Accumulated: 0.9235, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0116, Accumulated: 0.0116, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0091, Accumulated: 0.0207, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0083, Accumulated: 0.0290, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0214, Accumulated: 0.0504, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0057, Accumulated: 0.0561, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0121, Accumulated: 0.0683, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0052, Accumulated: 0.0734, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0062, Accumulated: 0.0797, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.0245, Accumulated: 0.1042, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.7816, Accumulated: 0.8858, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Layer 4/16: Halt prob: 0.1244, Accumulated: 0.1244, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0472, Accumulated: 0.1716, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0218, Accumulated: 0.1935, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0189, Accumulated: 0.2124, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0164, Accumulated: 0.2287, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0294, Accumulated: 0.2581, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0313, Accumulated: 0.2894, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.0674, Accumulated: 0.3568, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1129, Accumulated: 0.4697, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.1480, Accumulated: 0.6177, Threshold: 0.8500\n",
            "Layer 14/16: Halt prob: 0.1658, Accumulated: 0.7835, Threshold: 0.8500\n",
            "Layer 15/16: Halt prob: 0.1372, Accumulated: 0.9207, Threshold: 0.8500\n",
            "Early exit at layer 15/16\n",
            "Layer 4/16: Halt prob: 0.0155, Accumulated: 0.0155, Threshold: 0.8500\n",
            "Layer 5/16: Halt prob: 0.0103, Accumulated: 0.0258, Threshold: 0.8500\n",
            "Layer 6/16: Halt prob: 0.0067, Accumulated: 0.0324, Threshold: 0.8500\n",
            "Layer 7/16: Halt prob: 0.0249, Accumulated: 0.0574, Threshold: 0.8500\n",
            "Layer 8/16: Halt prob: 0.0073, Accumulated: 0.0647, Threshold: 0.8500\n",
            "Layer 9/16: Halt prob: 0.0115, Accumulated: 0.0761, Threshold: 0.8500\n",
            "Layer 10/16: Halt prob: 0.0242, Accumulated: 0.1003, Threshold: 0.8500\n",
            "Layer 11/16: Halt prob: 0.3202, Accumulated: 0.4206, Threshold: 0.8500\n",
            "Layer 12/16: Halt prob: 0.1120, Accumulated: 0.5325, Threshold: 0.8500\n",
            "Layer 13/16: Halt prob: 0.4663, Accumulated: 0.9989, Threshold: 0.8500\n",
            "Early exit at layer 13/16\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (MMLU) ---\n",
            "exact_match: 0.3500\n",
            "accuracy: 0.3500\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.3499999940395355, 'accuracy': 0.35}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.12889700651168823}, 'time_per_token': {'mean': 0.12400754019618035}, 'tokens_per_second': {'mean': 8.852130305767059}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking MMLU:   1%|          | 1/100 [00:00<01:24,  1.18it/s]\n",
            "Benchmarking MMLU:   2%|▏         | 2/100 [00:01<00:50,  1.93it/s]\n",
            "Benchmarking MMLU:   3%|▎         | 3/100 [00:01<00:34,  2.80it/s]\n",
            "Benchmarking MMLU:   4%|▍         | 4/100 [00:01<00:24,  3.87it/s]\n",
            "Benchmarking MMLU:   5%|▌         | 5/100 [00:01<00:19,  4.92it/s]\n",
            "Benchmarking MMLU:   6%|▌         | 6/100 [00:01<00:18,  5.19it/s]\n",
            "Benchmarking MMLU:   7%|▋         | 7/100 [00:01<00:15,  5.95it/s]\n",
            "Benchmarking MMLU:   8%|▊         | 8/100 [00:01<00:13,  6.71it/s]\n",
            "Benchmarking MMLU:   9%|▉         | 9/100 [00:02<00:13,  6.85it/s]\n",
            "Benchmarking MMLU:  10%|█         | 10/100 [00:02<00:13,  6.86it/s]\n",
            "Benchmarking MMLU:  11%|█         | 11/100 [00:02<00:12,  7.41it/s]\n",
            "Benchmarking MMLU:  12%|█▏        | 12/100 [00:02<00:11,  7.98it/s]\n",
            "Benchmarking MMLU:  13%|█▎        | 13/100 [00:02<00:10,  8.27it/s]\n",
            "Benchmarking MMLU:  14%|█▍        | 14/100 [00:02<00:10,  8.44it/s]\n",
            "Benchmarking MMLU:  15%|█▌        | 15/100 [00:02<00:09,  8.78it/s]\n",
            "Benchmarking MMLU:  16%|█▌        | 16/100 [00:03<00:13,  6.28it/s]\n",
            "Benchmarking MMLU:  17%|█▋        | 17/100 [00:03<00:11,  7.01it/s]\n",
            "Benchmarking MMLU:  19%|█▉        | 19/100 [00:03<00:10,  7.69it/s]\n",
            "Benchmarking MMLU:  20%|██        | 20/100 [00:03<00:09,  8.02it/s]\n",
            "Benchmarking MMLU:  21%|██        | 21/100 [00:03<00:10,  7.38it/s]\n",
            "Benchmarking MMLU:  22%|██▏       | 22/100 [00:04<00:16,  4.86it/s]\n",
            "Benchmarking MMLU:  24%|██▍       | 24/100 [00:04<00:12,  6.29it/s]\n",
            "Benchmarking MMLU:  25%|██▌       | 25/100 [00:04<00:10,  6.88it/s]\n",
            "Benchmarking MMLU:  26%|██▌       | 26/100 [00:04<00:09,  7.40it/s]\n",
            "Benchmarking MMLU:  27%|██▋       | 27/100 [00:04<00:09,  7.76it/s]\n",
            "Benchmarking MMLU:  28%|██▊       | 28/100 [00:04<00:08,  8.04it/s]\n",
            "Benchmarking MMLU:  29%|██▉       | 29/100 [00:04<00:08,  8.37it/s]\n",
            "Benchmarking MMLU:  30%|███       | 30/100 [00:04<00:08,  8.59it/s]\n",
            "Benchmarking MMLU:  31%|███       | 31/100 [00:04<00:07,  8.94it/s]\n",
            "Benchmarking MMLU:  32%|███▏      | 32/100 [00:05<00:07,  8.99it/s]\n",
            "Benchmarking MMLU:  33%|███▎      | 33/100 [00:05<00:07,  8.81it/s]\n",
            "Benchmarking MMLU:  35%|███▌      | 35/100 [00:05<00:07,  9.26it/s]\n",
            "Benchmarking MMLU:  36%|███▌      | 36/100 [00:05<00:06,  9.38it/s]\n",
            "Benchmarking MMLU:  38%|███▊      | 38/100 [00:05<00:06,  9.56it/s]\n",
            "Benchmarking MMLU:  39%|███▉      | 39/100 [00:05<00:06,  9.21it/s]\n",
            "Benchmarking MMLU:  40%|████      | 40/100 [00:05<00:07,  8.08it/s]\n",
            "Benchmarking MMLU:  41%|████      | 41/100 [00:06<00:06,  8.47it/s]\n",
            "Benchmarking MMLU:  42%|████▏     | 42/100 [00:06<00:06,  8.62it/s]\n",
            "Benchmarking MMLU:  43%|████▎     | 43/100 [00:06<00:06,  8.80it/s]\n",
            "Benchmarking MMLU:  44%|████▍     | 44/100 [00:06<00:06,  9.04it/s]\n",
            "Benchmarking MMLU:  45%|████▌     | 45/100 [00:06<00:06,  9.17it/s]\n",
            "Benchmarking MMLU:  46%|████▌     | 46/100 [00:06<00:06,  7.84it/s]\n",
            "Benchmarking MMLU:  47%|████▋     | 47/100 [00:06<00:06,  8.24it/s]\n",
            "Benchmarking MMLU:  48%|████▊     | 48/100 [00:06<00:06,  8.60it/s]\n",
            "Benchmarking MMLU:  49%|████▉     | 49/100 [00:07<00:08,  6.24it/s]\n",
            "Benchmarking MMLU:  50%|█████     | 50/100 [00:07<00:07,  6.99it/s]\n",
            "Benchmarking MMLU:  51%|█████     | 51/100 [00:07<00:07,  6.95it/s]\n",
            "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:07<00:06,  6.98it/s]\n",
            "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:07<00:06,  7.57it/s]\n",
            "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:07<00:05,  8.42it/s]\n",
            "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:07<00:05,  8.49it/s]\n",
            "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:08<00:04,  8.75it/s]\n",
            "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:08<00:04,  8.93it/s]\n",
            "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:08<00:04,  9.12it/s]\n",
            "Benchmarking MMLU:  61%|██████    | 61/100 [00:08<00:04,  9.13it/s]\n",
            "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:08<00:04,  9.25it/s]\n",
            "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:08<00:03,  9.35it/s]\n",
            "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:08<00:04,  8.61it/s]\n",
            "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:08<00:03,  8.91it/s]\n",
            "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:09<00:03,  9.01it/s]\n",
            "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:09<00:03,  9.01it/s]\n",
            "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:09<00:03,  9.18it/s]\n",
            "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:09<00:03,  9.08it/s]\n",
            "Benchmarking MMLU:  70%|███████   | 70/100 [00:09<00:03,  9.26it/s]\n",
            "Benchmarking MMLU:  71%|███████   | 71/100 [00:09<00:03,  9.25it/s]\n",
            "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:09<00:03,  9.13it/s]\n",
            "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:09<00:03,  8.88it/s]\n",
            "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:09<00:02,  9.00it/s]\n",
            "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:10<00:02,  9.21it/s]\n",
            "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:10<00:02,  9.05it/s]\n",
            "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:10<00:02,  9.18it/s]\n",
            "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:10<00:02,  9.23it/s]\n",
            "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:10<00:02,  9.39it/s]\n",
            "Benchmarking MMLU:  80%|████████  | 80/100 [00:10<00:02,  9.42it/s]\n",
            "Benchmarking MMLU:  81%|████████  | 81/100 [00:10<00:02,  8.80it/s]\n",
            "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:10<00:02,  8.71it/s]\n",
            "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:11<00:02,  7.22it/s]\n",
            "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:11<00:02,  7.82it/s]\n",
            "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:11<00:01,  8.18it/s]\n",
            "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:11<00:01,  8.46it/s]\n",
            "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:11<00:01,  8.83it/s]\n",
            "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:11<00:01,  8.80it/s]\n",
            "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:11<00:01,  8.72it/s]\n",
            "Benchmarking MMLU:  91%|█████████ | 91/100 [00:11<00:01,  8.89it/s]\n",
            "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:12<00:01,  7.34it/s]\n",
            "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:12<00:00,  7.77it/s]\n",
            "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:12<00:00,  8.49it/s]\n",
            "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:12<00:00,  8.78it/s]\n",
            "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:12<00:00,  8.82it/s]\n",
            "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:12<00:00,  8.97it/s]\n",
            "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:12<00:00,  8.94it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:12<00:00,  9.00it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:12<00:00,  7.72it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        }
      ],
      "source": [
        "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "    --dataset mmlu \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy depth_adaptive_sequence \\\n",
        "    --halting_threshold 0.85 \\\n",
        "    --min_layers 4 \\\n",
        "    --output_dir ./logs \\\n",
        "    --distributed False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: mmlu\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on MMLU with 100 samples...\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (MMLU) ---\n",
            "exact_match: 0.3500\n",
            "accuracy: 0.3500\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.3499999940395355, 'accuracy': 0.35}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.1270327115058899}, 'time_per_token': {'mean': 0.1270327115058899}, 'tokens_per_second': {'mean': 8.388850667476653}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking MMLU:   1%|          | 1/100 [00:00<00:44,  2.20it/s]\n",
            "Benchmarking MMLU:   2%|▏         | 2/100 [00:00<00:25,  3.81it/s]\n",
            "Benchmarking MMLU:   3%|▎         | 3/100 [00:00<00:19,  4.99it/s]\n",
            "Benchmarking MMLU:   4%|▍         | 4/100 [00:00<00:16,  5.75it/s]\n",
            "Benchmarking MMLU:   5%|▌         | 5/100 [00:00<00:14,  6.68it/s]\n",
            "Benchmarking MMLU:   6%|▌         | 6/100 [00:01<00:12,  7.46it/s]\n",
            "Benchmarking MMLU:   7%|▋         | 7/100 [00:01<00:11,  7.90it/s]\n",
            "Benchmarking MMLU:   8%|▊         | 8/100 [00:01<00:11,  8.18it/s]\n",
            "Benchmarking MMLU:   9%|▉         | 9/100 [00:01<00:11,  7.61it/s]\n",
            "Benchmarking MMLU:  10%|█         | 10/100 [00:01<00:11,  8.11it/s]\n",
            "Benchmarking MMLU:  11%|█         | 11/100 [00:01<00:10,  8.25it/s]\n",
            "Benchmarking MMLU:  12%|█▏        | 12/100 [00:01<00:10,  8.45it/s]\n",
            "Benchmarking MMLU:  13%|█▎        | 13/100 [00:01<00:10,  8.66it/s]\n",
            "Benchmarking MMLU:  14%|█▍        | 14/100 [00:02<00:13,  6.56it/s]\n",
            "Benchmarking MMLU:  15%|█▌        | 15/100 [00:02<00:11,  7.20it/s]\n",
            "Benchmarking MMLU:  16%|█▌        | 16/100 [00:02<00:10,  7.72it/s]\n",
            "Benchmarking MMLU:  17%|█▋        | 17/100 [00:02<00:10,  8.07it/s]\n",
            "Benchmarking MMLU:  18%|█▊        | 18/100 [00:02<00:11,  6.89it/s]\n",
            "Benchmarking MMLU:  19%|█▉        | 19/100 [00:02<00:10,  7.37it/s]\n",
            "Benchmarking MMLU:  20%|██        | 20/100 [00:02<00:11,  6.69it/s]\n",
            "Benchmarking MMLU:  21%|██        | 21/100 [00:03<00:10,  7.34it/s]\n",
            "Benchmarking MMLU:  22%|██▏       | 22/100 [00:03<00:09,  7.81it/s]\n",
            "Benchmarking MMLU:  23%|██▎       | 23/100 [00:03<00:09,  8.15it/s]\n",
            "Benchmarking MMLU:  24%|██▍       | 24/100 [00:03<00:12,  6.12it/s]\n",
            "Benchmarking MMLU:  26%|██▌       | 26/100 [00:03<00:10,  7.37it/s]\n",
            "Benchmarking MMLU:  27%|██▋       | 27/100 [00:03<00:09,  7.79it/s]\n",
            "Benchmarking MMLU:  28%|██▊       | 28/100 [00:03<00:08,  8.19it/s]\n",
            "Benchmarking MMLU:  29%|██▉       | 29/100 [00:04<00:08,  8.51it/s]\n",
            "Benchmarking MMLU:  30%|███       | 30/100 [00:04<00:08,  8.48it/s]\n",
            "Benchmarking MMLU:  31%|███       | 31/100 [00:04<00:07,  8.80it/s]\n",
            "Benchmarking MMLU:  32%|███▏      | 32/100 [00:04<00:07,  8.91it/s]\n",
            "Benchmarking MMLU:  33%|███▎      | 33/100 [00:04<00:07,  9.08it/s]\n",
            "Benchmarking MMLU:  34%|███▍      | 34/100 [00:04<00:07,  8.86it/s]\n",
            "Benchmarking MMLU:  35%|███▌      | 35/100 [00:04<00:07,  8.96it/s]\n",
            "Benchmarking MMLU:  36%|███▌      | 36/100 [00:04<00:07,  8.98it/s]\n",
            "Benchmarking MMLU:  37%|███▋      | 37/100 [00:04<00:07,  8.61it/s]\n",
            "Benchmarking MMLU:  38%|███▊      | 38/100 [00:05<00:07,  8.09it/s]\n",
            "Benchmarking MMLU:  39%|███▉      | 39/100 [00:05<00:07,  8.48it/s]\n",
            "Benchmarking MMLU:  40%|████      | 40/100 [00:05<00:06,  8.61it/s]\n",
            "Benchmarking MMLU:  41%|████      | 41/100 [00:05<00:06,  8.76it/s]\n",
            "Benchmarking MMLU:  42%|████▏     | 42/100 [00:05<00:06,  8.91it/s]\n",
            "Benchmarking MMLU:  43%|████▎     | 43/100 [00:05<00:06,  8.98it/s]\n",
            "Benchmarking MMLU:  44%|████▍     | 44/100 [00:05<00:07,  7.13it/s]\n",
            "Benchmarking MMLU:  45%|████▌     | 45/100 [00:05<00:07,  7.59it/s]\n",
            "Benchmarking MMLU:  46%|████▌     | 46/100 [00:06<00:06,  7.95it/s]\n",
            "Benchmarking MMLU:  47%|████▋     | 47/100 [00:06<00:07,  6.83it/s]\n",
            "Benchmarking MMLU:  48%|████▊     | 48/100 [00:06<00:07,  6.71it/s]\n",
            "Benchmarking MMLU:  49%|████▉     | 49/100 [00:06<00:06,  7.38it/s]\n",
            "Benchmarking MMLU:  50%|█████     | 50/100 [00:06<00:06,  7.85it/s]\n",
            "Benchmarking MMLU:  51%|█████     | 51/100 [00:06<00:05,  8.33it/s]\n",
            "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:06<00:05,  8.59it/s]\n",
            "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:06<00:05,  8.84it/s]\n",
            "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:07<00:05,  8.99it/s]\n",
            "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:07<00:04,  9.23it/s]\n",
            "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:07<00:04,  9.39it/s]\n",
            "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:07<00:04,  8.85it/s]\n",
            "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:07<00:04,  9.03it/s]\n",
            "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:07<00:04,  9.19it/s]\n",
            "Benchmarking MMLU:  60%|██████    | 60/100 [00:07<00:04,  9.27it/s]\n",
            "Benchmarking MMLU:  61%|██████    | 61/100 [00:07<00:04,  9.38it/s]\n",
            "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:07<00:03,  9.55it/s]\n",
            "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:07<00:03,  9.47it/s]\n",
            "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:08<00:04,  8.81it/s]\n",
            "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:08<00:04,  8.71it/s]\n",
            "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:08<00:03,  8.51it/s]\n",
            "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:08<00:03,  8.73it/s]\n",
            "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:08<00:03,  8.89it/s]\n",
            "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:08<00:03,  9.00it/s]\n",
            "Benchmarking MMLU:  70%|███████   | 70/100 [00:08<00:03,  8.93it/s]\n",
            "Benchmarking MMLU:  71%|███████   | 71/100 [00:08<00:03,  8.53it/s]\n",
            "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:09<00:03,  8.75it/s]\n",
            "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:09<00:03,  7.52it/s]\n",
            "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:09<00:03,  6.89it/s]\n",
            "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:09<00:03,  7.05it/s]\n",
            "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:09<00:03,  6.51it/s]\n",
            "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:09<00:03,  7.09it/s]\n",
            "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:09<00:03,  7.32it/s]\n",
            "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:10<00:02,  7.71it/s]\n",
            "Benchmarking MMLU:  80%|████████  | 80/100 [00:10<00:02,  8.10it/s]\n",
            "Benchmarking MMLU:  81%|████████  | 81/100 [00:10<00:02,  8.25it/s]\n",
            "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:10<00:02,  7.06it/s]\n",
            "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:10<00:02,  7.64it/s]\n",
            "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:10<00:02,  6.87it/s]\n",
            "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:10<00:02,  6.42it/s]\n",
            "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:11<00:01,  7.14it/s]\n",
            "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:11<00:01,  7.68it/s]\n",
            "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:11<00:01,  8.06it/s]\n",
            "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:11<00:01,  7.82it/s]\n",
            "Benchmarking MMLU:  90%|█████████ | 90/100 [00:11<00:01,  8.31it/s]\n",
            "Benchmarking MMLU:  91%|█████████ | 91/100 [00:11<00:01,  7.76it/s]\n",
            "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:11<00:01,  7.32it/s]\n",
            "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:11<00:00,  7.86it/s]\n",
            "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:12<00:00,  7.97it/s]\n",
            "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:12<00:00,  8.37it/s]\n",
            "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:12<00:00,  8.77it/s]\n",
            "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:12<00:00,  9.07it/s]\n",
            "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:12<00:00,  7.63it/s]\n",
            "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:12<00:00,  8.01it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:12<00:00,  7.65it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:12<00:00,  7.83it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        }
      ],
      "source": [
        "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "    --dataset mmlu \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy depth_adaptive_sequence \\\n",
        "    --halting_threshold 0.9 \\\n",
        "    --min_layers 4 \\\n",
        "    --output_dir ./logs \\\n",
        "    --distributed False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: mmlu\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on MMLU with 100 samples...\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (MMLU) ---\n",
            "exact_match: 0.4200\n",
            "accuracy: 0.4200\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.41999998688697815, 'accuracy': 0.42}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.16820904731750488}, 'time_per_token': {'mean': 0.16820904731750488}, 'tokens_per_second': {'mean': 6.4621910572052}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since cais/mmlu couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'all' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\cais___mmlu\\all\\0.0.0\\c30699e8356da336a370243923dbaf21066bb9fe (last modified on Mon Mar 24 16:38:06 2025).\n",
            "\n",
            "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking MMLU:   1%|          | 1/100 [00:01<01:39,  1.00s/it]\n",
            "Benchmarking MMLU:   2%|▏         | 2/100 [00:01<00:49,  1.99it/s]\n",
            "Benchmarking MMLU:   3%|▎         | 3/100 [00:01<00:33,  2.93it/s]\n",
            "Benchmarking MMLU:   4%|▍         | 4/100 [00:01<00:25,  3.82it/s]\n",
            "Benchmarking MMLU:   5%|▌         | 5/100 [00:01<00:21,  4.51it/s]\n",
            "Benchmarking MMLU:   6%|▌         | 6/100 [00:01<00:19,  4.75it/s]\n",
            "Benchmarking MMLU:   7%|▋         | 7/100 [00:01<00:17,  5.21it/s]\n",
            "Benchmarking MMLU:   8%|▊         | 8/100 [00:02<00:16,  5.50it/s]\n",
            "Benchmarking MMLU:   9%|▉         | 9/100 [00:02<00:15,  5.90it/s]\n",
            "Benchmarking MMLU:  10%|█         | 10/100 [00:02<00:14,  6.06it/s]\n",
            "Benchmarking MMLU:  11%|█         | 11/100 [00:02<00:14,  6.32it/s]\n",
            "Benchmarking MMLU:  12%|█▏        | 12/100 [00:02<00:13,  6.42it/s]\n",
            "Benchmarking MMLU:  13%|█▎        | 13/100 [00:02<00:13,  6.63it/s]\n",
            "Benchmarking MMLU:  14%|█▍        | 14/100 [00:02<00:12,  6.67it/s]\n",
            "Benchmarking MMLU:  15%|█▌        | 15/100 [00:03<00:12,  6.68it/s]\n",
            "Benchmarking MMLU:  16%|█▌        | 16/100 [00:03<00:12,  6.72it/s]\n",
            "Benchmarking MMLU:  17%|█▋        | 17/100 [00:03<00:12,  6.87it/s]\n",
            "Benchmarking MMLU:  18%|█▊        | 18/100 [00:03<00:11,  6.86it/s]\n",
            "Benchmarking MMLU:  19%|█▉        | 19/100 [00:03<00:11,  7.05it/s]\n",
            "Benchmarking MMLU:  20%|██        | 20/100 [00:03<00:13,  5.86it/s]\n",
            "Benchmarking MMLU:  21%|██        | 21/100 [00:04<00:12,  6.13it/s]\n",
            "Benchmarking MMLU:  22%|██▏       | 22/100 [00:04<00:12,  6.45it/s]\n",
            "Benchmarking MMLU:  23%|██▎       | 23/100 [00:04<00:11,  6.73it/s]\n",
            "Benchmarking MMLU:  24%|██▍       | 24/100 [00:04<00:11,  6.86it/s]\n",
            "Benchmarking MMLU:  25%|██▌       | 25/100 [00:04<00:10,  7.03it/s]\n",
            "Benchmarking MMLU:  26%|██▌       | 26/100 [00:04<00:10,  6.90it/s]\n",
            "Benchmarking MMLU:  27%|██▋       | 27/100 [00:04<00:10,  6.94it/s]\n",
            "Benchmarking MMLU:  28%|██▊       | 28/100 [00:05<00:12,  5.97it/s]\n",
            "Benchmarking MMLU:  29%|██▉       | 29/100 [00:05<00:11,  6.28it/s]\n",
            "Benchmarking MMLU:  30%|███       | 30/100 [00:05<00:10,  6.48it/s]\n",
            "Benchmarking MMLU:  31%|███       | 31/100 [00:05<00:10,  6.61it/s]\n",
            "Benchmarking MMLU:  32%|███▏      | 32/100 [00:05<00:10,  6.63it/s]\n",
            "Benchmarking MMLU:  33%|███▎      | 33/100 [00:06<00:13,  4.93it/s]\n",
            "Benchmarking MMLU:  34%|███▍      | 34/100 [00:06<00:14,  4.70it/s]\n",
            "Benchmarking MMLU:  35%|███▌      | 35/100 [00:06<00:12,  5.25it/s]\n",
            "Benchmarking MMLU:  36%|███▌      | 36/100 [00:06<00:11,  5.72it/s]\n",
            "Benchmarking MMLU:  37%|███▋      | 37/100 [00:06<00:10,  6.02it/s]\n",
            "Benchmarking MMLU:  38%|███▊      | 38/100 [00:06<00:09,  6.27it/s]\n",
            "Benchmarking MMLU:  39%|███▉      | 39/100 [00:06<00:09,  6.50it/s]\n",
            "Benchmarking MMLU:  40%|████      | 40/100 [00:07<00:09,  6.38it/s]\n",
            "Benchmarking MMLU:  41%|████      | 41/100 [00:07<00:09,  6.31it/s]\n",
            "Benchmarking MMLU:  42%|████▏     | 42/100 [00:07<00:09,  6.23it/s]\n",
            "Benchmarking MMLU:  43%|████▎     | 43/100 [00:07<00:09,  6.32it/s]\n",
            "Benchmarking MMLU:  44%|████▍     | 44/100 [00:07<00:08,  6.46it/s]\n",
            "Benchmarking MMLU:  45%|████▌     | 45/100 [00:07<00:09,  5.89it/s]\n",
            "Benchmarking MMLU:  46%|████▌     | 46/100 [00:08<00:09,  5.72it/s]\n",
            "Benchmarking MMLU:  47%|████▋     | 47/100 [00:08<00:08,  6.05it/s]\n",
            "Benchmarking MMLU:  48%|████▊     | 48/100 [00:08<00:08,  6.29it/s]\n",
            "Benchmarking MMLU:  49%|████▉     | 49/100 [00:08<00:07,  6.58it/s]\n",
            "Benchmarking MMLU:  50%|█████     | 50/100 [00:08<00:07,  6.69it/s]\n",
            "Benchmarking MMLU:  51%|█████     | 51/100 [00:08<00:07,  6.73it/s]\n",
            "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:09<00:06,  6.93it/s]\n",
            "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:09<00:07,  5.92it/s]\n",
            "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:09<00:09,  4.86it/s]\n",
            "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:09<00:08,  5.41it/s]\n",
            "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:09<00:07,  5.75it/s]\n",
            "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:09<00:06,  6.16it/s]\n",
            "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:10<00:07,  5.89it/s]\n",
            "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:10<00:06,  6.32it/s]\n",
            "Benchmarking MMLU:  60%|██████    | 60/100 [00:10<00:06,  6.44it/s]\n",
            "Benchmarking MMLU:  61%|██████    | 61/100 [00:10<00:06,  5.90it/s]\n",
            "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:10<00:06,  6.20it/s]\n",
            "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:10<00:05,  6.42it/s]\n",
            "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:11<00:05,  6.63it/s]\n",
            "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:11<00:06,  5.74it/s]\n",
            "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:11<00:05,  6.12it/s]\n",
            "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:11<00:05,  6.50it/s]\n",
            "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:11<00:04,  6.73it/s]\n",
            "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:11<00:04,  6.82it/s]\n",
            "Benchmarking MMLU:  70%|███████   | 70/100 [00:12<00:05,  5.73it/s]\n",
            "Benchmarking MMLU:  71%|███████   | 71/100 [00:12<00:04,  5.99it/s]\n",
            "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:12<00:04,  6.07it/s]\n",
            "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:12<00:04,  5.46it/s]\n",
            "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:12<00:05,  5.14it/s]\n",
            "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:12<00:04,  5.57it/s]\n",
            "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:13<00:03,  6.03it/s]\n",
            "Benchmarking MMLU:  77%|███████▋  | 77/100 [00:13<00:03,  6.35it/s]\n",
            "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:13<00:03,  6.66it/s]\n",
            "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:13<00:03,  6.77it/s]\n",
            "Benchmarking MMLU:  80%|████████  | 80/100 [00:13<00:02,  6.83it/s]\n",
            "Benchmarking MMLU:  81%|████████  | 81/100 [00:13<00:02,  6.91it/s]\n",
            "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:13<00:02,  6.95it/s]\n",
            "Benchmarking MMLU:  83%|████████▎ | 83/100 [00:14<00:02,  7.06it/s]\n",
            "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:14<00:02,  6.95it/s]\n",
            "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:14<00:02,  6.51it/s]\n",
            "Benchmarking MMLU:  86%|████████▌ | 86/100 [00:14<00:02,  6.72it/s]\n",
            "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:14<00:01,  6.83it/s]\n",
            "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:14<00:02,  5.18it/s]\n",
            "Benchmarking MMLU:  89%|████████▉ | 89/100 [00:15<00:01,  5.77it/s]\n",
            "Benchmarking MMLU:  90%|█████████ | 90/100 [00:15<00:01,  6.05it/s]\n",
            "Benchmarking MMLU:  91%|█████████ | 91/100 [00:15<00:01,  6.28it/s]\n",
            "Benchmarking MMLU:  92%|█████████▏| 92/100 [00:15<00:01,  6.08it/s]\n",
            "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:15<00:01,  6.28it/s]\n",
            "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:15<00:00,  6.23it/s]\n",
            "Benchmarking MMLU:  95%|█████████▌| 95/100 [00:16<00:00,  6.23it/s]\n",
            "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:16<00:00,  5.37it/s]\n",
            "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:16<00:00,  5.74it/s]\n",
            "Benchmarking MMLU:  98%|█████████▊| 98/100 [00:16<00:00,  6.08it/s]\n",
            "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:16<00:00,  5.74it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:16<00:00,  5.23it/s]\n",
            "Benchmarking MMLU: 100%|██████████| 100/100 [00:16<00:00,  5.88it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        }
      ],
      "source": [
        "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "    --dataset mmlu \\\n",
        "    --num_samples 100 \\\n",
        "    --generation_strategy depth_adaptive_sequence \\\n",
        "    --halting_threshold 0.99 \\\n",
        "    --min_layers 4 \\\n",
        "    --output_dir ./logs \\\n",
        "    --distributed False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing generation config for multiple-choice dataset: race_m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since race couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'middle' at C:\\Users\\adity\\.cache\\huggingface\\datasets\\race\\middle\\0.0.0\\2fec9fd81f1dc971569a9b729c43f2f0e6436637 (last modified on Sun Mar 23 22:43:46 2025).\n",
            "\n",
            "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "\n",
            "Benchmarking RACE_M:   1%|          | 1/100 [00:00<01:11,  1.38it/s]\n",
            "Benchmarking RACE_M:   3%|▎         | 3/100 [00:00<00:22,  4.23it/s]\n",
            "Benchmarking RACE_M:   5%|▌         | 5/100 [00:01<00:14,  6.48it/s]\n",
            "Benchmarking RACE_M:   7%|▋         | 7/100 [00:01<00:11,  8.44it/s]\n",
            "Benchmarking RACE_M:   9%|▉         | 9/100 [00:01<00:09,  9.69it/s]\n",
            "Benchmarking RACE_M:  11%|█         | 11/100 [00:01<00:07, 11.45it/s]\n",
            "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:01<00:06, 12.50it/s]\n",
            "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:01<00:06, 13.53it/s]\n",
            "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:01<00:05, 14.31it/s]\n",
            "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:01<00:05, 14.47it/s]\n",
            "Benchmarking RACE_M:  21%|██        | 21/100 [00:02<00:05, 14.33it/s]\n",
            "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:02<00:05, 14.63it/s]\n",
            "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:02<00:05, 14.10it/s]\n",
            "Benchmarking RACE_M:  27%|██▋       | 27/100 [00:02<00:04, 14.70it/s]\n",
            "Benchmarking RACE_M:  29%|██▉       | 29/100 [00:02<00:04, 15.41it/s]\n",
            "Benchmarking RACE_M:  31%|███       | 31/100 [00:02<00:04, 15.50it/s]\n",
            "Benchmarking RACE_M:  33%|███▎      | 33/100 [00:02<00:04, 15.65it/s]\n",
            "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:02<00:04, 15.72it/s]\n",
            "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:03<00:04, 15.46it/s]\n",
            "Benchmarking RACE_M:  39%|███▉      | 39/100 [00:03<00:03, 15.63it/s]\n",
            "Benchmarking RACE_M:  41%|████      | 41/100 [00:03<00:03, 16.13it/s]\n",
            "Benchmarking RACE_M:  43%|████▎     | 43/100 [00:03<00:03, 16.11it/s]\n",
            "Benchmarking RACE_M:  45%|████▌     | 45/100 [00:03<00:03, 15.98it/s]\n",
            "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:03<00:03, 16.54it/s]\n",
            "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:03<00:03, 16.66it/s]\n",
            "Benchmarking RACE_M:  51%|█████     | 51/100 [00:03<00:02, 16.90it/s]\n",
            "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:04<00:02, 17.18it/s]\n",
            "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:04<00:02, 16.33it/s]\n",
            "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:04<00:02, 15.61it/s]\n",
            "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:04<00:02, 15.87it/s]\n",
            "Benchmarking RACE_M:  61%|██████    | 61/100 [00:04<00:02, 15.14it/s]\n",
            "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:04<00:02, 15.19it/s]\n",
            "Benchmarking RACE_M:  65%|██████▌   | 65/100 [00:04<00:02, 15.94it/s]\n",
            "Benchmarking RACE_M:  67%|██████▋   | 67/100 [00:04<00:02, 15.25it/s]\n",
            "Benchmarking RACE_M:  69%|██████▉   | 69/100 [00:05<00:02, 15.45it/s]\n",
            "Benchmarking RACE_M:  71%|███████   | 71/100 [00:05<00:01, 15.63it/s]\n",
            "Benchmarking RACE_M:  73%|███████▎  | 73/100 [00:05<00:01, 15.40it/s]\n",
            "Benchmarking RACE_M:  75%|███████▌  | 75/100 [00:05<00:01, 15.51it/s]\n",
            "Benchmarking RACE_M:  77%|███████▋  | 77/100 [00:05<00:01, 15.72it/s]\n",
            "Benchmarking RACE_M:  79%|███████▉  | 79/100 [00:05<00:01, 16.66it/s]\n",
            "Benchmarking RACE_M:  81%|████████  | 81/100 [00:05<00:01, 17.12it/s]\n",
            "Benchmarking RACE_M:  83%|████████▎ | 83/100 [00:05<00:01, 16.07it/s]\n",
            "Benchmarking RACE_M:  85%|████████▌ | 85/100 [00:06<00:01, 14.80it/s]\n",
            "Benchmarking RACE_M:  87%|████████▋ | 87/100 [00:06<00:00, 15.58it/s]\n",
            "Benchmarking RACE_M:  89%|████████▉ | 89/100 [00:06<00:00, 15.77it/s]\n",
            "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:06<00:00, 14.73it/s]\n",
            "Benchmarking RACE_M:  94%|█████████▍| 94/100 [00:06<00:00, 15.95it/s]\n",
            "Benchmarking RACE_M:  96%|█████████▌| 96/100 [00:06<00:00, 15.36it/s]\n",
            "Benchmarking RACE_M:  98%|█████████▊| 98/100 [00:06<00:00, 15.19it/s]\n",
            "Benchmarking RACE_M: 100%|██████████| 100/100 [00:07<00:00, 15.35it/s]\n",
            "Benchmarking RACE_M: 100%|██████████| 100/100 [00:07<00:00, 14.09it/s]\n",
            "WARNING:root:No calls to update() have been made - returning 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Updated generation config: max_steps=20, temperature=0.3\n",
            "Benchmarking on RACE_M with 100 samples...\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=C\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=B, target=B\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=C\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=B\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=C, target=D\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=D\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=D, target=A\n",
            "✗ INCORRECT\n",
            "--------------------------------------------------\n",
            "Extracted: prediction=A, target=A\n",
            "✓ CORRECT\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Final Metrics (RACE_M) ---\n",
            "exact_match: 0.4700\n",
            "accuracy: 0.4700\n",
            "Total Questions: 100\n",
            "{'predicted_text': {'exact_match': 0.4699999988079071, 'accuracy': 0.47}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.06993557214736938}, 'time_per_token': {'mean': 0.06993557214736938}, 'tokens_per_second': {'mean': 16.025753333568574}}\n"
          ]
        }
      ],
      "source": [
        "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
        "       --dataset race_m \\\n",
        "       --num_samples 100 \\\n",
        "       --generation_strategy layerdrop \\\n",
        "       --dropout_rate 0.2 \\\n",
        "       --layerdrop_seed 42 \\\n",
        "       --output_dir ./logs \\\n",
        "       --distributed False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-24 17:56:43,838 - INFO - Running benchmark for mmlu with autoregressive_exit8\n",
            "2025-04-24 17:56:43,838 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset mmlu --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\mmlu --generation_strategy autoregressive --exit_layer 8\n",
            "2025-04-24 17:56:58,620 - INFO - Benchmark completed for mmlu with autoregressive_exit8\n",
            "2025-04-24 17:56:58,621 - INFO - Running benchmark for mmlu with autoregressive_full\n",
            "2025-04-24 17:56:58,621 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset mmlu --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\mmlu --generation_strategy autoregressive\n",
            "2025-04-24 17:57:09,160 - INFO - Benchmark completed for mmlu with autoregressive_full\n",
            "2025-04-24 17:57:09,162 - INFO - Running benchmark for mmlu with self_speculative_exit8_spec6\n",
            "2025-04-24 17:57:09,162 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset mmlu --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\mmlu --generation_strategy self_speculative --exit_layer 8 --num_speculations 6\n",
            "2025-04-24 17:57:22,312 - INFO - Benchmark completed for mmlu with self_speculative_exit8_spec6\n",
            "2025-04-24 17:57:22,314 - INFO - Running benchmark for mmlu with layerdrop_dropout0.2\n",
            "2025-04-24 17:57:22,314 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset mmlu --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\mmlu --generation_strategy layerdrop --dropout_rate 0.2 --layerdrop_seed 42\n",
            "2025-04-24 17:57:35,015 - INFO - Benchmark completed for mmlu with layerdrop_dropout0.2\n",
            "2025-04-24 17:57:35,015 - INFO - Running benchmark for mmlu with depth_adaptive_sequence_threshold0.99\n",
            "2025-04-24 17:57:35,015 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset mmlu --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\mmlu --generation_strategy depth_adaptive_sequence --halting_threshold 0.99\n",
            "2025-04-24 17:57:46,366 - INFO - Benchmark completed for mmlu with depth_adaptive_sequence_threshold0.99\n",
            "2025-04-24 17:57:46,367 - INFO - Running benchmark for race_m with autoregressive_exit8\n",
            "2025-04-24 17:57:46,367 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset race_m --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\race_m --generation_strategy autoregressive --exit_layer 8\n",
            "2025-04-24 17:57:58,199 - INFO - Benchmark completed for race_m with autoregressive_exit8\n",
            "2025-04-24 17:57:58,200 - INFO - Running benchmark for race_m with autoregressive_full\n",
            "2025-04-24 17:57:58,200 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset race_m --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\race_m --generation_strategy autoregressive\n",
            "2025-04-24 17:58:10,930 - INFO - Benchmark completed for race_m with autoregressive_full\n",
            "2025-04-24 17:58:10,932 - INFO - Running benchmark for race_m with self_speculative_exit8_spec6\n",
            "2025-04-24 17:58:10,932 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset race_m --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\race_m --generation_strategy self_speculative --exit_layer 8 --num_speculations 6\n",
            "2025-04-24 17:58:22,896 - INFO - Benchmark completed for race_m with self_speculative_exit8_spec6\n",
            "2025-04-24 17:58:22,897 - INFO - Running benchmark for race_m with layerdrop_dropout0.2\n",
            "2025-04-24 17:58:22,897 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset race_m --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\race_m --generation_strategy layerdrop --dropout_rate 0.2 --layerdrop_seed 42\n",
            "2025-04-24 17:58:32,465 - INFO - Benchmark completed for race_m with layerdrop_dropout0.2\n",
            "2025-04-24 17:58:32,466 - INFO - Running benchmark for race_m with depth_adaptive_sequence_threshold0.99\n",
            "2025-04-24 17:58:32,466 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset race_m --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\race_m --generation_strategy depth_adaptive_sequence --halting_threshold 0.99\n",
            "2025-04-24 17:58:46,341 - INFO - Benchmark completed for race_m with depth_adaptive_sequence_threshold0.99\n",
            "2025-04-24 17:58:46,342 - INFO - Running benchmark for race_h with autoregressive_exit8\n",
            "2025-04-24 17:58:46,342 - INFO - Command: C:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Scripts\\python.exe benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --dataset race_h --num_samples 10 --n_shot 0 --output_dir ./benchmark_results\\race_h --generation_strategy autoregressive --exit_layer 8\n",
            "Exception in thread Thread-21 (_readerthread):\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 975, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1552, in _readerthread\n",
            "    buffer.append(fh.read())\n",
            "                  ^^^^^^^^^\n",
            "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
            "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 2566: character maps to <undefined>\n",
            "2025-04-24 18:00:05,642 - INFO - Benchmark completed for race_h with autoregressive_exit8\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\run_flops_accuracy_benchmark.py\", line 294, in <module>\n",
            "    main() \n",
            "    ^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\run_flops_accuracy_benchmark.py\", line 266, in main\n",
            "    success = run_benchmark(args, dataset, strategy_config, strategy_name)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\adity\\LayerSkip\\run_flops_accuracy_benchmark.py\", line 141, in run_benchmark\n",
            "    f.write(result.stdout)\n",
            "TypeError: write() argument must be str, not None\n"
          ]
        }
      ],
      "source": [
        "!python run_flops_accuracy_benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local --datasets mmlu race_m race_h --output_dir ./benchmark_results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
