{"model": "C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local", "model_args": null, "dist_url": "env://", "world_size": 1, "rank": 0, "seed": 42, "output_dir": "./logs", "distributed": false, "model_arg": {}}{"dataset": "mmlu", "data_path": null, "random_shuffle": true, "num_samples": 100, "n_shot": 0, "template": null}{"max_steps": 20, "exit_layer": 8, "num_speculations": 6, "generation_strategy": "layerdrop", "sample": true, "temperature": 0.3, "top_k": 0, "top_p": 0.9, "no_repeat_ngram_size": null, "stop_words": null, "stop_token_ids": [], "dropout_rate": 0.0, "layerdrop_seed": null, "halting_threshold": 0.99, "min_layers": 4, "max_layers": 32}{"predicted_text": {"exact_match": 0.4699999988079071, "accuracy": 0.47}, "acceptance_rate": {"mean": 0.0}, "total_time": {"mean": 0.06116943597793579}, "time_per_token": {"mean": 0.06116943597793579}, "tokens_per_second": {"mean": 19.326925933361053}}