{"model": "C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local", "model_args": null, "dist_url": "env://", "world_size": 1, "rank": 0, "seed": 42, "output_dir": "./logs", "distributed": false, "model_arg": {}}{"dataset": "mmlu", "data_path": null, "random_shuffle": true, "num_samples": 100, "n_shot": 0, "template": null}{"max_steps": 20, "exit_layer": -1, "num_speculations": -1, "generation_strategy": "depth_adaptive_token", "sample": true, "temperature": 0.3, "top_k": 0, "top_p": 0.9, "no_repeat_ngram_size": null, "stop_words": null, "stop_token_ids": [], "dropout_rate": 0.0, "layerdrop_seed": null, "halting_threshold": 0.99, "min_layers": 4, "max_layers": null}{"predicted_text": {"exact_match": 0.0, "accuracy": 0.0}, "acceptance_rate": {"mean": 0.0}, "total_time": {"mean": 0.4404392051696777}, "time_per_token": {"mean": 0.02202196031808853}, "tokens_per_second": {"mean": 46.20107904434204}}