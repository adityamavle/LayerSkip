{"model": "C:\\Users\\adity\\LayerSkip_Plus_Experiments\\LayerSkip\\LayerSkip\\llama3_1B_local", "model_args": null, "dist_url": "env://", "world_size": 1, "rank": 0, "seed": 42, "output_dir": "./logs", "distributed": false, "model_arg": {}}{"dataset": "mmlu", "data_path": null, "random_shuffle": true, "num_samples": 100, "n_shot": 0, "template": null}{"max_steps": 20, "exit_layer": 8, "num_speculations": 6, "generation_strategy": "self_speculative", "sample": true, "temperature": 0.3, "top_k": 0, "top_p": 0.9, "no_repeat_ngram_size": null, "stop_words": null, "stop_token_ids": [], "dropout_rate": 0.0, "layerdrop_seed": null}{"predicted_text": {"exact_match": 0.3199999928474426, "accuracy": 0.32}, "acceptance_rate": {"mean": 0.0}, "total_time": {"mean": 0.20441481113433838}, "time_per_token": {"mean": 0.20441481113433838}, "tokens_per_second": {"mean": 5.189822484850883}}