{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMLU Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: benchmark.py [-h] --model MODEL [--model_args MODEL_ARGS]\n",
      "                    [--dist_url DIST_URL] [--world_size WORLD_SIZE]\n",
      "                    [--rank RANK] [--seed SEED] [--output_dir OUTPUT_DIR]\n",
      "                    [--distributed [DISTRIBUTED]] --dataset DATASET\n",
      "                    [--data_path DATA_PATH]\n",
      "                    [--random_shuffle [RANDOM_SHUFFLE]] [--no_random_shuffle]\n",
      "                    [--num_samples NUM_SAMPLES] [--n_shot N_SHOT]\n",
      "                    [--template TEMPLATE] [--max_steps MAX_STEPS]\n",
      "                    [--exit_layer EXIT_LAYER]\n",
      "                    [--num_speculations NUM_SPECULATIONS]\n",
      "                    [--generation_strategy GENERATION_STRATEGY]\n",
      "                    [--sample [SAMPLE]] [--no_sample]\n",
      "                    [--temperature TEMPERATURE] [--top_k TOP_K]\n",
      "                    [--top_p TOP_P]\n",
      "                    [--no_repeat_ngram_size NO_REPEAT_NGRAM_SIZE]\n",
      "                    [--stop_words STOP_WORDS [STOP_WORDS ...]]\n",
      "                    [--stop_token_ids STOP_TOKEN_IDS [STOP_TOKEN_IDS ...]]\n",
      "                    [--dropout_rate DROPOUT_RATE]\n",
      "                    [--layerdrop_seed LAYERDROP_SEED]\n",
      "                    [--halting_threshold HALTING_THRESHOLD]\n",
      "                    [--min_layers MIN_LAYERS] [--max_layers MAX_LAYERS]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL\n",
      "  --model_args MODEL_ARGS\n",
      "  --dist_url DIST_URL\n",
      "  --world_size WORLD_SIZE\n",
      "  --rank RANK\n",
      "  --seed SEED\n",
      "  --output_dir OUTPUT_DIR\n",
      "  --distributed [DISTRIBUTED]\n",
      "  --dataset DATASET\n",
      "  --data_path DATA_PATH\n",
      "  --random_shuffle [RANDOM_SHUFFLE]\n",
      "  --no_random_shuffle\n",
      "  --num_samples NUM_SAMPLES\n",
      "  --n_shot N_SHOT\n",
      "  --template TEMPLATE\n",
      "  --max_steps MAX_STEPS\n",
      "  --exit_layer EXIT_LAYER\n",
      "  --num_speculations NUM_SPECULATIONS\n",
      "  --generation_strategy GENERATION_STRATEGY\n",
      "  --sample [SAMPLE]\n",
      "  --no_sample\n",
      "  --temperature TEMPERATURE\n",
      "  --top_k TOP_K\n",
      "  --top_p TOP_P\n",
      "  --no_repeat_ngram_size NO_REPEAT_NGRAM_SIZE\n",
      "  --stop_words STOP_WORDS [STOP_WORDS ...]\n",
      "  --stop_token_ids STOP_TOKEN_IDS [STOP_TOKEN_IDS ...]\n",
      "  --dropout_rate DROPOUT_RATE\n",
      "  --layerdrop_seed LAYERDROP_SEED\n",
      "  --halting_threshold HALTING_THRESHOLD\n",
      "  --min_layers MIN_LAYERS\n",
      "  --max_layers MAX_LAYERS\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "Error during generation: The expanded size of the tensor (191) must match the existing size (96) at non-singleton dimension 3.  Target sizes: [1, 32, 96, 191].  Tensor sizes: [1, 1, 96, 96]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (213) must match the existing size (107) at non-singleton dimension 3.  Target sizes: [1, 32, 107, 213].  Tensor sizes: [1, 1, 107, 107]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (303) must match the existing size (152) at non-singleton dimension 3.  Target sizes: [1, 32, 152, 303].  Tensor sizes: [1, 1, 152, 152]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (105) must match the existing size (53) at non-singleton dimension 3.  Target sizes: [1, 32, 53, 105].  Tensor sizes: [1, 1, 53, 53]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (399) must match the existing size (200) at non-singleton dimension 3.  Target sizes: [1, 32, 200, 399].  Tensor sizes: [1, 1, 200, 200]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (633) must match the existing size (317) at non-singleton dimension 3.  Target sizes: [1, 32, 317, 633].  Tensor sizes: [1, 1, 317, 317]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (1051) must match the existing size (526) at non-singleton dimension 3.  Target sizes: [1, 32, 526, 1051].  Tensor sizes: [1, 1, 526, 526]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (207) must match the existing size (104) at non-singleton dimension 3.  Target sizes: [1, 32, 104, 207].  Tensor sizes: [1, 1, 104, 104]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (133) must match the existing size (67) at non-singleton dimension 3.  Target sizes: [1, 32, 67, 133].  Tensor sizes: [1, 1, 67, 67]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (131) must match the existing size (66) at non-singleton dimension 3.  Target sizes: [1, 32, 66, 131].  Tensor sizes: [1, 1, 66, 66]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (135) must match the existing size (68) at non-singleton dimension 3.  Target sizes: [1, 32, 68, 135].  Tensor sizes: [1, 1, 68, 68]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (113) must match the existing size (57) at non-singleton dimension 3.  Target sizes: [1, 32, 57, 113].  Tensor sizes: [1, 1, 57, 57]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (159) must match the existing size (80) at non-singleton dimension 3.  Target sizes: [1, 32, 80, 159].  Tensor sizes: [1, 1, 80, 80]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (243) must match the existing size (122) at non-singleton dimension 3.  Target sizes: [1, 32, 122, 243].  Tensor sizes: [1, 1, 122, 122]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (213) must match the existing size (107) at non-singleton dimension 3.  Target sizes: [1, 32, 107, 213].  Tensor sizes: [1, 1, 107, 107]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (427) must match the existing size (214) at non-singleton dimension 3.  Target sizes: [1, 32, 214, 427].  Tensor sizes: [1, 1, 214, 214]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (215) must match the existing size (108) at non-singleton dimension 3.  Target sizes: [1, 32, 108, 215].  Tensor sizes: [1, 1, 108, 108]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (111) must match the existing size (56) at non-singleton dimension 3.  Target sizes: [1, 32, 56, 111].  Tensor sizes: [1, 1, 56, 56]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (127) must match the existing size (64) at non-singleton dimension 3.  Target sizes: [1, 32, 64, 127].  Tensor sizes: [1, 1, 64, 64]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (69) must match the existing size (35) at non-singleton dimension 3.  Target sizes: [1, 32, 35, 69].  Tensor sizes: [1, 1, 35, 35]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (171) must match the existing size (86) at non-singleton dimension 3.  Target sizes: [1, 32, 86, 171].  Tensor sizes: [1, 1, 86, 86]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (211) must match the existing size (106) at non-singleton dimension 3.  Target sizes: [1, 32, 106, 211].  Tensor sizes: [1, 1, 106, 106]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (233) must match the existing size (117) at non-singleton dimension 3.  Target sizes: [1, 32, 117, 233].  Tensor sizes: [1, 1, 117, 117]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (75) must match the existing size (38) at non-singleton dimension 3.  Target sizes: [1, 32, 38, 75].  Tensor sizes: [1, 1, 38, 38]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (75) must match the existing size (38) at non-singleton dimension 3.  Target sizes: [1, 32, 38, 75].  Tensor sizes: [1, 1, 38, 38]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (237) must match the existing size (119) at non-singleton dimension 3.  Target sizes: [1, 32, 119, 237].  Tensor sizes: [1, 1, 119, 119]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (111) must match the existing size (56) at non-singleton dimension 3.  Target sizes: [1, 32, 56, 111].  Tensor sizes: [1, 1, 56, 56]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (215) must match the existing size (108) at non-singleton dimension 3.  Target sizes: [1, 32, 108, 215].  Tensor sizes: [1, 1, 108, 108]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (141) must match the existing size (71) at non-singleton dimension 3.  Target sizes: [1, 32, 71, 141].  Tensor sizes: [1, 1, 71, 71]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (103) must match the existing size (52) at non-singleton dimension 3.  Target sizes: [1, 32, 52, 103].  Tensor sizes: [1, 1, 52, 52]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (115) must match the existing size (58) at non-singleton dimension 3.  Target sizes: [1, 32, 58, 115].  Tensor sizes: [1, 1, 58, 58]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (71) must match the existing size (36) at non-singleton dimension 3.  Target sizes: [1, 32, 36, 71].  Tensor sizes: [1, 1, 36, 36]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (81) must match the existing size (41) at non-singleton dimension 3.  Target sizes: [1, 32, 41, 81].  Tensor sizes: [1, 1, 41, 41]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (205) must match the existing size (103) at non-singleton dimension 3.  Target sizes: [1, 32, 103, 205].  Tensor sizes: [1, 1, 103, 103]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (93) must match the existing size (47) at non-singleton dimension 3.  Target sizes: [1, 32, 47, 93].  Tensor sizes: [1, 1, 47, 47]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (93) must match the existing size (47) at non-singleton dimension 3.  Target sizes: [1, 32, 47, 93].  Tensor sizes: [1, 1, 47, 47]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (169) must match the existing size (85) at non-singleton dimension 3.  Target sizes: [1, 32, 85, 169].  Tensor sizes: [1, 1, 85, 85]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (115) must match the existing size (58) at non-singleton dimension 3.  Target sizes: [1, 32, 58, 115].  Tensor sizes: [1, 1, 58, 58]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (93) must match the existing size (47) at non-singleton dimension 3.  Target sizes: [1, 32, 47, 93].  Tensor sizes: [1, 1, 47, 47]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (291) must match the existing size (146) at non-singleton dimension 3.  Target sizes: [1, 32, 146, 291].  Tensor sizes: [1, 1, 146, 146]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (627) must match the existing size (314) at non-singleton dimension 3.  Target sizes: [1, 32, 314, 627].  Tensor sizes: [1, 1, 314, 314]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (101) must match the existing size (51) at non-singleton dimension 3.  Target sizes: [1, 32, 51, 101].  Tensor sizes: [1, 1, 51, 51]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (149) must match the existing size (75) at non-singleton dimension 3.  Target sizes: [1, 32, 75, 149].  Tensor sizes: [1, 1, 75, 75]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (99) must match the existing size (50) at non-singleton dimension 3.  Target sizes: [1, 32, 50, 99].  Tensor sizes: [1, 1, 50, 50]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (73) must match the existing size (37) at non-singleton dimension 3.  Target sizes: [1, 32, 37, 73].  Tensor sizes: [1, 1, 37, 37]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (97) must match the existing size (49) at non-singleton dimension 3.  Target sizes: [1, 32, 49, 97].  Tensor sizes: [1, 1, 49, 49]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (97) must match the existing size (49) at non-singleton dimension 3.  Target sizes: [1, 32, 49, 97].  Tensor sizes: [1, 1, 49, 49]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (85) must match the existing size (43) at non-singleton dimension 3.  Target sizes: [1, 32, 43, 85].  Tensor sizes: [1, 1, 43, 43]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (141) must match the existing size (71) at non-singleton dimension 3.  Target sizes: [1, 32, 71, 141].  Tensor sizes: [1, 1, 71, 71]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (153) must match the existing size (77) at non-singleton dimension 3.  Target sizes: [1, 32, 77, 153].  Tensor sizes: [1, 1, 77, 77]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (259) must match the existing size (130) at non-singleton dimension 3.  Target sizes: [1, 32, 130, 259].  Tensor sizes: [1, 1, 130, 130]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (587) must match the existing size (294) at non-singleton dimension 3.  Target sizes: [1, 32, 294, 587].  Tensor sizes: [1, 1, 294, 294]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (177) must match the existing size (89) at non-singleton dimension 3.  Target sizes: [1, 32, 89, 177].  Tensor sizes: [1, 1, 89, 89]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (589) must match the existing size (295) at non-singleton dimension 3.  Target sizes: [1, 32, 295, 589].  Tensor sizes: [1, 1, 295, 295]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (303) must match the existing size (152) at non-singleton dimension 3.  Target sizes: [1, 32, 152, 303].  Tensor sizes: [1, 1, 152, 152]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (127) must match the existing size (64) at non-singleton dimension 3.  Target sizes: [1, 32, 64, 127].  Tensor sizes: [1, 1, 64, 64]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (135) must match the existing size (68) at non-singleton dimension 3.  Target sizes: [1, 32, 68, 135].  Tensor sizes: [1, 1, 68, 68]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (179) must match the existing size (90) at non-singleton dimension 3.  Target sizes: [1, 32, 90, 179].  Tensor sizes: [1, 1, 90, 90]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (195) must match the existing size (98) at non-singleton dimension 3.  Target sizes: [1, 32, 98, 195].  Tensor sizes: [1, 1, 98, 98]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (505) must match the existing size (253) at non-singleton dimension 3.  Target sizes: [1, 32, 253, 505].  Tensor sizes: [1, 1, 253, 253]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (85) must match the existing size (43) at non-singleton dimension 3.  Target sizes: [1, 32, 43, 85].  Tensor sizes: [1, 1, 43, 43]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (133) must match the existing size (67) at non-singleton dimension 3.  Target sizes: [1, 32, 67, 133].  Tensor sizes: [1, 1, 67, 67]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (115) must match the existing size (58) at non-singleton dimension 3.  Target sizes: [1, 32, 58, 115].  Tensor sizes: [1, 1, 58, 58]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (215) must match the existing size (108) at non-singleton dimension 3.  Target sizes: [1, 32, 108, 215].  Tensor sizes: [1, 1, 108, 108]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (135) must match the existing size (68) at non-singleton dimension 3.  Target sizes: [1, 32, 68, 135].  Tensor sizes: [1, 1, 68, 68]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (135) must match the existing size (68) at non-singleton dimension 3.  Target sizes: [1, 32, 68, 135].  Tensor sizes: [1, 1, 68, 68]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (77) must match the existing size (39) at non-singleton dimension 3.  Target sizes: [1, 32, 39, 77].  Tensor sizes: [1, 1, 39, 39]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (69) must match the existing size (35) at non-singleton dimension 3.  Target sizes: [1, 32, 35, 69].  Tensor sizes: [1, 1, 35, 35]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (239) must match the existing size (120) at non-singleton dimension 3.  Target sizes: [1, 32, 120, 239].  Tensor sizes: [1, 1, 120, 120]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (135) must match the existing size (68) at non-singleton dimension 3.  Target sizes: [1, 32, 68, 135].  Tensor sizes: [1, 1, 68, 68]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (181) must match the existing size (91) at non-singleton dimension 3.  Target sizes: [1, 32, 91, 181].  Tensor sizes: [1, 1, 91, 91]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (107) must match the existing size (54) at non-singleton dimension 3.  Target sizes: [1, 32, 54, 107].  Tensor sizes: [1, 1, 54, 54]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (117) must match the existing size (59) at non-singleton dimension 3.  Target sizes: [1, 32, 59, 117].  Tensor sizes: [1, 1, 59, 59]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (101) must match the existing size (51) at non-singleton dimension 3.  Target sizes: [1, 32, 51, 101].  Tensor sizes: [1, 1, 51, 51]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (163) must match the existing size (82) at non-singleton dimension 3.  Target sizes: [1, 32, 82, 163].  Tensor sizes: [1, 1, 82, 82]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (89) must match the existing size (45) at non-singleton dimension 3.  Target sizes: [1, 32, 45, 89].  Tensor sizes: [1, 1, 45, 45]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (203) must match the existing size (102) at non-singleton dimension 3.  Target sizes: [1, 32, 102, 203].  Tensor sizes: [1, 1, 102, 102]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (237) must match the existing size (119) at non-singleton dimension 3.  Target sizes: [1, 32, 119, 237].  Tensor sizes: [1, 1, 119, 119]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (191) must match the existing size (96) at non-singleton dimension 3.  Target sizes: [1, 32, 96, 191].  Tensor sizes: [1, 1, 96, 96]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (221) must match the existing size (111) at non-singleton dimension 3.  Target sizes: [1, 32, 111, 221].  Tensor sizes: [1, 1, 111, 111]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (111) must match the existing size (56) at non-singleton dimension 3.  Target sizes: [1, 32, 56, 111].  Tensor sizes: [1, 1, 56, 56]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (145) must match the existing size (73) at non-singleton dimension 3.  Target sizes: [1, 32, 73, 145].  Tensor sizes: [1, 1, 73, 73]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (77) must match the existing size (39) at non-singleton dimension 3.  Target sizes: [1, 32, 39, 77].  Tensor sizes: [1, 1, 39, 39]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (623) must match the existing size (312) at non-singleton dimension 3.  Target sizes: [1, 32, 312, 623].  Tensor sizes: [1, 1, 312, 312]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (277) must match the existing size (139) at non-singleton dimension 3.  Target sizes: [1, 32, 139, 277].  Tensor sizes: [1, 1, 139, 139]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (103) must match the existing size (52) at non-singleton dimension 3.  Target sizes: [1, 32, 52, 103].  Tensor sizes: [1, 1, 52, 52]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (313) must match the existing size (157) at non-singleton dimension 3.  Target sizes: [1, 32, 157, 313].  Tensor sizes: [1, 1, 157, 157]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (511) must match the existing size (256) at non-singleton dimension 3.  Target sizes: [1, 32, 256, 511].  Tensor sizes: [1, 1, 256, 256]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (249) must match the existing size (125) at non-singleton dimension 3.  Target sizes: [1, 32, 125, 249].  Tensor sizes: [1, 1, 125, 125]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (269) must match the existing size (135) at non-singleton dimension 3.  Target sizes: [1, 32, 135, 269].  Tensor sizes: [1, 1, 135, 135]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (545) must match the existing size (273) at non-singleton dimension 3.  Target sizes: [1, 32, 273, 545].  Tensor sizes: [1, 1, 273, 273]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (67) must match the existing size (34) at non-singleton dimension 3.  Target sizes: [1, 32, 34, 67].  Tensor sizes: [1, 1, 34, 34]\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (139) must match the existing size (70) at non-singleton dimension 3.  Target sizes: [1, 32, 70, 139].  Tensor sizes: [1, 1, 70, 70]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (293) must match the existing size (147) at non-singleton dimension 3.  Target sizes: [1, 32, 147, 293].  Tensor sizes: [1, 1, 147, 147]\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (139) must match the existing size (70) at non-singleton dimension 3.  Target sizes: [1, 32, 70, 139].  Tensor sizes: [1, 1, 70, 70]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (223) must match the existing size (112) at non-singleton dimension 3.  Target sizes: [1, 32, 112, 223].  Tensor sizes: [1, 1, 112, 112]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (265) must match the existing size (133) at non-singleton dimension 3.  Target sizes: [1, 32, 133, 265].  Tensor sizes: [1, 1, 133, 133]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (111) must match the existing size (56) at non-singleton dimension 3.  Target sizes: [1, 32, 56, 111].  Tensor sizes: [1, 1, 56, 56]\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (153) must match the existing size (77) at non-singleton dimension 3.  Target sizes: [1, 32, 77, 153].  Tensor sizes: [1, 1, 77, 77]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: The expanded size of the tensor (483) must match the existing size (242) at non-singleton dimension 3.  Target sizes: [1, 32, 242, 483].  Tensor sizes: [1, 1, 242, 242]\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.0000\n",
      "accuracy: 0.0000\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.0, 'accuracy': 0.0}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.0}, 'time_per_token': {'mean': 0.0}, 'tokens_per_second': {'mean': 0.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:01<01:41,  1.03s/it]\n",
      "Benchmarking MMLU:   3%|▎         | 3/100 [00:01<00:29,  3.28it/s]\n",
      "Benchmarking MMLU:   5%|▌         | 5/100 [00:01<00:17,  5.58it/s]\n",
      "Benchmarking MMLU:   7%|▋         | 7/100 [00:01<00:12,  7.34it/s]\n",
      "Benchmarking MMLU:  10%|█         | 10/100 [00:01<00:08, 10.55it/s]\n",
      "Benchmarking MMLU:  13%|█▎        | 13/100 [00:01<00:06, 13.28it/s]\n",
      "Benchmarking MMLU:  16%|█▌        | 16/100 [00:01<00:05, 15.60it/s]\n",
      "Benchmarking MMLU:  19%|█▉        | 19/100 [00:01<00:04, 17.76it/s]\n",
      "Benchmarking MMLU:  22%|██▏       | 22/100 [00:02<00:03, 19.51it/s]\n",
      "Benchmarking MMLU:  25%|██▌       | 25/100 [00:02<00:03, 20.48it/s]\n",
      "Benchmarking MMLU:  28%|██▊       | 28/100 [00:02<00:03, 21.06it/s]\n",
      "Benchmarking MMLU:  31%|███       | 31/100 [00:02<00:03, 21.52it/s]\n",
      "Benchmarking MMLU:  34%|███▍      | 34/100 [00:02<00:02, 22.48it/s]\n",
      "Benchmarking MMLU:  37%|███▋      | 37/100 [00:02<00:02, 22.28it/s]\n",
      "Benchmarking MMLU:  40%|████      | 40/100 [00:02<00:02, 23.02it/s]\n",
      "Benchmarking MMLU:  43%|████▎     | 43/100 [00:02<00:02, 22.23it/s]\n",
      "Benchmarking MMLU:  46%|████▌     | 46/100 [00:03<00:02, 22.81it/s]\n",
      "Benchmarking MMLU:  49%|████▉     | 49/100 [00:03<00:02, 22.24it/s]\n",
      "Benchmarking MMLU:  52%|█████▏    | 52/100 [00:03<00:02, 20.87it/s]\n",
      "Benchmarking MMLU:  55%|█████▌    | 55/100 [00:03<00:02, 20.88it/s]\n",
      "Benchmarking MMLU:  58%|█████▊    | 58/100 [00:03<00:01, 21.19it/s]\n",
      "Benchmarking MMLU:  61%|██████    | 61/100 [00:03<00:01, 20.90it/s]\n",
      "Benchmarking MMLU:  64%|██████▍   | 64/100 [00:03<00:01, 21.41it/s]\n",
      "Benchmarking MMLU:  67%|██████▋   | 67/100 [00:04<00:01, 21.59it/s]\n",
      "Benchmarking MMLU:  70%|███████   | 70/100 [00:04<00:01, 22.42it/s]\n",
      "Benchmarking MMLU:  73%|███████▎  | 73/100 [00:04<00:01, 21.29it/s]\n",
      "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:04<00:01, 22.17it/s]\n",
      "Benchmarking MMLU:  79%|███████▉  | 79/100 [00:04<00:00, 21.47it/s]\n",
      "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:04<00:00, 22.96it/s]\n",
      "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:04<00:00, 21.75it/s]\n",
      "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:05<00:00, 21.84it/s]\n",
      "Benchmarking MMLU:  91%|█████████ | 91/100 [00:05<00:00, 21.62it/s]\n",
      "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:05<00:00, 21.20it/s]\n",
      "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:05<00:00, 21.44it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:05<00:00, 21.62it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:05<00:00, 17.73it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset mmlu \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy self_speculative \\\n",
    "    --output_dir ./logs \\\n",
    "    --num_speculations 6 \\\n",
    "    --distributed False \\\n",
    "    --top_p 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "Error during generation: shape '[-1, 105]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 183]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 49]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 93]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 46]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 49]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 121]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 60]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 65]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 102]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 31]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 44]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 101]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 43]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 48]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 268]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 104]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 365]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 132]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 144]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 53]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 76]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 59]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 43]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 137]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 84]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 54]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 106]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 84]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 103]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 46]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 55]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 335]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 99]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 105]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 36]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 72]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 90]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 321]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 48]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 44]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 118]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 88]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 53]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 110]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 113]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 53]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 103]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 155]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 101]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 96]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 43]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 40]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 184]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 96]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 115]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 41]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 116]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 84]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 40]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 205]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 65]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 108]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 85]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 76]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 98]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 44]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 75]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 60]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 56]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 60]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 101]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 78]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 94]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 66]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 109]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 215]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 294]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 52]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 54]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 59]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 64]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 100]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 105]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 118]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 79]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 113]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 190]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 32]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 84]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 241]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 86]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 265]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 215]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 45]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 49]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 296]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 88]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 247]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: shape '[-1, 67]' is invalid for input of size 1\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.0000\n",
      "accuracy: 0.0000\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.0, 'accuracy': 0.0}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.0}, 'time_per_token': {'mean': 0.0}, 'tokens_per_second': {'mean': 0.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:00<00:50,  1.98it/s]\n",
      "Benchmarking MMLU:   3%|▎         | 3/100 [00:00<00:16,  5.82it/s]\n",
      "Benchmarking MMLU:   6%|▌         | 6/100 [00:00<00:08, 10.91it/s]\n",
      "Benchmarking MMLU:   9%|▉         | 9/100 [00:00<00:06, 14.86it/s]\n",
      "Benchmarking MMLU:  12%|█▏        | 12/100 [00:00<00:05, 17.32it/s]\n",
      "Benchmarking MMLU:  15%|█▌        | 15/100 [00:01<00:04, 17.84it/s]\n",
      "Benchmarking MMLU:  18%|█▊        | 18/100 [00:01<00:04, 16.86it/s]\n",
      "Benchmarking MMLU:  21%|██        | 21/100 [00:01<00:04, 18.01it/s]\n",
      "Benchmarking MMLU:  24%|██▍       | 24/100 [00:01<00:03, 19.11it/s]\n",
      "Benchmarking MMLU:  27%|██▋       | 27/100 [00:01<00:03, 20.33it/s]\n",
      "Benchmarking MMLU:  30%|███       | 30/100 [00:01<00:03, 21.34it/s]\n",
      "Benchmarking MMLU:  33%|███▎      | 33/100 [00:02<00:03, 20.89it/s]\n",
      "Benchmarking MMLU:  36%|███▌      | 36/100 [00:02<00:02, 21.69it/s]\n",
      "Benchmarking MMLU:  39%|███▉      | 39/100 [00:02<00:02, 20.34it/s]\n",
      "Benchmarking MMLU:  42%|████▏     | 42/100 [00:02<00:02, 21.68it/s]\n",
      "Benchmarking MMLU:  45%|████▌     | 45/100 [00:02<00:02, 22.32it/s]\n",
      "Benchmarking MMLU:  48%|████▊     | 48/100 [00:02<00:02, 22.91it/s]\n",
      "Benchmarking MMLU:  51%|█████     | 51/100 [00:02<00:02, 21.77it/s]\n",
      "Benchmarking MMLU:  54%|█████▍    | 54/100 [00:02<00:02, 22.73it/s]\n",
      "Benchmarking MMLU:  57%|█████▋    | 57/100 [00:03<00:01, 22.95it/s]\n",
      "Benchmarking MMLU:  60%|██████    | 60/100 [00:03<00:01, 22.73it/s]\n",
      "Benchmarking MMLU:  63%|██████▎   | 63/100 [00:03<00:01, 22.81it/s]\n",
      "Benchmarking MMLU:  66%|██████▌   | 66/100 [00:03<00:01, 23.00it/s]\n",
      "Benchmarking MMLU:  69%|██████▉   | 69/100 [00:03<00:01, 23.55it/s]\n",
      "Benchmarking MMLU:  72%|███████▏  | 72/100 [00:03<00:01, 23.07it/s]\n",
      "Benchmarking MMLU:  75%|███████▌  | 75/100 [00:03<00:01, 23.26it/s]\n",
      "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:04<00:00, 22.15it/s]\n",
      "Benchmarking MMLU:  81%|████████  | 81/100 [00:04<00:00, 22.88it/s]\n",
      "Benchmarking MMLU:  84%|████████▍ | 84/100 [00:04<00:00, 23.69it/s]\n",
      "Benchmarking MMLU:  87%|████████▋ | 87/100 [00:04<00:00, 23.98it/s]\n",
      "Benchmarking MMLU:  90%|█████████ | 90/100 [00:04<00:00, 24.36it/s]\n",
      "Benchmarking MMLU:  93%|█████████▎| 93/100 [00:04<00:00, 22.60it/s]\n",
      "Benchmarking MMLU:  96%|█████████▌| 96/100 [00:04<00:00, 23.32it/s]\n",
      "Benchmarking MMLU:  99%|█████████▉| 99/100 [00:04<00:00, 22.28it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:04<00:00, 20.19it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset mmlu \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy self_speculative \\\n",
    "    --exit_layer 16 \\\n",
    "    --output_dir ./logs \\\n",
    "    --num_speculations 6 \\\n",
    "    --top_p 0.9 \\\n",
    "    --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: mmlu\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on MMLU with 100 samples...\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (MMLU) ---\n",
      "exact_match: 0.3500\n",
      "accuracy: 0.3500\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.3499999940395355, 'accuracy': 0.35}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.05594775438308716}, 'time_per_token': {'mean': 0.05594775438308716}, 'tokens_per_second': {'mean': 21.353261655569078}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking MMLU:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking MMLU:   1%|          | 1/100 [00:00<01:22,  1.20it/s]\n",
      "Benchmarking MMLU:   3%|▎         | 3/100 [00:00<00:24,  3.90it/s]\n",
      "Benchmarking MMLU:   5%|▌         | 5/100 [00:01<00:14,  6.43it/s]\n",
      "Benchmarking MMLU:   8%|▊         | 8/100 [00:01<00:09,  9.90it/s]\n",
      "Benchmarking MMLU:  11%|█         | 11/100 [00:01<00:06, 13.26it/s]\n",
      "Benchmarking MMLU:  14%|█▍        | 14/100 [00:01<00:05, 15.92it/s]\n",
      "Benchmarking MMLU:  17%|█▋        | 17/100 [00:01<00:04, 18.11it/s]\n",
      "Benchmarking MMLU:  20%|██        | 20/100 [00:01<00:04, 19.67it/s]\n",
      "Benchmarking MMLU:  23%|██▎       | 23/100 [00:01<00:03, 20.07it/s]\n",
      "Benchmarking MMLU:  26%|██▌       | 26/100 [00:02<00:03, 19.61it/s]\n",
      "Benchmarking MMLU:  29%|██▉       | 29/100 [00:02<00:03, 19.57it/s]\n",
      "Benchmarking MMLU:  32%|███▏      | 32/100 [00:02<00:03, 19.36it/s]\n",
      "Benchmarking MMLU:  35%|███▌      | 35/100 [00:02<00:03, 19.70it/s]\n",
      "Benchmarking MMLU:  38%|███▊      | 38/100 [00:02<00:02, 20.75it/s]\n",
      "Benchmarking MMLU:  41%|████      | 41/100 [00:02<00:02, 20.55it/s]\n",
      "Benchmarking MMLU:  44%|████▍     | 44/100 [00:02<00:02, 20.99it/s]\n",
      "Benchmarking MMLU:  47%|████▋     | 47/100 [00:03<00:02, 22.06it/s]\n",
      "Benchmarking MMLU:  50%|█████     | 50/100 [00:03<00:02, 22.59it/s]\n",
      "Benchmarking MMLU:  53%|█████▎    | 53/100 [00:03<00:02, 21.44it/s]\n",
      "Benchmarking MMLU:  56%|█████▌    | 56/100 [00:03<00:01, 22.19it/s]\n",
      "Benchmarking MMLU:  59%|█████▉    | 59/100 [00:03<00:01, 22.41it/s]\n",
      "Benchmarking MMLU:  62%|██████▏   | 62/100 [00:03<00:01, 20.00it/s]\n",
      "Benchmarking MMLU:  65%|██████▌   | 65/100 [00:03<00:01, 21.12it/s]\n",
      "Benchmarking MMLU:  68%|██████▊   | 68/100 [00:04<00:01, 20.24it/s]\n",
      "Benchmarking MMLU:  71%|███████   | 71/100 [00:04<00:01, 19.76it/s]\n",
      "Benchmarking MMLU:  74%|███████▍  | 74/100 [00:04<00:01, 17.93it/s]\n",
      "Benchmarking MMLU:  76%|███████▌  | 76/100 [00:04<00:01, 17.92it/s]\n",
      "Benchmarking MMLU:  78%|███████▊  | 78/100 [00:04<00:01, 16.83it/s]\n",
      "Benchmarking MMLU:  80%|████████  | 80/100 [00:04<00:01, 17.34it/s]\n",
      "Benchmarking MMLU:  82%|████████▏ | 82/100 [00:04<00:01, 17.46it/s]\n",
      "Benchmarking MMLU:  85%|████████▌ | 85/100 [00:04<00:00, 18.74it/s]\n",
      "Benchmarking MMLU:  88%|████████▊ | 88/100 [00:05<00:00, 19.39it/s]\n",
      "Benchmarking MMLU:  91%|█████████ | 91/100 [00:05<00:00, 20.43it/s]\n",
      "Benchmarking MMLU:  94%|█████████▍| 94/100 [00:05<00:00, 20.79it/s]\n",
      "Benchmarking MMLU:  97%|█████████▋| 97/100 [00:05<00:00, 21.82it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:05<00:00, 21.90it/s]\n",
      "Benchmarking MMLU: 100%|██████████| 100/100 [00:05<00:00, 17.64it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset mmlu \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy self_speculative\\\n",
    "    --exit_layer 32 \\\n",
    "    --output_dir ./logs \\\n",
    "    --top_p 0.9 \\\n",
    "    --distributed False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race - H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard benchmark for dataset: race_h\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "  0%|          | 0/100 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 756, in <module>\n",
      "    main(args, benchmark_arguments, generation_config, f\"{args.output_dir}/benchmark_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 728, in main\n",
      "    metric_result = benchmark(model, tokenizer, benchmark_arguments, generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 274, in benchmark\n",
      "    return original_benchmark(model, tokenizer, benchmark_arguments, generation_config, seed)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\benchmark.py\", line 689, in original_benchmark\n",
      "    response: GenerationResult = generator.generate(\n",
      "                                 ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\self_speculation\\generator_base.py\", line 116, in generate\n",
      "    generation_strategy_result = self.generation_strategy.generate_token_ids(\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\LayerSkip\\self_speculation\\self_speculation_generator.py\", line 99, in generate_token_ids\n",
      "    acceptance_rate=total_draft_matches / total_generations,\n",
      "                    ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~\n",
      "ZeroDivisionError: division by zero\n"
     ]
    }
   ],
   "source": [
    "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset race_h \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy self_speculative \\\n",
    "    --output_dir ./logs \\\n",
    "    --top_p 0.9 \\\n",
    "    --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard benchmark for dataset: race_h\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55400\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00047278404235839844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25224\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002445220947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: It is not easy for people to sail   around the world in quite small boats. Sometimes the weather gets bad. Accidents can happen easily and quickly.\n",
      "One family once had an accident. A big fish swam under their boat and bit holes in it. Sea water came in and the boat soon went down. Luckily these people had another small boat----a lifeboat, so they all got into the lifeboat. They lived in the boat for many days. They ate and slept, and always hoped. At last people in a ship saved them.\n",
      "How do people live in a very small lifeboat for a long time? They must be strong in every way, they must have a hope, and they must have a strong desire to live. People cannot drink seawater. If they drink a lot of sea water, they will quickly die. They must catch rainwater and drink it. They must also catch fish and birds for food. Lifeboats do not often carry cookers. So people can not cook their food in the lifeboats. Raw   fish and birds are not very nice but they are their only food. They must eat raw food, or they will die.\n",
      "\n",
      "Question: One family once had an accident at sea, because   _  .\n",
      "A. their boat met bad weather\n",
      "B. their boat hit a big rock and it was broken\n",
      "C. nobody knew how to sail\n",
      "D. a fish bit holes in their boat\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55694\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09735107421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127075\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0250396728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear Boris,\n",
      "Thanks for your nice letter.\n",
      "After I had spent a week with my English family, I slowly began to understand their English a little better. It's very different from what I learned at school! Students in my group are from different cities of Britain and their dialects   are different too! Some of their accents   are quite strong and they also have their own words and expressions.\n",
      "But it's not the language that's different and surprising. Before I came to England I had thought that fish and chips were eaten every day. That's quite wrong! I get rather mad now when I hear all the foolish words about typical   English food.\n",
      "I had expected to see \"London fog\". Do you remember our texts about it? We had no idea that most of this 'thick fog' disappeared many years ago when people stopped using coal in their homes. But the idea to speak about the weather was very helpful. The weather in London is really changeable.\n",
      "On the other hand habits are different. People tell me what is typically British here in London is not always typical in Wales or Scotland. Local habits and traditions are not the same as what we knew.\n",
      "But what is ordinary for all British is that they follow traditions. Probably Britain has more living signs of its past than many other countries. And people have always been proud of having ancient buildings in capitals, big cities and the countryside.\n",
      "I will tell you more about Britain in my other letters.\n",
      "Love from Britain,\n",
      "Peter\n",
      "\n",
      "Question: Typical English food   _  .\n",
      "A. makes people mad\n",
      "B. can't be seen now\n",
      "C. is always fish and chips\n",
      "D. is not what he knew\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4052734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87903\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00018680095672607422\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: We have twenty minutes' break time after the second class in the morning.  Look!  Most of us are playing during the break time. Some students are on the playground . They are playing basketball. Oh! A boy is running with the ball.  And another is stopping  him. They look so cool. And there are some girls watching the game. Some students are in the classroom. They are talking.  A few of them are reading and doing homework. Look! A girl is looking at the birds in the tree in front of the classroom. She must be thinking of something interesting because she is smiling .\n",
      "What are the teachers doing? Some of them are working in the office. And some are talking with students. Everyone is doing his or her things, busy but happy!\n",
      "\n",
      "Question: There are   _   students in the classroom.\n",
      "A. no\n",
      "B. some\n",
      "C. few\n",
      "D. many\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.29345703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71658\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002147674560546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Picture Show\n",
      "There are 12,000 pictures on show here. You can see the whole Chinese history!\n",
      "Place: City Museum\n",
      "Price: ~30\n",
      "Time: 9:00 a.m.-5:00 p.m. Monday-Friday\n",
      "Films at the Museum\n",
      "There are two European films on Saturday afternoon at the Museum Theatre. See Broken Window at 2:30. The Workers is at 4:45. For more information, call 84987898.\n",
      "International Picnic\n",
      "Are you tired of eating the same food every day? Come to Central Park on Saturday and enjoy food from all over the world. Delicious and not expensive. Noon to 5:00 p.m.\n",
      "Do You Want to Hear \"The Zoo\"?\n",
      "\"The Zoo\", a popular rock group from Australia, Will give their first US concert  this Saturday night, at 8 at Rose Hall, City College.\n",
      "The Music Shop's Sale\n",
      "Sale on every record and tape in the shop, Pop, Rock, Jazz, Disco, Folk. Sale starts on Tuesday and ends on Thursday.\n",
      "\n",
      "Question: According to the ads , what can you do on Saturday afternoon if you have time?\n",
      "A. I can enjoy the delicious food in Central Park.\n",
      "B. I can see two films and buy some tapes.\n",
      "C. I can go to the City College to watch animals.\n",
      "D. I can see a picture show and listen to music.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.425048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.630859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Many years ago, I had my first chance to visit Russia. \"Russians are a very polite people,\" I had been told before my arrival. One of my friends explained that a gentleman will pour the lemonade for the ladies and show other good manners.\n",
      "Toward the end of my three-week trip, I was invited by my Russian friend Nicolai Vasilevich and his wife Yulya out to dinner. At the end of a wonderful meal, Yulya asked if I would like a banana. I politely declined  and thanked her, and explained I was most satisfied with the meal. But my mind was racing: \"What should I do? Should I offer her a banana though they are as close to her as they are to me? What is the polite thing to do?\"\n",
      "\"Would you like a banana?\" I asked Yulya.\n",
      "\"Yes,\" she smiled, but didn't try to take any of the three bananas in the fruit basket.\n",
      "\"Which one would you like?\" I asked again.\n",
      "\"That one,\" she pointed at one of the bananas. So thinking about Russian politeness, f picked the banana Yulya had pointed at. Then I _ it half way and handed it to her.Smiles on Yulya's and Nicolai's faces told me I had done the right thing. Alter this experience, I spent much time letting the world know that in Russia, the polite thing was to peel bananas for ladies.\n",
      "However, sometime during my third trip i learned I was wrong.\n",
      "\"Oh no, David,\" a Russian politely corrected me.  \"In Russia, when a man peels a banana for a lady, it means he has a romantic interest in her.\" How embarrassed   I felt.\n",
      "So to communicate properly with people of different cultures, we should watch carefully how people of the same culture communicate with each other. Besides, don't be afraid to ask questions about their culture.\n",
      "\n",
      "Question: Before his first visit to Russia, the writer learned Russian gentlemen are polite to  _  .\n",
      "A. foreigners\n",
      "B. strangers\n",
      "C. friends\n",
      "D. women\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64063\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0167388916015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Many people think sports are just for winning and honor, but there is a lot more you can gain from (get out of) them. I have learned over the past years that sometimes when I lose, I get a lot more out of it than winning. Also, I find a lot of times in sports, people are getting too caught up in the game instead of just having fun. The real purpose of sports is to have fun and learn life lessons along the way.\n",
      "I greatly encourage you to be a part of the school sports. Even if you are not the best, you can still have fun. Sports give people a great and healthy way of spending an afternoon, instead of lying around playing video games or even getting into bad things. Sports also give us a sense of achievement. There isn't a better feeling than to have done something fun and productive for my day.\n",
      "I think that we all need sports to give us courage. If we try hard in sports, we usually do well. If we did the same in study, we would all be champions. Another reason why I encourage you to play sports is that it's just fun. Without sports, our lives would just be boring. So as you may be able to tell, sports are amazing!\n",
      "Our coaches not only teach us to play sports, but show class and good sportsmanship while playing them. It's never fun when you lose to have the competitor rub it in your face. That's why our coaches teach us to show class when we lose; also, when coaches _ , don't get down. They only want to see you improve and learn from what they say. When you do badly and they don't shout loudly is when you should start worrying because they are giving up on you.\n",
      "Overall, sports are great! They bring out the best and worst of a lot of us. However, we can' t let sports get too serious to where it brings down all the fun. So to have the most fun in sports, you just need try your best and not worry so much about the winning or losing.\n",
      "\n",
      "Question: Which of the following statements is TRUE according to the passage?\n",
      "A. Sports bring us great fun only if we have the talent.\n",
      "B. Sports give us the best way of spending free time.\n",
      "C. We can get more out of winning than losing.\n",
      "D. We should take pleasure in doing sports.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.19873046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49333\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001480579376220703\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: If you do not use your arms or your legs for some time, they will become weak, when you start using them again, they slowly become strong again. Everybody knows that. Yet many people do not seem to know that memory works in the same way.\n",
      "When someone says that he has a good memory, he really means that he keeps his memory in practice by using it. When someone else says that his memory is poor, he really means that he does not give it enough chance to become strong.\n",
      "If a friend says that his arms and legs are weak, we know that it is his own fault. But if he tells us that he has a poor memory, many of us think that his parents may be blamed , and few of us know that it is just his own fault. Have you ever found that some people can't read or write but usually they have better memories ? This is because they cannot read or write and they have to remember things, they cannot write them down in a small notebook. They have to remember days, names, songs and stories, so their memory is the whole time being exercised.\n",
      "So if you want to have a good memory, learn from the people: practise remembering things in a way as other people do.\n",
      "\n",
      "Question: If you do not use your arms or legs for some time,   _  .\n",
      "A. you can't use them any more\n",
      "B. they will become stronger\n",
      "C. they become weak but they slowly become strong again\n",
      "D. they become weak and won't become strong until you use them again\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00449371337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: I am Wang Lin, I am twelve years old. My pen pal Tom is form the United States. He is the same age as I. He is a middle school student in Beijing. There are three people in his family. His father is a teacher, he teaches English in a high school in Beijing. His mother is an English teacher, too. But they work in different schools. Tom goes to school in his mother's car every day. They all like Chinese food. Tom's father likes Guangdong food, he thinks it is delicious. Tom's mother's favorite food is Sichuan food. But Tom doesn't like Sichuan food, he thinks it is too hot. So they often eat out on weekends.\n",
      "\n",
      "Question: They often eat out on weekends because   _  .\n",
      "A. they like Chinese food\n",
      "B. they like American food\n",
      "C. they are lazy\n",
      "D. they have different hobbies  .\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61754\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00060272216796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Lin Tao and Chen Hai are good friends. They are in the same class. They are in the same team. Lin Tao sits behind Chen Hai. Now it is four o'clock. School is over. They often go to play games after school. They can't look after their things very well. So their mothers don't give them watches. They don't have watches. They don't know the time. But they can ask a man under the big tree. His watch is very nice. They can also see the clock on the wall of the classroom. Now it's about five in the afternoon. It's time to go home. They must put on their clothes and go home.\n",
      "\n",
      "Question: How can they know the time?\n",
      "A. They can see the teacher's watch\n",
      "B. They can ask the man under the big tree.\n",
      "C. They can go home and ask their mothers.\n",
      "D. They can see the sun\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1273193359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43114\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00783538818359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: When he was a teenager, Hunter Adam was very unhappy and he spent many years in a special hospital for people with mental health problems.\n",
      "When he left the hospital, Adam decided to become a doctor, so he went to a medical school in Virginia, USA. But when he was there, he did things in a different way. For example, he didn't like the doctor's white coats, so he wore shirts with flowers on them when he visited his patients and he tried to make them laugh. The doctors at the medical school didn't like Adams because he was too different.\n",
      "But Adams believed that people in hospital need more than medicine. He saw unhappy and lonely people, and he tried to help them as patients, but as people too. He spent a lot of time with children in the hospital and often dressed up like a clown to make the children laugh\n",
      "When he finished medical school and become a doctor, Adams opened his own hospital, called \"the Gusundheit Institute\",together with some other doctors. They wanted it to be a place with a different way of working with sick people.\n",
      "Hunter Adams became famous during the 1980s, and in 1988, Universal Pictures made a film about his life. It was very successful. In the film, Robin Williams played Adams. Williams said,:\"hunter is a really warm person, who believes that patients need a doctor who is a friend. I enjoyed playing him.\"\n",
      "\n",
      "Question: The passage mainly tells us about\n",
      "A. how to cheer up patients\n",
      "B. people with mental health problems\n",
      "C. a film about Adams\n",
      "D. a doctor named Hunter Adams\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 107581\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002503395080566406\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Emily Urich 18 years old Canada\n",
      "A lot of teens aren't responsible ,and that's where I'm different. Not just about school but everyday things like being able to pay my own credit card bills on time.\n",
      "The first time I got a cartoon book was on my third birthday. From then on , I fell in deep love with it. And can you guess how many cartoon books I've read? I don't really know the exact number. But I have three full boxes of them under my bed. I also like drawing cartoons and wish to be an art teacher in a sch001.\n",
      "Joe Miller 16 year's old America\n",
      "I'm proud of doing things my own way. So whether somebody wants me to do something or whatever it is , I feel like they're all other people's thoughts , not really mine. But like others , I love reading , too. When I first took skiing lessons , I found it exciting. For ski racing,there's no question I'm better shape than most guys . I think it's fun. I mean,it is a challenge . It's where I picked up the idea of needing a challenge always in my life. In order to improve my skiing skills,I have read many books and magazines about it. No doubt it's my dream to win gold medals in the Olympic Games.\n",
      "An Oi 15 years old China\n",
      "I'm different because I prefer to drop out of the world to create my own world. I'd like to build a house on a mountain. And I choose to live without electricity, a telephone,or even indoor plumbing . I have many hobbies such as traveling,reading , writing and spending time with children. I love children because they are smart and creative. They always have many strange ideas. It makes me excited. I want to do something for Hope Project and become a country school teacher .\n",
      "\n",
      "Question: Which hobby do the three students all have?\n",
      "A. Writing.\n",
      "B. Skiing.\n",
      "C. Travelling.\n",
      "D. Reading.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5283203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85725\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001491546630859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Happiness is for everyone. You don't need to care about those who have beautiful houses with large  gardens and swimming pools or those who have nice cars and lots of money and so on. Why? .Because  those who have big house may often feel lonely and those who have cars may want to walk on the country roads at their free time.\n",
      "In fact, happiness is always around you if you put your heart into it. When you are in trouble at school, your friends will help you; when you study hard at your lessons, your parents are always taking good care of your life and your health; when you get success, your friends will say congratulations to you; when you  do something good to others, you will feel happy, too.All these are your happiness. If you notice them, you can see that happiness is always around you.\n",
      "Happiness is not the same as money.It is a feeling of your heart. When you are poor, you can also say you are very happy, because you have something else that can't be bought with money. When you meet with difficulties, you can say loudly you are very happy, because you have bad luck. As the saying goes, life is like a _ door. When it closes, it also opens.  If you take every chance you get,  you  can be a happy and lucky person.\n",
      "\n",
      "Question: Which is TRUE according to the passage?\n",
      "A. When you get success, your friends will be very proud of you.\n",
      "B. You can get help from others when you are in trouble.\n",
      "C. You can still be a happy person even if you have little money.\n",
      "D. All of the above.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29747\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004107952117919922\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.120849609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: John gets up early from Monday to Saturday, because he must go to school before 7:30 on weekdays  and go to Drawing Club at 8:00 on Saturday mornings. He usually goes to the bookshop on Saturday afternoon, and after dinner he watches TV until  midnight .\n",
      "He doesn't get up early on Sundays. John's parents both work on Sundays. John always watches TV after he gets up. Then he usually goes to KFC to have a hamburger and some juice for lunch. After that, he goes back home and starts to play computer games until his parents come back. He does his homework after dinner. He usually has lots of weekend homework, so he must spend three hours on it. He usually goes to bed at about 11:00 p.m. on Sundays. He often complains  he has too much homework to do.\n",
      ",.\n",
      "\n",
      "Question: How often does John need to get up early?\n",
      "A. Every day.\n",
      "B. Five days a week.\n",
      "C. Only on Saturdays and Sundays.\n",
      "D. Six days a week.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82844\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 8.064508438110352e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50393\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0024547576904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Joseph really felt very happy. When he arrived at his seat in the classroom that morning, he found an invitation on his desk. It was from several of his classmates asking him to join them on a camping trip. This was the first time he was asked to join in an out-of school activity. Why were they asking him now? Nobody seemed to like him. In fact, he had been so lonely _ . As a result, he had put on a lot of weight, and this gave the kids something more to make fun of him.\n",
      "Celina, who was standing near Joseph when he read the invitation, went out quickly to tell the others that the trick had worked. Everyone was pleased that Joseph thought that was true. But there was no camping trip. The whole thing was made up.\n",
      "At first, Celina thought it was fun. But later, when Joseph told her that he was going to buy a sleeping bag with his savings, Celina had a second idea. She knew that Joseph's family had little money, and she hated to see him spend his savings on something he would never use. Celina also hated to tell Joseph the truth. Her close friends would be angry with her.\n",
      "What could she do now?\n",
      "\n",
      "Question: If Joseph bought a sleeping bag,   _  .\n",
      "A. he would have it for no use.\n",
      "B. everyone else would also buy one\n",
      "C. it would be the best in the class\n",
      "D. Celina would pay for it\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1441650390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68362\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004669189453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Today is Sunday, and it is a fine day. The animals in the zoo are having a sports meeting now. Let's go and watch it. Look! Some tigers and horses are running fast. They all want to get the first place .What are elephants and lions doing? Oh ,they are playing soccer. The big elephants and the fast lions! What a funny picture it is! And some pandas are watching the soccer game happily .In the pool, a dolphin and a penguin are swimming. Near the pool, a monkey and a koala are climbing up an apple tree .They are both fast and want to get the apples on the tree. A giraffe is umpiring  the game under the tree. Who do you think can get more apples, the monkey or the koala? What an interesting sports meeting it is!\n",
      "\n",
      "Question: What is the best title  for the article?\n",
      "A. Welcome to the zoo\n",
      "B. The animal sports meeting\n",
      "C. The cute animals\n",
      "D. Welcome to the sports meeting.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.42431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05487060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Val is a six-year-old boy. He begins to go to school this term. He studies very hard and listens to the teachers carefully. He is polite and has many friends. They all like him very much.\n",
      "It was Sunday. Val, his sister and his mother stayed at home. His mother was doing some housework, his sister was doing her homework. Val was watching TV. At ten his father came back with some apples. The boy liked apples very much and wanted to eat some of them. His mother gave him four apples and said, \"Go and wash them.\"\n",
      "Val washed the apples and then gave them back to his mother. Mother asked, \"Which apple do you want, Val?\"\n",
      "\"The biggest one, Mum.\"\n",
      "\"What?\" said his mother, \"You should be polite and want the smallest one.\"\n",
      "\"Should I tell a lie to be polite, Mum?\"\n",
      "\n",
      "Question: Who was going to eat the biggest apple?\n",
      "A. His mother.\n",
      "B. His father.\n",
      "C. His sister.\n",
      "D. Val.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1968994140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.175048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: One day my wife and I went shopping at  the shop. We took the car as we had a lot of things to buy because my brother and his family were going to spend the weekend with us. We stopped the car in front of the shop. An hour later we came back to the car with a lot of things. Then the trouble started. We could not open the car door.\n",
      "\"Oh, dear,\" said my wife, \"What are you going to do?\"\n",
      "\"Let's ask that policeman,\" I said. The policeman was very kind and glad to help us. A few minutes later he got the door open. Just at that moment an angry man came up and shouted, \"What are you doing with my car?\"\n",
      "We looked at the number of the car and our faces turned very red.\n",
      "\n",
      "Question: The husband and the wife went shopping   _  .\n",
      "A. by bus\n",
      "B. in their car\n",
      "C. by bike\n",
      "D. on foot\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67405\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00220489501953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Several years ago, Kevin Stephan, then aged 11, was playing baseball when a player accidentally hit him with a bat.\n",
      "Kevin fell down and his heart stopped. Penny Brown, the mother of another player, was watching the game.Penny usually worked in the evenings as a nurse, but luckily that evening she wasn't working. Penny ran to helped Kevin and saved his life.\n",
      "Nearly seven years later, Kevin was washing up in the kitchen of the Hillview Restaurant in Buffalo, New York State. Normally, 18-year-old Kevin had school in the afternoon, but that week there were exams and he didn't have any class. At about 2 p.m., Penny Brown was having lunch with her family in the restaurant. She was eating when some food got stuck in her throat. She was very frightened because she couldn't breathe.\n",
      "Kevin was a volunteer firefighter in his free time and he ran to help. A waitress tried to help her, but the food was still stuck in Penny's throat. Kevin pulled his hands quickly into her stomach and saved Penny's life. He didn't know it was Penny, but his mother, Lorraine Stephan, was also having lunch in the restaurant. She realized that Penny was the woman who saved Kevin's life, seven years before, at the baseball game. Both Penny and Kevin were completely amazed by the coincidence !\n",
      "\n",
      "Question: What did Kevin usually do in the afternoon when he was 18?\n",
      "A. He had some exams.\n",
      "B. He studied at school.\n",
      "C. He worked as firefighter.\n",
      "D. He worked in a restaurant.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6650390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19673\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00321197509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Have you ever heard someone use the phrase \"once in a blue moon\"? People use this expression to describe something that they do not do very often. For example, someone might say that he tries to avoid eating sweets because they are unhealthy, but will eat chocolate \"once in a blue moon\". Or someone who does not usually like to go to the beach might say \"I visit the shore once in a moon.\" While many people use this phrase, not everyone knows the meaning behind it.\n",
      "The first thing to know is that the moon itself is never really blue. This is just an expression. In fact, the phrase \"blue moon\" has to do with the shape of the moon, not the color.\n",
      "As the moon travels around the earth, it appears to change shape. We associate names with certain shapes of the moon. For example, when we can see a small part of the moon, it is called a crescent moon. A crescent is a shape that looks like the tip of a fingernail. When we cannot see the moon at all, it is called a new moon. When we can see the whole moon, it is called a full moon. Usually, there is only one full moon every month. Sometimes, however, there will be two full moons in one month. When this happens, the second full moon is called a \"blue moon\".\n",
      "Over the next 20 years, there will only be 15 blue moons. As you can see, a blue moon is a very rare event. _ has led people to use the expression \"once in a blue moon\" to other very rare events in their lives.\n",
      "\n",
      "Question: Which of the following is another example of something that has a crescent shape?\n",
      "A. The letter \"O\".\n",
      "B. The letter \"M\".\n",
      "C. The letter \"H\".\n",
      "D. The letter \"C\".\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71525\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00030517578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.81201171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: It was the golden season. I could see the yellow leaves dancing in the cool wind. I felt lonely and life is uninteresting. But one day, the sound of a violin came into my ears. I was so surprised that I ran out to see where it was from. A young girl, standing in the wind, was lost in playing her violin.\n",
      "I had never seen her before. The music was so wonderful that I forgot who I was.\n",
      "Leaves were still falling. Every day she played the violin in the same place and I was the only listener. It seemed that I no longer felt lonely and life became interesting. We didn't know each other, but I thought we were already good friends.\n",
      "One day, when I was listening, the sound suddenly stopped. The girl came over to me.\n",
      "\"You must like violin.\" she said.\n",
      "\"Yes. And you play very well. Why did you stop?\" I asked.\n",
      "Suddenly, a sad expression appeared on her face and I could feel something unusual.\n",
      "\"I came here to see my grandmother, but now I must leave. I once played very badly. It is your listening every day that has _ me.\" she said.\n",
      "\"In fact, it is your music that has given me those meaningful days.\" I answered. \"Let us be friends.\"\n",
      "The girl smiled and I smiled.\n",
      "I never heard her play again in my life. Only thick leaves were left behind. But I will always remember the girl. She is like a dream; so short, so bright that it makes life beautiful.\n",
      "There are many kinds of friends. Some are always with you, but don't understand you. Some say only a few words to you, but are close to you. I shall always think of those golden days and the girl with the violin. She will always bring back the friendship between us. I know she will always be my best friend.\n",
      "\n",
      "Question: The story happened   _  .\n",
      "A. in a park\n",
      "B. in a lonely place\n",
      "C. in winter\n",
      "D. in autumn\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0860595703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: On a stormy day last August, Tim heard someone shouting. Looking at the sea carefully, he saw that two kids in a rowboat were being pulled out to sea.\n",
      "Two 12-year-old boys, Christian and Jack, had rowed out in a boat to _ a football. Once they'd rowed beyond the calm waters, a beach umbrella tied to the boat caught the wind and pulled the boat into open water. The boys were terrified and tried to row back to shore. But they were no match for _ and the boat was out of control.\n",
      "Tim knew that it would soon be swallowed by the waves.\n",
      "\"Everything went quiet in my head,\" Tim recalls. \"I'm trying to figure out how to swim to the boys in a straight line.\"\n",
      "Tim took off his clothes and jumped into the water. Every 500 yards or so, he raised his head to judge his progress. \"At one point, I considered turning back,\" he says. \"I wondered if I was putting my life at risk.\" After 30 minutes of struggling, he was close enough to shout to the boys, \"Take down the umbrella!\"\n",
      "\"Let's aim for the pier ,\" Jack said. Tim turned the boat toward it. Soon afterward, waves crashed over the boat, and it began to sink. \"Can you swim?\" he cried. \"A little bit,\" the boys said.\n",
      "Once they were in the water, Tim decided it would be safer and faster for him to pull the boys toward the pier. Christian and Jack were wearing life jackets and floated on their backs. Tim swam toward land as water washed over the boys' faces.\n",
      "\"Are we almost there?\" they asked again and again. \"Yes,\" Tim told them each time.\n",
      "After 30 minutes, they reached the pier.\n",
      ",.\n",
      "\n",
      "Question: When did the story happen?\n",
      "A. On a holiday.\n",
      "B. On a stormy day.\n",
      "C. At a weekend.\n",
      "D. After a football match.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.041015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64063\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007358551025390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Long long ago, there were three tortoises .  They were friends.\n",
      "One of them was a large tortoise, one was a medium-sized tortoise and the third was a small tortoise.\n",
      "One day they went into a restaurant and ordered some cakes. While(......) they were waiting for the cakes, they remembered that they didn't bring any money.\n",
      "\"Hey, we forgot to bring money to pay for our cakes,\" the big tortoise said.\n",
      "\"The little tortoise can go home and get it,\" the medium-sized tortoise said. \"He's the youngest, so he should be the one to go.\"\n",
      "The little tortoise wasn't very happy, but he knew he shouldn't argue with his elders, so he said, \"All right, I'll go. But you must promise  not to eat my cake while I'm away.\"\n",
      "The large tortoise and the medium-sized tortoise agreed, and the little tortoise left for home to get some money.\n",
      "A few days later, the big tortoise said to the medium-sized tortoise, \"Let's eat the little tortoise's cake. I'm hungry again.\"\n",
      "\"So am I,\" the medium-sized tortoise said, and reached for the cake.\n",
      "As she did so, the little tortoise shouted from near the door of the restaurant, \"If you touch  my cake, I won't go and get the money!\"\n",
      ", .\n",
      "\n",
      "Question: The three tortoises   _  .\n",
      "A. didn't know each other\n",
      "B. knew each other\n",
      "C. lived in a restaurant\n",
      "D. were very poor\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 100274\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007987022399902344\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67324\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00295257568359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: \"Make-A-Wish\" is one of the world's most well-known charities . It makes wishes come true for children who have serious illnesses. It gives them hope and joy and helps them forget about their health problems and have fun.\n",
      "It all started in 1980 in Phoenix,Arizona.Christopher was a 7-year-old boy who was very sick. He always dreamed of becoming a police officer.Tommy Austin and Ron Cox,two police officers, made his wish come true. They gave Cristopher a tour of the city  in a police helicopter( )and made a real police uniform for him.\n",
      "There are four kinds of wishes children usually have:\n",
      "I wish to go. Children ueually want to travel or go to a concert ,a game or a park.\n",
      "I wish to meet. Children sometimes want to meet their favourite actors,singers or players.\n",
      "I wish to be. Some children wish to become actors,singers or police officers.\n",
      "I wish to have. They often want to have a computer, a game, a bike or many other things.\n",
      "Let's hope more wishes will come true in the future.People who work in the charity always try for the best.Almost 25,000 volunteers help,work or give money. Will you be one of them?\n",
      "\n",
      "Question: What did the two police officers do for Christopher?\n",
      "A. They gave him a computer.\n",
      "B. They gave him a tour of the city .\n",
      "C. They took him to a concert.\n",
      "D. They took him to the hospital.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.47314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29667\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07037353515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Lucy:I like sports. I have ten tennis balls, seven basketballs, four volleyballs and five soccer balls. I play tennis with my friends every day.\n",
      "Mary:I have five baseballs, five volleyballs, two soccer balls. I like ping-pong. It's easy for me. I often play ping-pong with my classmates. I also have three ping-pong bats and some ping-pong balls.\n",
      "Alice:I don't have any balls. I  love sports, but I don't play them. I only watch them on TV.\n",
      "\n",
      "Question: _  has/have five soccer balls.\n",
      "A. Mary\n",
      "B. Lucy\n",
      "C. Alice\n",
      "D. Mary and Lucy\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28206\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01812744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0225372314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: You may have noticed that the world's population is not evenly distributed   around our planet. There are more countries where people seem to be living nearly _ each other because conditions are overcrowded . Then there are others where it seems that hardly anybody lives. What influences this unequal distribution of people ? There are specific advantages and disadvantages of living in a certain area.\n",
      "The two main factors   that influence people's choice of location are climate and resources. Climate is the usual weather conditions in a region. Areas that have bad weather are generally less ideal as places to live in . The north and south poles at the top and bottom of the world may be beautiful in their rugged, natural way , but the disadvantage of the bitterly cold and windy conditions usually keeps people away. When it comes to climates, warm conditions and a normal amount of rainfall are advantages that attract people.\n",
      "Natural resources are tings that we get from nature that help us survive. Each region offers different resources, and therefore attracts different groups of people. People who enjoy the beach can make their living by catching and selling the ocean's many fish and other sea creature. Those who prefer farming can take advantage of rich soil in valleys near rivers. Some people are willing to accept the disadvantages of the terrible conditions of deserts or mountains in order to take advantages of the resources like oil or woods.\n",
      "\n",
      "Question: The writer thinks many people don't live near the north or south pole because  _  .\n",
      "A. they can't get enough food there\n",
      "B. the natural sights there don't arrract people\n",
      "C. the unpleasant weather keeps them away\n",
      "D. the length of nighttime keeps them away\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 108279\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00629425048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91591\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0203094482421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Tom was a farmer. He worked on the farm all day,but sometimes he went to the town market to sell fruit and vegetables. One day, a terrible sound attracted his attention in the town market. He saw a young bull for sale. The bull was white and yellow. It was looking at Tom in fear. Tom walked up and touched its head gently. Just at that time they both seemed to have known each other for a long time. How amazing!Tom bought it at once and called it Amba.\n",
      "From then on , Tom and Amba got on well with each other. But some friends told him that it was dangerous to have such a close relationship with an animal.\n",
      "One afternoon , Tom was walking through the forest with Amba. Suddenly , Amba stopped walking and kept pushing Tom with its head. Tom was very surprised and looked around. There was a big snake in front of him. It was beautiful but poisonous. Quickly Amba stepped on the snake's tail with its foot and at the same time Tom picked up a stick and hit the snake's head heavily. Soon the snake . died.\n",
      "Tom was very grateful for Amba's help. When people heard this, they were shocked at the bull's expression of love for Tom. But for Tom, Amba was not a bull but a member of his family.\n",
      "\n",
      "Question: From the passage, we know Tom and Amba  _  .\n",
      "A. hated each other\n",
      "B. got angry with each other\n",
      "C. got on well with each other\n",
      "D. disliked each other\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 86760\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Foreign visitors are often puzzled   in Japan because most streets there don't have names. In Japan, people use _ in their directions instead of street names. For example, the Japanese will say to travelers, \"Go straight down to the corner. Turn left at the big hotel and go pass a fruit market. The post office is across from the bus stop.\"\n",
      "In the countryside of the American Midwest, usually there are not many landmarks. There are no mountains, so the land is very flat  . In many places there are no towns or buildings within miles. Instead of landmarks, people will tell you directions and distance. In Kansas or lowa, for example, people will say, \"Go north two miles. Turn east, and then go another mile.\"\n",
      "People in Los Angeles, California, have no idea of distance on the map: the measure   distance by means of time, not miles. \"How far away is the post office?\" you ask. \"Oh,\" they answer, \"it's about five minutes from here.\" you say, \"Yes, but how many miles away is it?\" They don't know.\n",
      "People in Greece sometimes do not even try to give directions because visitors seldom understand the Greek language. Instead of giving you the direction, a Greek will often say, \"Follow me.\" Then he'll lead you through the streets of the city to the post office.\n",
      "Sometimes a person doesn't know the answer to your question. What happen in this situation? A New Yorker might say, \"sorry, I have no idea.\" But in Yucatan, Mexico, no one answer, \"I don't know.\" They think that it is impolite. They usually give an answer, often a wrong one. A visitor can get lost in Yucatan.\n",
      "One thing will help you everywhere. You might not understand a person's words, by maybe you can understand his body language. He or she will usually turn and then point in the correct direction.\n",
      "\n",
      "Question: How many ways of giving directions in the passage?\n",
      "A. Four\n",
      "B. Five\n",
      "C. Six\n",
      "D. seven\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.055938720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40506\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001262664794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Most People don't like mice, but they love one mouse -- Mickey Mouse. In their mind, this mouse is their favourite animal. About 70 years ago, an American man called Walt Disney created  a cartoon mouse for films. He named this mouse Mickey Mouse. From the beginning, Mickey Mouse is a clean mouse. He always does many interesting things. That's why many children and people love him. He makes them happy and _ . In the film, Mickey Mouse also has a lot of friends, for example, Donald Duck and Pluto. Donald can do many things that Mickey cannot. Pluto is a dog. He always does foolish things and makes foolish mistakes. Many children like these cartoon animals, but they like Mickey most because the mouse is a star of beauty and wisdom .\n",
      "\n",
      "Question: Many children and people like Mickey Mouse because  _  .\n",
      "A. He never makes mistakes\n",
      "B. He is like a real mouse.\n",
      "C. He always does many interesting things\n",
      "D. He has many friends.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34286\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01070404052734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 37264\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01299285888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: On Children's Day a young woman from America goes to Beihai Park with her little daughter. There are too many people in the park. The woman can't find her daughter, So she goes to the policeman for  help. She tells the policeman her daughter is only six years old. She has two big eyes and a round face. Her hair is golden yellow. And she is in a short blue dress. At last the policeman helps her find her daughter. She thanks him very much.\n",
      "\n",
      "Question: The little girl's hair is   _  .\n",
      "A. yellow\n",
      "B. black\n",
      "C. brown\n",
      "D. golden yellow\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64575\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00034165382385253906\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.73388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The best day of the week for shoppers is Saturday. In America, women do most of the shopping, while the young also enjoy shopping with their friends. Men don't enjoy taking time in the store. There are many places to shop. A mall is a group of many shops where you can buy clothes, _ and everything of the house. Shopping malls provide parking of the cars which is very important to the shopper. Usually the mall is under one roof, so each people doesn't get cold or wet from rain, wind, or snow. Mothers can buy clothes for family members. For the children, shoes, socks, dresses, coats, and sweaters are bought in August for the new school year. For the kitchen the mother might buy cooking pots, drinking glasses, and the television set. The bedroom furniture has beds, mirrors and so on. Finally, there are pictures in most rooms.\n",
      "To buy all these things at the mall takes many trips but mothers enjoy this kind of shopping.\n",
      "\n",
      "Question: What is a shopping mall?\n",
      "A. It's a group of many shops where you can buy everything you need.\n",
      "B. A department store where you can buy everything you need.\n",
      "C. A supermarket where you can buy vegetables, fruits and so on.\n",
      "D. You can park your car there\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.344970703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53709\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00591278076171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: I was 10 the year my cousin Marley's parents gave her a painful Christmas surprise: they were getting a divorce . My aunt went to California, but my uncle decided to get her back. There was one matter: where to put his young daughter. Luckily, my mother loved Marley, giving her more attention than her family ever did.\n",
      "On that Christmas Eve, my cousin arrived on our doorstep carrying an old blue suitcase. Before she stepped inside, Marley said, \"It doesn't matter. When my parents come back, we'll have a bigger Christmas than this.\"\n",
      "Late on the night Marley arrived, my mom came into my room, her arms filled with packages.I knew they were my Christmas presents. \"I know how you love surprises but we have to decide which ones to give to Marley.\"\n",
      "My mother carefully opened the gifts. Wow! I saw ice skates, red leather gloves and a dollhouse. The last present was the music box we'd asked the lady at the local store to take down and play for us over and over again.\n",
      "\"Which ones?\" my mother asked. \"She can have the ice skates,\" I said reluctantly . \"That's good,\" my mother said. She began to tape the packages up again. Then she stopped and asked, \"Are you sure about these?\" At that moment, I realized she expected more from me than I had already given. So I gave her the music box, too, and  _ . The next morning, Marley's eyes were resolute . She expected nothing and wanted us to know she didn't care. But when she saw her name on the biggest box, she couldn't hide her excitement. I thought my happiness would be cut in half. Instead it was doubled.\n",
      "Over the last 40 years, Marley and I have grown apart . But the love we felt for each other that day still remains. Today Marley says, \"They were the best presents I ever got.\n",
      "\n",
      "Question: According to this passage, which of the following statements is TRUE?\n",
      "A. The writer's parents got a divorce when she was ten.\n",
      "B. The writer hated her cousin because she took away some of her presents\n",
      "C. Marley expected nothing, so she wasn't excited about the Christmas presents.\n",
      "D. The writer was very happy during that Christmas.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 72788\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003093719482421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The best way of learning a language is by using it. The best way of learning English is using English as much as possible. Sometimes you will get your words mixed up and people won't understand. Sometimes people will say things too quickly and you can't understand them.\n",
      "But if you keep your sense of humor( ),you can always have a good laugh at the mistakes you make.\n",
      "Don't be unhappy if the people seem to  laugh at your mistakes. It's much better for people to laugh at your mistake than to be angry because they don't know what you are saying. The most important rule for learning English is \"Don't be afraid of making mistakes. Everyone makes mistakes.\"\n",
      "\n",
      "Question: The most important thing of learning a language is   _  .\n",
      "A. laughing\n",
      "B. writing\n",
      "C. remembering\n",
      "D. practicing\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46407\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.040679931640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.069580078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Sales of laptop computers passed desktops in the U.S. for the first time ever this fall, according to market-research firm IDC. That's bad news for backs, necks and shoulders.\n",
      "Laptops are bad for our body. When you work at a computer, the keyboard should be at elbow height and the monitor should be roughly at eye level, so you can sit well in a chair. But most users simply set their laptops on a desk or table. The keyboard is too high, which makes your arms reach up, your shoulders feel tired and your wrists bend down. The monitor is too low, which pulls your head and neck forward and down and your back may feel hurt.\n",
      "That's OK if you use your laptop for a short time. But if you use one for hours without stopping - as do millions of college students, business travelers, telecommuters, video-gamers and growing numbers of office workers - your body may feel hurt. Ergonomics experts have warned about laptop problems for years. But people still like laptops better than the desktops. And they use laptops anywhere - in bed, on the floor - in all kinds of positions.\n",
      "\"How can a mouse or a keyboard hurt you?\" says Thomas Caffrey, the founder of Myofactors LLC, \"Wrong positions can be bad for your body. As time goes by, a wrong position can lead to pain in the neck, shoulders, back and arms, as well as headaches.\"\n",
      "\n",
      "Question: According to the passage, which of the following is NOT true?\n",
      "A. When you use a laptop, you should put your monitor at eye height.\n",
      "B. Laptop computers sold more than desktops this autumn.\n",
      "C. To keep healthy, you should use laptop computers.\n",
      "D. Business travelers often use the laptop computers for a long time.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20067\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005916595458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88818\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0115203857421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Many middle school students like watching TV very much. But from Monday to Friday, they must go to school. So on Saturday and Sunday they stay at home and watch TV from morning to night. They don't know it's bad for their eyes. Usually children like to eat fish, meat and chicken and don't like vegetables or fruit. They don't know eating more vegetables or fruit. They don't know eating more vegetables and fruit is better than eating meat.\n",
      "At school, the children only do a few minutes of sports or never do any sports. The teachers must know it isn't good for their health.\n",
      "We always think of ways to keep healthy. We must eat more vegetables and fruit, do enough sport every day. And we should watch TV and read in right ways.\n",
      "\n",
      "Question: How should we keep healthy?\n",
      "A. Eat more vegetables and fruit.\n",
      "B. Do enough sports every day.\n",
      "C. Watch TV in right ways.\n",
      "D. All of the above.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30135\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00354766845703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 90408\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0010786056518554688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Children in England mustn't work until they are 13. They need to have a work permit   to start working.\n",
      "The jobs teenagers can do\n",
      "Delivering   newspapers\n",
      "Many teenagers will get up early to deliver newspapers to houses in their local area before going to school. They are known as Paper-boys or Papergirls.\n",
      "Babysitting: Looking after young children in their home while their parents have gone out for the evening is a popular job for teenagers, as they get money for watching children and television all at the same time!\n",
      "Helping the Milkman: From the age of 14 some teenagers help the milkman deliver milk to houses.\n",
      "Other popular jobs : Working in a shop; Office work; Washing cars ; In a cafe or restaurant. The hours teenagers (13 and 14 year olds )can work:\n",
      "School Days\n",
      "Not more than 2 hours in one day during the following periods:\n",
      "Morning 7 a. m. --start of school or Evening\n",
      "close of school-- 7 p. m.\n",
      "Saturdays: Up to 5 hours between 7 a.m. and 7 p.m.\n",
      "Sundays\n",
      "Up to 2 hours between 7 a.m. and 11 a. m.\n",
      "Term time\n",
      "Up to 12 hours a week (Including weekends)\n",
      "\n",
      "Question: In England how old do children have to be before they can work?\n",
      "A. 15.\n",
      "B. 14.\n",
      "C. 10.\n",
      "D. 13.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2049560546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127854\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00014579296112060547\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear Boris,\n",
      "Thanks for your nice letter.\n",
      "After I had spent a week with my English family, I slowly began to understand their English a little better. It's very different from what I learned at school! Students in my group are from different cities of Britain and their dialects   are different too! Some of their accents   are quite strong and they also have their own words and expressions.\n",
      "But it's not the language that's different and surprising. Before I came to England I had thought that fish and chips were eaten every day. That's quite wrong! I get rather mad now when I hear all the foolish words about typical   English food.\n",
      "I had expected to see \"London fog\". Do you remember our texts about it? We had no idea that most of this 'thick fog' disappeared many years ago when people stopped using coal in their homes. But the idea to speak about the weather was very helpful. The weather in London is really changeable.\n",
      "On the other hand habits are different. People tell me what is typically British here in London is not always typical in Wales or Scotland. Local habits and traditions are not the same as what we knew.\n",
      "But what is ordinary for all British is that they follow traditions. Probably Britain has more living signs of its past than many other countries. And people have always been proud of having ancient buildings in capitals, big cities and the countryside.\n",
      "I will tell you more about Britain in my other letters.\n",
      "Love from Britain,\n",
      "Peter\n",
      "\n",
      "Question: The British people like to talk about weather because   _  .\n",
      "A. there is thick fog in London\n",
      "B. they like the weather in Britain\n",
      "C. the weather changes a lot\n",
      "D. it can be helpful\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 122063\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00368499755859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1187744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Driving a car at a high speed along a highway seems to be fun. You only need to follow the bright traffic signs beside the highway and it will take you where you wish to go. But to a London taxi driver, driving is not an easy job. A taxi driver needs to have not only good driving skills but also a good knowledge of the city of London, from the loneliest street to the popular restaurant around. He has to be at the service of all kinds of passengers   at all times.\n",
      "A London taxi driver said the following about his job.\n",
      "During the night it is usual for him to stop two or three times for some food. He said, \"I never drink when I'm working, otherwise I'd lose my license  .\"\n",
      "He normally goes home between two and three o'clock in the morning. There are times he has to stay longer and try to make more runs. He said, \"That's the worst thing about working for yourself. If you don't make money, no one is going to give it to you. \"\n",
      "London taxi drivers not only \"take\" but also \"give\". Every summer hundreds of poor children from London go for a day at the sea -- by taxi! There rides are paid by the taxi drivers. At the sea, they are met by the mayor   , and a lunch party is also held for the taxi drivers and the children. After a happy day's running around the beaches and visiting the market there, the children go home again by taxi, free of charge of course!\n",
      "\n",
      "Question: How do London taxi drivers \"give\"?\n",
      "A. They give the poor children a lunch party at the sea each summer.\n",
      "B. They give poor children the chance to meet the maor.\n",
      "C. They pay for some poor children's rides for a day's tour each summer.\n",
      "D. They play with some poor children at the sea for a day each summer.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.98974609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95372\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00031495094299316406\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear Mr. Expert,\n",
      "I grew up in an abusive  home. I always promised myself that I'd get out as soon as possible. Now, at age 20, I have a good job and a nice house of my own, and I'm really proud.\n",
      "Here's the problem: some of my friends who still live with their parents spend the weekends with me. But now they make mine theirs. They bring boy friends over, talk on the phone, etc.\n",
      "I enjoy having my friends here sometimes - it makes the place feel comfortable and warm, but this is my home, not a party house, what shall I do?\n",
      "Joan\n",
      "Dear Joan,\n",
      "If your family didn't pay attention to your needs when you were a child, you probably have trouble letting others know your needs now.\n",
      "And if you've gathered your friends around you to rebuild a happy family, you may fear that saying no will bring back the kind of _ that you grew up in. You need to understand that in true friendship it's okay to put your own needs first from time to time.\n",
      "Be clear about the message you want to send. For example, \"I really love you, but I also need some personal space. So please call before you come over.\"\n",
      "Edward\n",
      "\n",
      "Question: According to Mr. Expert, why can't Joan tell her friends her feeling?\n",
      "A. She is afraid of hurting her friends.\n",
      "B. She does not understand true friendship.\n",
      "C. Her family experience stops her doing so.\n",
      "D. She does not put her needs first.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1251220703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: There was a new maths teacher and some new students in the school. One of the new students named Karl was very _ . The other students tried to explain   numbers to him, but he didn't understand.\n",
      "Before Karl arrived, maths was the most boring lesson of all. Now it was great fun. The children would listen to Karl and correct his mistakes. They all wanted to be the first to find his mistakes, and then tried to think up the best ways to explain them.\n",
      "But little Lewis was sure that Karl felt sad and wanted to talk with him. So, one day, he decided to walk after Karl after school. Lewis was sure he would see him crying. On the way home, Karl walked a few minutes to a park, and there he waited for someone to meet him...\n",
      "It was the new teacher!\n",
      "They went off, hand in hand. Lewis could hear them talking about maths. And that stupid Karl knew everything about it, and even much more than anyone else in the class!\n",
      "\n",
      "Question: Which of the following is NOT true?\n",
      "A. The students liked maths after Karl arrived at the school.\n",
      "B. The students listened to Karl and tried to correct his mistakes.\n",
      "C. The students didn't want to be the first to find Karl's mistakes.\n",
      "D. The students tried to think up the best ways to explain to Karl.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7685546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01174163818359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Tom is a little boy ,and he is only seven years old. One day he went to the cinema. It is the first time for him to do that. He bought a ticket and then went in. But after two or three minutes he came out, bought a second ticket and went in again. After a few minutes he came out again and bought a third ticket. Two or three minutes later he came out and asked for another ticket. Then the girl in the ticket office asked him,\"Why do you buy so many tickets? How many friends do you meet?\"Tom answered,\" No, I have no friend here. But a big boy always stops me at the door and tears my ticket to pieces.\"\n",
      "\n",
      "Question: From the story we know  _  .\n",
      "A. the little boy had a lot of money\n",
      "B. the little boy knew nothing about the cinema\n",
      "C. The big boy wasn't friendly to Tom\n",
      "D. the girl wanted to get more money\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.409423828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: I was 10 the year my cousin Marley's parents gave her a painful Christmas surprise: they were getting a divorce . My aunt went to California, but my uncle decided to get her back. There was one matter: where to put his young daughter. Luckily, my mother loved Marley, giving her more attention than her family ever did.\n",
      "On that Christmas Eve, my cousin arrived on our doorstep carrying an old blue suitcase. Before she stepped inside, Marley said, \"It doesn't matter. When my parents come back, we'll have a bigger Christmas than this.\"\n",
      "Late on the night Marley arrived, my mom came into my room, her arms filled with packages.I knew they were my Christmas presents. \"I know how you love surprises but we have to decide which ones to give to Marley.\"\n",
      "My mother carefully opened the gifts. Wow! I saw ice skates, red leather gloves and a dollhouse. The last present was the music box we'd asked the lady at the local store to take down and play for us over and over again.\n",
      "\"Which ones?\" my mother asked. \"She can have the ice skates,\" I said reluctantly . \"That's good,\" my mother said. She began to tape the packages up again. Then she stopped and asked, \"Are you sure about these?\" At that moment, I realized she expected more from me than I had already given. So I gave her the music box, too, and  _ . The next morning, Marley's eyes were resolute . She expected nothing and wanted us to know she didn't care. But when she saw her name on the biggest box, she couldn't hide her excitement. I thought my happiness would be cut in half. Instead it was doubled.\n",
      "Over the last 40 years, Marley and I have grown apart . But the love we felt for each other that day still remains. Today Marley says, \"They were the best presents I ever got.\n",
      "\n",
      "Question: Who did Marley spend her Christmas with?\n",
      "A. Her father.\n",
      "B. Her mother.\n",
      "C. Her parents.\n",
      "D. Her uncle's family.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.26123046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.28173828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: There are several ways you can find out about the countries and places you wish to visit. You can talk to friends who have traveled to the places, you can go and see a colour film about them, or you can read a travel book.\n",
      "It seems that there are three kinds of travel books. The first are those that give a personal, subjective  idea of travels which their writer has got himself. These books can be useful if the writers share their traveling experiences with others. The second kind are those books which give objective  information of things to be done and seen. If _ has written such a book about the facts of a place, then it is more useful. The third kind are those books which are called \"a guide\" to some place or other. If they are good, they will describe and explain the place in detail. Like the first kind , they can be interesting and exciting, but their main purpose is to help the reader plan his travel in the most practical way.\n",
      "Whatever kind of travel book you choose, you must make sure that the book does not describe everything as interesting, exciting or fantastic. You must also keep an open eyes on its date of publication  because travel is very practical matter and many things change quickly in the 21st century. Finally, you should make sure that it's easy to find the useful information for you travel.\n",
      "\n",
      "Question: The writer of the first kind of travel books gave his ideas after he   _  .\n",
      "A. travelled\n",
      "B. read books\n",
      "C. a lot of experience\n",
      "D. surfed the Internet\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64900\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0633544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 108698\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.040557861328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: If an American is satisfied with you,he will put his thumb and forefinger into a circle.That means OK.But in Brazil,the very sign is considered to be rude.In Poland,a guest usually presents flowers to his hostess.The number must be an odd one.Besides,the hostess isn't expected to remove the cover of the bunch of flowers.And usually,the red rose is a sign of love.\n",
      "Usually we nod to express our agreement and shake our heads to show disagreement.To our surprise these body movements mean the opposite in Bulgaria.\n",
      "The differences in customs and cultures in the world are really noticeable.We should learn more about them to avoid embarrassment .Then,would you please remember:When in Rome,do as the Romans do.\n",
      "\n",
      "Question: In Poland,if a man gives some odd red roses to a woman as a present,it means that he   _  .\n",
      "A. will invite her to a dinner party\n",
      "B. has not been in love with her\n",
      "C. will invite her to a party\n",
      "D. has fallen in love with her\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40780\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00013577938079833984\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00687408447265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Chinese young people love their smart phones.They play with phone apps every day.But now, a book has let them forget about their phones.The book is called Secret Garden.\n",
      "It is a colouring book for adults'.You don't have to read it, because it has almost no words.All the pages are pictures but no colours.You just need to use colour pens to paint it.An artist in Britain made the book.\n",
      "The book is now the biggest selling book on amazon.Cn.last month, it sold 25,000 copies in China.Many young people bought this book.They like it so much that they stop playing games or surfing the Internet on their phones.These people are mainly young mothers and workers.It is very difficult to take care of babies or do a good job at first, so they feel a lot of pressure.Drawing the book can help them become less nervous.\n",
      "In the past, people thought colouring books are only for children.With Secret Garden getting more and more popular, many young adults also begin to paint as a hobby.\n",
      "\n",
      "Question: What made Chinese young people forget about their phones?\n",
      "A. Games.\n",
      "B. A book.\n",
      "C. Housework.\n",
      "D. Colours.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.990234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01441192626953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Do you know why different animals or pests have their special colours? Colours in them seem to be mainly used to protect themselves.\n",
      "Some birds like eating locusts , but birds cannot easily catch them. Why? It is because locusts change their colurs with the changes of the colours of crops .When crops are green, locusts look green .But as the harvest time comes, locusts change into the same brown colour as crops have .Some other pests whose colours are different from plants are easily found and eaten by others .So they have to hide themselves for lives and appear only at night.\n",
      "If you study the animals' life, you'll find the main use of colours is to protect themselves .Bears, lions and other animals move quietly through forests .They cannot be easily seen by hunters because their colours are much like the trees.\n",
      "Colours are useful not only on the land , but also in the sea .A kind of fish in the sea can give out a kind of black liquid when the fish face danger. The liquid spreads over quickly, so they cannot be found by their enemies and can quickly swim away. That is why they can live safely though they are not strong at all.\n",
      "\n",
      "Question: According to the passage, the fish can keep safe because  _  .\n",
      "A. they can change their colours\n",
      "B. they can give out a kind of black liquid\n",
      "C. they are strong enough\n",
      "D. they swim faster than any other fish\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.34033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77776\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013637542724609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Just as \"Tiger Mom\" leaves, here comes the \"Wolf Daddy\" called Xiao Baiyou. He believes he's the best parent in the world. Some days ago, Xiao Baiyou's latest book about how to be a successful parent came out. He is pretty strict with his four children. Sometimes he even beat them. But the children don't hate their daddy at all. And all of them finally went to Pecking University, one of the top universities in China. So Xiao proudly tells others about his education idea that children need strict rules. In his microblog, he said, \"Come on, want your children to enter Peking University without rules? You must be joking.\" And, \"Leave your children more money, and strict rules at the same time.\"But the \"Wolf Daddy\" way was soon questioned by other parents. Some say that Xiao Baiyou just want to be famous by doing so. The \"Wolf Daddy\" Xiao Baiyou is a 47-year-old Guangdong businessman who deals in luxury goods  in Hong Kong. Unlike many other parents who usually have one child, Xiao has four children. Two of them were born in Hong Kong and two in the US. Some people on the Internet think the reason why his children were able to enter Peking University is because the exam is much easier taken from Hong Kong.\n",
      "\n",
      "Question: _  of Xiao Maiyou's children went to Pecking University.\n",
      "A. One\n",
      "B. Two\n",
      "C. Three\n",
      "D. All\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68976\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002185821533203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01045989990234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: China and the Netherlands   are long-time friends. The Netherlands is more than 41,500 square kilometres in area. It is a bit larger than the size of Taiwan, China.\n",
      "The Netherlands is rich in culture and art. It is home of many great artists, for example, Vincent van Gogh. Besides fine art, the Netherlands is also called the country of tulips  . It has the world's largest tulip garden: Keukenhof garden.\n",
      "Dutch people are very hard-working. There's a saying: \"God made the Earth, but the Dutch made Holland.\" More than a quarter of the country is below sea level. So Dutch people build many dams   to protect the country from flooding. They have created almost one sixth of the country from seas and rivers!\n",
      "Did you know?\n",
      "* Rubber ducks are popular around the world. Dutch artist Florentijn Hofman created it in 2007. The yellow duck is 26 metres high.\n",
      "* Wooden clogs   are traditional shoes in the Netherlands. They make good gifts for tourists.\n",
      "* In the Netherlands, it is impolite to start eating at once. Dutch people will sometimes say \"delicious\" before eating.\n",
      "* Like the UK, the Netherlands also has\n",
      "kings and queens.\n",
      "\n",
      "Question: What is not talked about in the reading?\n",
      "A. Table manners.\n",
      "B. Artists.\n",
      "C. Weather.\n",
      "D. Tulips.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76754\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007648468017578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Kids have unbelievable imaginations. We asked one hundred kids how robots might help them learn better. This is what they thought.\n",
      "Roberts can make learning fun\n",
      "Kids dreamed robots would make learning fun. One 9-year-old boy in Germany says, \"When I get home, my robot helps me with my homework. My mother and father came in and said 'no video games now, homework first'. When they saw that I had finished my homework, they'd be surprised\".\n",
      "Robots take care of the dirty work\n",
      "Dirty dishes? No problem. A quarter of kids surveyed imagined that their robots could do chores and boring work so that they might be freed up.\n",
      "Robots are our friends\n",
      "Two-thirds of the kids thought that their robots could be friends. One 10-year-old French boy describes his dream robot: \"He created books for me to read, we played with toy cars. He keeps my secrets. I can tell him anything, and he gives me suggestions.\"\n",
      "Robots are cool\n",
      "An 8-year-old girl in the U.S. imagines that her robot is \"really smart and everyone likes to talk to her. She has a funny voice, but we do not laugh at her.\"\n",
      "\n",
      "Question: The boy from Germany wanted his robot to  _  .\n",
      "A. help him with the homework\n",
      "B. play game spot with him\n",
      "C. surprise his parents\n",
      "D. make fun of him\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3193359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48067\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.011962890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The first time I went abroad was when I went to London. It was in the summer holidays about five or six years ago and I went with three friends. The plane and train were quite expensive, so we decided to travel by coach. We left at five o'clock in the morning and the journey to London took about sixteen hours but we didn't mind: we were all very excited because for all four of us it was our first time away from home.\n",
      "We stayed in London for three days, in a youth hotel not far from the centre. While we were there, we walked a lot. First, we went to see all the famous sites--Big Ben, Piccadilly Circus, Buckingham Palace, then we went shopping in Oxford Street. On the last morning my friends stayed in bed late, but I got up early and went to Camden Market. You can buy all kinds of jewelry and clothes there, and I bought a silver ring for my sister. It was really hot in the afternoon, so we went to Hyde Park for a game of football. Unfortunately, I think the ring fell out of my pocket during the game, because I couldn't find it when I got on the coach that evening!\n",
      "I've been back to London several times since then, but I don't think I'll ever feel as excited as I did that first time.\n",
      "\n",
      "Question: When did the wrier think he lost the silver ring he bought for his sister?\n",
      "A. When they went shopping in Oxford Street.\n",
      "B. When they played football in Hyde Park.\n",
      "C. When he got on the coach that evening.\n",
      "D. When he got back to London.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 86454\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002713203430175781\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89606\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.034576416015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Even though she's quite young, Drew Barrymore can be a Hollywood legend  . She was born on February 22, 1975, in California. Being from a family that produced great actors, she quickly found her way into the spotlight  .\n",
      "When she was 11 months old, she made her first advertisement  on TV. She made her first movie at the age of 2. Five years later, she acted Gertie in Steven Spielberg's famous film E.T. the Extra-Terrestrial(1982).[:,However, it wasn't all roses and sunshine when Barrymore was growing up. Most kid stars in Hollywood can't become stars as adults. And once they're out of order, their lives are in the darkness, smoking and drinking. So does Drew Barrymore\n",
      "As she was growing older, Barrymore started to realize that life is more meaningful than dangerous actions in the films. She started to build a career in 1997. She has made a series of successful films since then, including Charlie's Angels (2000) and 50 First Dates (2004).\n",
      "\"In my life, there is darkness and drama , and I have yet to explore some of that in my work life. I just want to challenge   myself and prove that I can do more.\"\n",
      "Actually, anyone who's not familiar with her disordered childhood might find it hard to believe she's such a sweet person now. Like many of the characters she plays in her comedy, Drew is easy-going and laughs a lot. In 2007, she was on the cover of People magazine's 100 Most Beautiful People issue.\n",
      "\"Life is very interesting ... in the end, some of your greatest pains, become your greatest strengths ,\" Drew said.\n",
      "\n",
      "Question: Drew Barrymore can be a Hollywood legend mainly because  _  .\n",
      "A. she was born form a family that produced great actors\n",
      "B. she used to be a famous kid star in Hollywood\n",
      "C. she always has roses and sunshine in her life\n",
      "D. she didn't give up even when she met difficulties\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4619140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13811\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03387451171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The widespread number of food scandals in  China is making many people pause before they put their chopsticks in their mouths.They are wondering if the food they are eating is clean,healthy and nutritious  or does it contain  something harmful that will cause disease?\n",
      "Most of the food we eat today is processed food .That means the foods we buy in stores and supermarkets,especially packaged foods,are prepared in factories.Chemicals are added to the foods in these factories to  make them look better,taste better and last longer on the shelf.The chemicals are supposed to be harmless and there are laws that regulate  which chemicals can and cannot be used.Unfortunately,some producers do not obey the laws.\n",
      "A producer of steamed buns in Zhejiang Province was recently discovered to be breaking the law.He was adding yellow dye and other banned chemicals to the buns.He was also taking old buns and using them to make new buns.Most of the buns were sold to schools and eaten by students...like you!\n",
      "Why did he do it? Why did he break the law and endanger people's  health? The answer is simple:he wanted to make more money.It was a moral failing,and this is at the heart of the food scandals in China.Too many people focus on making money and not on the effects their actions can have on others.\n",
      "\n",
      "Question: What is the main reason of the food scandals in China ?\n",
      "A. Some products do not obey the laws.\n",
      "B. The processed food is clean, healthy and nutritious.\n",
      "C. Too many people pay attention to making money.\n",
      "D. The chemicals are supposed to be harmless and can be used.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.12237548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29398\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0024700164794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Hi, friends! Welcome to our Family Rock Band. There are four members in our band. They are Wangwang, Mimi, Yingying and I. Wangwang is my dog. It can sing and dance. Mimi is my cat. It can't dance but it can sing and do Chinese kung fu. Yingying is a parrot . It can sing very well. I can play the guitar. When I play the guitar, they sing and dance. We have a show in our home every Sunday evening. Many boys and girls come to my show. They like it very much.\n",
      "\n",
      "Question: Please come and watch our show on   _  .\n",
      "A. Sunday morning\n",
      "B. Saturday evening\n",
      "C. Sunday evening\n",
      "D. Saturday morning\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1543\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01151275634765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96935\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Do you know the phrase \"Weibo Addicts\"  ? Do you write a Weibo? If you don't, you are \"out\"!\n",
      "Weibo means microblog. People may spend much time writing a blog, but it takes a little time to write a microblog. Why? Because every message on a microblog is less than 140 words.\n",
      "Microblog started in the USA. It came to China in 2009 and it grows very fast. In 2011, the number of Chinese micro-bloggers grew to 300 million. People write microblogs for many reasons. For many microblog users, it is a great way of learning the freshest news, talking with friends and sharing different kinds of information, including news, everyday life, pictures, music, videos and so on.\n",
      "It is easy and fast to send a message on a microblog. However, this can also bring problems and even panic  . For example, when the big earthquake and tsunami   hit Japan in March, 2011, messages like \"Salt can help people fight radiation  \" were hot on microblogs. Then a crazy buying of salt followed. Later people knew it was just a rumor  .\n",
      "In a word, microblog plays a new part in the life of Chinese people.\n",
      "\n",
      "Question: What does Para. 2 mainly talk about?\n",
      "A. How to use Weibo.\n",
      "B. Why Weibo is so popular.\n",
      "C. Who is using Weibo.\n",
      "D. What Weibo is.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56049\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011653900146484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106460\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00041484832763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: A long time ago, in 1893, in the United States, some people were talking about fruits and vegetables. They asked, \"What are fruits and what are vegetables? How are fruits different from vegetables and vegetables different from fruits?\" They talked for a long time and then they decided, \"We eat vegetables as part of a meal, but we eat fruits before or after a meal.\"\n",
      "In real life, people do not think the dictionaries give the right meaning of a word. For example, the dictionaries say that tomatoes are fruits. But few people know that. Most people think they are vegetables. They call them vegetables and eat them as vegetables. To most people, fruits mean sweet things like apples, pears, oranges and watermelons.\n",
      "What are vegetables then? We call many plants and grasses vegetables. Some people think some fruits are vegetables, such as apples, pears and bananas. But to most people, vegetables mean things like potatoes, onions and carrots.\n",
      "\n",
      "Question: People usually eat vegetables   _  .\n",
      "A. before a meal\n",
      "B. after a meal\n",
      "C. alone\n",
      "D. during a meal\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64900\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0694580078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.452880859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: I am an English girl. My name is Lily. I am thirteen. I am at school. Look! This is my school. It is No. 14 Middle School. I am in Class 1, Grade 1. I am in row 3. I am No. 12 at schhol. I have a good friend. She is a girl. Her name is Mary. She is not at school today. I think she is at home. My Chinese teacher is Miss Gao. She is a very good teacher. I don't know her age.\n",
      "\n",
      "Question: I don't know   _   age.\n",
      "A. Lily\n",
      "B. Miss Gao's\n",
      "C. Miss Gao\n",
      "D. Mary's\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.246826171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57953\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08740234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Would you like to adopt an animal? Although this sounds very unusual, some children have done just this. The Natural Zoo has given people the chance to adopt animals by paying for all of its food for one year. One of the animals that needed parents was a young tiger named Brocky. The people at the zoo said that it would cost about $900 a year for the food for Brocky.\n",
      "Not many boys and girls have $900 to spend. That is why several hundred children and grown-ups each have sent a little money to the zoo to help pay for Brocky's food. Some children sent in only a quarter because that was all the money they had. Other children sent in more money than that.\n",
      "Since so many people sent money to the zoo to help pay for Brocky's food, he now will be able to eat as much as he wants. Brocky surely must be a happy tiger to know that he has so many adopted parents. Many children must also be happy to know that they have helped to feed him. It really will be thrilling for those children to go to the Natural Zoo to visit their adopted tiger Brocky.\n",
      "\n",
      "Question: Several hundred people give money to the zoo to help Brocky because   _  .\n",
      "A. its food is too expensive for one person to afford\n",
      "B. people don't want to spend too much money on Brocky\n",
      "C. people don't love Brocky enough\n",
      "D. the zoo forces them to do so\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4541015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.68017578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 31039\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0038661956787109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79408\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.472412109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 105571\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1463623046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71027\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.058929443359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11490\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016880035400390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 124704\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.406494140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.033660888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43226\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.059814453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3781\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06744384765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 118958\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.314697265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36344\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009937286376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 119979\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0128173828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96310\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011243820190429688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21903\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04241943359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110336\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009813308715820312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25701\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 44409\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.246826171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 16349\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2099609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110336\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0048370361328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127300\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.447998046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.384033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 92368\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.009124755859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 112261\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001850128173828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29474\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.96533203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 122682\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00669097900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88909\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0019273757934570312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43344\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.64111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99088\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08587646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22552\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0675048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68514\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.59716796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15657\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2120361328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70754\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.012847900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26997\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1590576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121678\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016546249389648438\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 113020\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.133056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36939\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0058135986328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.403564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 44643\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3935546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75863\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008587837219238281\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96708\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0010166168212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120807\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.277587890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58785\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0010833740234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96237\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008168220520019531\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64347\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.027252197265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 598\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006961822509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50948\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013828277587890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013751983642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3520\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001589059829711914\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1101\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.70703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40085\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0261383056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 86056\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00021696090698242188\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82839\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005393028259277344\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85612\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.000774383544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114340\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0299224853515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19961\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1373291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81480\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004634857177734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52365\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006351470947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1101\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.57421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102201\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0179901123046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.12274169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71942\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002300262451171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74626\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00710296630859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56134\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05230712890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5929\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.033538818359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25188\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2099609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1625\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.160400390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 116954\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10113525390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57017\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.000316619873046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3691\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.270751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 119314\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004001617431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 122682\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0034198760986328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29875\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00814056396484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3125\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0038051605224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002532958984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68882\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003802776336669922\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96041\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 4.7266483306884766e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75249\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.053741455078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121827\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08575439453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34669\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01149749755859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83951\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0025424957275390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 100531\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002073049545288086\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45508\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004955291748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77981\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007350921630859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68676\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004764556884765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 31464\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.016265869140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22991\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0037555694580078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39776\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001857280731201172\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7190\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00811767578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58043\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00270843505859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39333\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00040340423583984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77981\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00974273681640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81868\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006418228149414062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 72116\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002513885498046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121261\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002014636993408203\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19961\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1463623046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114340\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11474609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91591\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006237030029296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106863\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00406646728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004795074462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53405\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0233001708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42880\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006168365478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40459\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00506591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61260\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.33251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104891\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.053009033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13446\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.271728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 116954\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.059295654296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 31061\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009169578552246094\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121793\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.19580078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52310\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0022125244140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38692\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.017120361328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54318\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0027332305908203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46870\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.27685546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40516\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.140869140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006537437438964844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82808\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0053558349609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2305\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.33740234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 90219\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007061004638671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 18172\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00012135505676269531\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 726\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.081787109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6847\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.167724609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8486328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22591\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0113983154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003447532653808594\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20067\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00033736228942871094\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34420\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.032928466796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67187\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0819091796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52649\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.71044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2699\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005974769592285156\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67696\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018396377563476562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 78536\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.012603759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50535\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00025582313537597656\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 117765\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.71142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 113828\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.057464599609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 65687\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0233612060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61330\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005596160888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 65687\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.28564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23581\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 108714\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.023956298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106623\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005096435546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22552\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001644134521484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3691\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.329345703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48067\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11834716796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64641\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1661376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35549\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007953643798828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83947\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001064300537109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52649\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.038238525390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2601\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74626\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.438720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56786\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00984954833984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74517\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.028533935546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83838\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1546630859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110398\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.012847900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.015838623046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3172\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0028743743896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121805\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04144287109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7634\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004596710205078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5964\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0288238525390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 16651\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0443115234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114340\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01300048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74526\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03656005859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.477783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 108714\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.061248779296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22552\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09478759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88416\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00464630126953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.49365234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53805\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0174102783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 72070\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0367431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48067\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2066650390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81189\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006532669067382812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53405\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0869140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 86914\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01006317138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.56298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 668\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07470703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66876\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0019683837890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 107337\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.012237548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1141\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.038421630859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22369\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009055137634277344\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66759\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.020050048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1141\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2293701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75999\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0035381317138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46051\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.205078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81269\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0022182464599609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61833\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 6.008148193359375e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2744\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.26904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102343\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00013208389282226562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83985\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1260986328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 123144\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0221710205078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40361\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0186004638671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9706\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05950927734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3422\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.56103515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39099\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0057525634765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77585\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0430908203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26349\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00020825862884521484\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56951\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01103973388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99581\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.012603759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114884\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.067138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01505279541015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104848\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.028167724609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13441\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.15625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46051\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2254638671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4940\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.050384521484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58260\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 9.85264778137207e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55860\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0298919677734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59080\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2025146484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9684\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103259\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2420654296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101014\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0044708251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106863\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.009185791015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8974609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29436\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007562637329101562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 93014\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07684326171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94710\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003199577331542969\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54831\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00035071372985839844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2603\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0037364959716796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3422\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.86767578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3422\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00322723388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2200\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007404327392578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 93166\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.029327392578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64863\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013780593872070312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94201\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0076904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98520\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007659912109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1104\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06646728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 118580\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001556873321533203\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59925\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007099151611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103259\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08441162109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 24993\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008869171142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2744\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1468505859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 124011\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0260009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34572\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004901885986328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11312\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006275177001953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32458\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002579689025878906\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114884\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.079833984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45920\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0041656494140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.775390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11312\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06341552734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1141\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04510498046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 93166\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00893402099609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1141\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.158935546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114884\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.14453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23802\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001434326171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 846\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0689697265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30930\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00647735595703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45836\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.041229248046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47114\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.036529541015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8491\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00036787986755371094\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103598\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0010366439819335938\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12837\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011301040649414062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83434\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002410888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103259\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.024993896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 65854\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0214385986328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6847\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.57568359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5472\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011548995971679688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0083465576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004074573516845703\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27965\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0066375732421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22218\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00015485286712646484\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26719\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11175537109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127312\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01374053955078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27307\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0024204254150390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3581\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003978729248046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11312\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003421783447265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 69281\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0125579833984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50897\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008993148803710938\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64117\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00791168212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47661\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0421142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13441\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09881591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 125927\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003020763397216797\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 84817\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004711151123046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2768\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008893013000488281\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 24119\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.019744873046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3691\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1776123046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83985\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1593017578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48110\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0012264251708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 118466\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.058563232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005350112915039062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70904\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0255126953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42880\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0577392578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9552\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0012226104736328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87457\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003132820129394531\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5771484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82894\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002651214599609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66042\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00493621826171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47661\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.067138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127312\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006628036499023438\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.013824462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73170\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002663135528564453\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06536865234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46370\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0020313262939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29615\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1033935546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.34375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 84817\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0294952392578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14576\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0031280517578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106863\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0479736328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8349609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79481\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00748443603515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 93014\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0826416015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8119\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00872802734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95690\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011272430419921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103224\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02294921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42880\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02886962890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55454\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014514923095703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9423828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82017\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101862\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.043121337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66376\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014467239379882812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36207\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0380859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 80262\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0032024383544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 846\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.034637451171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 454\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005222320556640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 69021\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014801025390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34992\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.036895751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11038\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06707763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 44326\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004553794860839844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64567\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0899658203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 501\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011310577392578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63453\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0012006759643554688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57850\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006870269775390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54574\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001003265380859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75179\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01087188720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.49755859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4853\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002227783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 92216\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04339599609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7880859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1141\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11859130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70591\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0406494140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 100942\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0352783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103259\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007717132568359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73828\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0012483596801757812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 31277\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01364898681640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48448\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0024471282958984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 124199\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.000743865966796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64573\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00696563720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77453\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.939338684082031e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36863\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002666473388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58887\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0026912689208984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101520\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.048004150390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1101\n",
      "  Verified Probability: 1.0\n",
      "  Draft Probability: 0.2440185546875\n",
      "\n",
      "[DEBUG] Speculation Step 1\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.76318359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 1: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0063323974609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 24831\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.404296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21151\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0811767578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 106091\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.200241088867188e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35316\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007030487060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26488\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00933074951171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.943359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46051\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007556915283203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32190\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.016510009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82017\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.187744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101862\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.061248779296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1141\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1082763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71158\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00208282470703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4047\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01806640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14573\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0026836395263671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20058\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.124267578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 33207\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006572723388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22777\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002758026123046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66018\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0662841796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63190\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 115120\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00025916099548339844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2375\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00012969970703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10754\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003573894500732422\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47608\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011377334594726562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9706\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11260986328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70904\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.043487548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2636\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005869865417480469\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.91748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23994\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.019195556640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.81591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101840\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007843017578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14406\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005860328674316406\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81189\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02960205078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 24590\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007529258728027344\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29700\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003021240234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34572\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0180511474609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1842\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01557159423828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10214\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.018402099609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55860\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0061798095703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19569\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0031833648681640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 33888\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00037288665771484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 18180\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.605552673339844e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 109667\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002170562744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121827\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2374267578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121827\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.063720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50455\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018854141235351562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120428\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014467239379882812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59488\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0015783309936523438\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 78183\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0163116455078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114884\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1334228515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3422\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08270263671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8427734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8801\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00634765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7643\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.599592208862305e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.88720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104296\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0157012939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82860\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0191192626953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23938\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00020587444305419922\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114884\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.541015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20058\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0333251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101892\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006961822509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73828\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011157989501953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 90922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0198516845703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104401\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101520\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.045501708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63726\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001255035400390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 109015\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003514289855957031\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 24951\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00391387939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 107709\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02032470703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1424560546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35316\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0193634033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75179\n",
      "  Verified Probability: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "  1%|          | 1/100 [00:01<02:13,  1.35s/it]\n",
      "  2%|▏         | 2/100 [00:01<01:07,  1.44it/s]\n",
      "  3%|▎         | 3/100 [00:01<00:45,  2.12it/s]\n",
      "  4%|▍         | 4/100 [00:02<00:35,  2.70it/s]\n",
      "  5%|▌         | 5/100 [00:02<00:30,  3.14it/s]\n",
      "  6%|▌         | 6/100 [00:02<00:27,  3.39it/s]\n",
      "  7%|▋         | 7/100 [00:02<00:25,  3.67it/s]\n",
      "  8%|▊         | 8/100 [00:02<00:23,  3.98it/s]\n",
      "  9%|▉         | 9/100 [00:03<00:21,  4.27it/s]\n",
      " 10%|█         | 10/100 [00:03<00:20,  4.38it/s]\n",
      " 11%|█         | 11/100 [00:03<00:20,  4.29it/s]\n",
      " 12%|█▏        | 12/100 [00:03<00:20,  4.35it/s]\n",
      " 13%|█▎        | 13/100 [00:03<00:19,  4.50it/s]\n",
      " 14%|█▍        | 14/100 [00:04<00:19,  4.52it/s]\n",
      " 15%|█▌        | 15/100 [00:04<00:18,  4.57it/s]\n",
      " 16%|█▌        | 16/100 [00:04<00:18,  4.55it/s]\n",
      " 17%|█▋        | 17/100 [00:04<00:18,  4.54it/s]\n",
      " 18%|█▊        | 18/100 [00:05<00:18,  4.53it/s]\n",
      " 19%|█▉        | 19/100 [00:05<00:17,  4.53it/s]\n",
      " 20%|██        | 20/100 [00:05<00:17,  4.49it/s]\n",
      " 21%|██        | 21/100 [00:05<00:18,  4.38it/s]\n",
      " 22%|██▏       | 22/100 [00:06<00:17,  4.35it/s]\n",
      " 23%|██▎       | 23/100 [00:06<00:17,  4.36it/s]\n",
      " 24%|██▍       | 24/100 [00:06<00:16,  4.55it/s]\n",
      " 25%|██▌       | 25/100 [00:06<00:16,  4.57it/s]\n",
      " 26%|██▌       | 26/100 [00:06<00:16,  4.48it/s]\n",
      " 27%|██▋       | 27/100 [00:07<00:16,  4.44it/s]\n",
      " 28%|██▊       | 28/100 [00:07<00:15,  4.60it/s]\n",
      " 29%|██▉       | 29/100 [00:07<00:14,  4.82it/s]\n",
      " 30%|███       | 30/100 [00:07<00:14,  4.84it/s]\n",
      " 31%|███       | 31/100 [00:07<00:14,  4.69it/s]\n",
      " 32%|███▏      | 32/100 [00:08<00:14,  4.85it/s]\n",
      " 33%|███▎      | 33/100 [00:08<00:13,  4.79it/s]\n",
      " 34%|███▍      | 34/100 [00:08<00:13,  4.78it/s]\n",
      " 35%|███▌      | 35/100 [00:08<00:13,  4.85it/s]\n",
      " 36%|███▌      | 36/100 [00:08<00:13,  4.80it/s]\n",
      " 37%|███▋      | 37/100 [00:09<00:13,  4.72it/s]\n",
      " 38%|███▊      | 38/100 [00:09<00:13,  4.68it/s]\n",
      " 39%|███▉      | 39/100 [00:09<00:12,  4.76it/s]\n",
      " 40%|████      | 40/100 [00:09<00:12,  4.75it/s]\n",
      " 41%|████      | 41/100 [00:10<00:12,  4.71it/s]\n",
      " 42%|████▏     | 42/100 [00:10<00:12,  4.63it/s]\n",
      " 43%|████▎     | 43/100 [00:10<00:12,  4.68it/s]\n",
      " 44%|████▍     | 44/100 [00:10<00:11,  4.79it/s]\n",
      " 45%|████▌     | 45/100 [00:10<00:11,  4.76it/s]\n",
      " 46%|████▌     | 46/100 [00:11<00:11,  4.79it/s]\n",
      " 47%|████▋     | 47/100 [00:11<00:11,  4.67it/s]\n",
      " 48%|████▊     | 48/100 [00:11<00:11,  4.66it/s]\n",
      " 49%|████▉     | 49/100 [00:11<00:11,  4.64it/s]\n",
      " 50%|█████     | 50/100 [00:11<00:10,  4.56it/s]\n",
      " 51%|█████     | 51/100 [00:12<00:10,  4.58it/s]\n",
      " 52%|█████▏    | 52/100 [00:12<00:10,  4.67it/s]\n",
      " 53%|█████▎    | 53/100 [00:12<00:10,  4.51it/s]\n",
      " 54%|█████▍    | 54/100 [00:12<00:10,  4.59it/s]\n",
      " 55%|█████▌    | 55/100 [00:13<00:09,  4.74it/s]\n",
      " 56%|█████▌    | 56/100 [00:13<00:09,  4.73it/s]\n",
      " 57%|█████▋    | 57/100 [01:01<10:32, 14.71s/it]\n",
      " 58%|█████▊    | 58/100 [01:01<07:15, 10.36s/it]\n",
      " 59%|█████▉    | 59/100 [01:02<04:59,  7.32s/it]\n",
      " 60%|██████    | 60/100 [01:02<03:27,  5.18s/it]\n",
      " 61%|██████    | 61/100 [01:02<02:24,  3.69s/it]\n",
      " 62%|██████▏   | 62/100 [01:02<01:40,  2.65s/it]\n",
      " 63%|██████▎   | 63/100 [01:03<01:10,  1.91s/it]\n",
      " 64%|██████▍   | 64/100 [01:03<00:50,  1.40s/it]\n",
      " 65%|██████▌   | 65/100 [01:03<00:36,  1.04s/it]\n",
      " 66%|██████▌   | 66/100 [01:03<00:27,  1.25it/s]\n",
      " 67%|██████▋   | 67/100 [01:03<00:20,  1.61it/s]\n",
      " 68%|██████▊   | 68/100 [01:10<01:18,  2.46s/it]\n",
      " 69%|██████▉   | 69/100 [01:10<00:55,  1.79s/it]\n",
      " 70%|███████   | 70/100 [01:11<00:39,  1.32s/it]\n",
      " 71%|███████   | 71/100 [01:11<00:28,  1.02it/s]\n",
      " 72%|███████▏  | 72/100 [01:11<00:21,  1.31it/s]\n",
      " 73%|███████▎  | 73/100 [01:11<00:16,  1.68it/s]\n",
      " 74%|███████▍  | 74/100 [01:11<00:12,  2.10it/s]\n",
      " 75%|███████▌  | 75/100 [01:12<00:09,  2.55it/s]\n",
      " 76%|███████▌  | 76/100 [01:12<00:08,  2.99it/s]\n",
      " 77%|███████▋  | 77/100 [01:12<00:07,  3.17it/s]\n",
      " 78%|███████▊  | 78/100 [01:12<00:06,  3.41it/s]\n",
      " 79%|███████▉  | 79/100 [01:13<00:05,  3.58it/s]\n",
      " 80%|████████  | 80/100 [01:13<00:05,  3.81it/s]\n",
      " 81%|████████  | 81/100 [01:13<00:04,  3.97it/s]\n",
      " 82%|████████▏ | 82/100 [01:13<00:04,  4.22it/s]\n",
      " 83%|████████▎ | 83/100 [01:13<00:03,  4.44it/s]\n",
      " 84%|████████▍ | 84/100 [01:14<00:03,  4.60it/s]\n",
      " 85%|████████▌ | 85/100 [01:14<00:03,  4.82it/s]\n",
      " 86%|████████▌ | 86/100 [01:14<00:02,  4.88it/s]\n",
      " 87%|████████▋ | 87/100 [01:14<00:02,  4.86it/s]\n",
      " 88%|████████▊ | 88/100 [01:14<00:02,  4.75it/s]\n",
      " 89%|████████▉ | 89/100 [01:15<00:02,  4.64it/s]\n",
      " 90%|█████████ | 90/100 [01:15<00:02,  4.55it/s]\n",
      " 91%|█████████ | 91/100 [01:15<00:01,  4.61it/s]\n",
      " 92%|█████████▏| 92/100 [01:15<00:01,  4.56it/s]\n",
      " 93%|█████████▎| 93/100 [01:16<00:01,  4.60it/s]\n",
      " 94%|█████████▍| 94/100 [01:16<00:01,  4.50it/s]\n",
      " 95%|█████████▌| 95/100 [01:16<00:01,  4.47it/s]\n",
      " 96%|█████████▌| 96/100 [01:16<00:00,  4.63it/s]\n",
      " 97%|█████████▋| 97/100 [01:16<00:00,  4.58it/s]\n",
      " 98%|█████████▊| 98/100 [02:06<00:29, 14.88s/it]\n",
      " 99%|█████████▉| 99/100 [02:06<00:10, 10.48s/it]\n",
      "100%|██████████| 100/100 [02:06<00:00,  7.41s/it]\n",
      "100%|██████████| 100/100 [02:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Draft Probability: 0.0142822265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.93896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.313720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55767\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.028961181640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.89013671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 92216\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.054840087890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.91357421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.33154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104741\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0022182464599609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22078\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 9.185075759887695e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60207\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003628730773925781\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.016021728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63583\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00038361549377441406\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6112\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00830078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 16906\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 9.85860824584961e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104892\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01082611083984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2305\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0118560791015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07861328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2399\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09344482421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101520\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.038177490234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6847\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1063232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.490966796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 37093\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004703521728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 24831\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5341796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21151\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1373291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2030029296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94082\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00032019615173339844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9706\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.036712646484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11312\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0443115234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 126620\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011072158813476562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21313\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7255859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10827\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006275177001953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114884\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.48876953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20058\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.029083251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101862\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0035419464111328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34127\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00012165307998657227\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27190\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004754066467285156\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68880\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005584716796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73914\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008254051208496094\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38195\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00418853759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15120\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011005401611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83985\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.059722900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 123144\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1947021484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009107589721679688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114884\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.151611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75212\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.020751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8974609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1285400390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Many families do not eat very healthy food now . If   you do not eat good food ., then you are not healthy . Doctor Smith from the hospital says that people need   to eat a lot of healthy food in this order   :\n",
      "Rice and noodles .\n",
      "Fruit , such as oranges and apples , and vegetables , such as carrots , tomatoes and potatoes .\n",
      "Meat , such as pork , chicken , beef and fish .\n",
      "Doctor Smith says that people should not   eat unhealthy food like hamburgers , candy chocolate or ice cream , or have some drink such as cola . And they should drink milk , juice or water .\n",
      "So , to stay healthy and away from hospital , eat only healthy food !\n",
      "\n",
      "Question: Which of the following you should eat first ?\n",
      "A. beef\n",
      "B. fish\n",
      "C. rice\n",
      "D. chicken\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "\n",
      "Explanation: Fish is the best food for your health. Fish contains lots of omega-3 fatty acids that are good for your heart. You should eat fish at least once a week. You can also eat beef, pork and chicken. You should eat chicken at least once a week. You can also eat beef, pork and chicken. You should eat beef at least once a week. You can also eat rice, noodles and fruit. You should eat rice, noodles and fruit at least once a week. You can also eat rice, noodles and fruit. You should eat rice, noodles and fruit at least once a week. You can also eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes. You should eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes at least once a week. You can also eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes. You should eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes at least once a week. You can also eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes. You should eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes at least once a week. You can also eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes. You should eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes at least once a week. You can also eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes. You should eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes at least once a week. You can also eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes. You should eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes at least once a week. You can also eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes. You should eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes at least once a week. You can also eat fruit, such as oranges and apples, and vegetables, such as carrots, tomatoes and potatoes. You should eat fruit, such as oranges and apples, and\n",
      "[Acceptance Rate]: 0.0003284072249589491\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.370361328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.70751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: What does it feel like to break a bone  ? It's different for everyone, but the pain is often sharp  . If the break is small, however, the person may not feel much pain at all. If you think that you or someone else has broken a bone, the most important things to do are to stay calm, make the hurt person comfortable, and call the doctor. Do not move the injured body part since movement could make it worse.\n",
      "To treat the break, the doctor will need to take an X-ray. This gives the doctor the information he or she needs to set   the bone: to put it back to its normal place. If the bone is large or it is broken in more than one place, the doctor may need to use metal pins   to set it. After the bone has been set, the next step is usually putting on a cast, the special, hard thing that will keep the bone in place for a month or two.\n",
      "Your bones are excellent at healing themselves. Broken bones will produce many new cells   and tiny blood vessels  . These cover both ends of the broken part, and close up the break until the bone is as whole and strong as before.\n",
      "\n",
      "Question: Which of the following is the best title for the passage?\n",
      "A. How to Know if a Bone is Broken\n",
      "B. How Broken Bones Heal Themselves\n",
      "C. Common Causes   of Broken Bones\n",
      "D. What You Should Know about Broken Bones\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52578\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009183883666992188\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Roosegaarde, an artist and designer from Dutch has thought of a device . He hopes it will make Beijing's sky clear again and help the people with masks breathe fresh air again in Beijing.\n",
      "An electromagnetic field  will pull the dirty particles in the air to the ground, and then they can be easily cleaned.\n",
      "Roosegaarde says, \"It's like when you have a balloon which has static electricity  and your hair goes toward it. Smog happens the same way as the hair.\"\n",
      "His workplace has reached an agreement with the Beijing government to test the technology in one of the capital's parks.  Beijing's skies are regularly covered by grey smog. Serious cases of air pollution are often reported in Beijing. Roosegaarde says an indoor test has already shown it works well and he is confident of the results. With the help of a team of scientists and engineers, he is sure that the device can be worked outside.\n",
      "\"Beijing is a very good place to test the device because the smog in Beijing is quite low and there's not so much wind.\" says Roosegaarde. \"We'll be able to make the air pure but the most difficult thing is to remove the smog. As a result, you can see the sun again.\"\n",
      "Roosegaarde also reminds us that his aim is not only to give a plan to solve Beijing's dirty air pollution but also to make people pay attention to the environment problem. He adds, \"This is not the real answer for smog. The real answer to do with it is clean cars, different industry and different lifestyles. \" However, he hopes the project will make the citizens realize the differences between clean air and smog-filled air.\n",
      "\n",
      "Question: After reading the passage, we can know  _  .\n",
      "A. the device doesn't work well indoors\n",
      "B. the people with masks can breathe fresher air\n",
      "C. Beijing government agreed to test the device\n",
      "D. clean cars aren't helpful to the environment in Beijing\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.15576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34486\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.185791015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Usually, students are not encouraged to run or jump around in the corridor  . However, students in a British grammar school really enjoy running on the corridor tiles   and their teachers even encourage them to do that.\n",
      "Why? It is because the corridor was built with special kinetic   tiles. When students jump on the tiles, electricity will be produced. After one year, the electricity produced from the tiles can fully charge 853 mobile phones or power  an electric car to drive seven miles. It's amazing, isn't it?\n",
      "The corridor tiles are really a brilliant invention. Students can not only play on the corridor, but also help power the lights in their school corridors and other equipment in their classrooms. Besides, this is a good way to teach students to be creative. They will be _ to be scientists, inventors and engineers in the future to find clean energy for all humans.\n",
      "The inventor of the magic corridor tiles is Laurence Kemball-Cook. He was once a student in this school. Now, he is CEO of his own company. The corridor tiles are not Laurence's only invention. He has also invented a special dance floor, which can be used at music festivals. It allows dancers to charge their mobile phones while they are dancing on the dance floor.\n",
      "\n",
      "Question: Why do the students in the passage enjoy running on the corridor tiles?\n",
      "A. Because the corridor tiles are expensive.\n",
      "B. Because the teachers ask them to do that.\n",
      "C. Because the corridor was built with special tiles.\n",
      "D. Because students like running and jumping.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101861\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001567840576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61244\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00495147705078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: \"High tech\" and \"state of the art\" are two expressions that describe very modern technology. High tech is just a shorter way of saying high technology. And high technology describes any invention or system that uses the newest ideas or discoveries of science and engineering.\n",
      "What is high tech? A computer is high tech. So is a communications satellite. A modern manufacturing     system is surely high tech.\n",
      "High tech became a popular expression in the United States during the early 1980's. Because of improvements in technology, people could buy many new kinds of products in American stores, such as home computers, microwave ovens  , etc. \"State of the art\" is something that is as modern as possible. It is a product that is based on the very latest ways and technology. Something that is \"state of the art\" is the newest possible design or product of a business or industry. A state of the art television set, for example, uses the most modern electronic design and parts. It is the best that one can buy.\n",
      "\"State of the art\" is not a new expression. Engineers have used it for years, to describe the best and most modern way of doing something.\n",
      "Millions of Americans began to use the expression in the late 1970's. The reason was the computer revolution . Every computer company claimed   that its computers were \"state of the art\".\n",
      "Computer technology changes so fast that a state of the art computer today might be old tomorrow. The expression \"state of the art\" has become as common and popular as computers themselves. Now all kinds of products are said to be \"state of the art\".\n",
      "\n",
      "Question: What can we learn from the passage?\n",
      "A. American stores could provide new kinds of products to the people.\n",
      "B. \"High tech\" describes a technology that is not traditional.\n",
      "C. \"State of the art\" became popular later than \"high tech\".\n",
      "D. A lantern out of a big orange pumpkin is \"state of the art\".\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10308837890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67324\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0380859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Paper is one of the most important products ever invented by man.\n",
      "The invention of paper meant that more people could be educated because more books could be printed. Paper provided an important way to communicate with knowledge.\n",
      "Paper was first made in China about 2000 years ago. In Egypt and the West, paper was not very commonly used before the year 1400. Paper was not made in southern Europe until about the year 1100. After that, the forestry country of Canada, Sweden, Norway, Finland, and the United States became the most important in paper-making. Today Finland makes the best paper in the world. And it has the biggest paper industry in the world.\n",
      "When we think of paper, we think of newspapers, books, letters, envelopes, and writing paper. So paper plays an important role in our lives.\n",
      "Paper is very good for keeping you warm, Houses are often insulated with paper. You have perhaps seen homeless men sleep on a large number of newspapers. They are insulating themselves from the cold. In Finland, in winter it is sometimes 40 degrees below zero. The farmers wear paper boots in the snow. _\n",
      "\n",
      "Question: What's the meaning of the sentence \"  _  \"?\n",
      "A. Books are warmer.\n",
      "B. Newspapers are warmer.\n",
      "C. Houses are the warmest.\n",
      "D. Paper is the warmest.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.378173828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98421\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0633544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Is it important to have breakfast every day? A short time ago, a test was given in the United States.People of different ages, from 12 to 83, were asked to have a test.During the test, these people were given all kinds of breakfast, and sometimes they got no breakfast at all.Scientists wanted to see how well their bodies worked after eating different kinds of breakfast.\n",
      "The results show that if a person eats a right breakfast, he or she will work better than if he or she has no breakfast.If a student has fruit, eggs, bread and milk before going to school, he or she will learn more quickly and listen more carefully in class.Some people think it will help you lose weight if you have no breakfast.But the result is opposite to what they think.This is because people become so hungry at noon that they eat too much for lunch.They will gain weight   instead of losing it.\n",
      "\n",
      "Question: According to the passage, what will happen to you if you don't have any breakfast?\n",
      "A. To be healthier.\n",
      "B. To work better.\n",
      "C. To gain weight.\n",
      "D. To fail the test.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03546142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76634\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0062103271484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: People usually hate mice, but people almost all over the world like one mouse-- the famous Mickey Mouse.\n",
      "About eighty years ago, most films had no sounds. A man called Walt Disney made a cartoon mouse. The cartoon mouse could talk in these films. He made his mouse become a good friend of both young people and old people. Children liked to see their lovely friend, because he brought happiness to them.\n",
      "Mickey is a clean mouse right from the beginning. Maybe this is why people love Mickey Mouse very much. In his early life, Mickey did some wrong things. People were very angry. They wrote to Disney and said they didn't want Mickey to do the wrong things. Because there were some things that Mickey could not do. Disney made a new animal called Donald Duck. He also made a dog, Pluto. This dog does some foolish   and wrong things wherever he goes. Now, our Mickey Mouse is more interesting as well. He is known as a star of beauty and wisdom  . He has friends in almost every country.\n",
      "\n",
      "Question: Children love Mickey Mouse because   _  .\n",
      "A. it can speak\n",
      "B. It is clean\n",
      "C. it makes them happy\n",
      "D. it is a mouse\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.40576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102481\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01180267333984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear Mr Green,\n",
      "I am not happy these days. Please help me.\n",
      "I want to be a member of the class volleyball team. I think I am good at volleyball. But our PE teacher says I can't get into the team. He says I am too fat  .\n",
      "I really want to be a good volleyball player. This is my dream. Can you help me?\n",
      "Jane\n",
      "Dear Jane,\n",
      "I'm sorry to know that you're not happy.\n",
      "You play volleyball well. But your PE teacher doesn't like fat girls. If   you want to be a good volleyball player, you must be slim. Why not go running with Mary every morning? Mary is the best volleyball player in our class. You can be like her if you\n",
      "Allan Green\n",
      "\n",
      "Question: Allan Green wants Jane to    _    .\n",
      "A. stop playing volleyball\n",
      "B. eat much meat\n",
      "C. talk with her PE teacher\n",
      "D. go running every day\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 122063\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.028167724609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36544\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0096282958984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
      "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
      "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
      "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
      "\n",
      "Question: The best title for the passage is \"  _  \".\n",
      "A. Drugs are dangerous\n",
      "B. A famous Taiwan actor\n",
      "C. Apologizing for taking drugs\n",
      "D. At the press conference\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.090087890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 51249\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04681396484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
      "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
      "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
      "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
      "\n",
      "Question: Little Mike went to the park and   _  .\n",
      "A. played with pigeons\n",
      "B. met an old lady\n",
      "C. fed pigeons\n",
      "D. saw a friend of his grandma's\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36940\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.039520263671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13296\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.041778564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27457\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.62744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 78629\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00197601318359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 116342\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.055877685546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111432\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 6.157159805297852e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42876\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00797271728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45648\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76036\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0562744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110559\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.36083984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5988\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3779296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99793\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.037445068359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102541\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0027713775634765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 68833\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5068359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23246\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.223388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 84364\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003475189208984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 51507\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2205810546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 18673\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 97916\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.54150390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67844\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0023288726806640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52191\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00109100341796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 41681\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.024658203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12401\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1934814453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81913\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 9.40561294555664e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46385\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.80712890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54754\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2474365234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17088\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0124359130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4459\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03411865234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 599\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.479248046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 80889\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007442474365234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48965\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003561973571777344\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39535\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0028247833251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62874\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00024700164794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11880\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.24560546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6958\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007581710815429688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73254\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.282958984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64920\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05596923828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114152\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08087158203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95930\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01226043701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96420\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003361701965332031\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110365\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005626678466796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 31138\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0019741058349609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4929\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00577545166015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127587\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007677078247070312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70014\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01055908203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102831\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 3.5822391510009766e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4423\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21739\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01319122314453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54456\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008859634399414062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53864\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0034198760986328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23937\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0029430389404296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74996\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.97900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36828\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.009506225585938e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23581\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.49560546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20631\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0084228515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94575\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1187744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28410\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09228515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3060\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.31982421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63699\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4553\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0379638671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1396\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.367431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52035\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002620697021484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 124044\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002682209014892578\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29145\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.292236328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45648\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.037506103515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57477\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00010246038436889648\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91653\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.048858642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Snack time is a part of the day for children of all ages. But new research suggests that kids snacking in big groups could be at risk for _ .\n",
      "Scientists from American University looked at the eating behavior of 54 kids between the ages of 2 and 6. At snack time, the scientist watched the amount of food each child ate while they were in groups of either three or nine. According to the study, the more children there are in a group, the more likely they are to eat more. Those in the larger group ate nearly 30 percent more than those in the smaller group, and they actually ate faster.\n",
      "Since this is the first such study in children, scientists are quick to point out the importance of encouraging healthy habits in kids as early as possible.\n",
      "\"If you know kids eat more in large groups, it seems perfect to use this information to keep snack groups small or use small tables,\" says Dr. Jana Klauer, an expert in New York.\n",
      "Smaller groups would allow for a quiet and more relaxing environment-a perfect chance to teach children about food, manners and how to know when they feel full. \"This would have an effect on kids' eating,\" adds Klauer. \"They would slow down and eat less.\"\n",
      "\n",
      "Question: Why do children in smaller groups lose weight?\n",
      "A. Because children in smaller groups eat faster.\n",
      "B. Because children in smaller groups don't like eating.\n",
      "C. Because children in smaller groups don't know about food.\n",
      "D. Because children in smaller groups eat slowly and eat less.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "\n",
      "## Explanation\n",
      "\n",
      "In the study, children ate less in smaller groups. The smaller groups were probably more relaxed and comfortable, so the children didn't feel as pressured to eat as much.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "This study suggests that if you want to encourage kids to eat healthy, you should limit the number of people in the group.\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.74365234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2066650390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Hearing what I said, my dad laughed kindly. I continued, \"I owe your thanks, and I hope you realize how much you did for me as my dad.\"\n",
      "I could almost hear him smiling one the other end. I knew he was touched and felt a little shy. His voice sounded shaky.\n",
      "\"Well, we got you educated,\" he said, laughing generously.\n",
      "\"You did more than that,\" I said, \"You did well.\"\n",
      "\"You like your house now, and your life?\" he asked quietly.\n",
      "\"Yeah, Dad, I'm happy. You don't have to worry--things are going great for us.\"\n",
      "I told him I loved him and he told me he loved me and I hung up the phone. As I got ready for bed, I thought about what an amazing conversation we had.\n",
      "Ten hours later, my mother called, waking me up. I could hardly understand what she was trying to say.\n",
      "\"Your father's dead!\" she cried. \"I found him lying on the dinning room floor.\"\n",
      "Suddenly I was standing straight up beside my bed, holding the phone and sobbing .\n",
      "I was a thousand miles away. All I could think about was how many hours, minutes and seconds it would take me to jump on a plane and get there. I thought about my mother sitting there alone with my father, and I couldn't move fast enough.\n",
      "The flight was long and painful. I had planned on going home to see my dad and mom in another month, and I cried aloud, thinking I was too late. Then I suddenly realized the incredible miracle of it all: I hadn't been late at all. Actually, everything had been right on time.\n",
      "\n",
      "Question: From the last part, we can know  _\n",
      "A. the writer will be sad.\n",
      "B. the writer will change pain into power.\n",
      "C. the writer will be happy.\n",
      "D. the writer won't do anything.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52622\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00867462158203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1969\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007719993591308594\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: A gentleman put an advertisement in a newspaper to look for a boy to work in his office. From nearly fifty persons, he chose one and refused the others.\n",
      "\"I should like to know,\" said a friend, \"Why you liked that boy better. He did not have a letter or a recommendation  .\"\n",
      "\"You are wrong,\" said the gentleman. \"He had a great many. He cleaned his feet at the door and closed the door behind him. That showed that he was careful. He gave his seat at once to that old man. That showed that he was kind and _ . He took off his cap when he came in and answered my question at once. That showed that he was polite and gentlemanly.\"\n",
      "\"I threw some books on the floor and some persons went over them, but that boy picked them up and put them on the table. He waited quietly for his turn instead of pushing. When I talked to him, I found his clothes were tidy, his hair was brushed clearly and his finger nails   were clean. I think these are more important than a letter and a recommendation.\"\n",
      "\n",
      "Question: Which is the best title for this passage?\n",
      "A. How to Do Everything Well.\n",
      "B. What Is Most Important for Asking for a Job.\n",
      "C. To Have Good Manners Before a Boss.\n",
      "D. Try to Find a Good Job.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63812\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001933574676513672\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 85725\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00020515918731689453\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: To make sure that you enjoy your visit to the Harper Hot Springs and that you are safe during your visit, please take time to read the following:\n",
      "Do not put your head under the hot water because it may be bad for your eyes.\n",
      "Do not run around because the floors may be _ \n",
      "Do not leave your children alone.\n",
      "Do not leave your things about. Just ask one of our workers to look after your things.\n",
      "Do not eat or drink anything in the area because we want to keep the area clean .There is a place for you to eat and soft drinks when you need to have a rest.\n",
      "Do not bring anything made of glass into the area, because it maybe easily to broken when you fall.\n",
      "Do not bring any hard drinks into the area.\n",
      "Do not smoke in the area.\n",
      "Do not stay in the sunlight for too long.\n",
      "We hope that you will enjoy your visit here\n",
      ",. . (10)\n",
      "\n",
      "Question: _  is not mentioned in the notice.\n",
      "A. How long visitors can stay in the area\n",
      "B. What visitors cannot come to the area.\n",
      "C. Who can take care of the visitors things\n",
      "D. Whether smoking is allowed in the area\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0027370452880859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30691\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004870891571044922\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Roosegaarde, an artist and designer from Dutch has thought of a device . He hopes it will make Beijing's sky clear again and help the people with masks breathe fresh air again in Beijing.\n",
      "An electromagnetic field  will pull the dirty particles in the air to the ground, and then they can be easily cleaned.\n",
      "Roosegaarde says, \"It's like when you have a balloon which has static electricity  and your hair goes toward it. Smog happens the same way as the hair.\"\n",
      "His workplace has reached an agreement with the Beijing government to test the technology in one of the capital's parks.  Beijing's skies are regularly covered by grey smog. Serious cases of air pollution are often reported in Beijing. Roosegaarde says an indoor test has already shown it works well and he is confident of the results. With the help of a team of scientists and engineers, he is sure that the device can be worked outside.\n",
      "\"Beijing is a very good place to test the device because the smog in Beijing is quite low and there's not so much wind.\" says Roosegaarde. \"We'll be able to make the air pure but the most difficult thing is to remove the smog. As a result, you can see the sun again.\"\n",
      "Roosegaarde also reminds us that his aim is not only to give a plan to solve Beijing's dirty air pollution but also to make people pay attention to the environment problem. He adds, \"This is not the real answer for smog. The real answer to do with it is clean cars, different industry and different lifestyles. \" However, he hopes the project will make the citizens realize the differences between clean air and smog-filled air.\n",
      "\n",
      "Question: What does Roosegaarde use his device for?\n",
      "A. To make smog.\n",
      "B. To make the air clean\n",
      "C. To make static electricity.\n",
      "D. To make Beijing's parks beautiful.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27367\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0015659332275390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0748291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The Monkey Buffet Festival is on the last Sunday of November. It is a great day for monkeys in Thailand  . The festival has a history of 25 years. People there think monkeys can bring good luck to them. So, to thank monkeys, they have this special festival.\n",
      "On that day every year, people put lots of fruit, vegetables, cakes and even drinks on the tables outside. They are all for monkeys. Many people come to see the monkeys on that day.\n",
      "During the festival, there are a lot of interesting activities about monkeys. Young people always dress like monkeys and they sing and dance and play some music on the street.\n",
      "Monkeys always live in groups. Most of them live in the trees. They are good at running and jumping. They eat fruit, vegetables, flowers and birds' eggs. Monkeys are clever. Do you think so?\n",
      "\n",
      "Question: What do people always do on that day?\n",
      "A. Eat all kinds of food.\n",
      "B. Sing and dance.\n",
      "C. Play with monkeys.\n",
      "D. Run and jump.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9792\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005021095275878906\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87728\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013856887817382812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Hearing what I said, my dad laughed kindly. I continued, \"I owe your thanks, and I hope you realize how much you did for me as my dad.\"\n",
      "I could almost hear him smiling one the other end. I knew he was touched and felt a little shy. His voice sounded shaky.\n",
      "\"Well, we got you educated,\" he said, laughing generously.\n",
      "\"You did more than that,\" I said, \"You did well.\"\n",
      "\"You like your house now, and your life?\" he asked quietly.\n",
      "\"Yeah, Dad, I'm happy. You don't have to worry--things are going great for us.\"\n",
      "I told him I loved him and he told me he loved me and I hung up the phone. As I got ready for bed, I thought about what an amazing conversation we had.\n",
      "Ten hours later, my mother called, waking me up. I could hardly understand what she was trying to say.\n",
      "\"Your father's dead!\" she cried. \"I found him lying on the dinning room floor.\"\n",
      "Suddenly I was standing straight up beside my bed, holding the phone and sobbing .\n",
      "I was a thousand miles away. All I could think about was how many hours, minutes and seconds it would take me to jump on a plane and get there. I thought about my mother sitting there alone with my father, and I couldn't move fast enough.\n",
      "The flight was long and painful. I had planned on going home to see my dad and mom in another month, and I cried aloud, thinking I was too late. Then I suddenly realized the incredible miracle of it all: I hadn't been late at all. Actually, everything had been right on time.\n",
      "\n",
      "Question: The writer thought  _\n",
      "A. his father did well.\n",
      "B. his father do enough.\n",
      "C. his father did badly\n",
      "D. his father is too old to do.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 97507\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006824493408203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99155\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.16259765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Look! Here's a pencil box, it's orange, it's my pencil box, it's on the desk. Look! This is a pen, it's black. And this is an eraser, it's blue and white. They're both in the pencil box. This is a ruler, it's red, it's on the pencil box. That is a ruler, too. It's yellow. It's in the drawer. Where's my math book? Ah, it's there, under the sofa.\n",
      "\n",
      "Question: Where is my English book?\n",
      "A. Under the sofa.\n",
      "B. On the desk.\n",
      "C. Sorry, I don't know.\n",
      "D. On the sofa.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.382080078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74895\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0034885406494140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear Mr. Lee,\n",
      "I am Jack. I want to be in a club in our school. I can't sing or dance or act in movies, but I can do many other things. I can play three _ , the guitar, the violin   and the piano. I think I can be in the music club. Maybe   I can be a famous musician. I like reading story books and I can write stories. Maybe I can be a famous writer. I like sports too, but I don't think I can be a famous and successful sportsman  . Can I join you?\n",
      "Yours,\n",
      "Jack\n",
      "\n",
      "Question: Jack can't   _   .\n",
      "A. act in movies\n",
      "B. write stories\n",
      "C. play the violin\n",
      "D. read\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.12109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4749\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0762939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Sam is twenty-seven now. He's tall and strong. He worked hard in the small field. He's known a girl called Mabel for three years, who lives in another village. He wishes she could marry him soon, but she won't marry him until he has built a new house. He hasn't enough money. Of course it's difficult for him to do so.\n",
      "Winter had come and the fields were covered with thick snow. Sam had nothing to do at home. Mabel told him to find some _ in the town. He thought she was right and came to Mr White's factory, where he carried stones from the hill to the workplaces. It was hard work but he was paid more. At the end of the month Mr White paid the young man nearly two thousand dollars. He was very happy. He hurried to the post office, but it was closed. He had a look at the clock on the wall. It was half past five, and he was told to go there the next morning. He had to return to the factory. He felt hungry and went into a restaurant and ate something. He didn't see a thief following him, and as soon as he sat at table, the man sat down next to him and asked him to drink a cup with him. He agreed and drank a lot. And when he woke up two hours later, his money was stolen. He was sad of it and cried for a long time.\n",
      "The following day Mr White saw the young man's eyes were red and asked what had happened to him. He told him about it and at last he said, \"I worked for the thief last month!\"\n",
      ",.\n",
      "\n",
      "Question: The money was stolen when   _  .\n",
      "A. Sam left the factory\n",
      "B. Sam went into the restaurant\n",
      "C. Sam ate something in the restaurant\n",
      "D. the thief got Sam drunk.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64609\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0012388229370117188\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1737060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Do You Want To Be A Musician?\n",
      "Do you want to be a musician? Come to our club, and you'll be very happy in the club. We have _ about the piano, the drums, the bamboo flute,the trumpet, the guitar and the violin for just $20 each.You can also learn to sing , to dance for $25 each. If you like art, you can be satisfied , too. It's just for $30 each!\n",
      "\n",
      "Question: We can't learn about  _  in the club.\n",
      "A. drums\n",
      "B. Bamboo flute\n",
      "C. guitar\n",
      "D. chess\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39720\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001556396484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13638\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0151214599609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Sam is twenty-seven now. He's tall and strong. He worked hard in the small field. He's known a girl called Mabel for three years, who lives in another village. He wishes she could marry him soon, but she won't marry him until he has built a new house. He hasn't enough money. Of course it's difficult for him to do so.\n",
      "Winter had come and the fields were covered with thick snow. Sam had nothing to do at home. Mabel told him to find some _ in the town. He thought she was right and came to Mr White's factory, where he carried stones from the hill to the workplaces. It was hard work but he was paid more. At the end of the month Mr White paid the young man nearly two thousand dollars. He was very happy. He hurried to the post office, but it was closed. He had a look at the clock on the wall. It was half past five, and he was told to go there the next morning. He had to return to the factory. He felt hungry and went into a restaurant and ate something. He didn't see a thief following him, and as soon as he sat at table, the man sat down next to him and asked him to drink a cup with him. He agreed and drank a lot. And when he woke up two hours later, his money was stolen. He was sad of it and cried for a long time.\n",
      "The following day Mr White saw the young man's eyes were red and asked what had happened to him. He told him about it and at last he said, \"I worked for the thief last month!\"\n",
      ",.\n",
      "\n",
      "Question: Sam went the post office to   _  .\n",
      "A. ring up Mabel\n",
      "B. post the money\n",
      "C. buy some stamps\n",
      "D. post a letter\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21422\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.003353118896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67324\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0543212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Do you know the phrase \"Weibo Addicts\"  ? Do you write a Weibo? If you don't, you are \"out\"!\n",
      "Weibo means microblog. People may spend much time writing a blog, but it takes a little time to write a microblog. Why? Because every message on a microblog is less than 140 words.\n",
      "Microblog started in the USA. It came to China in 2009 and it grows very fast. In 2011, the number of Chinese micro-bloggers grew to 300 million. People write microblogs for many reasons. For many microblog users, it is a great way of learning the freshest news, talking with friends and sharing different kinds of information, including news, everyday life, pictures, music, videos and so on.\n",
      "It is easy and fast to send a message on a microblog. However, this can also bring problems and even panic  . For example, when the big earthquake and tsunami   hit Japan in March, 2011, messages like \"Salt can help people fight radiation  \" were hot on microblogs. Then a crazy buying of salt followed. Later people knew it was just a rumor  .\n",
      "In a word, microblog plays a new part in the life of Chinese people.\n",
      "\n",
      "Question: People usually don't share their   _   on Weibo?\n",
      "A. videos.\n",
      "B. music.\n",
      "C. pictures.\n",
      "D. secrets.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09271240234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48067\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.023345947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: How much should you save? You may be able to save 100% of your money. Does that mean you should? Not at all. The best way to develop good saving habits is to make saving a regular part of your life, along with spending.\n",
      "Here is the rule you should remember: save before spending. Whenever some money gets into your hands, from a job or your pocket money or whatever, take your savings out immediately, before spending any of the money. The beauty of this system is that if you take away your savings, you are free to spend the rest.\n",
      "Here are some more suggestions on how to successfully get into the saving habit from teens. Let's see!\n",
      "Tony,13: I put my money in a bank instead of my wallet, so the money is not there. And I have to take an extra step to get it.\n",
      "Bill,14: When considering a major purchase , wait a week or so, at least. This will help you make sure if you still want it, and the price might go down.\n",
      "Dick, 13: Carry very little money always. You can't spend money if you don't have it. A cake would be nice, but without a dollar, you can't get it. Little things like that really add up quickly.\n",
      "Steve,16: I used to be weak when it came to money. I bought something whenever I went into a store. I'm glad I'm not that person now. I taught myself discipline by keeping a $20 bill in my pocket while waking around the mall all day and not buying anything. Now I have no strong wish to buy things when I go into a store. It works for me.\n",
      "These ideas should help you get started. If you have some questions about anything you've read here, or would like to share your ideas about saving money, please write to us.\n",
      "\n",
      "Question: According to Billy, if you want to buy something expensive, you'd better  _  .\n",
      "A. wait at least a month\n",
      "B. make sure it's necessary\n",
      "C. wait until it's for sale\n",
      "D. ask somebody for help\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 977\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0105438232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 37161\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01172637939453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: The scientists from the Lockheed Space Company   work in Felton, California, with the help of a computer. But the computer is placed in Sunnyside, about 80 kilometers away. What the scientists input is sent by telephone lines to the computer, and after a time, copies of the designs are needed back in Felton as possible. Lockheed people have tried several ways of sending the prints  , but the most effective seems to be by pigeon  . Are pigeons really used to carry messages in these days? They are, and they send the prints faster and cheaper than any other way.\n",
      "Human   messengers (persons carrying messages) are much more expensive and slower than the pigeons. The road to Felton goes through the mountains, and the driving is not easy. An electronic printout system  could do the work in Felton, but at a cost of 10 dollars a print. Pigeons carry the designs for about 1 dollar each.\n",
      "Now Lockheed people have ten pigeon messengers. The pigeons do the work, and they have made Lockheed more famous. You can often read the news about the pigeons in the newspapers around the world.\n",
      "\n",
      "Question: This story is unusual because pigeons_.\n",
      "A. don't like carrying things\n",
      "B. are often cheap to keep\n",
      "C. seem out of place in the space age\n",
      "D. aren't friendly to the scientists\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0293426513671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.436767578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: One evening , my dad asked me to buy some bread for dinner . It was dark and cold outside . I rode a bike to a shop near my school . When I left the shop ,it got even darker , so I got on my bike right away. Then I found a woman in a white dress riding a motorcycle after me . She followed me for a long time . I rode very fast and started to cry for help, but no one was there . I was too scared and too tired to ride any faster . At last , I gave up . The woman stopped in front of me and said , \" Why were you riding so fast , Ken ?It's dangerous !\" I looked at the woman . \" Oh , It's you, mum !You really scared me . Dad said you wouldn't be back for dinner tonight !\"\n",
      "\n",
      "Question: Why did Ken go out that night ?\n",
      "A. To ride a bike\n",
      "B. To buy some food\n",
      "C. To go to cram school\n",
      "D. To look for his mother\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101626\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00035834312438964844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42946\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1181640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Men Xue and Yang Yue are good friends. They are in the same school. They are in Class Two , Grade Seven. Men Xue is from Heze,Shandong. She is eleven years old . Her QQ number is 839922660. Yang Yue is from Dalian. She is twelve years old. Her brother   is Harry. He is a worker  . He is twenty-five (25). His telephone number is 18845036918.\n",
      ".\n",
      "\n",
      "Question: Where is Men Xue from?\n",
      "A. Henan.\n",
      "B. Hebei.\n",
      "C. Dalian.\n",
      "D. Heze.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 90919\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006480216979980469\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99688\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0711669921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Mike is seven and begins to go to school this week . It's Sunday . His mother Mrs. Smith doesn't go to work. Mike wants to go to the zoo. He gets up at six thirty and asks his mother to take him there. After breakfast they go to the bus stop. They want to take a No.3 bus to the  zoo .\n",
      "\"Look ,Mummy!\" the boy is calling out, \"A NO.3 bus is coming !\"\n",
      "\"No, dear\" Mrs. Smith is saying ,\"It isn't No.3 It's No.21.\"\n",
      "\"You're wrong, Mummy, \"Mike is saying. \"My teacher says two and one is three !\"\n",
      "\n",
      "Question: Mike is going to the zoo with  _  .\n",
      "A. his father\n",
      "B. his mother\n",
      "C. his sister\n",
      "D. his brother\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 227\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06744384765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35386\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00980377197265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Jim and Andy are standing at the bus stop and waiting for the No.6 bus. They want to buy some new books. Suddenly , two men are running past them. A short man is crying,\"help! help! Catch  the thief! Give my bag back to me.\"\"Oh! That man is a thief!\"Jim shouts to Andy. They begin to run after the tall man, and very soon they catch him and get the bag back. The short man runs over and smiles,\"Thank you. But we are filming a movie.\"\n",
      "\n",
      "Question: Andy and Jim think the tall man is   _   .\n",
      "A. an actor\n",
      "B. a thief\n",
      "C. a policeman\n",
      "D. the short man's friend.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23832\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0027141571044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 105126\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0307159423828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: In some countries, people eat rice every day. Sometimes they eat it twice or three times a day for breakfast, lunch and supper. Some people do not eat some kinds of meat. Muslims, for example, do not eat pork.\n",
      "Japanese eat lots of fish. They are near the sea. So it is easy for them to get fish.\n",
      "In the West, such as England and the USA, the most important food is potatoes. People there can cook potatoes in many different ways.\n",
      "Some people eat only fruit and vegetables. They do not eat meat or fish or anything else from animals. They eat food only from plants . They say the food from plants is better for us than meat. These people are called _\n",
      "\n",
      "Question: In some countries, people eat   _  every day.\n",
      "A. fish\n",
      "B. vegetables\n",
      "C. fruit\n",
      "D. rice\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27769\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0028591156005859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.038909912109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: There are several ways you can find out about the countries and places you wish to visit. You can talk to friends who have traveled to the places, you can go and see a colour film about them, or you can read a travel book.\n",
      "It seems that there are three kinds of travel books. The first are those that give a personal, subjective  idea of travels which their writer has got himself. These books can be useful if the writers share their traveling experiences with others. The second kind are those books which give objective  information of things to be done and seen. If _ has written such a book about the facts of a place, then it is more useful. The third kind are those books which are called \"a guide\" to some place or other. If they are good, they will describe and explain the place in detail. Like the first kind , they can be interesting and exciting, but their main purpose is to help the reader plan his travel in the most practical way.\n",
      "Whatever kind of travel book you choose, you must make sure that the book does not describe everything as interesting, exciting or fantastic. You must also keep an open eyes on its date of publication  because travel is very practical matter and many things change quickly in the 21st century. Finally, you should make sure that it's easy to find the useful information for you travel.\n",
      "\n",
      "Question: The passage was written to introduce  _  .\n",
      "A. travel maps\n",
      "B. travel books\n",
      "C. travel films\n",
      "D. travel places\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70178\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.197509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: John lives on a farm. The farm is not very big. His parents grow rice and corn. They don't use animals to do farm work any more. Today they use a tractor . It works faster and better. After he does his work in the fields, he likes to sit and look at the blue sky and the green hills. He thinks the country is more beautiful than the city. In the city, he can't hear the animals. In the country, he can hear birds singing. He likes to play with his dog, Cody. Cody is a very interesting dog. He likes to follow people. When they stop, he stops.\n",
      "When they walk, he walks. John thinks Cody is the best dog of all.\n",
      "\n",
      "Question: John's parents are   _  .\n",
      "A. workers\n",
      "B. teachers\n",
      "C. doctors\n",
      "D. farmers\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15702\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007152557373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5146484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Today is the fifth day of August. It is Judy's birthday. When she comes back home from school, she sees a card on the table. It says, \"There's a present   for you, Judy. Look for it in your bedroom.\" Judy runs into her bedroom. Her parents are looking at her and _ . On the chair she sees a red box. She thinks her present must be in it. She opens it, and there is a piece of paper in it. She reads it, \"Dear Judy, I'm your present. My first letter is in the word 'bag', but not in 'age'. My second letter is in 'like', but not in 'lake'. My third letter is in \"know\", but not in 'now'. And you can find my last letter in both 'desk' and 'get'. What am I?\" Judy thinks for a while and says, \"Aha, I know. But where is it?\" Her father tells her it is in her study.\n",
      "What is it? Do you know?\n",
      ". (5)\n",
      "\n",
      "Question: Where can Judy find her present?\n",
      "A. On the chair.\n",
      "B. In her study.\n",
      "C. In the box.\n",
      "D. In the living room.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28206\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07659912109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 50281\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00461578369140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Dear John, Thank you very much for your letter. I am glad that you enjoyed your holiday with me. We enjoyed having you and your sister here. We hope that you will both be able to come again next year. Perhaps you'll be able to stay longer next time you come. A week is not really long enough, is it? If your school has a five-week holiday next year, perhaps  you'll be able to stay with us for two or three weeks.\n",
      "We have been back at school three weeks now. It feels like three months! I expect  that you are both working very hard now that you are in Grade One. I shall have to work hard next year when I am in Grade One. Tom and Ann won't be in Grade One until 2011.\n",
      "They went for a picnic yesterday but I didn't go with them because I cut my foot and I couldn't walk very well. They went to an island and enjoyed themselves. Do you still remember the island? That's where all five of us spent the last day of our holiday.\n",
      "Tom, Ann and I send our best wishes to Betty and you. We hope to see you soon.\n",
      "Yours sincerely,\n",
      "Michael\n",
      "\n",
      "Question: _  stayed with Michael for a holiday.\n",
      "A. Only John\n",
      "B. Only Tom and Ann\n",
      "C. John and his sister\n",
      "D. Only Tom\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.76171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23174\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001583099365234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: After my husband died, my world crashed around me. My six children were 10, nine, eight, six, three and 18 months, and I was overwhelmed with the responsibilities of earning a living, caring for the children and simply _ .\n",
      "I was fortunate to find a wonderful housekeeper to care for the children during the week, but from Friday nights to Monday mornings, the children and I were alone, and frankly I was uneasy. Every unusual noise or any late-night phone call filled me with fear. I felt incredibly alone.\n",
      "One Friday evening I came home from work to find a big beautiful German shepherd  on our doorstep. It was obvious he wanted to make the house his home. The children took an instant liking to \"German\" and begged me to let him in. I agreed to let him sleep in the basement until the next day. That night I slept peacefully for the first time in many weeks.\n",
      "The following morning we made phone calls and checked lost-and-found ads for German's owner, but with no results. Saturday night he was still with us.\n",
      "On Sunday I had planned to take the children on a picnic. Since I thought it best to leave German behind in case his owner came by, we drove off without him. When we stopped to get gas at a local station, we were amazed to see German racing to the gas station after us. He stayed again Sunday night.\n",
      "Monday morning I let him out for a run while the children got ready for school. He didn't come back. We thought we'd never see him again. On Friday evening, German was back again. We took him in, and again he stayed until Monday morning, when our housekeeper arrived. It went like this for almost 10 months. We looked forward to his coming each Monday morning he left home.\n",
      "Each week, between German's visits, I grew a little braver, but every weekend I enjoyed his company. Then one Monday morning we patted his head and let him out for what turned out to be the last time. He never came back.\n",
      "\n",
      "Question: Which of the following is Wrong according to the article?\n",
      "A. German was fond of living with the family.\n",
      "B. The writer felt safe and protected with German around.\n",
      "C. The dog stayed until the writer was strong enough to go on alone.\n",
      "D. The writer was too busy that weekend to go find the dog's owner.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " C\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: C, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 52622\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0355224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57640\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0080413818359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: In many countries, holidays are important parts in people's life. Let's show some countries to you.\n",
      "America\n",
      "American people's holidays are flexible ( ). They can use up their holidays once, and they can also use them up a few times. During the holidays, they still get money.\n",
      "Canada\n",
      "Many people in Canada can rest three days a week. They have all kinds of activities   for holidays. They may go fishing, boating or mountain climbing. Also, they have long holidays. They may go to the beach to spend a sunny winter holiday. Like American people, Canadians also get money during the holidays.\n",
      "France\n",
      "People in France are very good at enjoying life. They have a 6-week holiday every year, and they work less than 40 hours a week.\n",
      "\n",
      "Question: Which of the following activities is not mentioned in the passage?\n",
      "A. Go fishing.\n",
      "B. Go boating.\n",
      "C. Go skating.\n",
      "D. Go mountain climbing.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " B\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: B, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 127312\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006763458251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17465\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11297607421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: \"Depend on yourself\" is what nature says to every man. Parents can help you. Teachers can help you. Others still can help you. But all these people only help you to help yourself.\n",
      "There have been many great men in history. Many of them were very poor when they were young, and had no uncles, aunts, or friends to help them. Schools were few and not very good. They could not depend on them for education. They tried their best to learn something and never gave up till they became well-known. One of the most famous teachers in England used to tell his pupils, \"I cannot make worthy men of you, but I can help you make men of yourselves.\"\n",
      "Some young men don't try their best to make themselves valuable to the human beings. If they see their weak points and change their ways, they can be successful. They are nothing now, and will be nothing as long as  they live, unless they accept the advice of their parents and teachers, and depend on themselves.\n",
      "\n",
      "Question: If young people depend on their own efforts,   _  .\n",
      "A. they are sure to be very famous in the world\n",
      "B. they can be successful in their lives\n",
      "C. they no longer need help\n",
      "D. they are sure to fail\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " D\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: D, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 613\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002727508544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20865\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018444061279296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: A little girl thought she was not as beautiful as other girls, and nobody liked her. So she was always unhappy and didn't like to talk to others. However, one day, her mother gave her a beautiful hair clip . When she wore it, she looked much more beautiful than before. She decided to wear it to school.\n",
      "On her way to school she found that everyone who saw her smiled at her. Most of her schoolmates said \"Hello\" to her, but this never happened before. She thought that the beautiful hair clip had brought her them all. She was so happy about all of the wonderful things. Although she didn't tell her classmates about her beautiful hair clip, they all wanted to know what had happened to her.\n",
      "When she went back home after school, her mother asked her: \"Did you know you dropped your hair clip? I found it by the door this morning.\"\n",
      "She understood that she hadn't worn the hair clip to school at all.\n",
      "\n",
      "Question: Her classmates wanted to know what had happened to the girl because  _\n",
      "A. she didn't tell her classmates about her beautiful hair clip.\n",
      "B. she was always unhappy but that day she was so happy.\n",
      "C. she looked more beautiful wearing the hair clip.\n",
      "D. she wanted to talk to others.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30554\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007176399230957031\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77064\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0022258758544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: It's the second time for me to come to Beijing. There are many places of interest in Beijing, such as the Summer Palace, the Great Wall, etc. What's more, I think great changes have taken place in Beijing. People's living conditions have improved a lot. Their life is very happy. Almost everyone has a big smile on the face. People in Beijing are in high spirits and hard-working. Children can receive a good education.\n",
      "But in the past, some children didn't have enough money to go to school. They often worked for cruel bosses. The bosses didn't give them enough food. I feel sorry for them. Today people have already lived in tall building, worn beautiful clothes and so on. Life has changed greatly.\n",
      "\n",
      "Question: People's living conditions have improved   _  in Beijing.\n",
      "A. a lot\n",
      "B. little\n",
      "C. few\n",
      "D. slowly\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: A\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09185791015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.100341796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Do you know \"World Reading Day\"? It is on April 23rd. It is the eighteenth \"World Reading Day\". As we know books are very important for us.\n",
      "In Germany, more than 70% of people like reading: They often read. They read in their homes. They read in libraries. They read in parks. They even read in hospitals. Parents often read books for kids.\n",
      "It is easy to buy books in Germany. There are many bookshops in Germany. They are in big cities and small town. A bookshop can sell many books every day. Germans also like to buy books on the Internet. More and more people buy books on the Internet.\n",
      "In Germany, people often have reading parties. They are happy at the parties.\n",
      "Do you love reading? Hope you enjoy it!\n",
      "\n",
      "Question: Where can Germans buy books?\n",
      "A. Bookshops.\n",
      "B. Small towns.\n",
      "C. On the Internet.\n",
      "D. Everywhere.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: D\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21935\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 9.936094284057617e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36671\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016736984252929688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27457\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1064453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95723\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.045135498046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12307\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08563232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1954345703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 97443\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005083084106445312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111715\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.380126953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40506\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 6.717443466186523e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89234\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1856689453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79543\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1082763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32184\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 8.636713027954102e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47608\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005788803100585938\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 105412\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0262298583984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56418\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73260\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00801849365234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09112548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64003\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.041168212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38237\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1566162109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98774\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0183258056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12129\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005573272705078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56619\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.077880859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 70127\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.77978515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95852\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5419921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57449\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00044035911560058594\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46201\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007166862487792969\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39075\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0105133056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73431\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2237548828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28726\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007376670837402344\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34818\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00047779083251953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88844\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001385211944580078\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82665\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006256103515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102935\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016937255859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77990\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.080810546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10179\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001901388168334961\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82633\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004227161407470703\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 117088\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007977485656738281\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 115277\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.017608642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56757\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0254669189453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 125506\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004627227783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57971\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00014352798461914062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83985\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.418701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8466796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99123\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001316070556640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5748\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.146484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.31884765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 90145\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0022373199462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36851\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.73583984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67075\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.011688232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 72271\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.031768798828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 18604\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.12298583984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27257\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.047027587890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38735\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.324462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42612\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01166534423828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 71017\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00905609130859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34444\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2493896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7643\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.113037109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 18036\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004012584686279297\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27845\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38447\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00847625732421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12680\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0026073455810546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 119706\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.37255859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 65160\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2880859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 64467\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004584789276123047\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42439\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00783538818359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49251\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002734661102294922\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 87293\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00021219253540039062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8823\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.209228515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73457\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 100220\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.91845703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29256\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.7275390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43953\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.027069091796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102882\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.444620132446289e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 69267\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0548095703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99575\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.71923828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99575\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.345458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 99575\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.67626953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20427\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02215576171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48067\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07696533203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.469482421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40096\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79543\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08489990234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77585\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.904296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11166\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.220947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 316\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03228759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19522\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 7.873773574829102e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008373260498046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.63818359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77585\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.12890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5685\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.032623291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42455\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00881195068359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12287\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.126953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5149\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2381591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8173828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94562\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08746337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47816\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 9.441375732421875e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32133\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.023284912109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 102764\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001964569091796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8662109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13909\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002294778823852539\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2959\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0264892578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3300\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01131439208984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 108217\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.037994384765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 47530\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00038552284240722656\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62261\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0156707763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27253\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005168914794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88126\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007354736328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2335\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 96018\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.010467529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60005\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0262603759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4280\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1263427734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 33713\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009522438049316406\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43847\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0019121170043945312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.51806640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.56982421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 84137\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.30859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53133\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.183349609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 80061\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.020751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6847\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.68994140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9413\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.000244140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 114884\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00406646728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 100103\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 6.753206253051758e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34495\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03973388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 92979\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.030975341796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9208984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3514\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0517578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34322\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.000988006591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 24063\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004436969757080078\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 128001\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0255889892578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40568\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004337310791015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19846\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016155242919921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121827\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.072998046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48946\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03155517578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2695\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00199127197265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15792\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00327301025390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2695\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01416778564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83595\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.056121826171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120131\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018205642700195312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12287\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0158233642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55858\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.286376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8823\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.72216796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73457\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.822265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43165\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0188751220703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.580078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25675\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00019109249114990234\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 67325\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0182342529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83816\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.033721923828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91827\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005275726318359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91591\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0943603515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63237\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2313232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110497\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001255035400390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10815\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 9.125471115112305e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48166\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004839897155761719\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 115916\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0015649795532226562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55947\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00030541419982910156\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36343\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.304443359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25506\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05889892578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54425\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0012216567993164062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3023\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007648468017578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101008\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01360321044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8023\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1346435546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28931\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.034027099609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 92823\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003211498260498047\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10087\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.031707763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4395\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0078582763671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45961\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0209503173828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35552\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10626220703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3300\n",
      "  Verified Probability: 1.0\n",
      "  Draft Probability: 0.0909423828125\n",
      "\n",
      "[DEBUG] Speculation Step 1\n",
      "  Draft Output Token: 3300\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05303955078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 1: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54064\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0184478759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103495\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0067291259765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95399\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0262908935546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.81201171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55087\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.012664794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28233\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014619827270507812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1644287109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111484\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002300262451171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73327\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006055831909179688\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 450\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0021419525146484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27514\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0035076141357421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89502\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1773681640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104071\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0010824203491210938\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12837\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0243988037109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36562\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005550384521484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4280\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3779296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 78412\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013055801391601562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83985\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.166259765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81121\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.424072265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 726\n",
      "  Verified Probability: 1.0\n",
      "  Draft Probability: 0.43017578125\n",
      "\n",
      "[DEBUG] Speculation Step 1\n",
      "  Draft Output Token: 69339\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.24658203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 1: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13446\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.65478515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111419\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02252197265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2439\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008320808410644531\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 101959\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0015468597412109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.46875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104848\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.041015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12246\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00011736154556274414\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20934\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00021648406982421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.85009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38735\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1480712890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 31422\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0286407470703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 100445\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005878448486328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13441\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00679779052734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83430\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0017852783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12660\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48946\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0012884140014648438\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 11722\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01314544677734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46712\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004970550537109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22479\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006322860717773438\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29471\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05535888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 116278\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0020542144775390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 108475\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01934814453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79875\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0180816650390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 51507\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0312042236328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8823\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73457\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.67138671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10826\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00025844573974609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3576\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.3544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103543\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1275634765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2574\n",
      "  Verified Probability: 1.0\n",
      "  Draft Probability: 0.0478515625\n",
      "\n",
      "[DEBUG] Speculation Step 1\n",
      "  Draft Output Token: 119923\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00058746337890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 1: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61831\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.032379150390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94723\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006890296936035156\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 37539\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06866455078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 80643\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.005222320556640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3864\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.024017333984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.951171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04400634765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94917\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00022983551025390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13358\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02130126953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36343\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5439453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77585\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.052459716796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 668\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00930023193359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53911\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0168914794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 454\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.017303466796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.033935546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13870\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002694129943847656\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12610\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00030517578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98325\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.17578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3512\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.290283203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 93918\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01216888427734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.83544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.385009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13038\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006022453308105469\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17327\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0364990234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95221\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00022351741790771484\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21828\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08758544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.494140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 14029\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001556396484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1073\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0246734619140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 109590\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00010401010513305664\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 56029\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06353759765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30727\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 8.32676887512207e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27993\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.018524169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89502\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.149169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25262\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00037741661071777344\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110000\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00021135807037353516\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29256\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0115966796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26466\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.000354766845703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 115806\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002371072769165039\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22272\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0026683807373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81121\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.492431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 726\n",
      "  Verified Probability: 1.0\n",
      "  Draft Probability: 0.47265625\n",
      "\n",
      "[DEBUG] Speculation Step 1\n",
      "  Draft Output Token: 42576\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.296142578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 1: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13446\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4248046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 54574\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0021266937255859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10521\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0029926300048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 34081\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02197265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.445068359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81121\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2042236328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 450\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01320648193359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91591\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.038238525390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1141\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.17333984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3975\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00017964839935302734\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74147\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0205841064453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53358\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00044417381286621094\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 16789\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0321044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81121\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04339599609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89234\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00797271728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49944\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00047087669372558594\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 41737\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.036773681640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89894\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09075927734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 16079\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00756072998046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 31523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013408660888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6780\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0183563232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1655\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10791015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28470\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09161376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 55858\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.11114501953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8823\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.16357421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 603\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01009368896484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 100220\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05645751953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.406005859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 103543\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.197509765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83738\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0699462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83048\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.026580810546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 48626\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0019073486328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91591\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.57421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 40590\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0057830810546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2028\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0020236968994140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5678\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0084075927734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.95263671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9873046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104440\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00016200542449951172\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0743408203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12826\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.054443359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36343\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 588\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03973388671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 88212\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04534912109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.409423828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 107107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0258331298828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15752\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.014495849609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.85595703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12287\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.043670654296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 33078\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0022296905517578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98325\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.397216796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39415\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00154876708984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10087\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004852294921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.85009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.493408203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28578\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.033203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49944\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00843048095703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 33713\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004439353942871094\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.095947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 2959\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.12017822265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42747\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01207733154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49521\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.491455078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 454\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.034332275390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19703\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0970458984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 77318\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00016832351684570312\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120554\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.276611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76490\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.080078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61486\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003104209899902344\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29901\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05419921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4280\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.478271484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46122\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004031658172607422\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62596\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.133544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2041015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.422607421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10323\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0134429931640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36171\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003654956817626953\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22225\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00014388561248779297\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21418\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0029125213623046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75095\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1461181640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.424072265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 76706\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001407623291015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 395\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0105438232421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8784\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0093536376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.82666015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81121\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.196044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 63328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0021877288818359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 6198\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.010162353515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 44806\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.463623046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121827\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12660\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89234\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.060699462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 59408\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005359649658203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66922\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 24429\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0261383056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57149\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01067352294921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13446\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.074462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10915\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005321502685546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4647\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008645057678222656\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 124680\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007587432861328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8823\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.096435546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73457\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.423095703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 107860\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002582550048828125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 58523\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.313720703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29256\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.411376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83738\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.07196044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 27929\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0023345947265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 42576\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.25390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13446\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06109619140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 116399\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0021610260009765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 86491\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00015723705291748047\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12278\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.67333984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 1.0\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.9619140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120396\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014009475708007812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 7420\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 6.461143493652344e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 23010\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0273590087890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36343\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 377\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006723403930664062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006537437438964844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.346435546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 104276\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.049041748046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29699\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.043060302734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.91259765625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 109484\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0004303455352783203\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49521\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00836181640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98325\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.445556640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3512\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.28271484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3512\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1334228515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.822265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 95852\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1680908203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3167\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0029735565185546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17327\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04437255859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62238\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00031185150146484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 19703\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04547119140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91674\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.06097412109375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 74330\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00720977783203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.29736328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 49521\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.45654296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38661\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1383056640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 35635\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0221710205078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38094\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03533935546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 45737\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0006847381591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01299285888671875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98936\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0001989603042602539\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 79543\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01153564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4280\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.5244140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.047027587890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 62596\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.085693359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.218017578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.39990234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66873\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.09808349609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13446\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.33349609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8164\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0221405029296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04888916015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36343\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.001422882080078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38716\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0016651153564453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 73646\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00038743019104003906\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 615\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1397705078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 588\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0201416015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81121\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2083740234375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 83400\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00505828857421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 38790\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0007181167602539062\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 44803\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0011653900146484375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 668\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.004299163818359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12660\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6943359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 82250\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0038127899169921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 66472\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.03814697265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 32260\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0102691650390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12660\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.033843994140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57149\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.006649017333984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22173\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00038886070251464844\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17277\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00209808349609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 1101\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04266357421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10145\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1793212890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 9943\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0013914108276367188\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 17277\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0024471282958984375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43314\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0010929107666015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 3576\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6455078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29256\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.381591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 46354\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04840087890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8088\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0138702392578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 97613\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00019669532775878906\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13446\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08612060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39322\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0009641647338867188\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 43982\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.007511138916015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 89469\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0018243789672851562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5255\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.916015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.8408203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 110909\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.200927734375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.04071044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13358\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.068359375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 107328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1766357421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 69399\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0005121231079101562\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91049\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.10858154296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 36107\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.33544921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 91049\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.05401611328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 10693\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002429962158203125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 13772\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.93310546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 80889\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.324462890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 5694\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1397705078125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 98325\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.437744140625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12287\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.02093505859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8940\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0014219284057617188\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.85400390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 29359\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.51806640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 12288\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002982616424560547\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 84137\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.418701171875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 122919\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.000278472900390625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 21376\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002033233642578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 18666\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00547027587890625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 26989\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.024200439453125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 121019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0002930164337158203\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 97647\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0012226104736328125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 57944\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0003802776336669922\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 15819\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00138092041015625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 39115\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 9.548664093017578e-05\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 120554\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.342529296875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01343536376953125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81964\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.032867431640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 60624\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00012302398681640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 4280\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.54345703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 31690\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.002521514892578125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 30592\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0008516311645507812\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81121\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.6669921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 726\n",
      "  Verified Probability: 1.0\n",
      "  Draft Probability: 0.66552734375\n",
      "\n",
      "[DEBUG] Speculation Step 1\n",
      "  Draft Output Token: 726\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1783447265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 1: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 53133\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.019256591796875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25849\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.01171112060546875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 61323\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.038726806640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 75095\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.1929931640625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 22374\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.30224609375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 81121\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.446044921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 8897\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.00443267822265625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 450\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.4794921875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 94348\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.82421875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: As prices and building costs keep rising, \"the do-it-yourself\"(DIY)trend  in the US continues to grow.\n",
      "\"We needed furniture for our living room,\" says John Kose, \"and we didn't have enough money to buy it.\" So we decided to try making a few tables and chairs. John got married six months ago, and like many young people these days, they are struggling  to make a home when the cost of living is very high. The Koses took a 2-week course for $ 280 at a night school. Now they build all their furniture and make repairs around the house.\n",
      "Jim Hatfield has three boys and his wife died. He has a full-time job at home as well as in a shoe-making factory. Last month, he received a car repair bill for $420. \"I was very upset about it. Now I've finished a car repair course. I should be able to fix the car myself. \"\n",
      "John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and his wife went to evening classes to learn how to   _   .\n",
      "A. improve the quality of life\n",
      "B. save time and money\n",
      "C. make or repair things\n",
      "D. run a DIY shop\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " C\n",
      "\n",
      "Question: John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those\n",
      "[Acceptance Rate]: 0.0016578249336870027\n",
      "Extracted prediction: C, Extracted target: C\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 28206\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.0173187255859375\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 111019\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.08807373046875\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: We know exercise is important in our life. Everyone needs to do exercise. Doctors say doing sports is good for us. Sports can make our body healthy.\n",
      "It's very useful  for children, too. It can make children clever. This means they will do well in study and schoolwork.\n",
      "There are easy ways to exercise. You can walk, run, or only jump. When you do exercise, you need to know what you are doing. Don't do sports too much at a time. Try all kinds of sports and look for one, two or even three sports you like. You can also exercise at the gym . Exercise can be fun. It can make you happy. Friends can exercise together at a gym or they can do sports together at any place they like.\n",
      "\n",
      "Question: It is NOT true that   _  .\n",
      "A. everyone needs to do sports\n",
      "B. doing a lot of sports at a time makes you very healthy\n",
      "C. we should try all kinds of sports\n",
      "D. people can do exercise at the gym or at home\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 20328\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2271728515625\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "\n",
      "[DEBUG] Speculation Step 0\n",
      "  Draft Output Token: 25417\n",
      "  Verified Probability: 0.0\n",
      "  Draft Probability: 0.2110595703125\n",
      "\n",
      "[DEBUG] Probability Distribution before multinomial at step 0: tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "[SUMMARY] Zero-Division Cases Encountered: 0\n",
      "[Prompt]:\n",
      "Article: Many people think sports are just for winning and honor, but there is a lot more you can gain from (get out of) them. I have learned over the past years that sometimes when I lose, I get a lot more out of it than winning. Also, I find a lot of times in sports, people are getting too caught up in the game instead of just having fun. The real purpose of sports is to have fun and learn life lessons along the way.\n",
      "I greatly encourage you to be a part of the school sports. Even if you are not the best, you can still have fun. Sports give people a great and healthy way of spending an afternoon, instead of lying around playing video games or even getting into bad things. Sports also give us a sense of achievement. There isn't a better feeling than to have done something fun and productive for my day.\n",
      "I think that we all need sports to give us courage. If we try hard in sports, we usually do well. If we did the same in study, we would all be champions. Another reason why I encourage you to play sports is that it's just fun. Without sports, our lives would just be boring. So as you may be able to tell, sports are amazing!\n",
      "Our coaches not only teach us to play sports, but show class and good sportsmanship while playing them. It's never fun when you lose to have the competitor rub it in your face. That's why our coaches teach us to show class when we lose; also, when coaches _ , don't get down. They only want to see you improve and learn from what they say. When you do badly and they don't shout loudly is when you should start worrying because they are giving up on you.\n",
      "Overall, sports are great! They bring out the best and worst of a lot of us. However, we can' t let sports get too serious to where it brings down all the fun. So to have the most fun in sports, you just need try your best and not worry so much about the winning or losing.\n",
      "\n",
      "Question: What is the best title of this passage?\n",
      "A. Are we too caught up?\n",
      "B. To win or to gain?\n",
      "C. Are sports really great?\n",
      "D. For honor or for health?\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " A\n",
      "[Acceptance Rate]: 0.0\n",
      "Extracted prediction: A, Extracted target: B\n",
      "{'predicted_text': {'exact_match': 0.3499999940395355, 'accuracy': 0.35}, 'acceptance_rate': {'mean': 1.9862321787513794e-05}, 'total_time': {'mean': 1.2633147525787354}, 'time_per_token': {'mean': 0.22252344399690627}, 'tokens_per_second': {'mean': 4.806430654525757}}\n"
     ]
    }
   ],
   "source": [
    "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset race_h \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy self_speculative\\\n",
    "    --exit_layer 8 \\\n",
    "    --output_dir ./logs \\\n",
    "    --num_speculations 6 \\\n",
    "    --top_p 0.9 \\\n",
    "    --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "  1%|          | 1/100 [00:07<12:59,  7.87s/it]\n",
      "  2%|▏         | 2/100 [00:14<11:27,  7.02s/it]\n",
      "  3%|▎         | 3/100 [00:21<11:17,  6.99s/it]\n",
      "  4%|▍         | 4/100 [00:28<11:03,  6.91s/it]\n",
      "  5%|▌         | 5/100 [00:34<10:37,  6.71s/it]\n",
      "  6%|▌         | 6/100 [00:40<10:16,  6.56s/it]\n",
      "  7%|▋         | 7/100 [00:47<10:09,  6.56s/it]\n",
      "  8%|▊         | 8/100 [00:53<10:04,  6.57s/it]\n",
      "  9%|▉         | 9/100 [01:00<09:48,  6.47s/it]\n",
      " 10%|█         | 10/100 [01:05<09:23,  6.26s/it]\n",
      " 11%|█         | 11/100 [01:11<09:09,  6.18s/it]\n",
      " 12%|█▏        | 12/100 [01:17<09:01,  6.15s/it]\n",
      " 13%|█▎        | 13/100 [01:24<08:53,  6.13s/it]\n",
      " 14%|█▍        | 14/100 [01:30<08:49,  6.15s/it]\n",
      " 15%|█▌        | 15/100 [01:36<08:41,  6.13s/it]\n",
      " 16%|█▌        | 16/100 [01:42<08:34,  6.12s/it]\n",
      " 17%|█▋        | 17/100 [01:48<08:26,  6.10s/it]\n",
      " 18%|█▊        | 18/100 [01:54<08:23,  6.14s/it]\n",
      " 19%|█▉        | 19/100 [02:00<08:14,  6.11s/it]\n",
      " 20%|██        | 20/100 [02:06<08:08,  6.11s/it]\n",
      " 21%|██        | 21/100 [02:12<08:02,  6.11s/it]\n",
      " 22%|██▏       | 22/100 [02:19<07:56,  6.10s/it]\n",
      " 23%|██▎       | 23/100 [02:25<07:51,  6.13s/it]\n",
      " 24%|██▍       | 24/100 [02:31<07:47,  6.15s/it]\n",
      " 25%|██▌       | 25/100 [02:37<07:38,  6.11s/it]\n",
      " 26%|██▌       | 26/100 [02:43<07:37,  6.19s/it]\n",
      " 27%|██▋       | 27/100 [02:50<07:45,  6.38s/it]\n",
      " 28%|██▊       | 28/100 [02:56<07:38,  6.37s/it]\n",
      " 29%|██▉       | 29/100 [03:03<07:33,  6.39s/it]\n",
      " 30%|███       | 30/100 [03:09<07:22,  6.32s/it]\n",
      " 31%|███       | 31/100 [03:15<07:13,  6.28s/it]\n",
      " 32%|███▏      | 32/100 [03:22<07:11,  6.34s/it]\n",
      " 33%|███▎      | 33/100 [03:28<06:57,  6.24s/it]\n",
      " 34%|███▍      | 34/100 [03:34<06:50,  6.22s/it]\n",
      " 35%|███▌      | 35/100 [03:40<06:45,  6.24s/it]\n",
      " 36%|███▌      | 36/100 [03:47<06:42,  6.29s/it]\n",
      " 37%|███▋      | 37/100 [03:53<06:36,  6.29s/it]\n",
      " 38%|███▊      | 38/100 [03:59<06:30,  6.30s/it]\n",
      " 39%|███▉      | 39/100 [04:06<06:30,  6.41s/it]\n",
      " 40%|████      | 40/100 [04:13<06:28,  6.47s/it]\n",
      " 41%|████      | 41/100 [04:18<06:12,  6.32s/it]\n",
      " 42%|████▏     | 42/100 [04:24<05:59,  6.19s/it]\n",
      " 43%|████▎     | 43/100 [04:30<05:46,  6.08s/it]\n",
      " 44%|████▍     | 44/100 [04:36<05:38,  6.04s/it]\n",
      " 45%|████▌     | 45/100 [04:42<05:29,  6.00s/it]\n",
      " 46%|████▌     | 46/100 [04:48<05:20,  5.93s/it]\n",
      " 47%|████▋     | 47/100 [04:54<05:13,  5.91s/it]\n",
      " 48%|████▊     | 48/100 [05:00<05:07,  5.91s/it]\n",
      " 49%|████▉     | 49/100 [05:06<05:03,  5.96s/it]\n",
      " 50%|█████     | 50/100 [05:12<04:59,  5.98s/it]\n",
      " 51%|█████     | 51/100 [05:18<04:53,  5.99s/it]\n",
      " 52%|█████▏    | 52/100 [05:24<04:52,  6.08s/it]\n",
      " 53%|█████▎    | 53/100 [05:30<04:46,  6.10s/it]\n",
      " 54%|█████▍    | 54/100 [05:37<04:45,  6.20s/it]\n",
      " 55%|█████▌    | 55/100 [05:43<04:39,  6.22s/it]\n",
      " 56%|█████▌    | 56/100 [05:49<04:34,  6.25s/it]\n",
      " 57%|█████▋    | 57/100 [05:55<04:23,  6.14s/it]\n",
      " 58%|█████▊    | 58/100 [06:01<04:12,  6.00s/it]\n",
      " 59%|█████▉    | 59/100 [06:06<04:02,  5.91s/it]\n",
      " 60%|██████    | 60/100 [06:12<03:54,  5.86s/it]\n",
      " 61%|██████    | 61/100 [06:18<03:47,  5.83s/it]\n",
      " 62%|██████▏   | 62/100 [06:24<03:41,  5.83s/it]\n",
      " 63%|██████▎   | 63/100 [06:30<03:37,  5.86s/it]\n",
      " 64%|██████▍   | 64/100 [06:36<03:33,  5.92s/it]\n",
      " 65%|██████▌   | 65/100 [06:42<03:28,  5.96s/it]\n",
      " 66%|██████▌   | 66/100 [06:48<03:24,  6.01s/it]\n",
      " 67%|██████▋   | 67/100 [06:54<03:21,  6.11s/it]\n",
      " 68%|██████▊   | 68/100 [07:00<03:14,  6.09s/it]\n",
      " 69%|██████▉   | 69/100 [07:07<03:14,  6.28s/it]\n",
      " 70%|███████   | 70/100 [07:14<03:16,  6.54s/it]\n",
      " 71%|███████   | 71/100 [07:25<03:46,  7.81s/it]\n",
      " 72%|███████▏  | 72/100 [07:36<04:03,  8.69s/it]\n",
      " 73%|███████▎  | 73/100 [07:47<04:11,  9.33s/it]\n",
      " 74%|███████▍  | 74/100 [07:57<04:13,  9.76s/it]\n",
      " 75%|███████▌  | 75/100 [08:03<03:36,  8.67s/it]\n",
      " 76%|███████▌  | 76/100 [08:09<03:06,  7.78s/it]\n",
      " 77%|███████▋  | 77/100 [08:15<02:44,  7.13s/it]\n",
      " 78%|███████▊  | 78/100 [08:20<02:27,  6.69s/it]\n",
      " 79%|███████▉  | 79/100 [08:26<02:15,  6.47s/it]\n",
      " 80%|████████  | 80/100 [08:32<02:04,  6.20s/it]\n",
      " 81%|████████  | 81/100 [08:38<01:54,  6.04s/it]\n",
      " 82%|████████▏ | 82/100 [08:43<01:47,  5.95s/it]\n",
      " 83%|████████▎ | 83/100 [08:49<01:40,  5.89s/it]\n",
      " 84%|████████▍ | 84/100 [08:55<01:34,  5.91s/it]\n",
      " 85%|████████▌ | 85/100 [09:01<01:28,  5.89s/it]\n",
      " 86%|████████▌ | 86/100 [09:07<01:23,  5.95s/it]\n",
      " 87%|████████▋ | 87/100 [09:13<01:19,  6.08s/it]\n",
      " 88%|████████▊ | 88/100 [09:20<01:15,  6.32s/it]\n",
      " 89%|████████▉ | 89/100 [09:27<01:11,  6.54s/it]\n",
      " 90%|█████████ | 90/100 [09:33<01:04,  6.42s/it]\n",
      " 91%|█████████ | 91/100 [09:39<00:56,  6.28s/it]\n",
      " 92%|█████████▏| 92/100 [09:45<00:49,  6.13s/it]\n",
      " 93%|█████████▎| 93/100 [09:51<00:42,  6.05s/it]\n",
      " 94%|█████████▍| 94/100 [09:57<00:36,  6.10s/it]\n",
      " 95%|█████████▌| 95/100 [10:03<00:30,  6.12s/it]\n",
      " 96%|█████████▌| 96/100 [10:10<00:24,  6.13s/it]\n",
      " 97%|█████████▋| 97/100 [10:16<00:18,  6.10s/it]\n",
      " 98%|█████████▊| 98/100 [10:23<00:12,  6.36s/it]\n",
      " 99%|█████████▉| 99/100 [10:29<00:06,  6.48s/it]\n",
      "100%|██████████| 100/100 [10:36<00:00,  6.58s/it]\n",
      "100%|██████████| 100/100 [10:36<00:00,  6.37s/it]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard benchmark for dataset: race_h\n",
      "[Prompt]:\n",
      "Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
      "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
      "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
      "\n",
      "Question: How did Victory deal with the money finally?\n",
      "A. He gave it away to a very sick baby.\n",
      "B. He kept it himself.\n",
      "C. He gave it back to the owner.\n",
      "D. He gave it to the police.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "engaIBEIBEedeADEADEADEadeADEadePLEoogoogOi vydáníeviainmentmindmindдоaderaoolaoolaoolaoolaadeADEtakplyplyALERøjøjافsarFORCEoner Erik ErikGenre rose rose hershirigarigarigarigarannessannesshaftsworthsworth� Ming Minghirเว선EOATEerdeadeADEéesesiz生的生生ENCEmáydıitationalitationalGenrefigcaptionolinioliniichichichich하elijkeerdeerdeéeéesigarigarigarigaridarhanahana interracial interracial Interracial interracialness卒 Casc Casc Mormlobal-globalizedizedovatovatovskyovskyovskyhaftsworthletteerdeekerarerarerALER bikitationalkeit Cove Cove Cove Coveannessannessannesshaft-original/originalINYlakeerde-scadeADE RooseinateEARsteadsworthsworthspirpirannesséesées生的bpsPropertyNamegebergeberhaftizzy spirits spiritsibsibsibsreate prost prost VP SetPropertyAceEYeloadeload Traineririm/member/memberhaftigigigiigibooøjøjηγadenaCoordinateANGLEnglengle bore bore bore bore bore boreannessanness-self-selfaler-rights-rightsimony.member.member-helpuriousness {}\n",
      "\n",
      "\n",
      "umannmassgrossgrossgrosshaftBuilt-builtermerm Morm Morm Morm Mormhaftутьpassesаваava RavsworthewsookeадiociocUIи địchpestpestbspadeadeχη Wah Wah Wahundy Wah Wahiancesperseperseibs Roosevelt Roosevelt/releaseserdeade Bau/basic­i Migpiopiooolonolonolonolonolonolonannessannessizzizzizzicoloricoloricoloricoloricoloricoloricoloricolor_visibilityąd Assertion AssertionhaftBuilt-builtPrevantryинкуávky escap.escape_escapeEscapeAVAAVAantrywearwearhaft-builtBuilt Built boisernesinsiinsiinodeSIDEsteadsworthsvilleideIDESTE StamfordcrestcrestaretharetharetharethannessávkyevaAVAanasanasanasanasanasanasanasanasontaunionunion息 ๆ ๆπλstanceevaAVAAVAAVAAVAAVAAVAAVAAVAAVAatte初CASnapnapnaplap RocketsrocketRocket Rockettail垂sworthsworthVEerdeennieennieennieennieπ Least Leastesseaceynglengleatelysianolonolonomorousy料umeapeape Pep Pep Pepannessanness-mindednessideadeeatwearwearhaft-builtbau../../../../ANCHbayWARDéesées SandraANGeloadeload FormatsFormatsibli義eperer jusPASSdraidedolonolonlian spiritsREA래auseWER Wah Wah Wah Wah Wahannessperseperseesseщо Santo Santoanchors anchors ]];невendantsspirpirpirorampirohnovatovatろADEuiltsworthggererateerate RTE numérouelleerateerate Cove Cove Cove Coveannessannessnapطةстройmanshipmanshipelonickéeviikkiäänäänäänainmentfestfestfestfest фактsworth Sav SavFeatFeatFeatFeat Moor\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: \"Can I see my baby?\" asked the happy new mother. When the baby was in her arms, she couldn't believe her eyes. The baby was born without ears.\n",
      "Time proved  that the baby's hearing was very good though he had no ears. He got on well with his classmates. But one day, he said to his mother, tears in his eyes, \"A big boy called me a freak  .\"\n",
      "The boy's father asked the family doctor. \"Could nothing be done?\"\n",
      "\"I believe I could graft   on a pair of outer ears if they could be got,\" the doctor said. They tried to find a person who was helpful for the young man.\n",
      "One day, his father said to the son, \"You're going to the hospital, son. Mother and I have someone who will donate the ears you need. But we must keep it a secret who the person is.\"\n",
      "The operation  was a great success, and a new person appeared. His cleverness and hard work made him a very successful person. He married and lived a happy life.\n",
      "He once asked his father, \"Who gave me the ears? I could do enough for him or her.\"\n",
      "\"I do not believe you could, \"said the father.\" The agreement was that you are not to know...not yet.\"\n",
      "For years they kept it a secret, but the day did come. He stood with his father over his mother's body. Slowly, the father raised the thick, brown hair. To his surprise, the son found his mother had no outer ears.\n",
      "\"Mother said she was glad she never needed to cut her hair,\" his father said in a low voice, \"and nobody ever thought mother less beautiful, did they?\"\n",
      "\n",
      "Question: The sentence\"...a new person appeared.\" means\"  _  .\"\n",
      "A. a new baby was born in the hospital\n",
      "B. a stranger came into the hospital\n",
      "C. a new doctor took care of the boy\n",
      "D. the boy began to live a new life\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " sleampie lodgeorceadeadeadeadeadeadeadeiodeiodeoberoberoerdeadeovatovatovattatBuilt-built Ernest NapoleonENCES Royale domaine domaineannessannessannessannessannessannessannessontaavana Cooke Cookeercercercercerterepteerdeadeeat doncoco CookeletteehrehrTraversalerdeéeínyøjøjbjøjDefinesćiWXWX sey服毛毛毛毛毛毛毛毛毛BUReloadeload Kushner Kushner Kushner Kushner Kushner Kushnerhurstasse päственнойitéeviatches Builds-buildsworthsworth Kushner Kushner Kushner Kushner Kushnerallah Wah Wah Wah Wahannessperseperseibsitationalovatovovessionsionesiones ReiRTCuryvaleerdeerdeovebvbv-master-master berlinfellfellfellilogueilogueohoapesh pitspitichhirpirigarigarigar synonyms synonymsemezalaradarasar生的生生着emarks Vernonsworthovatovatews级级-levellevel-levelhaftsworthøj própsworth-vous_VEestreEREhaftBuilt-builtecutsworthz�pendforthsworthsworth着山 Ruddsworth böyle下去下去下去 GünjiSpatial着ichiichi blitz Blitz Blitzbuzzbuzzbuzz惑PERT PettsworthwearwearVRVRVRVR tandem Tangoangoسه servantserviceeaseeasehaft着sworthletteengeengeehrophon着 Killsigar각각각undyundyundyundyDGernes posición PositionichikkiikkiainmentshakeshakehaftéeEY Myers Myers氏setSizeozillaozillapegávkaavaapeapeapePRESS sensation sensation Sting Stingレットmaktkyiphyiphyinhaимвynamicδρο.househousehaft-builtistratistratistratistratistrat пози역역ERC Mandela Mandela Mandela Mandelaannesshafthaftéeéeerateerateerateewardrewardovat PattyettejitjitGenre唱着 Beverف uměníاو sunset sunset mái Ferry Ferry ance ance Morm Wah wah wah wahуш.spatialletalletalernityądążsequent rapportNEXTardyardyardyardyhaftbaubauBuibuibuinspaceinspaceinspaceinspaceIDEávkyávky xpcepcoeadeIntegratedشاءстрой-build-buildauf AufAUSEaussRenderer Rendering WadeLEEauce célnem potomannessanness écLANGUAGEonedolonolonolonolonolonolonardonсильsideSide-sidevelop Vance VanceannessannessannessannessannessannessannessannessontaBUILD-builtbuildhaft-built-build thầugebergeberVRggereratejitjitмінunganungan độihideduckduckduckduckduckduckinskyinsiinsi-datIQIQpeed-speed-speed RTEODEIDEIDEDAerateewardğında сутUpsUpsUps пропelijkeerdeerdeende석 Cobraenegecessarilyerdeée hautepestpestTEávky widest shootersiodeboleategbuilder-builder生的生生的生生的生的生 Sangsworthophoneophone iotaahoiloantoantoantorthrThrøj着ichiichiheartheart*/)utowyawyaw 發universaluniversal\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: In a small village in England about 150 years ago, a mail coach (    ) was standing on the street . It didn't come to that village often  . People had to pay a lot to get a letter . The person who sent the letter didn't have to pay the postage (     )  , while the receiver had to .\n",
      "\"Here's a letter for Miss Alice Brown , \" said the mailman .\n",
      "\" I'm  Alice Brown , \" a girl of about 18 said in a low voice .\n",
      "Alice looked at the envelope  for a minute , and then handed it back to the mailman .\n",
      "\" I'm sorry I can't take it , I don't have enough money to pay it\", she said .\n",
      "A gentleman standing around were very sorry for her . Then he came up and paid the postage for her .\n",
      "When the gentleman gave the letter to her , she said with a smile , \" Thank you very much ,This letter is from Tom . I'm going to marry him . He went to London to look for work . I've waited a long time for this letter , but now I don't need it , there is nothing in it .\"\n",
      "\" Really ? How do you know that ? \" the gentleman said in surprise .\n",
      "\" He told me that he would put some signs on the envelope . Look ,sir ,this cross in the corner means that he is well and this circle means he has found work . That's good news .\"\n",
      "The gentleman was Sir Rowland Hill . He didn't forgot Alice and her letter .\n",
      "\" The postage to be paid by the receiver has to be changed ,\" he said to himself and had a good plan .\n",
      "\" The postage has to be much lower , what about a penny (    ) ? And the person who sends the letter pays the postage . He has to buy a stamp and put it on the envelope .\" he said .\n",
      "The government accepted his plan . Then the first stamp was put out in 1840 . It was called the \" Penny Black \" . It had a picture of the Queen on it .\n",
      "\n",
      "Question: The idea of using stamps was thought of by   _   .\n",
      "A. the government\n",
      "B. Sir Rowland Hill\n",
      "C. Alice Brown\n",
      "D. Tom\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " sleivyindedINEDødSEND봉� Invocationandumandumandumarkingarking Barksworthsworthsworthsworthstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonontaonta-ra-raalement banyakongandeideovatovatovatapoapoapoapoapo尾尾尾着sworthsworthsworthtingDisallowDisallow역역역ercadeadeADEADEинку Elev хвavsworthující(prolingorumorumminimumigmaADEASSESandedsideSIDEhaftsworthsworth-cross-crossovskyovskyovskyovskyhaft ManorsemblererdeadeovatovatauseperseiveerdeéeEYEY-TVrnaitraщоilaterspirpirpirerither生的born生生 sànोच-кnavMVlavvyøjDomainsponge 의해론ovatovatovov Vance VanceannessannessannessannessannessannessannessannessannessannessontaBUILD-build-buildborgborganchors borne borne bore bore bore bore boreheadededlyictory downstream upstream upstreamушка\"./bíplynglenglenglehaftsworthdüumannmammam maternitylogueantryspirspirspirpirerأةlicheerdeerdeizzlingちichiichiichSkipDest DESTtempt RTEionaleideávkyEV DeVantageantageπλorampiroram상 BuildsестиastiastiAsian hemisphereerdeerdeENTER_enterernernesesseessehaft-built-built-buildkokkokichicareicareicareicarehaft-built-built bois bois boisсоодаодаosteosteosteosteIDE NUITKA Royale RoyaleunreadableophonophoniramITHER ElementTypeościaceichtenichtenehrehrehrVRigarigaromorovovovσ.WhiteWHITEbuzzbuzzbuzzhaft-builtptyptyadeADE Annieetteiichiichiichiddyýchfdsøjumptumpt Weinsteinovichovichhir HirHIRHIRHIRhir.TabIndexvipvip-PainmentądRATIONeloadeloadewn-rights-rights Coat Coat.wav SOUNDSoundsMMappointióiociocoprpirpir Inspirpirspir生的生生的相相 bore서 концепoprojectovatovat生生生的生的生的 doncocootion ElementTyperowseawe岡丈丈-speed-speed-speed-stop-stopomor岗assembleassemble Bundy Bundy Bundy Bundy Bundy BundyannesséeséesDISPLAYovanéevaeniaoniaideávkybuiltin-built-built生的生生���� Origredoigiigiigi720 Upgradeupgradepeed-speedtraintrakistratistratistratди\"])AZYply�ää Miy Miyannessmj Mahar MaharVR려dexろ래hanaupaupaundykaar MaharanskendoMAND-built-builtbau Builds-built-built hoodsworth chezpestpest Pep Pep PepMomentMoment Mandela Mandela Mandela Mandelaanness kdyevaава着esinovatovatpv Pence Pence Pence PenceannesswearwearVR danske343ądろろ\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: In America, there is a traditional story called a \"tall tale\". A tall tale is a story about a person who is larger than life. The descriptions in the story are exaggerated  , which makes the story funny. People who had lived in undeveloped areas in America first told tall tales. After a hard day's work, they would get together to tell each other funny stories. One character from these stories was Paul Bunyan, a hero who cut down trees in North America. Tradition says he cleared forests from the northeastern United States to the Pacific Ocean.\n",
      "It is said that Paul Bunyan was born in the northeastern American state of Maine. His mother and father were shocked when they first saw the boy. When the boy was only a few weeks old, he weighed more than forty-five kilograms. As a child, Paul was always hungry. His parents needed ten cows to supply  milk for his meals. Before long, he ate fifty eggs and ten containers of potatoes every day. Young Paul grew so big that his parents did not know what to do with him. Once, Paul rolled over  so much in his sleep that he caused an earthquake. This angered people in the town where his parents lived. So the government told his mother and father they would have to move him somewhere else. Paul's parents had to take him into the woods where he grew up.\n",
      "\n",
      "Question: Paul Bunyan was   _  .\n",
      "A. a story teller\n",
      "B. a war hero\n",
      "C. a tree cutter\n",
      "D. a famous writer\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " sleLETTE Beauisseurazeadeadeadeadeadeadeadeadeiodeiodeщо Findsabeejeejeeeednorenorehaft 포alesce*dxinkiinkiehrehrehriminødød Boo Boooho Boo Boo bunny Bunny Bunnymobile includ sublistingoingoingoingoingoiodeiodeonte kho khoINES VýouragePRntonTourTouribliillationitational生的生生 Scopedarked Sawsworthsworthanceδροíoapoantoantoanto Territoriesibusibus lamb行動pirpirALERbetburonalointovatovat生的生生MMdolldollottesperseσ labeledLEGRTCRTCordeordehaftsworthsworthsworthWhatsAppWhatsApp justepestстра러cretiononingングAnimationFrame/Foundation/Foundationüstü伏iociociocC bearbearVRVRVRVRVR Psychologicalenegernityąd Integrated Blend Blendbspbspadeade Whale Whaleinspaceinspaceinspaceinspaceannessannessannessannessannessannessannessannessannessannessannessontaavaavaicareicareicareicareichael Casc Cascorampirpirηγηγ NachrichtinesisantagenglenglengleRuntime.getRuntimejitjitimonyvěevaavaAVAAVAAVAAVAAVAontaupaAVAanasanasanas석叔enskéلىщоpasses closちichiichihirHIRHIRanter산婆婆婆VRggererhaftBuilt-built生的生婆婆婆 máiannotationwoordsworthsworth hersloseptiveutivepvardeadeletteztepteovat367danceGSTmember.memberhaftBuilt-builterkert良�Pyarataratacho tantoloseolonolonformanceAGONeloadeloadmav scho-fileiodeenqueueyneSTESTEessepee Connectivitydaleadeواءądχής doncoco ngũungungungnge nyejtepestvelt Mandela Mandela Mandela MandelaideIDEIDElif lif Lif生的onsenseionalionalIBCIBC boreůvodu doncoco Universaluniversalitarian/social/socialbuzzBuzzbuzzbuzz Laud Laud Laud LaudannessannessannesshaftBuilt-built Bauhaus-style-stylehaft-builtigteizzieizzieicareicare生的getteting Phong上が Plum Plum проп AssertionAZYAZY-mediaproxøj338ąd-built-built Baubaubuilders doncletteitteichichich beidenfellfellJon Jonas Jonasicipicipercηγeloadeload Roose Rooseesseesseesseesse生的生生的生的生生的 donc矢 ๆ ๆ ๆπλapsitationalisiertiertrendeevaantage���-removeolonolonEbávkyаваeva EverywhereophoneophoneophoneolonolonookewearwearwearhaftBuilt-built-builtbecBecomeBecomeMirrormirrorろ着 Miy MiyINavigationistrationistrationandon Everydaydaycasting водойepereromor_RELenschaftsveltąd-built-builderbudPROCローeyJ domest domestesseessehushus Mans Mans Mansannessannesshaft차 ๆ ๆجمجمجمجم成了AGONатоontaontaodaide closestतम Sons Sonsannesshaft-built doncjon dissolve dissolveDIGDIGηγ\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Is it important to have breakfast every day? A short time ago, a test was given in the United States.People of different ages, from 12 to 83, were asked to have a test.During the test, these people were given all kinds of breakfast, and sometimes they got no breakfast at all.Scientists wanted to see how well their bodies worked after eating different kinds of breakfast.\n",
      "The results show that if a person eats a right breakfast, he or she will work better than if he or she has no breakfast.If a student has fruit, eggs, bread and milk before going to school, he or she will learn more quickly and listen more carefully in class.Some people think it will help you lose weight if you have no breakfast.But the result is opposite to what they think.This is because people become so hungry at noon that they eat too much for lunch.They will gain weight   instead of losing it.\n",
      "\n",
      "Question: According to the passage, what will happen to you if you don't have any breakfast?\n",
      "A. To be healthier.\n",
      "B. To work better.\n",
      "C. To gain weight.\n",
      "D. To fail the test.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " fraseionesionesjoningoigeigeIDEADEADEide WadeFORCEækkefelléeséeéeMonster světa acordoantoantoavaavaavaAVAAVAAVAAVAAVAonta Lodgeigarigarhaft服eeséesées生的生 Livingstonburgh Telegraphoesoesicareicareicare生的生生的生生coverseloadeload生的生生PRESSPress-static donciocicumicumicum ADV_Speed-SpeedernermicareavaAVAAVAAVAAVAAVAAVAAVAparalleéeséesées máipassesavaavaava怕着iocidataateonedicarebachsworthsworth masturbation masturb masturb masturbhaft-l latina latina latinaannessannessannessannessannessannessannessannessontaubreubreitationalitationalategηγηγ republicenateerateerateerate生的 subtree subtreeercERCERCercerc bore bore bore bore bore boreolet尽ichiichiichi尿 bureaucr bureaucr bureaucr bureaucr Monumenteumantoantoاگ AssertionbusterbustersVRT_FEetypeetypeetypehaftBuilt-builtDIGarellaoolaoolaoola Manor Manorannessannesshaft着 AssertionAZYahuahuomorip Lage Lageензduckduckmav Consortsherstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonphase/runtime/runtimeALER.coordinateerdeerdeerpadeerdeicareicareunate Turtlesworthizzyjayjay Mormocre CreCREMomentMomenthaftêteigeigeippleeratejitjit}());\n",
      "chlusstrappravолжtower-corner-cornerhafthaftолет府aderaosteosteosteosteosteURITYozillaozillaozilla borelose latina latinaédovatovatovatmavoyburguhl München München Munichborgehr着 ๆ ๆ ๆWhatsAppWhatsAppapoapoapoapoapoapoapoapoapoapoapoеса Casc Cascesp Cascmercistratistratistratapoolonolon Laudsworth-Smithhir Hir HirHIRHIRlal Vall Vall석역역息息formanceościBuilt-builtecutipipipіп đảo đảo đảo borehaftBuilt Builtlets AllocateoniaasmaasmaapeapeInsidewardswardswardswardwardwardhaftêteonte Manor ManoricipicipicipicipicipiinsiinsiINTRINTRehrwearwearwear生的gett Peyton DalšípestpestNAMEovanáatatتوzensINESlettesantryantryantryGetInstanceаниюANTI AUX AUXtejuyojoininglideADEADEIZEINESізinenNSElette sahiptirθηκεitationaliteitąd(/^AZY Islanders IslandershirhirhirhirhirhirAdvancedEDGEEDGEVRasjebusGVGenreGenreGenreGenreizzardhaftauseperseESCOCO Vancehanahanaomor Perryání InvocationpioADE shadingendashettoetroastoangoango Bitematepestinanticericer生的gettittiجهбоberoberoomoromor Mori MoripedopedoendoadeávkyAVAAVAAVAibo\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Many pet owners see their pets as family members. However,when they have to go away on business or for some other reasons,and cannot take their pets along,they feel guilty about it and wish they could do something for their deeply loved pets. The Pet Hotel is set up especially for this reason.\n",
      "What do we offer?\n",
      "The Pet Hotel offers pets large rooms and the latest equipment .Like other hotel rooms,we offer color TVs,suitable beds,sofas and other pieces of furniture for pets.\n",
      "We prepare great food for the little guests,walk them at least twice a day,and provide them with all kinds of amusements . In addition,we brush and clean pets. To make pets feel at home,we play the sort of music which is often played at their homes and turn the TV to the pets' favorite channels. Pets will surely feel comfortable in our hotel!\n",
      "We also have video cameras in each room so that owners can check online twenty-four hours a day to make sure that the pets are having a good time at the hotel. We also have phones so that pet owners can call their pets and talk to them every day.\n",
      "How much does It cost?\n",
      "The prices change according to the size of the rooms. A regular room with standard service costs 1,500 dollars.\n",
      "\n",
      "Question: In the Pet Hotel,pets can  _  .\n",
      "A. take photos for their owners\n",
      "B. enjoy their favorite TV programs\n",
      "C. brush and clean themselves\n",
      "D. book rooms according to their size\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "avanaidaazeAZEUCEadeADEADEADEADEADEadeadeimdeadeadeadeadeadeadeade戒津津Mediaiplina delahettohettoADEoogøj-force force FORCE FORCE boisinusinsiINESsteadstead­iquantity Quantityhaftsworthsworth Kushner Kushner Kushner Kushner Kushner.loaderAGEReloadируFLICTovatatatatat太 bäестиovatovatovskyovskyhaft قائمة立 Builtsworthbearbear Economics Insecta InsectaAnimeTV局etroantoantoantoanto Weinsteinreich Eisen Eisen EisenantererarerarerVRVRVRVRhaft-builtIntegrated Blend BlendEYEYIESnineovatovat Paviliontournament tournamentsomyselfself masturbation masturb masturb masturb masturb控制 Buildsестиoptimizeatesitheritherinhainhainhaination bä� \"./erlandspirpirpirhaftøjøj Assertion Assertionhaftsworth-cross-crossERC國際_border.lock.lockhaftéeéeEYää生的 Uzsworthovat伏uffyuffy masturbation masturbation masturbation Günkö Kö KöxD柳三卒itationaliteitijkeijkeyneEYookeávkyávkaурарати زاده زاده伏haar GarageantoantoonteendAttachment Attachment Attachmentilogueichteewardspirspir-fired.Bundle.Bundleundyнгungongaongaipoitationaloyávkyausehaftsworthøj/\") Gib Gib Gib хвpassesantryspirspirTIаныkeepeeade Royale Royale Royaleloyiturvertical Positionspiopio Christophhofrendetingądapoantoanioanioцепsideade Royale Royale momentos Moments FotoserviceSX SX socialismophoneophoneolonolonolonolonolonolonannessannessannessannessannessannessannessannessannessannessonta 立 hlavníitzerettelrenderendehaftávkyávkyhaftagmaγγávávSnakehawkssworthsworth inwardkehorneEnglandatingATINGITCHITCHêteêteEYéeséesEY326ądANDINGwishwishaeaaea Mormassoc assort assorthaftahoIMP Pence Pence Pence boreholeookeookeERClak Island Island importantlypokepokehai.hyNKangkanannessannessardyadeADEadesteenéeaaroonoonbecuebecue cháyестиitationalisibleằằRelationshipmatesatebuilt-built CoatcoatcoatanguagAGжиunion unionsomyselfself RoosepioBUS/bus/busásttemptEY便fdsøj HOH جمهورorateerdeerdeadeADEADEéeséeippleippleookeipseicareicareicareicareω BUILD-build-buildibusibusandanandanandanhalstonismus jetzt今ioc래 ๆ ๆTraversalająsworthbbbppyppyMatch-match-matchmínnumNUMercERCdorfadeéeávkyávkaauseAZEascus-built-builtibu-builtPRESSPressichف InternationalROC ralliedardyasuryasuryhaft Manor Manor Manor Manor Manorannessьюьюformanceerdeávka whistle whistle whistlehalt-composeióiociocachoangoyawyaw Завsworthänderänderhaft-built-builtbuildersbuilders/km/km пропää vuuttoǐigarigarapoantoanioanio\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: What does it feel like to break a bone  ? It's different for everyone, but the pain is often sharp  . If the break is small, however, the person may not feel much pain at all. If you think that you or someone else has broken a bone, the most important things to do are to stay calm, make the hurt person comfortable, and call the doctor. Do not move the injured body part since movement could make it worse.\n",
      "To treat the break, the doctor will need to take an X-ray. This gives the doctor the information he or she needs to set   the bone: to put it back to its normal place. If the bone is large or it is broken in more than one place, the doctor may need to use metal pins   to set it. After the bone has been set, the next step is usually putting on a cast, the special, hard thing that will keep the bone in place for a month or two.\n",
      "Your bones are excellent at healing themselves. Broken bones will produce many new cells   and tiny blood vessels  . These cover both ends of the broken part, and close up the break until the bone is as whole and strong as before.\n",
      "\n",
      "Question: Which of the following is the best title for the passage?\n",
      "A. How to Know if a Bone is Broken\n",
      "B. How Broken Bones Heal Themselves\n",
      "C. Common Causes   of Broken Bones\n",
      "D. What You Should Know about Broken Bones\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " Choice khakhakhMirrormirrorhafthaftovskyovskyovskyovskyhafthaftichtenichtenadopt AdoptionSoustonissan Кар hobberoberoberoberoisko propioSIDEンズocksocks着ichiichi mái Resorts Resortsunate valideateametgetViewџбоFORCEerdeerdeerdeadeADEADEhaftsworthsworthbspAVAAVA wah Wah Wah Wahbuzzbuzzbuzz Neville Lowe dut wah wahhettoitationalodalCARDadeonedonedyneNSE 任antenhelperhelperysizeysizeysizehaftBuilt-built生的生生的下去evaAVAAVAAVAAVAAVAAVAatteFORCE FORCETRAINshaftsworthsworthibusibusaurusaurusaurushafthaftBuilt-builtERMsteadsteadsworthsteadBuiltggererhaft-builtirampirpir生的生 uden宗宗노INESmaidsmaidsaeacheséeéeloe래래Localizationateséeée生的ventedolonovskyovskyovskyovsky Manor Manor Manor Manorannessannessannessannessannessannessannessannessannessannessannessannessannessontahuahu Wah Wah WatrucRC래 ๆ ๆπλkeaidesiociocliceسهeviachiachiEYětjitjitDIGmaticmaticaticycsic TerritoriesatesomedardeADEávkyávky-к Pikepioantoantoantoθεrowsingozillaozillaolonolonomorolonolonolonolonolonannessannesshaftbauause FORCE wah Wah wah Wah Wahibus wah wahhfennieennieehrehrehrер射射 ForcedIVEDoodlesoodleoodleoodleoodlehaft-built-builder-builderhaftée Madame Majestyates Canter Canterehrdra Wah Wah UIWindowbudgyptypty.forwardشاء trưởng responsableное Builds Buildshaft Built-builtibaMAerahawahsworthauseate 立ichiichiovatovatovovhafthaft-built supporting/supportstandingstandinghaft-builtbuilders-builtercercercercercercercercPsychPsiPsiardyávkyav-stageULERigarigaromorphoneolonolonomorhausachsachsesseækkeávkyávkyhaftcoatcoat级级arsityinsiinsi Sey Seyangersiones closest.closestonednoreorateovatovatovovelen Wah Wah Wah Wah Wah Wah вагloadsOfeloadigraphigraphianernaerna MormmarterveintrINTRINTRlal FrontierREAAVAAVA太curybumoxoxox проп丸丸 Markusлав着 Fredovatovatcht princçeEYprisespirpireriigiicareicareicare生的 BikomikfilmTVitra соот SurSURhaftMakesDDSDDSDDS.sysRIXัคsarovatovovAttachment Attachment Attachment Attachment Attachment Attachment Attachment Attachment nhiên прох проходаoba래etal料 nepDIGcímAZYwyckyckykyercercercercσsnakefellfellfellibushevovov Cove Cove Cove Cove Covehurst�� Fet成了 kho khoundyardsrowseabwe着haftBuilt-built रहन singsendascoperowseyneyneyneyneинеupeolonávkyEV\n",
      "Extracted prediction: C, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Mrs. Black has four sons. Dick is six years old. David is five. Dean and Denis  are four. The boys don't go to school. They play soccer every day. So their clothes are always very dirty . Mrs. Black has to wash  clothes for them.\n",
      "Today is Sunday. Mrs. Black is washing clothes for her sons. Dean comes in and asks her, \"Mom, when is your birthday?\"\n",
      "\"May 15th,\" says Mrs. Black, \"and it's in next month.\"\n",
      "\"Will we have a birthday party, Mom?\"\n",
      "\"Yes,\" she says. \"We will have a big and great party at home.\"\n",
      "\"What _ do you want for your birthday?\" asks the little boy.\n",
      "\"Four clean  boys.\"\n",
      "\"Oh, that's great! Then I will have another  four brothers! And we can play soccer together,\" the boy says happily.\n",
      "\n",
      "Question: Who is the oldest  of the four boys?\n",
      "A. Dick.\n",
      "B. David.\n",
      "C. Dean.\n",
      "D. Denis.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " sleackleacyacyadeadeadeadeadeadeadeade하ého FileNotFoundException dneblingbling champagne famillearkingadeadeéesées Bever Bever BevererPLEinhasideSIDEsteadsworthsworth KushnernierEARsteadéeездаσειςancesCycleCycleercercercercPLEngeerateeratejitjitinspacepravpravpravpravpravpravpravpravpravpravpravpravonta groupe groupeцеп associativeocial/social/socialmavTEXηγηγηγηγ interrog interrog生的hir HirHIRhirhirhirhirhirIntermediateičeizesindedsideSIDEhaftsworthhaftديد Sons下去ovskyadeặnpliereréeERCід Bend BendензsaririribiribirInsidewardswardswardswardshaftBuilt-built-builderbuilderWERVR-componentèleerateerateerate&actionModes-mouth-mouthAttachmentAttachmentAttachment Attach Attachmentitarian trúistanihiririgarigarigarigarigareloadeloadatronantryeloadeloadercercercERCàngàngbuilt-buildercRVigarigarjitjitfatfatfat Cannonsworthveltveltchy teżumannstonston Sanders Sanders Sandershvackleacieacie Rickyjayjayhaft-built-builtittedødhanahana Mormsworthanzanzanz tandemAGONistratistratistratistratston Attachment AttachmentAttachment-sided sided-sided sidedannessannesshaft-builtältält stessostanceborgubberubber生的 jeszczepestpestperedperedpered生的生pokeOWNER/member/memberhaft Manor Manorhaftéejayjayetalomas무무次次次aneousgettiibAttachment AttachmentAttachment Attachment Attachmenthurst차hanahanahvumptumptainmentppyppy Grüasonry质ижávkyevaAVAAVAavaainmentäänäänEYτευSnakeSelectablePLEletteCastCast.cast Ryanelijksideptykých� Yunxacxac�-followfollower/member/memberVRánaavaAVAAVAAVAlavshedshedadeADEAVEFEadeicareicareicareicare生的wonsworth dissolve dissolve dissolve dissolveanness Nappper Parkerburghinsiinsihaft AttachmentAttachmentAttachment Anhsworth務 SetsmateicipationicipationagalBlo BloBloMomentmomentMomentMoment Moment/momentPRODUCTPRODUCThaftBuilt-built-self-self-selfhaftBuilt-builtbuildersbuildershaft-builtggererоприPRIPRIiávkyevasehensehen着sworthsworth Jonathanشاءioc FORCE ForceEXECedoedoingoingoingoіп Fallsfellsworthéeecome AchievementovatapeppyppyBURána Wah Wah Wah Wahpak Wah wah Wah wah wah너 Wah Wahalet PharmaceuticalsPRODUCTambleambleAMBAMBAMB生的wonittappoppoClose/closeBOR써UNGYG Sizedすぎsworthsworthirampirernteupeupe.display/showapeshauseausehaftbuilt-built boisinded Weinsteinensonovatovatovovoxoxox пропaits lionsenegnglenglehaftBuilt-built etterpassedpravovsky柳柳 PeoplesperseadeADEandonovatovat-vousipoipoTURN Kre BRE porte\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: \"I don't want to move!\" Kevin said to his father,\" I like living here in New York City. And I like to play in the streets. My friends are here. I want to stay!\" \"We have to move, Kevin.\" Mr. Black said, \"I have a new job on the island*. Why don't you go with us?\"\n",
      "\"No,\" Kevin answered.\n",
      "After a few weeks, the Black family left the city by plane. They flew over water. In the end they saw the land*. \"That is Hawaii. It is beautiful!\" Mr. Black said.\n",
      "\"I don't care* what it is like,\" said Kevin, \"I wish I could go back to New York City now!\"\n",
      "They lived in their new home near the sea. It rained a little every day. When the sun came out again, they could see a rainbow* every day. People in the neighborhood came to visit them. The visitors brought fruit from their farms.\n",
      "Weeks went by*.One day Kevin wrote to Bob and in the letter he said, \"I still miss my old friends. But I think these are our happy islands. Please come to see me. I know you will like Hawaii, too.\"\n",
      "\n",
      "Question: The Blacks went to Hawaii by  _  .\n",
      "A. plane\n",
      "B. bus\n",
      "C. train\n",
      "D. ship\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "badge-user-user HowebishmommammammammammommamstonestoneonesINES Độ DaooningsworthéeaduANA联系立igigeADEADEeatEatEathaftpestpest Epidemi Epidemi EpidemiannessannessannessannessannessannessannessontaideADE waiveesaANAANA Mormkah Wah Wah Morm Morm Morm WritersанныхphonphonysizeysizeysizeannessannessipsipsorisdirATERerateerateynebuilt-built/simple/simple-sided-sided-sidedannessanness初 ๆ ๆnemčetDomains služ holland hollandising doncocoletal-rights-rights painsťADE-built-built-builtäänään Wah Wah�assocassoc Soci Soci/mediaщіigaradaradarozillabate upstream upstream Mandela Mandela Mandela MandelaannessridehraADEacklebondAttachmentAttachmentAttachment Attachment AttachmentAttachmentEDGEEDGEomorachiachiEYEYقاء Patton生iocičičrucovatovat着ichiichi blitz blitzovskyowitzowitzinzonzonzinzincicumicumummammamhattmagηγ使indedINEDødatchesateerdeerdeosteosteosteosteoste Manor Manorloseloselestółmovesitationalitationalizedizedвет DeVANC Casc CascReduconerasherascaladeade laatť HOH spirits Spiritsibovatovatovat着 Japan/world mieuxincerDICDIC keyed-b differential Differential RTEerdeendduck AttachmentAttachment AttachmentAttachment Attachment Attachment AttachmentpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravargarAVAAVAAVAemm filmm filmmTRAINeloadeload Kushner Kushner Kushner Kushner protagonolonolonomorolonolonolonolonolonolonolonontaontaainmentąd Empresaapoapoapoapoapoapoapoapoapoapoapoontacontricontri Francescoovatchtéhoorgesorgeshaftsworthsworthhaft-built-built morphologyfonoohana Wah Wah Wh-wh Wah WahBV Bever Bever Beverสง expectationantoantoansiansi RTEletteaviaatchesаждsworthsworthibliGRAMGRAMHAM phòngorerwearwearhaft Weinsteinowitzowitz_rgb866olonolonoledoledomorAttachmentizzyozillaicodeicodeicodeideIDEIDE đàiнопiapookOLONeloadeloadipedipedesse eCommerceEDGEgardsworthsvilleantroantoantoenteESCOcéástCastCastAddonystoneystoneosteosteosteosteosteteeßeAffineTransformibusibusibusibusibusiodeávkyitationalerateerateerateheartheart redheadnessolonolonertypePLE Pence Pence anceanness éc賞賞.pem Everywheregencygencygency-gunistratistratistrat립itationalistrateicareicareicare生的 ]];rij裝moveshaftBAerdeBuilt-built生的生生еньantryspirpirasmusasmus Pence Pence Bundy Bundy Bundy BundyDGUpsUpsUps-upsuriousnessisce 관계anto Patty Patty着ichiichiigliaizzizzizzinationpirpirerBURHTTPHeaderystonebuilt-built生的 outros生的 Relationshipsоныnglenglenglehaftahoooseooseesse\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Three men traveling on a train began a conversition about the world's greatest wonders.\n",
      "\" In my opinion,\" the first man said, \" the Egyptian pyramids are the world's greatest wonder. Although they were built thousands of years ago, they are still standing. And remember: the people who built them had only simple tools. They didn't have the kind of machinery that builders and engineers have today.\n",
      "\" I agree that the Egyptian pyramids are wonderful,\" the second man said, \" But I don't think they're the greatest wonder. I believe computers are more wonderful than the pyramids. They have taken people to the moon and brought them back safely. They carry out mathematical calculations in seconds that would take a person a hundred years to do.\"\n",
      "He turned to the third man and asked, \" What do you think is the greatest wonder in the world?\"\n",
      "The third man thought for a long time, then he said, \" Well, I agree that the pyramids are wonderful, and I agree that computers are wonderful, too. However, in my opinion, the most wonderful thing in the world is the thermos .\"\n",
      "And he took a thermos out of his bag and held it up.\n",
      "The other two men were very surprised. \" A thermos?\" they exclaimed , \" But that's a simple thing.\"\n",
      "\" Oh, no, it's not,\" the third man said, \" in the winter you put in a hot drink and it stays hot, in the summer you put in a cold drink and it stays cold. How does the thermos know whether it is winter or summer?\"\n",
      "\n",
      "Question: The third man was not very clever because   _  .\n",
      "A. he could not think of anything to say\n",
      "B. he did not understand how a thermos works\n",
      "C. he did not think the pyramids were wonderful\n",
      "D. he did not know anything about computers\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " sleackle-match-match刚才igarigarigariminøj Assertion AssertionhaftsworthsworthbspadeadeADEADEoleADEideADEo Booboo Boo BooINESINESINESundyckyckyinspaceinspaceinspaceinspaceinetcot Cove Cove Cove Bundyøjøjuvreuvrehaftbah Wah wah Wah wahушкаqualitylevellevel-level-levelaaloolaoolaoola MaharHIRHIRhiritherbranch次次-master-masterTRAIN TracksadlaingoANGOjàstva Santo Santo Santo бок Kommentируигdexelderookeolateerdeerde bande bandevelopfoundationfoundationinspaceBUILD-build-vs-vs-vsipseoduleodulepeedside-sidevelopengaIGOIGOainmentIQ ярpassesnaveantryności각각ๆmoves Moves-through thru thru impeccIMATEerdeerdeerdeerdeperedeltáváv Streaming.pack봉avaavaava whereverwolf Epic EpicFeatADVantageantageradeerateerateewardrewardhaft-built각passesятияatatatat ration ration生的ontaNativeanyaanasINEShaftBuilt-built-builderVRVRVRVRVRhaft-built-built生的yerHIRggerer Cove Cove Cove Cove boreosteosteosteosteemmeasjeFORCE FORCEERCercercercercercerc Presidentshipskyinskyckykokkokkokilogueilogueantry무velocityantageavaavaichtenforce FORCEeerée.choice choiceibsóbást ngũLINGzdyplyitationalśćdiaibipADEafiaapoategाफilateratererpestávkaávka-trackeloadeload MormoproADE Built-build-vs態standolonolonolonolonannessannessannessannessannessannessannessannessannessannessontaonta staloosteovatovat MevjteFORCEdradraarWERlingennahmenahmeesseppoppoipoipoinspaceonium高いlosepokeookeOLEerateookeERCsvěstand Budd Buddessesmerc Merc Merc Mercmerc merc merc mercmercmercцепπpirpirP Daniels bulld bulld \"*.AZYppyppyppyppyangueum غذchangermove昌ynchronousutherlandutherlandhaftBuilt-built SteinsteinhirHIRbatimshiadeADElettelettelet Cove Cove Cove Coveheartheart-heartосковATEppyppoppoimity zámастBuilt-builtibs级DENetingally поэтомуotherskyographiesyneennieennieinionervice serviceshaft-builtättéerenderende inseолькуب bäшейстройodefletteletteasjeặn Casc Cascаннямotify席side-sideoho Wah Wah Wah Wah WahVVlluminate SPDX-disc-discDischafthaft-built-built生的getti σχέ成IGHIGHpv Pence Pence Bundy Bundy Bundy Bundy BundyaletSafetyبيةSideSideSidehaft-built-self-self �стесте Cove Coveleighehr HirHIRHIRhirahihirhirhirMoment MomentMomentmomentMoment Mond MondespêteerdeerdeypedotherotherhaftdraavaAVAAVAainmentskillιαpassesogueCO máximo máximoannessannesshaftéeée Ricky pant\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Several years ago,a television reporter was talking to three of the most important people in America. One was a very rich banker,another owned one of the largest companies in the world,and the third owned many buildings in the center of New York.\n",
      "The reporter was talking to them about being important. \"How do we know if someone is really important?\" the reporter asked the banker.\n",
      "The banker thought for a few moments and then said, \"I think anybody who is invited to the White House to meet the President of the United States is really important. \"\n",
      "The reporter then turned to the owner of the very large company. \"Do you agree with that?\" she asked.\n",
      "The man shook his head, \"No. I think the President invites a lot of people to the White House. You'd only be important if while you were visiting the President, there was a telephone call from the president of another country,and the President of the US said he was too busy to answer it. \"\n",
      "The reporter turned to the third man. \"Do you think so?\"\n",
      "\"No, I don't,\" he said. \"I don't think that makes the visitor important. That makes the President important. \"\n",
      "\"Then what would make the visitor important?\" the reporter and the other two men asked.\n",
      "\"Oh, I think if the visitor to the White House was talking to the President and the phone rang, and the President picked up the receiver, listened and then said, 'It's for you. ' \"\n",
      "\n",
      "Question: The following is true EXCEPT  _  .\n",
      "A. The banker thought any visitor to the White House was really important.\n",
      "B. The owner of the very large company thought the visitor would be important if while he was visiting the President, the President would not answer any telephone call\n",
      "C. The owner of many buildings thoughtthe visitor was really important if he was talking to the President and the President received a telephone call for the visitor.\n",
      "D. the reporter knew the way to find out who was the most important.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " sleackleIVAindedindedhaftarta RisingggererateeratehaftbahanaANAANAhaft-forceforce FORCEbuzzbuzzbuzzBuzzBuzzBuzzطفahnéeADEADEADEhaft chez chezhaftintersect역ääinspaceinspaceinspaceinspaceideidehaftbau-apiidataiatiatiatjitjitlendijong Jongernesaussauss-psPX柳ynchronousynchronoushaft最高crestcrestقاءigarigarigarigarolineolineodoreodoreodoreodoreannessannessannessannessannessannessannessannessanness런eloadeloadlalcheidsworthsworthercadeADE Royale Royale Royale Whip combosingoingoingoсо Cobra-anchor-anchor-anchorhaftBuilt-built thầuilateratererERC卒sworthletteerdeadeippleerateerateeratehaft ACTION-action Coke Coke Coke bore bore bore bore boreannessannesshaftsp出来asuSoloSoloReading aloudscanably-builtBUILD-buildernTeam/team/team vnitřارية ๆ ๆ Simpsons nó matesannessannessannessannessannessannessannessannessannessontaonta��IGNOREigarAGONAGONomorặn339cqSenseAZEAZEazeboo týdblingsannessannessannesshaft-built-builtleşikprisePLEsteadsteadside-side-side sided sided sided sidedperedadeovatovatovat婆婆 proprietoratesboroodium nodsantryarnalaala delegationmaticmatic haldeerdeontaontaerta婆婆amoantoantoonyonyonyonyonyonyonyonyonyonta Manor ManorannessRaisedALERodiumblingsanskeannieannieercERCERCERCERCERCercerc孔одаobo Soloilogue록antererynetynetynetyneyneinečečeCOää StephENCE Greenwood Greenwood林 Builds Buildshaft-built конструкции BuildsipsерыideoogsworthwearwearVRVRVRVR Mahar Mahar Mahar Maharannesshaft-role ràng Rack Rackцеп归SEMBmbandingングundyundyundyundy Haroldsworthardargaradar生的borgborgundyogygyичногоundywearwearhaft-builtijdsworthlettelette 生chez-built-builtBuilt-builtіп UpsUpsUps проп проп проп пропสง ๆ ๆ ๆstvaeva latina latina latinaanness écEDGEEDGEomor ощущsworthzIFFaugaugFORCE Cove Cove Cove Coveannessénéoodlesoodlesoodleoodleingoappearance Plumetteerdeolestitone kho kho boreerdeorate Cove Cove Covehurst gigsigmjitjitjit tandemBuilt-built-builtchy秋津ENABLEedImageedImagepicichichichich tropePX位於iociocapoantoanto Angelo AngeloSenseabox着iociocachoahuahuameADE-built-buildPrevailer/member/memberosteosteosteosteinodeolandoolaoolaoolaoola Manor Manor Manor ManorannessméávkyIDESTEesteSTE Cove Країна柄kiitationalonicalonicalonicalonicalhal着 Senselessly-minded mindedalerALER/memberligeigeitherبةadenaoniaoniaoyaideADE Bend Bend incest nhau deportationatesBuilt\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: The Biggest and the Gentle\n",
      "The elephant is the biggest four-legged animal in the world.It is also the gentlest,but not always!\n",
      "Elephants are like us in some ways.They live for a long time--fifty or sixty years.They can remember things very well.They never forget great sadness or great happiness.When female elephant dies,her daughters and her granddaughters are sad for many months.They stay with the dead body.Then they carry a bit of it away with them.They never forget a dear friend.\n",
      "Elephants are like us,but they are also different.They live in families of females.There will be a few young males a few\"baby boys\".But the females will soon send them away.And elephant family keeps only its daughters,mothers and grandmothers.And its great-grandmothers.\n",
      "The females stay together for fifty,sixty...a hundred years.The older animals look after the younger ones.The mothers teach their daughters and set a good example.\n",
      "And what happens to male elephants?Well,the young males stay with their family.Then the females just send them away.A bull elephant does not often have a friend.He lives apart,away from the family,and often away from other bulls.\n",
      "Sometimes the females call a bull.He can visit them then,and stay for some time.But soon his\"wives\"and sisters send him away again.The females have a very happy family life.What do the bulls think about it?We don't know.\n",
      "\n",
      "Question: Elephants are usually  _  towards other animals.\n",
      "A. fierce\n",
      "B. friendly\n",
      "C. rude\n",
      "D. grateful\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "dish Dish Ritchьotive Geoff Geoffkip kok Lage Lageosteapoapoapoapo-remove Removes不了igansigansantisantisantisantisannessannessannessannessannessannessannessannessannessonta quang cock cockercercercercercercercerchariHIR Hir HirHIR ersTaylorantagenglenglehaftøjøj角antryANGLEhaftsworthsworthsworthine ting ๆ ๆ ๆ Snapshot Snapshot Insertships Happsworthom着iocberoberoantrywearwearhaft-built-builtPrev此-raiareNSEanking siderborgasseassehaft právoLicensedlicense LeerAGINGbuzzbuzzbuzzbuzzideitheratatatatapoávkaavaavaigarigarigarigarigarigarhaftBuilt-built helplessnessimitynglenglekidskidskids fuckingratioantoantoantocomingongaongaipoichteichtepteotleTAILéeséesboo následаваavaavaavaAVAAVAAVAAVAAVA-degreeerateerateeratejitjitMomentmomentMomentMoment MomentsplashATEReloadeloadpeednanonano bore bore bore bore bore bore bore boreamblepeluratiletatebateDIGDIGernesapisdegreesumsmysmys SyLeast Leastníhoitationalitational-safe-cut-cutInto�cit cachACHávkykiikkiPIuttoAttachment AttachmentAttachment ребھhirhirbirbir生的 ๆ ๆpirpirichichichich각각sworthsworthhaft-built-builtibuibu проп丸 ๆ ๆovatovatovskyovskyovskyovskyborgborg根 Greenwoodsworth doncoco料variablyozillaoolaoolaoolaoolaoolaoolaoolaoolaoolaoolaontaoolaHorizontalAlignmentistratistratistratachoatchesatches生的bps ощущsworthjiFORCE force FORCEhafthaft-trackanton IncontriangoangoangohaftBuilt-builtibuibuibuibu Surv Surv Surv SurvhaftBuiltBuilt нами Ming MinghirHIRggereratejitjit.Help.Help_dispycleadeOLE सदस members.memberingoangoavanaava�� LaudmateEARerlanderlandPRESS Press pissjayjay-mediaambleamblehaftخ Moy Moy Meyer Meyer/M поздsworth Parkeransenäänään проп PavelovatovaovaapoAVAAVAAVAAVA Minimumbumolonolonomor핀crestovatovaterculeratejitjitilizsarsaribseltseltsなる론론theonohophonolonolonistentiveeaseeaseeaseheartheartngth력itationalodalodesensibleeratejitjit LASTánaínaітиoutputolonolonolonannessannessannessannessannessannessannessannessannessannessannessannessannessannessannessannessannessontaESCOioc-ipičiatiatiatiat Cove CoveTRAINشاءesor宮 cykев Sovietافadenaidiaadeadeantry滿passesanzonzangoangooho Wah Wah Wah пропortedovatovovovσsnakehawkshawksagon droitpesticularallybí� ๆ ๆ ๆijiلىääää RooneyPJPJpedoelopitational RomanceRTCanglesávkyávky\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Many boys and girls love watching TV. They spend many hours watching TV every day. But many parents let their children watch TV at special time.\n",
      "TV shows are like books and movies. There are many kinds of TV shows, such as sitcoms, soap opera, sports shows, fashion shows, and so on. A kid can learn good things and bad things from them. Some shows help children know the news all over the world. Children don't have to go to the zoos or the parks to see animals. They can see on TV at home. Some shows teach children how to cook, how to paint or how to study.\n",
      "Many boys and girls think it is interesting to watch TV but it is also interesting to read books , to play games or to visit the friends.\n",
      "\n",
      "Question: What does the writer think of watching TV?\n",
      "A. It's good for kids\n",
      "B. It's bad for kids\n",
      "C. Children don't need to watch TV\n",
      "D. Something is good, but something is bad\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " sle skipping skips redirects redirects자가geberinersinershafthaftante DESTtemptevaavaاناetroetroetroetroaalaaroolaoolaoolaosteosteosteoste Howesworthsworth着sworthsworthsworth MorrisonsworthanasanasanasantryinyinistentinodeSIGNSIGNVRسرsar生的生生生生 LebensmansmansAnythingitarian/social/socialstonstontractiontractionantryGGLEerateerate Cove Cove Cove Bundysworthsworthalementhipsveltスコilater관계关系haftsworthlettePLE Royale RoyaleRoy nested-composeoningnglenglehaftBridgeEDGEEDGEhaftéeIx Royale Royale生的生生的ød EgilogueantryantryinehirHIRHIRHIRdrugdrughaftennennStartPositionéeéeéehaft-built-builder-builderhaftêteêteitoneitationalspirpirspirpirσsnake snakeynetynetynetynetise Casc Casc borne borne bore bore bore bore bore boreENABLE Able AblehaftéeekerbowerbowerVRackleUCEinsi�ưngungungTAGTAGbuilt-builtे-endoSIDEéeséeseseheart-heart-heart生的IQIQtejその他その他nard bäister bä thắngiocηγstreamsomedolonolonolonolonolonolonolonolonannessannessannessannessannessannessannessannessannessontailetiletiletumorexorexorexERCERCERCERCERC bore Norris Norrisesseennieennieennieennieanness doncocoocoomoromoromoromorDGAttachment AttachmentAttachmentAttachment-sendióiocicareicareicareicareicareinodeenateitheritherithermomentmomentbsp stehtiertiertighterigarigarAMBбудsworthlumrungrungFinishsworthsworthlet래 ๆ ๆumptumpt-readonedolonolonomor Tổ成ahuahu Harbor船achtsbuilt-built-built生的生生的生生的生的生的生 Dynamics teďheksworthsworthokieozillaoolaoolaoolaoolaoolaannessannessrolesionalogyansaanaiphy Astroph AstrophGetInstance seysectsisceiscehaft-built-built-builtetchedicedumpt-fly-flyidayidayiday Maversworthsworth mieuxpestättessesseesseMESS Mash Mashibselves-self-selfêteenateel AttachmentAttachmentAttachment Attachment Attachment Attachment Attachmentontaonta nyeloseloseomorakIRCigarigarALARigarigarigarigarannessannessnTheuyenuyen十八 ๆ ๆUFFmatch-match-match-matchhaft-built-built-song-song createElement出来毛毛毛毛毛毛毛毛毛毛毛毛antererippleerdeerde Cove Cove Cove Cove Coveolet多い Relationshipsоныubo máximoParameterValueаваavaavaAVAAVAAVAANAANAonyony務務antenberobero boreTRAINeloadeload boredraeru ngũungungistentiséIPLEerateerateerate سویevaMOVEVsVsibs347apturedikedkd tand handheldangoangoangoinspace_SPACEivelildoango Fence Fence Fence bore borneitant خارجية Paramountatesbateantry tantoloseorceoxoxoxUpsUps\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: This is a special class. The students come from different countries. Some come from America. Others come from Canada, Japan, Australia and England. They speak different languages,but all of them can speak English. They are good friends. They study together, play together and live together. They help each other. All the teachers of this class are Chinese, but they can speak English. They are very kind and friendly. They work hard. The students in this class study Chinese cooking and Chinese gongfu.\n",
      "All the students like China. They say China is a great country and the Chinese people are very friendly. And they are happy in China.\n",
      ",.\n",
      "\n",
      "Question: What kind of class is this?\n",
      "A. A Chinese cooking class\n",
      "B. A Chinese gongfu class\n",
      "C. A foreign language class\n",
      "D. Both A and B\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " biopsyopsyovskyacyadeadeadeadeadeadeadeadeafiaafiaafiaamideøj nướcuangækkeækkepeg Royale Royale Royaleretteбудsworth justepestpestacea Cru Cru Coat Coat Coat着ertureerdeerdeerde生的生生着 zemírijkrijkrynnenään兴兴兴rom Assertion Assertionhaftsworthovatovatovat Mev wah Wah Wahhirfühioc/;\n",
      "итсяmov liaisonIOCIOC sânannessannessannessannessannessannessannessontaunganunganandan生的enden游danceNGerlanderland bore bore bore bore bore bore tropeophageerdeerdeerde Kushner Kushner Kushner Kushner tantra/pyPLEADEIDEIZEIZEateganding WadeBOTTOM Downingsworthsvillesvilleade odenseendaleerateerateicareicareicareicarehaft-built-built-cut-cutcut woodworking момент/moment andraanness écigationibusibusibusibusuriousnessinodeinodeercercercerc boreovatovat Sandra tongues tonguesesp Santo Santoicipič联系eesीज子的_DefigungigungTAGWGigarigarigarisableisableisablehaftigig-svgigoipoipo�548AZY tưởng Buildsprs級级haftsworthizzyanse bornehanahanaomorahuanchých kho khoRoyRoyRoy대의loseloseomorbasicionalerateerateewardwearwear WearwearrucrucSENS Nem elseifsworthsworthBSTainsovatovatovat生的 BornHon Mouriancescope Wadejdeppoppooliniinsinglengleantryسرासनahuahu Wah WahhirhirhirhirhiranimFORCEeloadeloadamus무ana balloangoango Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger delegationierungierunginkηγetal thấp ๆ ๆidf-confInterandonookeookeikkiikkiinspaceonium/reposelly široดา[]}AZYANG BuildsNVnglenglehaftBuilt-built før thíchUNGhaftiendaideADEADEeated faitFORCEانا حم حمRoyRoyicip PattonpioadeAttachment Attachment Attachment Attachment Attachment Attachmentontaoliniolini dniatchesщощо关系boro Wah Wah wah Wah Wah Wah WahhurstBushBush bulldsworthower�:checkedatikitationalonicalcopecope Kushner Kushner Kushner Airwaysbuzzbuzzbuzzbuzz BurstsworthsworthundyundyundyundyannesswearwearhaftBuilt-builtardu-su-su Relationshipschaftecomecomeewnrowseolateateitherahoahoainment육육-хerryfüh../../../../../../../../../../../../../../tons TonannessannessannessannessannessannessannessontaOriginalsworthsworthsworthBSTizzizzizzizzmerc Merc merc Mercmercercσ Dynamo_dispatchiociocycyc­i子的 ningún ningunaodoxyodoxyhaft HVääääää пропääVyvyibovatovatpvevaansi conexiónousedownolonolon boreести riendasalusintegrationérationigeigeyneyneyneyneyneyne Attachment Attachment Attachment Attachment AttachmentontaontaontalerceatoriaideADEggeronicalonicalonicalonicalinenäänisson松\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Victory Bacelis is a California immigrant who grew up in a poor village in Mexico. He is used to working hard. He works more than 90 hours a week at three different jobs, including McDonal's. He is saving up to buy a house.\n",
      "One day, while Victory was cleaning the floor at McDonal's, he found an envelope and picked it up. There was $612 in it. He called the police to report the lost money. The police couldn't find the owner, so they gave the money back to Victory.\n",
      "Then Victory read a story in the newspaper about Adrian Snadoval, a baby who was very sick. Victory decided to give the money away to help pay for the baby's operation. Victory truly has a heart of gold.\n",
      "\n",
      "Question: Where did Victory Bacelis grow up?\n",
      "A. in California\n",
      "B. in America\n",
      "C. in Mexico\n",
      "D. at McDonal's\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " sleackle入りoramovatovatặnặnhaftsworthhaftoningnorehaftنوع samoARBigarigarinationadeadeadeadeadeiodeiodeiodeiodeiodeiodeiodeiodeiodeiodeiodeontaoolaicumicumicum각sideAZEAZEAZE проп проп проп проп пас각isterovatovatovatstonston Stonrestoreosteosteostehaft chez chez석icipøjøjSIDEávkyávkyhaftávky生的生生生 doncionesSenseâteformationspirspirspir生的ittaittaete Cove Cove Cove borepoke Pikelake Lowe Loweupo Wah Wah Wah WahannessperseESCOSCO关系关系haft-builtbuilders-builtIntegratedATEDcosaocoCOCOINES्हenuityąd gáiannessannessannessannessannessannessannessannessannessannessannessannessannessontaánačíčíirHIRHIRHIRhir生的거거EbsworthsworthwardwardhaftBuilt-built teďpassesonesONESxnxnxnCollapsed Cooperative Cooperative Cooperativeibusibusvipvipvip Glover Gloverstonjitjit-masterMomentmomentMoment Moment生的huswearwearhaft-builtbaubuilt-builtêteibeSTESTESTESTEσsm_MAPPINGemapapoapoapoapoapoapoapoapoapoapoapoapoapo-caret Carp CarpespipipipngeERINGsteadsteadibsibsibsibsodialsidejayjayynsynthesizeovat họaiphyiphy대의činungsmovesMOVEainmentpirpirهاHIRHIR Aberayaspirpirerдеeviøj_ivSpatial着wingannieannieannieehrehrehrVRVR Tmaxamax.Match-match-matchinemaچهinsiinsiibshaftbaubauBABBABBABbabBABRelationshipuruppoppoipoipoπsnakeTriplePHAPHA.displaySIGNnglenglenglehaftBuilt-built生生softnessościщоeviFEFEแดงеньEYEYerc Casc CascDesign/designBlendBlend翼wingongaongaisinhaft-built-built生的.historyBearerInfinity Infinity Infinityibus Gibibip проп Kushnerlewjayjayookeerc konumangoantoanto AndreasشاءPAIReloadeloadpeed-speed-speedpeed SERVICE Merc MercmercercercngeackleفتهeesEYقاءumptumptTAGTAG-trackTRACK Rak Rak før臣臣 delegationpioantryantryantryminezeroxonoxoxoxMoment MomentULERerlanderlandanismervicehaft WeinsteinreichesseesseINESsteadsteadHTTPHeaderjohnسونson_SIDE_side-sideickouikkiikki Vineponepioioioanolościości-fiangoanto widestpestpest-_atairesauseapeADEoniumovatauseausehaftBuiltbaubauarendσκεlettesasjeasjeinationerateerate đàiiocηγηγηγsworth-blumlumTAGdex GXailles-built-builtinishslidejitjit efterpasseséeséeovereovereGVVAidataこちら下UNDUMamaxshaftshaftshaftagmaagma Mormsworthqv Ruddsworthsworthsworthsworthletahkanahuahu\n",
      "Extracted prediction: A, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Tony is a boy. He is 16 years old. He studies in a middle school. He often watches TV and likes the popular hair style . His parents and teachers tell him not to do so, but he doesn't listen to them.\n",
      "One Sunday afternoon his mother buys a beautiful shirt for him and he loves it very much. The next morning, it is cold, but he still puts it on. That evening he has a bad cold. His parents take him to hospital.\n",
      "About thirty minutes later, a nurse brings him to a women's ward .\"Don't you know I am a boy\"? says Tony.\"Oh, I'm sorry. I don't know you are a boy, because your hair is too long\".\n",
      "\n",
      "Question: --Do his parents and teachers like his hair style? --  _  .\n",
      "A. Yes, they do\n",
      "B. No, they don't\n",
      "C. Sorry, I don't know\n",
      "D. Yes ,I think so\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " sle sleawllallallallal Vallmatebuilt-builthaft-built生的 Plumclooxoxox spoilers spoiler spoileradinistrationistrationwhile кольisleislehaftéhoEYEYhanaupaapoapoapoapoapoapoapoapo-degreeلاةigarigaricareicareicarehaftêteige-photo最佳最佳BSTøjtrxøjøjøj阶sideADEADEADE slightesticiaryawksworthsworthsworthsworthllandcast CASTánaavaava关系賞賞haftsworthsvilleasjehanahanaanasanasINESIDESideSIDEhaft stessoaggioaggio_escape.escapeescapehaftBuilt-built thầu thầuilaterilatererateerateerateewardwearwearwearhaftêteêteither बयgeberasmusasmusالمinterINTER疆-safe-safeDISPLAYσεις posiçãoapedoledategoanto соотсо 포 ParkerFly-fly проп CONDITION Condition الوزDACateg sottoocoultimo ultimoardyagrantpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravontaGetPropertyGetProperty/writeovacíPIernesernesernesereerateerateewardpravpravprav проп立Builtggerehricare生的atchedatchedMedia-media DerrickizzleizzleizzleizzleTAILTAILideávkyplyitationalizedizedinersATEReloadeloadimonyatesperseatecreateView Gardner Gardner Bundy Bundy Bundy Bundy Bundykin Essentialidataidataozillaozillaozilla borehole생활생활 miglioribestnst한movesMOVEppingULERjoyfullyitationalTaylordancedanceupyoyoiχο Країна着ioc пози Positions PositionBSTсиава-ra latina latinaardoantoantoandas swipeEDGEEDGEomoromikomikomikomervice/service-servicehaft-built-builtoplevelbuiltinPRODUCTizzoizzoercercercercercercercercerc孔enateenateoyaPI WaynepioitationaljohnsonsonomoromoromorMomentmomentMomentMomentmomentMoment새sworthsworthγωνDefinesćiMbMbFeatvýخابџswordsworthousy jednot Othersothersannessannessannessannessannessannessannessannessannessannessannessannessannessontaontaámaraclosestclosest Bundy BundyBURBURBUR durannessannessizzaيفةigeERTääsureyawyawumblr着 Bensonpio RooseáceEYøj HOH HOHsherर�attach Ninh Ninhhirizzling sensation sensationichigiigiicareicare生的 GreeneetingwijwijставasuasuEYéeppoppoppoUpsUpsUpsENABLEająACTION-actionEYéeeeeehrookeookeypedendendoinovatovatovovovathanachiachiEYehrehrehr boreTRAINeloadeloadlifbahbah MevjtepteFEbbedelegateantryantryantryDonaldسونwearwearewearewearhaft-builtév Casc CascERCERCERCercercerc祥祥祥 boreheadedness spreeääppoppoimitynglenglengle boreptyptyTY Hinderedendasectaernaovaoolaoolaoola Manor Manor Mans Mansannessannessinenesseesse mái\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: When you were very young, you liked to play with your friends. Did you find that playtime was always more fun when everyone shared the toys? Everyone got a turn. No one was left out.\n",
      "That's a life lesson that changes as you get older. As you grow up, you begin to understand that others have less than you do - in China and in the world. And that those of us who \"have\" things should help those who \" have less\" than we do. The idea of sharing _ \n",
      "At your age, you can \"share\" with people in need in three ways.\n",
      "1. You can give them a part of your money. Many adults do that regularly.\n",
      "2. You can share items you no longer use, such as clothing and toys. You can pass them onto others who cannot buy them.\n",
      "3. You can help people by giving your time and your energy.\n",
      "The last one is also called volunteering. Volunteering is about giving your time to take part in activities that will help others. Every year, many thousands of volunteers in the world give the most valuable gift of all. They give their time. They give their talent. They give of themselves. And they are enjoying it. Volunteering isn't just about work. It's about fun too.\n",
      ",.\n",
      "\n",
      "Question: What does volunteering mean according to the passage?\n",
      "A. Give people money.\n",
      "B. Share items one no longer uses.\n",
      "C. Help people by giving one's time and energy.\n",
      "D. People give themselves to others.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "engaideADEADEADEadeadeadeadeadeadeADEadeadeADEadeADEade-LASTtempttempt RTEiertéeIBEidepteGenreernesernesereadeade生的生INESannessannesshaftideADEggererINETINET生的noreøreerateerateeratejit裝built-built生的生生еньinniehoo Wah Wah Wah Wahhurstsledsled everywhere everywhereannessannesshaft supportatesieneideIDEIZEIZEIZEzimctruryPLEADE Royale Royaleocial/social/socialideIDEletteinodeAZEAZEIZEIZEhaftsworthsworthBSTøjøjoejayjay Cooke Cooke Dickinsonmammamlavaantryantry vọngepereronesnglengleeratejit-built-builtogradovatovatovat着 ReadOnlyóbóbIncreasesDDS Wassduckduckduckduck Duckduck Jarvisintelligenceacad_escape.escapeescapeπ thầniociocicoloricoloricoloricoloricoloricoloricolorontaideoideoomoromoromoromorωpassespirpirozillaozillaozillaicoloricoloricoloricoloricolorinode groupe groupeyped servantservicelevellevellevel水平iocávkyávkyaskingASKsteadsteadsteadhaftестovatovatAVAavaava着Sink sink_dragSpatialitesiastiardyardyardyardytailsideideupeupeupeupeanguужTAGTAGTAGhaft-built-builtbau buildersHIR HirHIRHIR vọng pointing-pointRCTapoapoapoapooinolonolon Laud Laud Laudbdb chica suiv义\"]}owanieаниюantoantoangoangoangohaft Built-builtBURdragovatauseapeADEkéIPLEPLEADE Royale RoyaleyneCoordinateerdeerdehaftbuilt-builtletalwearwear WearwearhaftéeéeínythelessnessfuckfuckInternalitéourseiveerdeadeろ outrosatesauseitchedéeséeенеuanghaushausBuilt-built Weinsteinensonangoinsiinsiincess nguyệnopalopalinateateidebuilt-built LevinepioantryweaponчикiociocventusovskyskyskyLFøj 바로DIGernesill Harbor Harbor Morm.member.member-linederdeade bulld bulld bulldPastecoatcoat Cove CoveyneyneSTESTEitzerovatovovony wäh ๆ ๆanchors borne borneERMerlanderlandannessannessannesshaftête lửa lửaerméeailleantrybusterbuster frankfurticumicumipipiadeávkyávkyERCси Shorts Shorts ShortscomingsongaongaolonolonatreальноесосоCOávkyávkyجهiancespirpir наруж прохiocfüh FahmachforceiocLeast LeastDisallowbeerbudICHICHichongyang_Build-buildhaft-built-built).^ieziezIESіз GamMariMariinateotifyovat justepestovatanasanasINESčečeče boreoletovatovatcht TechnEDGEEDGEhaft-built-builtbuilders-builtcosaovsky Norrisantryramidovatovat서atches engagements engagementANGOangoangoyneynećeče BUILD Viktor ViktorovskyovskyovskyovskyovskyovskyovskyWESTelijkeerdeerdeerate\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: What are some successful foods? McDonald's Big Macs  are popular. Instant noodles have also become a global  success. Now instant noodles are celebrating their 56thbirthday!\n",
      "Instant noodles were invented in Japan by Momofuku Ando. Trying to find a way to make noodles last longer, Ando began experimenting and in 1958, he made the first ever pack of _ Now, 56 years later, they're eaten all around the world. In fact, they're so popular the Japanese voted   instant noodles as their best invention!\n",
      "Each year, 95 billion packets of instant noodles are eaten, according to the World Instant Noodles Association. In the U.K., people call instant noodles \"pot noodles\". University students like them a lot. During your first semester ,you may be given a gift bag that includes instant noodles! But watch out, people may think you're lazy if you are a pot noodle lover. Why? Because they are cheap and easy to eat!\n",
      "Despite  the bad reputation , the U.N. send instant noodles as part of food aid packages. This is because of their long shelf life and high fat content,, which makes you feel full for longer.\n",
      "However, instant noodles aren't innocent . They're high in fat and salt. Health experts say they're bad for us and we shouldn't eat them too often.\n",
      "\n",
      "Question: From the passage, we can know that instant noodles  _  .\n",
      "A. Can be kept longer than common noodles\n",
      "B. were the best invention in the world\n",
      "C. were the best food aid package\n",
      "D. are good for us and we should eat them often\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "engaideideIDEIDEhaft hlavatatatatatatpsychpsychALERinded-eyed-eyedewnertonertonsteinsteinstein Eisen/front선onalionalinspaceoniumoniumodoreodoreovatovatovat生的生生生OLDERVRggerborough Royale Royale improvised improvised improvised improvised improvisedlohloh ChristophinuscoloantoantoantoercFORCE制RELEASE/releaseiocjayjayLaughsucksucksbspbspbspbspbieseltseltsimonyomy MorrisonpioantryantryantryannessannessannessannessannessannessannessannessannessontaionaluniversalizedizedIZED*/)\n",
      "рост tallerйомayloadnavenaveMASTERMASTERhaftsworthsworthsworthancehaftsworthiesijeadeADEADEeateatEat Danielservice SERVICEGenreehr HirHIRHIRhir生的 PlumertzrtøjmoveMVigarigaromorookeookeookeinspaceøjoiingu beiden sexesortionovatovatovatovatMinimumnímすぐannessannessbastianbastianbastianMoment MomentmomentMoment Momentmomentmomentfestfestfestfest reflexivityFORCEovskyaskASKéeassembleassemblehaftخiratesуетilet각각sworthsworthlet ça Chance ChanceAnim Animynesitherbirbir生的生生athan/peoplePLEPLEonedolonolonomorальноеblockedong.coordinateerdeerdeinkenateenate Morm wah Wah Wahalamateg�出来-releaseioc_Referenceióbooophonophonolonolonardonardon../../../../ismusduckduckduckduckhaft Manor Manor Manor Manorannessannessjesstvaeva.setToGovCO-co-co EverywhereizadorinishinishSlice elkaar họaVietuyen IdeADEаваодаодаhaftχήpassesander生生���Inter Interprd relegated ràngUNGUNGUNGptepteipseipseYPEypeypeypeypehaft-built-built Relationships生婆婆关系 Mafia dut dutundyundyundyineitherliklerолжside-side sided sided sided sidedalet bure bureBUMmav-trackolonolonaimainment/servicejeejeeEYää777777сон ferFER/member/memberhaftBuilt-built-builthaft-builtpravpravoramoram пропicumicumicumum Ide IDEødéesEY联系立iocioc Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wengeranterehrehrehrehrangiγγ.removeChildнг NavigateerdeengeernesigeigiigiigingeerateerdeéeقاءehréeerryONYony_ivająhanaupaupa máihaičí stirpestpestrietjitjitinter dissolve dissolve dissolveolorodoreodoreaddonolonippleipple666MATCH-match-match-matchpeedBuilt-builtестиastiastiantiseltsvelteneponeerateerateerate生的生生的esseESCOercercercercERCERCERCERCERCideمینenderecoío соотíoocaideADEBuilt-builtPrevaillesatelyardyardyardyhaftBuilt-built生的生生的 donchaltshaftshaftshaft Manor Manor Wenger Wenger Wenger Wengeriskoitationalitationalalizationicodeicodeicodeicode numéro\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Mr Smith goes to the town   to see his son, Tom. Tom is studying music in a school there. He tells his father he does well and his father is very happy. That evening Mr Smith buys two tickets for a concert  . They get there early after dinner. They're sitting in the hall   and listening to them playing. The music is beautiful and Mr Smith enioys it very much. But he finds  his son doesn't like it at all. Mr Smith wants to know something about Tom. So he asks, \"Do you know the music?\" \"Yeah,\" answers Tom. \" And what's the musician playing now?\" Mr Smith asks. Tom doesn't know how to answer it. He thinks hard and then says, \"... the piano.\"\n",
      "\n",
      "Question: Which of the following is right ?\n",
      "A. Mr Smith lives in town.\n",
      "B. Tom knows much about the music.\n",
      "C. Mr Smith likes the music.\n",
      "D. Tom likes the music.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "engaelderelder rooftop rooftop rooftopannessannessannessannessannessannessannessannessannessannessannessannessannessannessannessontaionicspirspirirsarerEREigarigarGenre류 erreur erreurірpasses passer Perr Perrannessanness初hirHIRhirhirhirantererateerateerate生的jakbekbekceføj Assertion AssertionhaftsworthsworthsworthsworthоскNB frontline frontline whistle whistleinspaceinspaceinspaceachoachoantryantryantryehrhaftsworthøjøj-кmovesmoveshaft-trackездаTRAINtraktrak着ioclette Соichoatches pundduckduckduck DucktailplineoduleAZEletalletal闭 ๆ ๆonalerateerateerate-heartednessest Attachment Attachment AttachmentAttachmentдет násled ๆ ๆnemINETød.showsευσηANAANA석각foundation/Foundationtons DowninganskansionchyEYmansmans Mans Mansannessbecapture忍iocinateovatovat MevannessanasanasanasanasanasANAодаодаooterolonolonTAGTAG-readDIGernesальныйsideSIDEhai관계relationship orgasmolinioliniodeitherchoice-choicehaftsworth/confinhainhainhaicolorcolourasureasaravaAVAقاءедь naamsworthmáaggableبية ballo-es-esàngerateerateратиachiichiichiundynglenglehaft Vineletallak Pharmaceuticalsomedolonelon máximopiopioipplePLE latinaatesEDGEEDGEInRange이어이어haft-su dissolve dissolveatron quang quangundywearwear着USAGEACHIávkyávkaIBCerdeerdeippleerateerateENTEbaubauBURchtererHIRHIRhirggereratejitjitRuntime.getRuntime söz.wavwav Easeeaseeaseheartheartheartheartheartheartношovat着elligerateerateerate-heartednessiyatiyatabh역역ERCevaAVAavaava VPapoapoapoapooinćićićićiMAeva�iernesедьедьformance Tango TangoTAG-anchor-anchorundyauseauseapeADEADE {:?}\",ająternalsidesidehaft-built-built Cutkova_COPY COPYomorolumovatovatoka着sureSUREhaftBuilt-builtermermERMRTCicodeicodeicodeicoloricolorousy料毛毛毛毛毛毛毛毛毛着iocイクญrolePLEoined Joined Joined sided sided sidedannessannessализацииierungigarigarigarigarContextMenu역역ercercercERCàngàngàngaulávkyapisitheritherhaft-built momento MomentmomMommommom Moment MomentFeatFeatFeatfffFEFEFEainmentąd UnidosíoangoangooiIFFaugauganguanguanguanguanguangu../../../jerne柳着�Attachment AttachmentAttachmentиж transformationSUREhaft-builtreauoonophonophonophonolonolonategorex Broadsworth-trackurface_SIDEbladeaxeixeixece CoveetingčiichiichihirHIRgger Randallizadorolonolonlif panoroplanistratistratistratistrat립least Leastinspace乎umptumpt Technänأةиновksenämasmaasma\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Emily Urich 18 years old Canada\n",
      "A lot of teens aren't responsible ,and that's where I'm different. Not just about school but everyday things like being able to pay my own credit card bills on time.\n",
      "The first time I got a cartoon book was on my third birthday. From then on , I fell in deep love with it. And can you guess how many cartoon books I've read? I don't really know the exact number. But I have three full boxes of them under my bed. I also like drawing cartoons and wish to be an art teacher in a sch001.\n",
      "Joe Miller 16 year's old America\n",
      "I'm proud of doing things my own way. So whether somebody wants me to do something or whatever it is , I feel like they're all other people's thoughts , not really mine. But like others , I love reading , too. When I first took skiing lessons , I found it exciting. For ski racing,there's no question I'm better shape than most guys . I think it's fun. I mean,it is a challenge . It's where I picked up the idea of needing a challenge always in my life. In order to improve my skiing skills,I have read many books and magazines about it. No doubt it's my dream to win gold medals in the Olympic Games.\n",
      "An Oi 15 years old China\n",
      "I'm different because I prefer to drop out of the world to create my own world. I'd like to build a house on a mountain. And I choose to live without electricity, a telephone,or even indoor plumbing . I have many hobbies such as traveling,reading , writing and spending time with children. I love children because they are smart and creative. They always have many strange ideas. It makes me excited. I want to do something for Hope Project and become a country school teacher .\n",
      "\n",
      "Question: We know that Joe Miller    _    .\n",
      "A. doesn't like to follow others\n",
      "B. thinks skiing is too dangerous\n",
      "C. does well in drawing cartoons\n",
      "D. Enjoys living somewhere quiet\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " sleackle morphology suggestsRaisesigaradeideADEADEADEedeadeaalしい thuyết thuyếthai Liailiainspaceinspaceinspaceiodeiode RTEplineerdeerdeadeée lửaLAGigarTAG-linedicericer/news-events-events자eviinsinglengleteste Pine Pine狼 ๆ ๆ Morrisonjon EssentialsworthsworthBSTøjmovesMOVEhanaupa Wah Wah WahDGAZY-match-match-match McCarthyitéêteerdeerdeerde류 KillerkillerALERbloodbloodBloodercadeptyTYysizeysizeysizeannessannessannessannessannessannessannessannessannessontaional-social-social-socialinhaptiveateičηγηγηγanchorsègeRaiseNSEerdeerdeembeddedsherakerwearwearewnewardwardSIDEéeséesEYilogueilogue Whipsworthsworthhaftsworthsworthée-facediociocapoiocercinsi.adv.advBURøjøjpeepeeansi Wah Wah WahizzyozillaozillaozillaanaMAsteadsteadide dětíetroetroungecretionπλside래 ๆ ๆORED nombreuxoblibenkiikki.fiinethradBuilt-built生的生生 Coatdetach tantr tantr Morm wah WahijaengaungaWBoggleOGLEantryantryantryINES회RoyRoyozillaoolaoolaoolaoola Manor Manor Manor Manorannessannessannessannessannessannessannessannessonta Action-action公开 Bensonwickwickercercercercercercercmerc merc Merc merc mercmercERC卒achtssworthsworthsworthBST justepestovatovatovat着ichiichiichiundyundyinen LoweestoneletalletaligliaigliahirHIRHIRHIR Glosssworthavaava Sandersmans Mans Mans Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger.configure/releaseRELEASE/releaseALER/\")\n",
      "../گاهگاهakeakeanchorsêteRaiseRaisehaftête zichiyahiyahikes thướcioc CrushersSherRoyal육육육生的生 Livingstonpioantryingleinglehaft force FORCEstaffstaffom-composeجمةdbeBUR ihnpiopioinenäänääninenesseesones iotaiocinateine生的生paiávkyávkyMirrormirror Mirror Mirrorhaftbau-building-builderhir HirHIRhirhirhir-inter-inter пропulatesatosapoapoapoapoapoachoangoangoAndysworthsworthardyantasyostiigiaggibuzzbuzzbuzzbuzzachoachoantrywearwearyneyneyneyneyneseltServebbebbeête ngheophoneophoneceenceerdeأةiocupoptionościinkiinkiercESCOoaches-built-buildVisualibliibiibsibsibsinha kho khoENABLEerateerateeeréehtahtaernaiyatiyattagakestเสนamentalizedALER��� Fucking dreadpawnpawn Niger Niger NigerannessannessannessannessannessannessannessannessannessannessontaいかIQSenseNSE ràng ๆOREDigTAG-built-builtibscoes')\");\n",
      "jerfewfewehréeée-ending Dante DanteannessannessipsávkaávkaMirroraclefewдав-taxhawk Hawksworth\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: As prices and building costs keep rising, \"the do-it-yourself\"(DIY)trend  in the US continues to grow.\n",
      "\"We needed furniture for our living room,\" says John Kose, \"and we didn't have enough money to buy it.\" So we decided to try making a few tables and chairs. John got married six months ago, and like many young people these days, they are struggling  to make a home when the cost of living is very high. The Koses took a 2-week course for $ 280 at a night school. Now they build all their furniture and make repairs around the house.\n",
      "Jim Hatfield has three boys and his wife died. He has a full-time job at home as well as in a shoe-making factory. Last month, he received a car repair bill for $420. \"I was very upset about it. Now I've finished a car repair course. I should be able to fix the car myself. \"\n",
      "John and Jim are not unusual people. Most families in the country are doing everything they can save money so they can fight the high cost of living. If you want to become a \"do-it-yourself\", you can go to DIY classes. And for those who don't have time to take a course, there are books that tell you how to do things yourself.\n",
      "\n",
      "Question: John and his wife went to evening classes to learn how to   _   .\n",
      "A. improve the quality of life\n",
      "B. save time and money\n",
      "C. make or repair things\n",
      "D. run a DIY shop\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "ady-/hofhof soakinghafthaftligeindedindedligeligelige WadeAZE lửaitationalitationalisedisedadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeeturervererateerate生的生的生生 borehouseselveselvesSELF david/news津津 <$>..<UCEUCEhaftsworthsworthsworthhaftsworthletteerdeerde生的yclic-ringistratistratehrehrctrjitjit masturbation masturb masturb masturbation masturbation MoorLEE-KeymeyEYEYEYhaiǐhirHIRHIRunreadovatovatovskyovskyovskyovskyhaftBuilt-builtIntegratedérationéeéeséesقاءDICDICTAGängmediaomediodeiodeoline-solid-solidannessannessannessannessannessannessannessannessontaAction-action역ilaterPBøj臣nahmenahmenahmeescape escapeescape生的ød料IQnapnapnap bore bore bore bore bore bore(withIdentifierigliaizzieizzieinateenateitherningarigarigar-compose chim chim chim хвsworthovatovatovatewswearwearwearVRVRVRVRRCFORCE봉sworthachsophonophon Mansmansibs ingigiigiannessannessannessrietovatovovovVPøjmoveMOVEhaftigIGerlanderlandovatovskyovskyovskykkejayjayEYéeséesizzizzizzbuzzbuzz Laudbeerzahlsworthggererasher vọngंदरcastlebudAttachment AttachmentAttachmenturiousuriousnessovatovovovBViances địchultiigiigiigiしょう Builds-build-builder-builderhaft-builtестиastiastiapo着ichiichiigigiigi Mahar Maharctor/front Vend Vend Vendtail Casc CascPaste Perryapatarataratimony Pry Pryレットávkyitationalitational府wareswarehaftBuilt-builtjadBuiltbuiltGViances级 ๆ ๆ ๆinerspirpirTransfer/releaseigarigarEREądigarínyажsarstvíovatovatakat IntegralloseloseALERPHAinsiinsiibus Joined JoinedSystemsNetworkingubat mínitationalizedateg DanielsassenassenhaftbauBuilt-built Bauhaus-style態ydıEMPLáteáteitheritheritherDGää Wah Wah Morm511coordinateightlyosteosteosteosteosteustiest jusFORCEhaft-builtittedningar svenskaborgAttachment AttachmentBOUNDään Wah wahapeshsenseSenseبودultiastiSIietsEYatchesershINES ΑναääEYppoppoimitynglenglenglehaft-builtptyptyopyopyolineogradovathevauseauseitherfühserv Ferdinand Ferdinand tanımnemrung zichiocipadeADEyatovatovskyovskyips пропglich-rights-rightshaft-built生 Fallscrestcrest-linedinednoreffeicareicareicarehaft-builtunglewearwearhaft-builtptyptyptyGGLEantwortsworthggerhaushausesseesseesseesseidge/backgroundGVizzizzizzizzbuzzProvider材wareWERsteadsteadovathev SavcastpitpitInside意ávkyausehaftinantwearwear生的 ]];asonryπλαDIC\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Do you know the phrase \"Weibo Addicts\"  ? Do you write a Weibo? If you don't, you are \"out\"!\n",
      "Weibo means microblog. People may spend much time writing a blog, but it takes a little time to write a microblog. Why? Because every message on a microblog is less than 140 words.\n",
      "Microblog started in the USA. It came to China in 2009 and it grows very fast. In 2011, the number of Chinese micro-bloggers grew to 300 million. People write microblogs for many reasons. For many microblog users, it is a great way of learning the freshest news, talking with friends and sharing different kinds of information, including news, everyday life, pictures, music, videos and so on.\n",
      "It is easy and fast to send a message on a microblog. However, this can also bring problems and even panic  . For example, when the big earthquake and tsunami   hit Japan in March, 2011, messages like \"Salt can help people fight radiation  \" were hot on microblogs. Then a crazy buying of salt followed. Later people knew it was just a rumor  .\n",
      "In a word, microblog plays a new part in the life of Chinese people.\n",
      "\n",
      "Question: What is NOT an advantage   of Weibo?\n",
      "A. It is short but carries many meanings.\n",
      "B. It can help us learn the latest news.\n",
      "C. It can send rumors.\n",
      "D. It is easy to use.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " Revenge vengeance vengeanceerrerereeereehaft着ioc兴兴兴pirpirererhaftalteACTION-action everywhere everywhereannessannessannessannessannessannessannessannessannessannessontajoiningjoin sorumlu ràngANTEadeade Coat/coTeX HitsHitsسب MediaMEDIAbuzzbuzzbuzzbuzz Burst Burst-faced-facedrietovatovatatatTAGTAGTAG Whenever möglich возможности возможностиavaavaadeADEADEhaftsworthsworthswortherc spokesperson spokespersonTEAM/group/groupmarefewfewernityernityasmusasmus林anáодаодаooke-teertihtaupaupaoinolonolon着 PipodesitoneiocaeFORCEstrengthakestakestGetInstancehaltitationalitational-global-global著sworthizzy quang verdeborgovatovatidataadeقاءernaovaAVAavaavaAVAAVAAVAAVAAVA.aspectpertpitigatejitjitTAG_MAGดาapo래hanaupaavaavaAVAAVAAVAhursthurstressingizzieizzieiccعد332 certoicieqtynglengleMedia/mediaواء Broadsworthsvillewylewlewinspaceantoantoanto dítěDDSDDSDDSDDSDegreesDDS daiANTIinyaichichichenekfew-rights-rightsレットichiichiichi각각 ErnstenegPositions Positionhipsipsipsіп Fallsardyardyardyardyardyhaftsworthlettelettesithertridgeadeade(alwaysolutely Blondeidia-independent-mindednessYSTmammam clos clos成了OthersOthersALER frontline frontline_enterprisingnessesseesseessehariHIRHIRHIR/trainTRAIN Mandela Mandela Mandela Bundyøjその他étéétéehsnake snakesGam Russinatejitjit justepest래_PROntonulationmaticateateodoreodoreodoreσ Whiteelowoxyoxyyneperseperse�� Dochøj HOHategsenseفتهside-bcarriererdeerdeinenaussaussBVlettelette-teetreTAGtrag“That Evening Tonight Tonightlakasonicoolaoolaoola Manor Manor Manor Manor Manor Manoranness doncocoicoicoultimoolonolon喝snakeistaniernaerna carnAttachment Attachment Attachment Attachment Attachment Attachment Attachment Attachment Attachment slightestpest Pett PettichьeesappearanceościungUNGINETeloadeloadimonyetroEREandingondheimjernehaft-built-builtковод伸стройстройasonryasonryhaft-built-builtbuildersbuildersyst้าย ๆ ๆ ๆundyнг Manning Manning Manningloy회ABILITY nouns nounsalerarer生的生生的hir HirHIRHIRelsonside-sidehaftBuilt-builtPrevPrevPrev Attachment AttachmentULER busesbud-builtIntegrateditteffeffeadeOLEAZE})();\n",
      "Solid-solidhirhirhirhirhirIntermediate Intermediatearsebitelediendas342abeledolonolon rtORKsworthsville Devil DevilctoreerTHRistratoristratoristrator� unionunionhaftBuilt-builtестigeFORCEveltveltveltimdeade spiritualityREA래یشه relationRelationshiponing่าย ๆ ๆ ๆWAYSsteadsteadsteadhaft doncONSEsargasSenseSensehaftéeéréeerateerateerate Garyblingsitationalitra\n",
      "Extracted prediction: A, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Tom was a farmer. He worked on the farm all day,but sometimes he went to the town market to sell fruit and vegetables. One day, a terrible sound attracted his attention in the town market. He saw a young bull for sale. The bull was white and yellow. It was looking at Tom in fear. Tom walked up and touched its head gently. Just at that time they both seemed to have known each other for a long time. How amazing!Tom bought it at once and called it Amba.\n",
      "From then on , Tom and Amba got on well with each other. But some friends told him that it was dangerous to have such a close relationship with an animal.\n",
      "One afternoon , Tom was walking through the forest with Amba. Suddenly , Amba stopped walking and kept pushing Tom with its head. Tom was very surprised and looked around. There was a big snake in front of him. It was beautiful but poisonous. Quickly Amba stepped on the snake's tail with its foot and at the same time Tom picked up a stick and hit the snake's head heavily. Soon the snake . died.\n",
      "Tom was very grateful for Amba's help. When people heard this, they were shocked at the bull's expression of love for Tom. But for Tom, Amba was not a bull but a member of his family.\n",
      "\n",
      "Question: Tom worked   _  .\n",
      "A. on the farm\n",
      "B. in the market\n",
      "C. in the forest\n",
      "D. in the town\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "ba bucktailiardséeséesligeadeadeadeadeadeadeadeadeadeelupline義義ilogue-api大利皮 BlendmateburyhaftsworthsworthbspbspbspbspavaAVAAVAVRGear寸寸izzieFORCEerdeerdehaftsworthletteerdeppelinppelin Passengerubberubber生的生的etusoppableerateerate生的生生 boreantryspirspirspir SpirIBičovatovat生的生生ALARALARNetworkingINETINETlalupaFORCEerde席席SIDESIDEhaftsworth-vousintrINTRehrehraffer Stellarcrest Crestetonehrehreward� RoyROY Islandersiodeiode đàiDICDIC/mediaiocotec spokespersoności義-sided sided sidedannessannessannessannessannessannessannessannessannessonta lửa lửa lửaersonicerateerateerateerate squaredborgøjøjøjcretionoxoxoxolonolonoyoy sey-taskioc 七antrywearwearewnardyardyhaftøj AssertionAZYZYVRggererehrehrehrVRggereraffer-rateerdeerdeerateerateerate-heartednessotimecycleCycleлицiocorningstdoutolonolon yellow développement生-bloodødéeée Rooney McCoyocket席-sideioc래丸 ๆ ๆπλzahlzahlercercERC願いozillaozillaozillaicoloricoloricoloricoloricoloricolorontaánaanasanasanasanasanasanasanasontaánaодаодаodaSpell.TabIndex.TabIndexære �leshgedopardumptumpt-ups gemachtsworth justepestøjøj-psøj HOH.TabIndex.TabIndex.TabIndex.TabIndex TalesalaavanaavaavaAVAAVAAVAAVAAVAAVAapoíopioERMdeenerateerate生的生生生生denána IncontriangoangoγωνćićitejateraftaftGVibuitationalpirpirRelative přikkererlingenjong Jongynetynetynetduckduckduckduck-cornererdeerateerate生的ält 국제glichglichhaftsworthizzyppoppoipoipo ganzeloseCLOSEerateerateynebuilt-built-built成了 kho khoumpingstakingstaking+k karakasmaphonphonalog Swingerduckduckduckercercercercercercangiangiangiangiideichteichtenichtenohoatcheská closerpasavaAVAAVAAVAAVAAVAAVAibusさ lakeslakeتها Wah Wah WahrucxAC招 ๆ ๆ ๆooter生的 donchaltshaftBuilt-builtüst-j-jPitchPitchhaft Built-built生的getetingendasGampirpirpirVRacklebottompioantino Angeloise-photoiocidatarowseolateolate生的生生的ibsaggio blitz blitzFeatumptстеedeEDGEEDGEpeedéeanterer CoveEDGEEDGEInsideSIDEhaftsworthizzyizzizzinationeratejitjitINavigationside Built-build-builderVRackleGGLEže built-built生的 ngồi chairsHIRHIRHIRhiriyataratarathaftBuilt-builtRoot래gebergeberhaftBuilt-built momento Momentsmans Mans MansannessannesshaftBuilt-builtGV Kapoor Kapoor\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Today is the fifth day of August. It is Judy's birthday. When she comes back home from school, she sees a card on the table. It says, \"There's a present   for you, Judy. Look for it in your bedroom.\" Judy runs into her bedroom. Her parents are looking at her and _ . On the chair she sees a red box. She thinks her present must be in it. She opens it, and there is a piece of paper in it. She reads it, \"Dear Judy, I'm your present. My first letter is in the word 'bag', but not in 'age'. My second letter is in 'like', but not in 'lake'. My third letter is in \"know\", but not in 'now'. And you can find my last letter in both 'desk' and 'get'. What am I?\" Judy thinks for a while and says, \"Aha, I know. But where is it?\" Her father tells her it is in her study.\n",
      "What is it? Do you know?\n",
      ". (5)\n",
      "\n",
      "Question: What does the piece of paper in the box tell Judy?\n",
      "A. The color of her present.\n",
      "B. The shape of her present.\n",
      "C. The place of her present.\n",
      "D. The name of her present.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " sleackleantryantryRITEovatatatatatatatatatatat震震haftsworthsworthsworth生的etus časunanonano segundosborg nøemmeélééléReadableMagnanterpitovatovatovatlerceoolaoolaoolaonsenseościości Blitz BlitzuntimehaftigigigiigihaftFastnesspitchwickigansusting-interINTERhafthaftéeiphypheADEADEantryantryALARALAR borepassesateatatatat 감독renderendehaftbestättnested-apiavaavaapoolonolonardonigarigarigar Dental Dentalhafthaftify-inter WeinsteinUUUUakash Mineralspirpir� Retro Retro_rpapoantoantoantooyooyoorefое着iocituraussausshaftbau着ersonicości gyro gyro gyro Kushnersworthiramnaparatistratistratistratistrat Manor Manor Manor Manorannessannessannessannessannessannessannessannessontaавааваannabin석kaarigarigarigarigarinodeinodeitheritherhaftBuilt-builtibsibsibsibstribitational IPA jab jab sànPortablePortable ràng Qué qué quéiancesfaction244strepestovatauseAZEAZE máiBuilt-built máipassesveltuvouvoapoidataATEšť/extóriosetupolonceancean borneCycleCycleBearersworthsworthsworth伸sworthhaftsworthéeéeée пропноеioc وسط事धर坂着nahmeänder ZimmerزمermERM MormsworthsworthsworthizzyitoneństщощsarARBynetovatauseauseDISPLAY/show/showUNDERhausen生的 Bathwash водойduckduckduckduckduckduckinsky快Speed-speed-speed-speed quotidzahlophoneophonehaltshaftshaftshafthaftêteetreENTERشاء 立adenaadena máiwonFORCEerdeerdeafferafferafferafferafferissonicodeicodeoitherfühfüh Neyannessanness-wh怕hanahana Wah Wah Wahundy-api benefindedjerneœurœur borepokeолжInvariant '/')erdeerdeewardbowánaitationalitationalonicalonicalonicalonical bore bore bore bore bore bore пасiociocithericycleicyclezwzwzwynrucruc Cove CoveIBCIBCletteette />}лия Relations관계关系IFSGBP gordsworthveltveltburgburgogneogneehr Oral-mouthveltantro마사지 육육육ewoodewoodolonolonlp frontline frontlineBuilt-builtipseltseltsCEF/member/memberULERmě-change CHANGE/devuv料 ๆ ๆижkaarpasseséeséeséeMirrormirrorpirpirerieltseltscross-crossставistrationistrationhaft-built-built_BUILD-build/buildborgREATEerateBuilt-builterreerre生的CycleCyclexAA nahHIRHIRHIRhirSkyPIиstancenglenglenglehaft-built-built建-builtimdeadeADEbuilt-builtêteahiGIжиornoornoomorramidolinioliniachoango máximo /\n",
      "\n",
      "AZYyuǐancesômehfynetœuromorTAGTAGhafthaftêteêteéeENDEDайдsworthgasGasapoapoapoapoapoinha Royale\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: A farmer had four lambs ( ) . One was black , and the other three were white. The black lamb was friendly to the others in the group . But the white lamb s often laughed at him. They thought he was ugly. The farmer did not like him, either. He gave bad food to the black lamb.\n",
      "One winter day, the four lambs went out to eat grass. They went far away from home. Suddenly, it began to snow. It was such a heavy snow that the ground was all white soon. They couldn't find the way home.\n",
      "When the farmer found that the lambs were not at home, he went out to look for them. There was snow everywhere. Suddenly, he saw something black . He went to it. Oh , it was his black lamb! And the white lambs were there, too. The farmer said excitedly, \"Thanks to the black lamb, I can find you! \"\n",
      "\n",
      "Question: What can we learn from the story?\n",
      "A. Appearance is the most important in our life.\n",
      "B. A friend in need is a friend indeed.\n",
      "C. Don t tell a person by his appearance.\n",
      "D. Many hands make light work.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "engaontaideIDEAZEindedindedideadeADEADEADEoantoantoonoovatovat着eviながら着ooseoose RooseFORCEoningéeekerigeigeêteête-ceCARDadeppoppoipoipoinhainhaantryMotion-motioniocioc độ quickest quickestardyardyardyardyannessannessannessannessannessannessannessannessontaadena Rooseinate latina latinaardyøjøjewnsworthsworth着wing benefisteriyaiphyiphy-cartistratistratapoapoapo проп ๆ ๆ ๆundyitationalminatekehsworthsworthstonAttachment Attachment Attachment Attachment Attachment AttachmentINETINETlal � easternEDGEerdeptehta-levellevelLEVELoning خارجية خارجيةIDE.POS Forcesforceshaft-anchorèreigebouncebounce-heartedheartick-eng Speakingگاه manners mannershafthaftercongaongaERCUNGgensgensgenshaft-bestpestovatovat射射射射ideсте Cove Cove Cove Covehurstáváletečeče boreholeądедьθυoqueqxイク meisten/single/single/singleannessannessannessannessannessannessannessannessonta牌iocuosWER�ưngUNGligeFORCEsteadsteadBSTsaristratistratistratYellow Myers Myers林 Plum PlumpirpirVRCoordinate Coordinateрадиidatailet井ONESannessannessannessannessannessannessannessontaoka Wah Wahhirhirhirhirhireradeoolaoolaoolaoolaoola Manor Manor Manor Manorannesséeoineigungspirpirpirhaftsworthsworth justepestocracyPoliticsigarigarigaricoloricoloricoloricoloricoloricoloricoloricoloricoloricolorPLEADEeleloeCLOSE clos closंपरbiltbilt filBILEsteadsworthsvilleinsiinsi-compose/Set/Set нимaggioettoettoinodeoduleminateстестеosteosteosteideolandolandomorальноеerateerateerate Cove Cove CoveجمpasseslewpirerER�� Feed.selectionتص子的edByondheimondheim mái着iocolandolandolandannessanness écτευsnakeerdeADEávkyasking席sideSIDEhaftsworthggereregerehrainmenticipanticipationicipationicipercercercercERCàng柳柳ewn차-team/grouponinghton máximoดาDICDIC SAFidataidataonium/engine firefight firefightressingwjjayjayjayjayarryasonryDAYdayburyburythoughtmomentmomentannessannessositykehnahme Infinity Infinity狼 ๆ ๆ đàiioc doncocoucoucoerc Casc Casc Fence Fence Fencehaft../../../../../ANCHbay HarborhfOutlineeyJeyin심 ๆ ๆ ๆrovéppyppyyneyneyneyneannesséesées777 七атьсяbuiltsworthsworthéd成了成womanolonolonomorSegment567angkan진 BuildsDIGηγηγηγimonyicumicumundygold')\");\n",
      "eveávрабerbigiigiigihirhiripplebottombottomundybilt-built-builtibsibuiboainmentwearwearhaft-built Harmony HarmonyorampirpirpireréeéeTREE(tree компанії\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Kitesurfing as a water sport began in the 1980s, but didn't get popular until the end of last century. It is also known as kiteboarding, and in some European countries as flysurfing. Kitesurfing works through wind power  by using a large kite to pull a rider on the water at high speed.\n",
      "At first, kitesurfing was a difficult and dangerous sport. Now it is becoming easier and safer because of the safer kite design. For an able and strong person, kitesurfing can be a very fun, extremely exciting sport, just like skating on the water with a feeling of flying. It has become more and more popular.\n",
      "Compared with other water sports, kitesurfing is easier to learn. A beginner can understand how to operate the kite with 5--10 hours of training. And anybody aged from 13 to 65 can learn. It is not expensive to get the equipment for kitesurfing, which costs $1,000 to 82,500. Training lessons _ from $200 to $500 for two or three hours. With the development of its equipment progress, kitesurfing is becoming even safer. After some training, you can enjoy its excitement and challenging feeling.\n",
      "With the rising popularity of kitesurfing, most major seaside cities have kitesurfing clubs. In China, Xiamen is the only place that has the kitesurfing club, which provides professional kitesurfing training and equipments.\n",
      "\n",
      "Question: Kitesurfing has a history of about  _  years.\n",
      "A. 30\n",
      "B. 50\n",
      "C. 100\n",
      "D. 130\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " dao-netoqoqoq Mansion hall hallhafthaftiginesisecta Preserve Preservevipvipvip tropeategieveshaftافsarhanaanaANAANAANAideADEADEADEadeOLEADEéeséesSpeakbubblebuzzbuzzbuzzbuzzinationPASSéeséeséeAVAanasanasanasINESletteserdeerdelatehanaovatovatovskyovskyovskyovskyhaftsworthsworthsworthsworth-sidediodeiodejit EFFECTsonoatoantoantoupoávkaawaavaoolaoolaoola Manor Manor역역ercercercercercercerciodeletteèle.coordinateCoordinateategNOPayacakолжantryarataratapoapoapoapoamus kho khoстав Casc Casc Mormnofovatovatovat SandramomSenseillionsantry zich Vijovskyovskyovsky-whENCEηγsnakeletal AssertionAZYhaftsingle/single/single-sided/singleborgasjongeberigeigeicareicareicareereadeerdeerdeerdeetalasalsideerdelettesonteaweaweitherIFFsteadsteadideávkyбобоantinoAction-actionKERicareicare生的成了成了досоío Rebellion Rebellionhafthaftiyatiyatiatiatiataletitte территorted écibbhbh BhattachLatchsworthsworthizzyizzizzExcypass passer passer生的pawnpawnVRVRVRtranBridge_boundary BoundsworthizzyizzizzizzizzizzimaxRIX-match-match-match-deleteakesttoolsości生生 brom BromrzebzGENborg써sworth justepestovatppoppoipoATELeastLeast Least реб ребmatesktkчикиmirrormirrorwardswardswardswardswardwardwardhaftfellfelltejacím宮 Russo Russo RussoophoneophoneolonolonolonolonannessannessannessannessannessannessannessannessannessannessontaavanaAVAavaavaavaaaléeséeéesπλsidejšímirrorvět ๆ ๆERM.removeChildinghir HirigarigarigarigarCircularAZYетьсяioc载iocietenehrehrehr Laudsworthsvillesvilleichichichichiminäänोच حم حم� Ing IngлядويDICDIC Ligaundaozilla vọngpassedoliniuiUI Mandela Mandela Mandela Mandelaide तरह ๆ ๆovatovatovatousyбы着iociocicoloricoloricoloricoloricoloricoloricoloricoloricoloricoloricolorеevaAVAAVAAVA長 Buildsестиastiastiapo/show-showGMTpertpert Neville LageADEADE-built-builtbuildershaft-built LeerотеcretionittaNSSNSSVRasmusasmus715øre Gearpillpipipinge글ertextościościarcyANGLEANGLEhaftsworthittiilliADEeing(/^atoriaiyatiyatiyatiyatål Cancsworthlsa래 ๆошsarletteERTigarigarigarLARigarंपरINESčečeovat마passes Manning ManningespättrippripprippannessannessibsibsIESnośćościousyuffymoveMOVE/activitybuľsendMessageopeapeoxyoxy oxyEDGEEDGEhaft-built-buildborgborgborgborg\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: People usually hate mice, but people almost all over the world like one mouse-- the famous Mickey Mouse.\n",
      "About eighty years ago, most films had no sounds. A man called Walt Disney made a cartoon mouse. The cartoon mouse could talk in these films. He made his mouse become a good friend of both young people and old people. Children liked to see their lovely friend, because he brought happiness to them.\n",
      "Mickey is a clean mouse right from the beginning. Maybe this is why people love Mickey Mouse very much. In his early life, Mickey did some wrong things. People were very angry. They wrote to Disney and said they didn't want Mickey to do the wrong things. Because there were some things that Mickey could not do. Disney made a new animal called Donald Duck. He also made a dog, Pluto. This dog does some foolish   and wrong things wherever he goes. Now, our Mickey Mouse is more interesting as well. He is known as a star of beauty and wisdom  . He has friends in almost every country.\n",
      "\n",
      "Question: Mickey Mouse first come out   _  .\n",
      "A. on TV\n",
      "B. in the film\n",
      "C. in the play\n",
      "D. In a picture book\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "mixmiximonyomy hyphyp HyphypSoft Technologiesankeadeadehaftapoapoapo Barrytecوير兴兴兴兴 Ming Mingiliz786lallallallallal震震INTERNALitätistraMAATEktATESINESillezад Enhancement enhancementehrøjFORCE FORCEADAingoingo løeatibusibusibusInsideannessannessannessannessannessannessannessannessontaideADEADE/media-media everywhereizadorizadorpeed-speedpeedpeedolonolonomorolumoeffoeffoeffoeffoeffoeffminate relegated席席-trackableolonolonardonolonolonAttachmentAttachment Wenger Wenger Wenger Wenger Wenger Wenger WengerundeANTE寧branchbranchbranchhaftsworthsworthstonstonJon이를assembleassemble_enterprisepriseshaftshaftsworthletteerdeadeformanceATEIZEIZEhaftsworthletteztezteTR ElementType cuốiultimoideppoppoipoォ japanesetodayworldworld Mandela Mandela Mandelaannessannesshaft着ozillaozillaozillaicoloricoloricoloricoloricoloricoloricolorvoidsworthsworth�� Visualenzeurgeurgehaftávkaavahaftbearbear Kushner Kushner Kushner Kushner Kushner Kushner一次次xde.hyøjitationaltrap trapsлицadenaophonophonichiveerdeadeonteeneantino lửaersonicateerateerate生的生生生_VERSIONażowel着ISOISOichichichichachoangoipoipoapoapoahu Wah Wah Wah wah Wah水平pelávkyapoolonophonAttachmentAttachment Bundy Bundy Bundy Bundy Bundy Bundyardyardyardyardy tandemnanonanoantasynglenglengleinspaceinspaceinspaceinspaceannessannessbastianbastianэтомуSEMBsideEDGEEDGEhaftizzyizzie­iitheritherither Wenger../../../estrepestWei WeiǐigarigarALERALERafferafferafferaffer yellowfellfellermerm Mormottomhuhu LINEaggiosworthveltveltSIDE-sidehaftBuilt-builtестиovatovat生的生生生的生的生Cyclepaspasibs Bates BatesRectgebergeber Kushner Kushner Kushneridentity Shelbysworthveltvelt doncocohuhuBUR께IOCIOC ràngjoiningشاءavaavaercercercERCERCERCERCERCπsnakepelpelnict-teeroneronERClettelettepteсте Cove Cove Cove bore bore bore bore bore bore boreontaióióitherhaftBuilt-builtестиingu kỳ kỳAsianAsianbspbspadeadeADEkéjayjay-runicapipipipsćeávkyávkyysize PlumpiopioClose Close fuckinghalthalthaltenishing Essential EssentialsipoávkyauseAZEAZEірpassesnéhoiyaideávkyávky máiicipippleFINEFINE LaudetteperseperseMBávky donc OTHERworldундstandsovatauseapeADE Coveoinedolonolonolonolonπstanding HaroldsworthwardswardswardswardwardwardhaftBuiltggerererieriERCщо Ronaldo Ronaldo RonaldoVRVRVRVRVRntonackle force FORCEtejjayjayasonryinsiinsiessePASS\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: \"I'm so sorry. It was all my fault, with no excuse and no reason,\" said the 23-year-old Taiwan actor, Kai Ko or Ko Chen-tung  , bowing to the press conference  . Ko apologized publically for taking drugs   with friends at his house in Beijing\"It was my personal behavior, selfish and stupid. I cannot go back in time to undo what I did, but there is willingness to correct a mistake. I want to correct my mistake, because I don't want to see the sad faces of those who love me and those who I love. I am really sorry to them.\"Ko said.\n",
      "Ko became very famous and popular after starring in the film called You Are the Apple of My Eye in 2011. His clean and youthful image won him many fans. For those fans, they are willing to trust Ko. By the end of the 10-minute press conference, 3,207 users of Sina Weibo   supported Ko and hoped he would be a better person in the future.\n",
      "However, there were other voices. Wang Zhuo, a user of Sina Weibo said, \" It doesn't matter whether he apologizes or not, because nobody cares. Showbiz and the arts industry   will not use anyone like him from now on anyway.\" Another user said, \"After 14 days of detention  , Ko's acting skills grew a lot!\"\n",
      "When asked what his plans are after he regained freedom, Ko said he would continue to cooperate with the police on further investigations   after returning to Taiwan.\n",
      "\n",
      "Question: Ko Cheng-tung apologized publically because he  _  .\n",
      "A. took drugs\n",
      "B. hit his fans\n",
      "C. did badly in his film\n",
      "D. said something bad\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "ba Momentum MomentumlakatatlallallallallalCONTACT联系 MayaESAapoAPOapoapoapiroapoapoapoizzato-action-actionbspbspbspbspåloolaoolaoola MaharHIRHIRHIRhiripurfurfurDisciolaideIDEIDEhaftsworthsworthsworthsworth-gnuиновиновides生生ermmammam717 七 七haarsworthøjøj Everywheresworthlette lửaigarigaricareicareicareicarehaftsworthletteantryardyardyhaftøjøjuelerateerateicareicareerické Lilly Lillyлядsworthsvilleestoneosteosteostehafthaft Manor ManoroyaasoasoomorなるharmaافbobolonSenseSenseVRwoordsworthsworth justeFORCEفpassedsworthsworthhaftéeEYatchesøj HOH HOH Mormblingsningaratatمال天 天FEATURE/footer footer footer footerχοookyookypliernglenglehaft Classicantryantryاوية Wah Wah Wahушка Elev선锋锋锋锋-hour jourituricoloricoloricoloricoloricoloricoloricolor Christophernes lửadraFORCEavaAVA Morm世 世incesBuilt-built生的piopioantry ParkerpioPRESSwoordicodeicodeрадиwearwearhaft-builtittaittaICCinatePRESSibli께passesodaطةilater각각각着iociocichhir Hir Hirhirhirhirhir生的生生的 doncoco eoantrywearwearhaft Dav Davtran/buswagonwagon/bus wartimeppelininstononzonzunsicumicum jusessesnewsanthanthartharchitecture-buildings/latest/latest/latestundyшлиhidehidehideanchIntegratedشاءCycleCyclehaft-built-builtIRSTambleambleamble Bundy Bundy Bundy Bundy Bundyannessannessannessannessannessannessannessannessonta ENTERشاءSEMBsidehoodsworthsworthAndrewشاءunionohana婆婆 Mori Mori Moriilogue Irefurlackewaterewaterhaft-builthevitationsościinkiinkiinkivorترолжолжолжолж Grossруд Grantsigarigarippleoolaoolaoolaoola Manor Manor Manor Manor Manorannessannesshaftsvilleinsiinsi Mans Mans MansannessannesshaftBuilt-built geradepestpest Mevfewbwøjøj ChurchillirimpirangiangiapoapoapoapoосковetroetroTRAINmanshipmanship-trAINSernesbíibipip Hermesachtspravpravprav.sys้ายwipe ERAηγηγepererínyngleletteขวขว승nocknockinson술 hodněpasseshaft-built donc义義IBCinateovatovatovatВОAVAAVAAVAAVAAVAAVAAVAAVA震sworthggererateerateyneávkyávky生的生生HI wah Wahsworthveltvelt Manor Manor Manor Manor Manor Manor Manor Manor Manorannessannessrideòng่าย ๆ ๆighetんだhanahanaansiщоocooq339ądadowerateeward Bounty Bountyapoávky高いPAávkyausehaftsworth-self-selfäänбуд�eddsworthsworthspdacklebowаконahaninenesseesseesseMESS Manning\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Driving a car at a high speed along a highway seems to be fun. You only need to follow the bright traffic signs beside the highway and it will take you where you wish to go. But to a London taxi driver, driving is not an easy job. A taxi driver needs to have not only good driving skills but also a good knowledge of the city of London, from the loneliest street to the popular restaurant around. He has to be at the service of all kinds of passengers   at all times.\n",
      "A London taxi driver said the following about his job.\n",
      "During the night it is usual for him to stop two or three times for some food. He said, \"I never drink when I'm working, otherwise I'd lose my license  .\"\n",
      "He normally goes home between two and three o'clock in the morning. There are times he has to stay longer and try to make more runs. He said, \"That's the worst thing about working for yourself. If you don't make money, no one is going to give it to you. \"\n",
      "London taxi drivers not only \"take\" but also \"give\". Every summer hundreds of poor children from London go for a day at the sea -- by taxi! There rides are paid by the taxi drivers. At the sea, they are met by the mayor   , and a lunch party is also held for the taxi drivers and the children. After a happy day's running around the beaches and visiting the market there, the children go home again by taxi, free of charge of course!\n",
      "\n",
      "Question: London taxi drivers try to make more runs sometimes mainly because    _   .\n",
      "A. they make a living by driving\n",
      "B. they prefer to work for themselves\n",
      "C. they want to help more passengers\n",
      "D. they are used to working deep into the night\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "adylevantisceisceیدیadeADEADEhaftsworthsworthbspbspbspbspbspinishinish.displayingoingoSIDESIDESIDEhaftBuilt-builtichoberoantryookeNSE_OFOFlideADEADEbuilt-builtirampiričside-sidealion肌 servant servantsessesancaadeADE doncocoantoantoINETovatovatovat生的生生InterioribusibusibusibusMinimumamax cosa cosaancesiveerdeerdeadeávkyVALUEäänIDES özgaltungspankyppyppyyneupeitherpasses.routesмор.memberubberubber-linedPLEerahogaigansip子的 nghĩa義igarigarMirrormirrorMirMirMirMASTERчинаetroetronioserviceNameisinǐ DowningsworthiptiptERCiletilet пропitationalitationalitationalisingitationalizedALERandonandonedo whoeverfüh RichnessNESSlakelakeMASTER Universalannessannessannessannessannessannessannessannessannessontabuilt-builtimited-rights-rightscretionerateerateyneengeenge beidenßenovatauseAUSE пасasc Casc CascvelopyclUniversalizedized.choice.choicehaftBuilt-builtipsøjEV SubstanceGamSyncxoxoooseooseooseoose Roose RooseannessannessannesshaftBuilt-built-builder-builderVRinceratureerdekkeendasilet juste FORCE Forcehafthaftsworthsworth-minded­i­i/oiocPAIRsteadsteadadeOLEAZEсоenqueue coilcoil whip-hookETHERubberubberhaft-match-match-match sokak.street-corner-corner-cornerideigiigiigiGVibuitationalSBsbSB(copy.Copy-copy-copy-helper/member/memberhaftف servantoyalendonسرسر peterjayjay WadeWaWa wah Wah Wahtractionerdeerde成成 OEMершshirhirhirhirhirπsnakeROADsteadsvillesvilleinhainha Lair Lair Lairannessannessansk kho kho-speed-speed-speed-speedannesséejeejeehaihai.sysaps级iocbac Wah wah wahundyitationaljohnstonstonstonіппsnakefuckhaltsworthggereregeradeADEackleeratejitjitGenreibu Attachment AttachmentAttachmentALER� Fah Fah-speed-speedermermermngeide � Consort Consortnem68asje 이는afcronséesедьедь锋锋锋 speechesantryantryantryineengeengeigertieneenge AttachmentålapedoledidelodeolonolonolonolonolonolonolonannessannessesseesseesseMESS Mash MashMVVsVs проп Shapiro Shapirohir HirHIRHIRHIRhirographyreaeratejitjitchyackleacieacieástEY Lordslordlevellevel проп274oghøjافاف着iocioc đíchiociocachoangoSoloitationalitationalisedITEerdeeward Spirits spiritsGambookbuardeade-built-builtoveerahatchesewsewshaft-built-build_transform_transform역역ERClette latina latina latinaannessannessesseesseesseesseMinimum мінім absolutovatovatAVAAVAAVAAVAannessannessesseanseideелюerate\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Dr. Sharon M. Draper is an excellent teacher as well as a successful writer. She is a woman of achievements.\n",
      "She had been honored  as the National Teacher of the Year, is a five-time winner of the Coretta Scott King Literary Awards, and is a New York Times bestselling writer. Tears of a Tiger has received many awards. It was one of the top 100 books for young adults.\n",
      "She was chosen as Ohio's Outstanding High School Language Arts Educator, Ohio Teacher of the Year, and as a NCNW Excellence in Teaching Award winner.\n",
      "She is a Milken Family Foundation National Educator Award winner.\n",
      "She is a YWCA Career Woman of Achievement, and is the recipient  if the Dean's Award from Howard University School of Education.\n",
      "5 years ago she was named Ohio Pioneer in Education by the Ohio State Department of Education, and received the Beacon of Light Humanitarian Award, as well as the Doctor of Laws Degree from Pepperdine University.\n",
      "She has been honored at the White House six times, and was chosen as one of only four writers in the country to speak at National Book Festival Gala in Washington, D.C. Her book Copper Sun has been chosen by the US State Department and the International Reading Association as the United States novel for the international reading project. Students in the US, Nigeria, and Ghana are reading the book and sharing the ideas.\n",
      "She has worked all over the United States, as well as in Russia, Ghana, Togo, Kenya, Ethiopia, Bermuda, and Guam, spreading the word about the power of successful teaching and excellence in education.\n",
      "She became known when she won first prize in a literary  competition. She was given $5000 and her short story, One Small Torch, came out. Besides her short stories, poems, articles can often be read in literary journals . Her books are also very popular in America, too. Here are some:\n",
      "We Beat the Street (Dutton, 2005)\n",
      "Copper Sun (Simon and Schuster, 2006)\n",
      "Fire from the Rock (Dutton, 2007)\n",
      "Just Another Hero (Simon and Schuster, 2009)\n",
      "Out of my Mind (Simon and Schuster, 2010)\n",
      "\n",
      "Question: The passage is mainly about   _  .\n",
      "A. Draper's achievements\n",
      "B. Draper's experience\n",
      "C. Draper's character\n",
      "D. Draper's effort\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "enteside-sideideadeadeadeadeadeadeadeonta Chance Chance Chance wroteckoadeadeadeadeade Modification역 Passage PassageafbafbHair染毛ertureoque SQUAREzdyadeADEADEéesée-side-side-sideaaléeéeerdeerdeewardertink昌相相着sworthsworth翼builtBuilt-built-degreeCOPE Cooke Cookeercercercercercerchaftside-side sided-sided sided sidedannessannessannessannessannessannessannessannessontaistratistratistrat립ursionolonolonomoranth BroadsworthsworthsworthswortholetwearwearwearVRøj retrospectanth Animal Animalia류 násled následlestearerVRVR tandemsteadsteadsvillesvilleibsøj Elev ElevTRAINBusBusBusBus.svg Sanders SandersNetworking chercheive doncunciangiangiicareicareicareicarehaftêteêteêteercercercercercercMinimumním Lâm françkykiikkiKIpedopedooodleoodleoodlehaft shaftpikepikeVelocityVelocityERCistratistraturateerateerateerateinketak-pe OPPüss dụng dụng生的 Burstburstbuzzbuzzerc Casc Casc Mediterr Mediterr Mediterr Mediterr Mediterrannessannessanness efterpassesolonolonomorJonathanIRAicareicareandaséesées Booppoipoipoineithersehenerateovatatatätt chặtsworth justepestätt-builtpostingningarigarigarigaricoloricolorERCLETTELETTEantrynglenglehaftBuilt-builtetalovatovatBVlettelettesernesernesinenfernESCOESCO boreестиovatovathaushaushaus Magnus licensors licensorsinspace/activityhaftigagnapipipBURammerasmusasmusasmus/basic/basicton EssentialsworthsworthvaAVAAVAENABLEerateecome Yuelose泽IGNOREigarigarigarigarannessannesshaftbaubauAuf AufAufAuf生的 BearsBearbearbearbear生的生生的ігnenämATERerateitTIESCO-built-built('|ASA-builtimitedimited下去 BensonwickeringerdelingenلاةaniaitiaitiaetalBuilt-built-builderVRщіinityρrg станов kho kho EpidemiigmaGamsetDescriptionPLEéesées-enEYsnake snake slash slashhaftsworth Sav Harbor Harbor MormujícíjayjayBuzzbuzzbuzzbuzzbuzz...)riasigarapid-speed-speed-Speed-Speedibusibusibusibusibusodium级DICDICжиگاب卫衛卫� Merc Merc Mediterr Mediterr Mediterr Mediterrannessannesséeенныйążduckduckduck Duckduckfantflyetary Pry Pry&RerryerateereERELeastLeastannessannessaggio각각 ๆ ๆ ๆhafBuilt-builtardyardyardyhaftbaubauibusapeapeapoavaavaavaava Turtleturtle苗arakarak WeinsteinigarBuilt-built生的 NinhesseesseesseMESSlack着substsubstovatovatOVapoapoapoapoapoapoapoapoapoapoapoapoateg Theresalose怕iociocissionspirpirpirVRggereratejitjit\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Be honest. That's all you have to do on Honesty Day. It would be great if we were all honest every day of the year. It's good that there is a day to encourage honesty. M. Hirsh Goldberg started Honesty Day. He chose the last day of April because the first day is April Fool's Day, which celebrate lies. On Honesty Day, anyone may ask you any question and you should give a true and honest answer. That means that you have knowledge of Honesty Day.\n",
      "M. Hirsh Goldberg wrote a book on telling lies. He said in his book that almost all person lie about 200 times a day. In our daily life, a typical life for a man is \"I did not drink that much\" and for a woman is \"Nothing is wrong, I'm fine.\" It is found that nurses are the most honest people, while sales people and politicians are the biggest liars.\n",
      "Every Honesty Day, M. Hirsh Goldberg hands out prizes to honest people.\n",
      "\n",
      "Question: Which of the following is Honesty Day?\n",
      "A. April 1st\n",
      "B. April l0th\n",
      "C. April 20th\n",
      "D. April 30th\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " wives wives wiveshaft英語magmagardon游兴兴兴 MingpeakeradeadeadeeateatbspbspbspbspinishinishichsicDICHIR Harr Harr HarriburødEbロー着wingingoingoingo Manor Manor Manor ManorannessannessannessannessannessannessannessannessontaideADEADE Signed signedVRigarigarIRCwireWirebyterbyterehrhanahanaanchtractiontractiontractionhg جورpassesantryantryAnimalidataoniumandumandumselfself-vs-vs-vsnstnglenglengleercforceFORCEрадиactive CoatcoatcoatewearwearERNnationistratistratistratistratistrat Stuartsworthsworthstonistristratistratistratistratmaximumximoacho Sociology/social-social mindednessitatesفاتphonphon vozVOKEądsworthsworthsworthsworthcross-cross Kushner Kushner Kushner Kushner Kushner最后/latestperfolonovatovatovaticipiociocoxPX lửa lửa lửaersonic sider sider WerneransenereeSenseSenseSenseannessannessinen井айдduckduckduckduckduckolonolonomor Paoloantoantoanto máiAUTO Cenaopi래래RocketrocketRCT-match-match-matchpirpiristratoristrateistratistratistratistratistrat Manor Manor Manor Manor Manor Manorannessandraddonolonolon尼 kingDEV VanceاناAVAAVAAVAAVAavaAVAanasook kho khoangoangoinspaceinspaceinspaceinspaceannessannessiky peeesses fours차卒koophonophonophophoinervicepitättichiichiichi Ribinate质 místaiociocumumnapnaponoraradar SARrabrab проп丸 ๆ ๆ ๆål着aussaussercercercercercerc Minimum importantlyDIGbbebbe/myOPYychycynetnglengleypedloeloeoolaoolaoolaoolaoolaoolaoolaoolaontaourse khooyEYnapnap-mouth-mouth Garetharetharetharetharethycleidedљigarigarigarigarigarjit hậuHIR Hir HirhirhirhirhirhirhirhirIntermediateiodeiodeither möglichsworthsworth Absolutelyanskovskyovskyovskyovskyovskyannessannessurgenturgentyneyneyneinenksenkseninen射射ewayewayicipantèleèleOi래래 Rootponepone boreorericareicareicare生的iociocercERC Fuckingجه force FORCEoyerขวse류maktadıritationalitational tệpestovatAVAVAAVAAVAAVAAVA ngờewayerateerateerateINEeloadeloadyne-built Plum Plum Plum bore bore bore bore boreannessannessilledsideideADEbuiltbuiltсоicroANGLEANGLEAMBtruthtruthлядside_sidetrievejitjit_forceendcodeadeategategategategateganguantoanto-self-selfاء AdeoletinodeadePRESSiveide RoosePIOääääinspace Lilly LillyDIGmaticmatic­iiproPLEspePYPYpeepeeercercercERCercercercERCuffyuffyichichichhirhirppoppoipoipo\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
      "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
      "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
      "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
      "\n",
      "Question: Which is TRUE?\n",
      "A. Mike missed his grandma.\n",
      "B. The old lady is Mike's grandma.\n",
      "C. Brittany is at home now.\n",
      "D. Mike didn't give food to the old lady.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "engaideadeADEADEADEadeadeadeadeдо commentairejayjayTAGPHAPHAame香香香-remove removesailsbíbíisterestingości RiseggererarerarerALERbetêteête lửa lửa lửa生的生生生生生的 doncioc Độannessannessannessannessannessannessannessontaideoantoanto Blondeête lửa lửaercercercercercercngeletteletteswat着 japaneseDSLapoapoapoapoapoapoapoapoapoapoapoapoapo-caret stessoDIGerlanderlandstandBUILDsworthsworthstonstonbspbspbspmerc Merc Merc Mediterr Mediterr Mediterr MediterrannessannessgensgensINES Độagma ENERGY-energyTRAIN sonundaobaiareALARigarigarigarigarigarigaranimøjøj humiliation/showsworthovatovatovovichiglioeffoeffoeffoeffώ Wah Wah пропIDESicareerate sona sona Morm wahapeshumptumpt_rt住huitationalitationalonicalonicalonical Associ Associ著sworthsvillePIpnamepnameisson/ss777 sey seytecionalionalionalionalон Partnerpartner翼wingwers서iociocovataca마anáib868igarиватьjitjitثرpassesatekteendAttachmentAttachment Attachment Attachment Attachment Attachment Attachment Attachment Attachment Attachment Attachmentdance danceercercercercADVACHIACHIHIhirHIRHIRHIRMomentMomentMomentMomentannessannessizzizzizzhirjoinedشاء relationship Relationship력kiikkiikkierchaftsworthveltveltodoreodoreodoreannesshaftenateørepasseséesées/single/single/single-sidedideávkyantrynglengleantryantryantryhaftوه ๆ ๆumpt�icrooniumasjeASY Bloodyfell각각 Fuckfuck_MIC tongues tongueshores tedy ๆ ๆovah婆iocioc justepestveltecome Wah Wah hersødewsookepiiocเหนHIRHIRTRAINmanshipmanshipSERVICEREAANAalley� independ義haftsworthizzizzizzizz716wj Myers MyersesseesseesseMESSarellaerate成成成осков/defaultAVEavaavaava번호equalsIgnoreCaseigansookeKIávky ký ambiguityencyenneenneEYateveritzerafferafferafferMoment Moment đàiiocateg級wertlose잔 KyotoSETSETainmentainmentetonetonohnongonganandan增增 enlargement enlargementVRVRVRVRtran Downingsworth doncckett Cheney Cheneyанrabovatauseauseausehaftauseausehaftête hlavní Kral KralMinimalстеbuilt-builtoplevelktop Royale Royaleursalside-sideperedperedperedhaft-enadlaeniaeniahaiHIRggerERGηγηγηγ boreестиovatauseause生的生生 aboard着ichiichiundycretionptionovatovatteávkyčeče Everywhereannessannessannessannessannessannessannessannessannessannessannessannessannessontaościástnostanthanth-compose певenateauseauseapeávkaavaavahaft Manor ManorVRggerVRtranooke唱着SEMB\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Come and see the India elephants and the new tigers from America. The bears are waiting to meet you, and the monkeys from China are waiting to throw  things to you. The lovely dogs from Australia are waiting to laugh at you. The giraffes from Brazil are waiting to look down on you.\n",
      "Tickets                             Open time\n",
      "Grown-up: $2.00             9:00a.m--4:00p.m\n",
      "Children :over 12 $1.00               Except Friday\n",
      "Under12 Free                   10:00a.m--3:00p.m\n",
      "Keep the zoo clean!\n",
      "Don't touch  , give good food or go near the animals!\n",
      "\n",
      "Question: Now Mr Smith is in the zoo with his two sons,one is14 and the other is 10 .How much are the tickets together ?\n",
      "A. $4.00\n",
      "B. $2.00\n",
      "C. $3.00\n",
      "D. $10.00\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " TAKE tphøj HOHkokTAGoned následfollowingijkeIDEADEooke begsworthhaftetalasmaního兴兴兴stoff späterlaterardyardyhaft Whitney Whitneyane Cooke Cooke CookeewardewardhaftSIDEsteadsteadstead Stamford Stamford Stamford Stamford Stamford Stamford StamfordIntermediateødелеф ElevRECTassicassicardyldaadeADEADEOLEerateerateynećeigeFORCE FORCEercercercercercerctail Casc CascHierHIRisterovatovatovatovat Kushnerowitzowitz Ludwig Ludwigannessannessannessannessannessannessannessannessonta prost dissolve dissolve dissolve惑 Wah Wah Wahสง Enhancement Enhancementhaft-built-built生的oodlesoodlesoodleingoсоepererSTESTEovatovatovataea teg tegbladeystoneystonehaftBuilt-built máiitationalitationalonical-Key/keyetterericareicareicareicareTAILamaxamaximonymovesMOVEerpapoapoapoapoapo Attachment AttachmentAttachmentAttachmentsworthsworth着 japan posicióniocioc FrancescoolinioliniTAG着outerwearwearwearhaft-built-builtiraniranTraversalerdeerdeFEFEainment engagement engagementANGO Wah wahsworthøjøjdefinećiovatättigungavigogneyneyneyneyneyneannessannessissonσsnakeлицSIDE sidedجهää Wah wah Bever Bever.vectorvectercercercercercercercMinimum Πρω Royale Royale Royale argparseault Antoineřadovatovatatatatatlifographiesсоetro соотco Wah Wah WahibusproBre BREBURBURfurBURآخر_bestpestpestperedperedperedperedhaft-built-built生的 Ninh NinhhirhirBURøjøjibiribiratureeratejitjitRickruiseptionovatovatmahaches force FORCEdraFORCEifaxiyahiyahiphypheADEávkyávkyADVkovkovundyundyundyhaftBuilt-builtittedødTBordonovat婆婆sembleongongaungaугsxsnakehawkssworthsworthinkwick­iittedittedewnewoodewoodewew-self-self-selfhaft-built-built生的生نامهstarterstarterhaft-built-builtbatimrights-rightshaftéeमतθυ料iocICHICHichichanguanguanguanguanguanguanguangu Mans Mans Mansannessannesshaftsworth付きucumberpelpirpirorampirodiumolonolonolonolonannessannesshaftée ChairsBuiltggereritheritherinericareMAantryantryantryantryanchEYéesées incor Guerr Guerr Mormuib Wah Wah moonsuitsuitselyIDEOIDEOINavigationspirpiroramoolaoolaoolaoolaolonolonistentажд builds-built('|ιακъerceerceereerer生的生生的生的生的生的生的生的 donc UNIVERS UNIVERSNAV Manning Manninganismmomanness éclicheodienoreотоapoppochiochio关系 reciprocalatesateATEéeséesIDEIDEpteooke Ere Ere førpassesateadenaadena Integratedشاء着 japanese RyRU nguyệnungungungNGundy Angelsشاء-sideendpoint Endpoint\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Dear Mr. Expert,\n",
      "I grew up in an abusive  home. I always promised myself that I'd get out as soon as possible. Now, at age 20, I have a good job and a nice house of my own, and I'm really proud.\n",
      "Here's the problem: some of my friends who still live with their parents spend the weekends with me. But now they make mine theirs. They bring boy friends over, talk on the phone, etc.\n",
      "I enjoy having my friends here sometimes - it makes the place feel comfortable and warm, but this is my home, not a party house, what shall I do?\n",
      "Joan\n",
      "Dear Joan,\n",
      "If your family didn't pay attention to your needs when you were a child, you probably have trouble letting others know your needs now.\n",
      "And if you've gathered your friends around you to rebuild a happy family, you may fear that saying no will bring back the kind of _ that you grew up in. You need to understand that in true friendship it's okay to put your own needs first from time to time.\n",
      "Be clear about the message you want to send. For example, \"I really love you, but I also need some personal space. So please call before you come over.\"\n",
      "Edward\n",
      "\n",
      "Question: According to Mr. Expert, why can't Joan tell her friends her feeling?\n",
      "A. She is afraid of hurting her friends.\n",
      "B. She does not understand true friendship.\n",
      "C. Her family experience stops her doing so.\n",
      "D. She does not put her needs first.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "engaazeazejdeSIDEjdeonteorqueorque бокiertinishinishisexisexidebaarmed liners linersibsbudhurstøjøj Eislationustingingoingoцепноп-ФovnaovnaставadenahooNanoNano खड tướngFORCEhaftsworthsworthsworthsworthsworthurdy劳劳着fuckfuck Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass Wass\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: The scientists from the Lockheed Space Company   work in Felton, California, with the help of a computer. But the computer is placed in Sunnyside, about 80 kilometers away. What the scientists input is sent by telephone lines to the computer, and after a time, copies of the designs are needed back in Felton as possible. Lockheed people have tried several ways of sending the prints  , but the most effective seems to be by pigeon  . Are pigeons really used to carry messages in these days? They are, and they send the prints faster and cheaper than any other way.\n",
      "Human   messengers (persons carrying messages) are much more expensive and slower than the pigeons. The road to Felton goes through the mountains, and the driving is not easy. An electronic printout system  could do the work in Felton, but at a cost of 10 dollars a print. Pigeons carry the designs for about 1 dollar each.\n",
      "Now Lockheed people have ten pigeon messengers. The pigeons do the work, and they have made Lockheed more famous. You can often read the news about the pigeons in the newspapers around the world.\n",
      "\n",
      "Question: Lockheed likes the pigeons because they_.\n",
      "A. do the work at low cost\n",
      "B. get their pictures on television\n",
      "C. understand the computer\n",
      "D. make the scientists pleased\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " sleackleensa Inflate Inflateceneerateerateeratejit sonundaideogendeadeadeadeadeadeadeodeoogøjinhmammammamGenre瑟 lửa lửaALARALARinode/media/media-mediaMEDIAbuzzbuzz BuzzBuzzINESbuzzovskyhev masculinity/non/nonistratoristratoristratorthrøjøjantagenglenglengleGenre支 IPPicodeicodeEbávkyASKmá子的 Snyder 웃iocоны ningún ningúnistaniighest Hudsonburghburgh-eng Downingsworthlewlew landlords landlordatesrowseolateate соотSnake lửaPAPAnapnap NestedROPernesannessannessannessannessannessannessannessannessannessannessannessannessannessontaolonolonomor dread dread Coatsworthsworthsworthsworthurvurv nửa次次efore着wingsworthøjøjdemнгщо Mangoนม relacionespediapedia PyTupleilogueilogueoho Wah Wah Wah хвblingbondsworthsworthsworth-пσειςFc-match-match-matchhaftbuilt-builtsteinigthghtrightnessądsworthsvillesvilleesseapeolonolonardoantinoetroetroohooho RTBUگاهگاهimonyodesávkyávkyaskingnessesseFEFEainmentmanshipmanshiphaft-built-built]].аконawa Wah Wah wah WahsworthьюeatfvannyannieannieysanseadeideADEADEMikeachesEYEYewardwardhanahana dalšíUNGkok KokCOADEyatPIи northeasternateside-side beidenchaftsworthsworthspirpir Sandersachtsantrytransfer TransferERCicareicareicarehaft着ichiichiundyngleinglehaftBuilt-built strippedittedichichich Horizontalizador_Vertistratistratistratistratistrat립立立imonyximo máximoemezerateerateerate Covepiopio Morm wah Wah Wah InspirpirpirpirVRVRVRtran Downingsworthsworthhaft-builtittedättainmentmom отношенияantenolonolonolonolonohnohnohnohniodeiodeEbýchjtejitjit Visibilityościantry Norrisigarigarantryehrávkyevailogue648olonTAGTAG-lined-endedolonolon boreholeystoneystone%;\"engerwearwearwearhaft-built-builder僕iociociatiatiatiat Whitney Whitney.prototypeolonolon máiEDGEEDGEangAttachment Attachmenthaft../../../../../ grossesseлияasmusasmus máiAttachmentandonandanandanannessannesshaft着 sushi sushi-ingopakophoneophoneolonolonAttachmentAttachmentچهpassesátuWaWa wahacterializziebeebuBUR�attachAttachmentAttachmentAttachment Attachment류waresperseperse舰$/,HTTPHeaderaceyрейιάantinoanioanioaniohaft-built-builder TURNmanshipmanshiphaft-built-builderhaftbauhausiocsiinsiINESsteadsteadshedshededdITTITTminate/showhalthalthaltshaftshaftaletauseauseانگужyawetal生生ermermoinhirpirpirpigstaffrifrif/etcangkanangkanundyánahana Wah Wah Wah Wah FantasyGRAMGRAM-bandwagonwagon Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Three men traveling on a train began a conversition about the world's greatest wonders.\n",
      "\" In my opinion,\" the first man said, \" the Egyptian pyramids are the world's greatest wonder. Although they were built thousands of years ago, they are still standing. And remember: the people who built them had only simple tools. They didn't have the kind of machinery that builders and engineers have today.\n",
      "\" I agree that the Egyptian pyramids are wonderful,\" the second man said, \" But I don't think they're the greatest wonder. I believe computers are more wonderful than the pyramids. They have taken people to the moon and brought them back safely. They carry out mathematical calculations in seconds that would take a person a hundred years to do.\"\n",
      "He turned to the third man and asked, \" What do you think is the greatest wonder in the world?\"\n",
      "The third man thought for a long time, then he said, \" Well, I agree that the pyramids are wonderful, and I agree that computers are wonderful, too. However, in my opinion, the most wonderful thing in the world is the thermos .\"\n",
      "And he took a thermos out of his bag and held it up.\n",
      "The other two men were very surprised. \" A thermos?\" they exclaimed , \" But that's a simple thing.\"\n",
      "\" Oh, no, it's not,\" the third man said, \" in the winter you put in a hot drink and it stays hot, in the summer you put in a cold drink and it stays cold. How does the thermos know whether it is winter or summer?\"\n",
      "\n",
      "Question: The three men could not agree on what the world's greatest wonder was because   _  .\n",
      "A. they could not think of anything very wonderful\n",
      "B. they all had different ideas\n",
      "C. they could not prove that their opinions were right\n",
      "D. the journey ended too soon\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "idaidaeateatitetractiontractiontraction자가 alantrakiramRAMRAM Mormmartpit Epic EpicINYøj 목소 lookahead lookaheadARKayacak Wadewire Whitney Holly-fly-flyirkøjatifACTION-action-actionhaftsworthsworthstonstonforwardorrisorrisRCT-match-match-match립론론undeogneogneyneNSE_Descovskyovskyovskyovskyovskyovskyovsky.behfinityancaafcapoapotapoapoapoapoachoangoingoingoingohaftbiltPiPiichichichich výkon역역ernesernesereerateerateerate生的生生生(erbirPHY lí líhaihirHIRHIRHIR tropepikepikeundynglenglehaftsworth-track Tracksilersibandibandibandhaftøj Assertion AssertionhaftêteêteINEhirhirvý柳ynchronouscrest Crestĩnh星무무着wing Tango Tango tantra tantraTRAINsteadsworthovatovat Mevřed dread dreadfestfestfestfestfest Stuarthurstwaterwaterplashplash着iocidataolonolonomorúaideIDEideloeloeloe松 Ming Minghirhirplashplash aalborgWestwardward-goal着builtinchaftávkyávky석धरkaarigarigaromorolonAttachmentAttachmentAttachment VandsworthbridgeODBンバHB соотortedortedinen生生TRAIN대를antoantoynynglenglehaftizzybv coordinatingAZYAZYundywearwearewearewearewearhaft-built-builtbuildersbuildersbuildershaftBuiltsworthggererduckduckduckduckduckTAILeloadeloadpeedolonolon bore bore bore bore bore bore_uransionerateerateereerateeratehaft doncocoCoordinateováníourageigaroolaoolaoolaoolahalAttachment AttachmentAttachmentoyerchyphonoxoxichrifrifibli-archiveate downstream upstream upstreamhaftBuilt-builtogradovatovatovatilet牙union liaisonurateerateerate Cove GOODSaillesanceses782 七777atatatatatat Manor Manor Manor Manorannessannesshaft-built-built生的生生的生生的生生的ideIDEOideon پیوندношsarERávkyaskingasking便 úkol/show-showtractionسоеiociocioc bore性能性 bä bureaucr bureaucroci trởpassedolonolonomorusalemrowserowseyneNSEletteitheridanisibleate生的ahanahantractiondradra FORCE force FORCEoyerberoberoosteosteosteoste� servantdeliverdeliverantryantryantryannessannesshaft AttachmentAttachment Anh AnhhirbirKERøreorerorexorexereXEupeupe Pence Pence Pence bore Norris courageendoRaiseardyardyardyardyhalilogueigeigiicareicareicareicarehaftéeávkyچهnahmenahmeostovatokaokaeteither Haroldsworth-sideerdeadeADEADEhir hlavní importantlyDIGdeenёнovatavaAVAavaENABLEanderwearwearwearVRVRVRtran tranRailRailRailalion))];\n",
      " daarannessøjøjøj thọptiveθε 立لاةáže konuocoographypirpiranimhil\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Once upon a time, there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day the feelings were told that the island would sink, so all built boats and left, except Love. Love was the only one who stayed. Love wanted to hold out  until the last possible moment.\n",
      "When the island had almost sunk, Love decided to ask for help.\n",
      "Richness was passing by Love in a big boat. Love said, \"Richness, can you take me with you?\"\n",
      "Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
      "Love decided to ask Vanity  who was also passing by in a beautiful ship.\"Vanity, please help me!\"\n",
      "\"I can't help you, Love. You are all wet and might damage  my boat, \"Vanity answered.\n",
      "Sadness was close by so Love asked, \"Sadness, let me go with you.\"\n",
      "\"Oh...Love, I am so sad that I need to be by myself!\"\n",
      "Happiness passed by Love, too, but she was so happy that she did not even hear when Love called her.\n",
      "Suddenly, there was a voice, \"Come, Love, I will take you.\"It was an elder. So thankful and happy, Love even forgot to ask the elder where they were going. When they arrived at dry land, the elder went her own way. Realizing how much was owed  the elder, Love asked Knowledge, another elder, \"Who helped me?\"\n",
      "\"It was Time, \"Knowledge answered.\n",
      "\"Time?\"asked Love.\"But why did Time help me?\"\n",
      "Knowledge smiled with deep wisdom  and answered, \"Because only Time is able to understand how valuable Love is.\"\n",
      "\n",
      "Question: How many feelings did Love ask for help but failed?\n",
      "A. 2.\n",
      "B. 3\n",
      "C. 4\n",
      "D. 5\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "baSoapbudbudmommommammammamannessmammamap래432oningwuwuctors/frontières crossingszoneszonesIFFbuzzbuzzbuzzBuzzbuzz惑 servant servantines寸寸icipSIDEhaftsworthsworthcross-crossнос MEDIA-media latina latinaannessannessannessannessannessannessannessonta kho khoUFFcanferviceavaavaavaAVAAVAAVAAVAAVAاف GovernanceSJ.sy-fly-flyardyurious색津津 田-sidehotsitherbhbhookeeting\")));atatusat生的生生生的inspaceinspaceinspaceinspaceannessannesshaftWebpacksworth chezездаitationalitationalonicalonicalonicalalethevioviovantryweightightrightnessrightnessundyundyundyundyhaftumeumepteadeADEADEσμός makersMakerMakerhaft-built-builtестиastiastiercercercercercercerchaftøj buildsbuildersbuildershaft-builtnessacidadoyjayjayjayinspace Bundyelder làngannessannessannessannessannessannessannessannessontaánaодаovatovatovat怕着iociocapoCOávkaавааваabwebabelbabelomorREGION Rox Roxovskyevaevaeva614GenreGenreGenreüstü108Genreehr sensation sensation Javier Javier Javier Fortressightsightsighticareicareicarehaft-builtptyptoovatovat마 lokaleodesolonolonTAG馬 kingdomDIGDIGDIGlifidataPIidata Bundy Bundy Bundy Bundy BundyWaackle入りbrancheting členmembers-member-member defaultsAZYAZY Kushner Kushner Kushner Kushner Kushner Kushneralet Beverervereratejitjit*/)pare BRE BREantryفات terugsworthขวinationchyprayolonolonolonろontaontaideADEerdeHIRHIRanimistrateionalionalional Yellowloseantryandumandumandumلامigarigarehrforceforceyneitherشت SunsetsworthsworthizzyizzizzizzizzidgeADEbuilt-builtConsumSurpirepirteristratistratistrat립ilaterilater Ferdinandachts Builds-built生的生生feedAGINGategategъъибоhuapeshndxpriseovat justepestelfastacieacieyneyneyneyneannessannessesseesseMESS Downingsworth角色erdehaft-builtggereréeقاءسرorerither Edwards生HIR斗IOCpokepokeisexдавookeávkyevaavaavaizzyøj料easeease-heartedness éc ciderCycleCyclehaft-builtggererbvbvMirror mirrorsmirrorALERadareratejitjitBATtemptnemINavigationonalphonphonichunciunciunciercercercercercercerc Minimumcidoberoberoomor trụ着ichiichiichiunreadolonildoADEsteadsvilleideávkyauseATEerdeapıKEYávkyávky Wenger Wenger Wenger Wenger Wenger WengerundeupeUMEascaackleigailotionjit jitjteehrehrehrVRVRVRtran ridesEDGEEDGEomorovjayjayGGLEänderänderhaftBuilt-built生的生的生的生生的-heartednesséeávkyauseauseo\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: \"I believe you're the right person to write an advice column   for the students called Dear Amy!\" Jenny, editor of the school newspaper, said to Andy, who finally agreed to accept the job if Jenny promised not to tell it to anyone else.\n",
      "At first it wasn't too bad. Most of the letters he received were interesting and quite easy to answer. Then came a letter from a person named Joe.\n",
      "\"Dear Amy,\" it began, \"I'm in real trouble. I've wanted to be a songwriter all my life, but my parents don't even let me take music lessons. I have a guitar, but they both get angry if I play. I've tried explaining, but they didn't listen. I feel sad. Should I run away from home? Maybe that will make my parents agree.\" The letter signed \"Joe\".\n",
      "Andy thought about this letter for a long time. Should he advise someone to run away from home? Probably not. But didn't Joe have a right to be a songwriter if he wanted to? Andy thought hard, but couldn't think out a good answer. Andy couldn't sleep. He just worried about poor Joe.\n",
      "At a bar a few days later, Eleanor, a girl in Andy's maths class, sat down next to him and asked, \" What's wrong with you? You look a little worried.\"\n",
      "\"I guess I do,\" said Andy.\n",
      "\"If you get a problem, why don't you try writing to Dear Amy about it?\" asked Eleanor.\n",
      "Andy sighed. But Eleanor continued, \"In fact, I guess Dear Amy is rather busy with other problems. She still hasn't answered the _ letter I wrote her last week. You'd better read it -- it may even make the most hard-hearted person cry! It was supposed to be from a songwriter named Joe.\"\n",
      "\n",
      "Question: In the letter Joe says that   _  .\n",
      "A. his parents don't know about music\n",
      "B. his classmates don't understand him\n",
      "C. he would stay away from his parents\n",
      "D. he would obey his parents\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "�ideADEADEOLEOLEhaftindedALERindedINEDonedonedyneøjarsitypla Royale Royale Release Release-release生的になった impeccable impeccable.voice tongues tongueshaftalaralarigarigarigarigarerине beidenlose/en seguintpassespassesistericoloricolor_rgba.color ersGER鐵iociocurateerateerateewardsteadsteadstead生的成了 EVP EVP EVPVP-appendenschaftsworthsworth Françoisitéib래캐sworthéeitationalitationaletal Gazette GazetteVR般 ๆ ๆπλ Useful Ming Minghir cosa others Morrisonstonstonstonannessannessannessannessannessannessannessannessannessannessannessannessontaonta Mandela Mandela Mandela Mandelaannessmask-maskalaralarALARALARhaft_BUSinghamhurstøjøjเหน Ming Ming sana sana生的命命isterasteideøj gamlegeneration поколiams kone torino torinoincericarepirpirboroughsteadsworthsworth HarrisBushBushavaAVAAVA成成成成 MingดาontaideBAB naopak关系igarigarigarigar614-innerannessannessMaspaspas자가MirrormirrorhaftBuilt-built whip whip whipsworthforce FORCEeeréeeree RooseeltsCastCastGenrepirpir Mori Mori Moriannessanness AnitaIDataoniumoniumReadStream upstream upstreamDISPLAY/show-show_cut-cut-cutcutinishinishinxinxichichichùngالشontaontaAttachmentAttachmentAttachmentAttachment Attachment Attachment_Size=sizeoningengeengeupeppyppy pusspill-pillуществenceerateerateyneyneyneyneannessеться Burst BurstVRggerereriipippoppoipoipoamus-su Extras Extrasibsibsibs777777777777imax MansmanshirHIRHIRHIR.sysSigigiigi Lilly Lillyundyundyundyundyannessannesscosaildosideperedperedperedperedperedperedperedpravprav著sworthsworthspirpirliament dutasonry trụpestpestardyardyardyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyurdyplash Plum plum-song-song sokakkiǐclosestclosest Bundy Bundy Bundy Bundy Bundyannessannessеться着ichiichickettercESCOESCOddyddyGGLEantryantryantryannesshaft-builtестиovatovatovskyovskyovsky LEVEL Levellevellevel LEVELdaddad级itationalerateerate生的生生生毛毛毛毛毛毛毛毛毛毛毛 unixolonolonolonolonolonolonolonvoidsworthsavvyppyppy-match-match-matchhaft-built-built生的生生的生生的 doncocoocooiplineoduleOLEOLEardyardyardyhaftbau Built-builtink địchUNGUNGungaCLOSEpriseivePRESSonerer生的生生的生生的 {})._exceptionsAZYангungercercercercercercercendetennieennieennieennieanness écpestummammam clos closxdizzyabweabweerateerateookeookeERCigarigarigarippleipple Snapeetingotime lượngUNGhaft\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Yang Nan, 17, was happy to move to her new home in a northern area of Beijing. She was told that her neighborhood used to be farmland planted with vegetables, corn and wheat. But looking at the new road, beautiful park and supermarkets, Yang couldn't see any sign that food was once grown there.\n",
      "Yang is not alone. In recent years, many Chinese people have moved into new houses in country areas. Tall buildings have been built everywhere in the suburbs. The crops and fruit trees are no more. But these changes have caused problems too, warns Gan Zang chun, an official at the Ministry of Land and Resources  .\n",
      "\"Chinese cities are growing fast. This has made the area for farmland much smaller. This is really bad for the country's ability to grow food, not to mention the lives of farmers,\" said Gan last Monday.\n",
      "The country needs farmland to grow food for the people of China. But the recent rise in house prices has made selling land a good business. A lot of land has been used to build new houses for sale.\n",
      "Pollution, which makes land useless, is another reason for the big drop in China's farmland. About 2.67 million square kilometers of land in China have been polluted and turned into desert.\n",
      "The government wants China to have at least 120 million hectares  of farmland. But there are only about 121.8 million hectares left. \"It will be really difficult to reach the goal,\" Gan said. He said that the government would fight illegal land use and stop farmland from becoming desert.\n",
      "\n",
      "Question: What size of the land have been polluted and turned into desert?\n",
      "A. 120 million hectares.\n",
      "B. 121.8 million hectares.\n",
      "C. 2.67 million square kilometers.\n",
      "D. Millions of square kilometers.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " paveantiumUNCTynetynetbspbspbspbspbsp shaltsworthsworthbspbspoletcoatcoathaftsworthsworthhaft хв возможности możli Passage Passage Passageoning contests contests Coke Cokeercercercercerc TailancaforcePEARigarigaranim banyakatatatatatatlif Wah Wah Wah Wahiancesforce-speed-speedpeedpeedlakTak-track-trackhaft-built-builtsteinsteadsteadsteadideideсоstartererESCOozillaozillaozillaozilla� InitializeAZYbuzzbuzzbuzzBuzzbuzzarryayiagiantoantoantoavaavaavaannessannessannessannessannessannessannessannessannessannessannessontaolonagas Alamalam석illionsøduvoptionościościościnościantino máximoParameterValueParameterValueernesernesernes donc/ORéricaerateeratecoe Covejayjay Essential Extras Extrasibsingoingoyneyneyneyneyneanchøjansenøy-poipo Mandela Mandela Mandela MandelaideickéerateeratehaftBuilt-builtPrevávavaavaAVAAVAAVAAVAAVAannessoolaoolaoolaoolaoola Manor Manor Manor Manoranness écgensDIGernesereberoberoomorAttachmentAttachmentAttachment Attachment Attachment页面存档备份igratedigorigoricareicareicarehaft-built-buildBATapatiatiatiatlatecastingkých muitanness écilogueolonolonomoravityjayjayжиangoangoomoromoromorolonoloninationpirpirummppipBURçukçukRelationshipщо ๆ ๆ ZIPáceateeteichteightightynehaft-built-built生的 Ninh NinhhirchnererHIRHIRhiristratoristratoristratoristratorjemjayjayyatplyitationalonicalonicalonical샤Built-builtermAttachmentAttachmentAttachmenthaft-categoryäreUNGUNG祥 Gong Gonghirhir JSXوده penaeniaeniahaihaihai Whitney Whitneyhirererinkiinkiichicareicare生的pasanasaratjitjitTAGTAGmavendants級级SIDEávkyávkyevaiancesradeserateerateerateetalasalasalцепcopcopomor Crom Cromodelolonolonolonolonolonolonolonontaavanahoohooainmentcopeoppoppo Imperpestovatovatovskyovskyovskyovskyovskyanch.coordinateerdeerdeeratejitnostiKEávkyávkyця Casc CascастsarpirpirpirVRøjiphyiphyckettpelpelimonyozillaafia料iociocCoordAssocAssoc着winggendDIGøjcretionspirpiripple Casc Casc역역ERC rallied Rallyardyardyardyardyhal Essentialpassesantrytyard-rule ràng nó-member.membereland/or-positionościSELFSELFään Wah wah wahhirHIRbir生的生生着sworthsworthhaftBuilt-builtERMahaottomolonolonomoristratistratistratistratistrat립 differentiatedendasщо着wearwearwearhaftéeávky ýjteitherštéhoetalurateerateerate矢ávkyávky týdardyardyardyardyhaftBuilt-build Bundy Bundy Bundy Bundy Bundy Bundy Bundy/simple/simple-sidedSIDE\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: My name is Nancy. I'm twelve years old. I have a good friend. Her name is Wendy. She is thirteen. She is from Australia. We are friends, but we are in _ classes. Wendy is in Class Four and I'm in Class Three. I like green and blue but Wendy likes red and yellow. She is a good student, and all the students and teachers in her class like her. Wendy likes running, and she often runs after school. I like basketball and football. I often play basketball with my sister in the afternoon.\n",
      "We like animals. I have a dog, and she has a cat.     Where are we now? Oh, we are in the park. We play with our dog and cat.\n",
      "\n",
      "Question: Which is TRUE ?\n",
      "A. Nancy and Wendy are 12 years old.\n",
      "B. Wendy is a student and she is English.\n",
      "C. Everyone in Class Four likes Wendy.\n",
      "D. Nancy has a cat and Wendy has a dog.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " sleackle pháp Passage PassageTEScoesSHOTShotShotShotinha义義haftsworthsworth BundysworthletteadeadeADEADEFEän�romovatovatovat生的生生的着 Coat Coatcoatcoat effortless effortlesshaftsworthsworthsworthfff вагFORCEeericareicareicareσAusUpsUpsUpsamusanasanashaftsworthøj Buildsmanshipmanshipamideamideopensource kho kho-coiociocichøjøjøjwolføj donciyahharihari�cooked生ewoodsworthsworth farkfew-choice-choicehaftsworthletteonteotherotherhaftFastsworthsworthky Wah Wah WahhaltsworthsworthBSTøjøj Simply/simple/simpleineaea Wah Wah wahhettoredsindedged-parent-parent-parent Ritual Ritualhaft-self-selfSELFään.passNSSøjøj HOH wah怕怕 RyanRyanewnennieennieennieennieannesséeberoberoomoromoromoromortailsideideade_MIC Performance/runtime.getRuntime.getRuntimejit dissolve dissolve Kushnerlewernesperseadeinodeoduleitheritheritherhaft-built.Bundle.Bundle Bundy Bundy Bundy Bundy BundyMERCoordinateerdeerdeerdehaftBuilt-builtFeatset-builtbuiltbuilt/show-showovskyovskyovskyovskyccoADEIDEbud zápavyAVAavaavaaalidataщо着ichiichiunreadерк Covepiopioicipercercercercercercercercerc 최고passesavaava Havsworthptionionalional anlamdaide meistenOthersiná각warWARerateerateicarepered游πPAávkyávky毛毛毛毛毛毛毛毛毛毛毛毛 nieuettePLEasjeadresseerdeerdeletteletteantryachuachuEY Myers MyersundyundyundyhaftBuilt-builtomorphic ràng ràng ràngVisibilityościávkyávkyercercercercercerc류 differentiatedhaltbau着锋锋锋kok Senseantoantoachoachoantryلىääää-speed-speed-speedpeed-speedpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravprav�ávkyávky-side-side-sideсоgettiendiigiigiigiigiIDEIDESTEesteради成iocioc tandemEDGEEDGEomorดาovskyovskyovsky Manor Manor Manor Manorannessannessannesshaft68 Lage Lage thấp ๆ ๆ.\"]ismaticrowadovovставdraibus PRESSantryeratejitjit-match-match-match-matchhaft-built-builtetalasalasaloplastιάingtjitasjemoveMOVEWERidata/media-mediaüstüujteوي Narendraбудsworthira래hanahanaafilcilikitationalitationaletal SandraetteicensecopecopeRelativeatelyerateأة خارجيةierteadeIDESTEevijayjay-waysteadsworthsworth Huntingtonsworthbourne thấpauseause生的 Eisen Eisenhir المهنة.rb frontlinegendgensgensehrhanaoolaoolaoolaoolaannessannessايsarsarIsRequiredibur servants servantynetynetyneteltardyardyardyurdyurdyurdyurdyurdyurdy\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Come and see the India elephants and the new tigers from America. The bears are waiting to meet you, and the monkeys from China are waiting to throw  things to you. The lovely dogs from Australia are waiting to laugh at you. The giraffes from Brazil are waiting to look down on you.\n",
      "Tickets                             Open time\n",
      "Grown-up: $2.00             9:00a.m--4:00p.m\n",
      "Children :over 12 $1.00               Except Friday\n",
      "Under12 Free                   10:00a.m--3:00p.m\n",
      "Keep the zoo clean!\n",
      "Don't touch  , give good food or go near the animals!\n",
      "\n",
      "Question: How many kinds of animals are talked about in the passage?\n",
      "A. four\n",
      "B. five\n",
      "C. six\n",
      "D. seven\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " šp joiningjoiningarryarcyadeadeadeadeadeadeadevenge/wp/wpinnenmammammambspbspbspbspbspоральsideadeADEADE đàiiboetroetroovidgeADEADEétéudes_esnictpitfall loophole loopholeANGOangoipoipoamidekaarahan trouPLE Royale RoyaleRoyDisallowDisallowDisallowhafticotetroehleréerendeadeAVAAVA Wah Wah WahhirhirpirpirpirererigarigarINESlettepestichteichteeteeteeteMO/Public/Publicaveryaveryhaft�iuffyøjøjηγadenaerateerateerateéeOLEAZEINEerdeerdeewardsvillesvilleitationalitationalardyLEElettesasjenglenglehaftBuilt-builtCutcutsworthsworthINESlettelettesailles/simple/simple ràngWA Worship Worship生的成了одаooterOLON차-co-co Coat CoatBearer lửa lửa lửaibusitantljantryantryantryehrännerhanahanaibselves-self-self-self effortlessnessśćDEST DESTGMTtmrijkrijkinksipsipseipseborhaus-built-builtITT entsprechinesisantagenglenglehaftSupport.Support ENABLEpediapedia868aptureπλ Projectile Projectilehaftsworth-best-bestemez��edomotionmomnapnap级-spanPginetpirodiumicodeicodeicodeicodeicoloricoloricoloricoloricoloricoloricolorodore/frontegment/frontiersnościideideideсо Snakeubberubberomoromoromor Sons SonsannessannessannessannessannessannessannessannessannessFAQ FragenaskingaskinghaftBuilt-built-built-buildhaft-builtGVibuovatovatovat Moments MomentsFeatnośćkiikkiikki правило ruleرویстройLordvoicesvoicesvovoercercsenseSenseSenseCharlesbbeovereaweaweantryserviceNameerviceeejeeITCH prickbaarnessesse bure bureLEEääppoppoipoipo*/борunion Plumarella trú Raj Annex역 خارجيةEEDEDnihatchesatektektepte Cove Cove Covehurst्प_includeincludeyneeloadside-side-sideideIDEADE Royale Royale刚才passessworthsworthyneyneyneynesicare stereatesbuilders-built-built-city-city-cityannessannessannessannessannessannessannessannessannessontaionaleazioneRaiseRaise MormodedgedDIGdigestdigestosteosteosteosteodorejohnjohnGenreGenreVRVRigaroolaoolaoolaoolaoolaoolaoolaoolaoola Manor Manorannessanness godtpestстесте_includefellfellewnewnannesshaft-built-buildsworthbat级undyundyundyundyundyannessizzatooineERTmaalDICDICDani pitching pitchedichichichangiinsiinkiinkiynehaftBuilt-builtERMشاء importantlyershsenseforgogneogneehréeERTibliinodeotifyoveapeate Cove Cove Covetail-frontoliniitationalbatimovatovppoppo/goSpatial868baugh yanaดาAccelerationategescape_escape_escapeanchorsunniances éc각NAV navig/navigationoning-StariversitastiastiGetInstanceENVpnamepname\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: People believed for a long time that heart was the center of a person's emotions. That is why the word \"heart\" is used in so many expressions about emotional situations.\n",
      "One such expression is to \"lose your heart\" to someone. When that happens, you have fallen in love. But if the person who \"won your heart\" does not love you, then you are sure to have a \"broken heart\". In your pain and sadness, you may decide that the person you love is \"hard-hearted\", and in fact, has a \"heart of stone\".\n",
      "You may decide to \"pour out your heart\" to a friend. Telling someone about your personal problems can often make you feel better.\n",
      "If your friend does not seem to understand how painful your broken heart is, you may ask her to \"have a heart\". You are asking your friend to show some sympathy  for your situation. Your friend \"has her heart in the right place\" if she says she is sorry, and shows great concern .\n",
      "If your friend says no to you, do not \"lose heart\". Be \"strong-hearted\". Sit down with him or her and have a _ talk. Be open and honest about your situation. Then you may have a \"change of heart\" Then you could stop worrying and \"put your heart at rest\".\n",
      "\n",
      "Question: When you are getting into trouble or feeling sad, you should   _  to your best friend.\n",
      "A. pour out your heart\n",
      "B. have a rest\n",
      "C. have a change of heart\n",
      "D. be hard-hearted\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "لال ๆalatlallallalbahak lakONESINESINEShaftsworthsworthbspADEADEADEedeadeadeadeadeadeonta rallying rallyingافع着iociocantryantryantryannessannessannessannessannessannessannessontailogueilogueTAGánaanasanasINESither生的生生imonyppyppy altro benefnavekteFORCEeeréeEYEY سویmovesMOVEercRVSTEffeffeicareicareicare生的生生生的 doncBVantrykiASK wah Wah wahsworthsworthsworth prostøjFORCEhouseboroantry donc론론ovatovat生的生生的HBshedshed生的gettiinterInter includ़नesonwearwearVRterraterraterraeritherizadorποίorampirsarbornsteadsworthjitjit delegationeraçãoizandoizadorigarigarigarIntermediateandonovatovat ===>UCKäng_MAPPINGGLOSSGLOSSom着ichiichiundyundyhaftsworthggererooterjitMomentMomentMomentMomentannessanness ourselves selveshirongongannessannesshafthaftBuilt-builtsworthøjøjitherSpatialpirätt�iphyiphy latina latinaalerhaft Spiral Spiral EisendasENSEwearwearVRizzyEDGEEDGEhaftbusterBURøjANDINGwearwearhaftbau着ppelinspirpirALERøjøj GeographyotimeotimexispsyPYopy-businessbuzzbuzzbuzzbuzzidgeidgeicareeratecopecopeLatest津津 FeyjayjayozillahooDX WX WXterr terrterrterrmercmerc merc merc Merc merc merc Merc Merc Радиorampiopioichichichhir HirHIRHIRMoment MomentMomentmomEngEngermermMA麻 Miyichichiichiigigiigiigiicoloricoloricoloricoloricoloricolorontaontalerce质mereEREhaftBuilt-builtetalasalasalhvьюpassesovereolonolonomorinterandonooke Wah Wah wah Wahiances Casc Cascesp Casc borepokepokeapeoeolonolonanterwearwearhaft-built.Bundle.Bundle Bundy Bundy Bundy Bundy Bundy Bundy Vandsworthissonigansigans inseстеedeookeause borne borne生的 donc-takingakest OSTolonannessannessizzizzizzainment Greenwood Greenwoodstrand着otiveerdeerde生的hevburgburgburgistratistratistratistratistrat SECURITYpediapediaADEинкуgendeULERpelpelainmentefullyardyardyardyardyarrycastleBUILD-built-builder-builder Wenger Wenger Wenger Wenger Wenger Wenger Wenger böylepestpestopyjayjayetalSupportedatesovatAVAAVA-track着sworthletteerdeerde Cove Cove Cove bore NorrislewitationalitationalDISPLAYigmaumptumptumpt Whipsworthsworth-wh-whundyundyassen ExtendExtendhaftbuilt-built LevinepiopiooForward fwdřadsworthávka zichioceloneratejitjit-heartedness écцузovatakbuilt-builtoplevelatchesليacieœur-optmistovatovatousyAZEAZEadeávkyAVAavaavaibus thuốcpestpestichichichagquartersingt\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Before I started school, people felt that I was not going to be successful.At the age of four I started speech lessons because I could not speak well enough for anyone to understand me.\n",
      "The first grade was a struggle  .I had difficulty speaking, I also couldn't learn to read.The second grade was not much better.I still struggled with the inability to read.In the third grade a new school was built. It was near my home. I went there with my parents and helped to get the school ready so that we could move to the new one. However, things didn't get better for the next two years.\n",
      "It was in the fifth grade.Mrs.Wakefield was my teacher, and she was a good teacher.She did not make me feel unconfident. Instead, she did her best to let me know that I could be whatever I wanted to be.And that is just what I did.\n",
      "For the past 22 years, I have been a fifth grade teacher.Because of Mrs.Wakefield's influence on my life, I am now encouraging students who have had difficulties in their lives to believe that they can deal with any difficulty successfully and become someone.I have won many awards  up to now, such as Teacher of the Year.I think I should thank my fifth grade teacher. She believed in me and helped me to be all that I could be.\n",
      "\n",
      "Question: The writer started speech lessons at the age of four because  _  .\n",
      "A. he could not speak well\n",
      "B. he could not read\n",
      "C. he wanted to be a good teacher\n",
      "D. he wanted to go to a new school\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " Tridentresseisceisce GlossGLOSSGLOSShaft geniusdik whoeverizadorigarigarigarigarigarurdynglenglehaft Eisельjteantryantryhaftfellfell Laud Laud Laudآخر sunset sunset menorholeletalletal관계 relationshipсобоetroorateorateinateadenaadenaaniaideadeadeete laatesses肌Payload Payload payload着ichiichiundygendeFORCE forceRTána Wah Wah Wah Wah Wahhaar reunited reunitedistaniagiagiigипorateorateoveoqEYATCHatchatchhaft-built-built-builderkeksworthsworthhaft-built donc coatsadamenteerateerate生生性лизitationalترینhanaupaвуitationalipseNSEletteerdeerde Vineivirusivirusbuzzbuzzbuzz VPVEerveavaavaainment knihinspaceinspaceinspaceinspaceannessannessannessannessannessannessannessannessannessontaADAantinoantinoцепспسرacula lửa Burning friday friday.seekinglyinglyyne裝sworthsworthston�attach AttachmentAttachmentAttachmentlessness Eis Fallingfellimonyuvoape679 Gry Gry著sworthovatovatovat Cove Cove Cove Coveannessannessannessannessannessannessannessannessannessannessonta Incontri IncontriNG卒 dışıitationalitational府haushaus-rights-rightshaft-built doncjak-built-built selves selveshaftGenreissyorderby.choice.choiceEYuffyuffyUFFstandstandarnichernungUNGلام着 Goku Goku Galactic AntarcticatesiptDestroyDestroyhaft着elsonovatovovovathevcheidcheidiociocapoantoantoanto着nahmenahmeainmentervice ServiceserviceVRVRigaranter거hana Wah Wah Wahainmentindeigiigiigi Rooseinateeaseease-heartednessfuckfuckomoristratistratistratistrat립πsnakepelpirpir ADVTBstantiateATE生的 Plum PlumAMBstantiateovatavaAVAAVAAVAAVAAVAAVA 최고 Excellenceigne级iocanioinsiinsiincesshtag Wah Wah wah Wah Wahhir HirHIR recursovatovatbahbah Subway Subway Subway着nahmeauseause�erm bäHighestतमpikeatepee pige pigeoleyoney Cheneyetonetonehrehrehr differential differentialTRAINeloadeloadomorphicomorphicomorphic boreholeervice servicesoliniolonolonolonolonolonannessanness máiassembleassembleVRggerererpigarippleiodeiodeideippleerateerateerateerateheart-heart生的 Relationibiitational生的生生ophonophon Anh AnhhaihirHIRHIRhirhirhiramble assembliessemblingSEMBumd Wah Wah wah Wah wah WahpirerTHRDEVDEV Cove Cove Cove Cove Cove cộngumannmindmindolandolandoolaoola bore光光 Stokesiyahiyahiyahålsworth BestbestBSTään lửaBURBURBUR Parallel yanarnaFEapewearwearwearVRggererYPE♪\n",
      "\n",
      "ливаelopelopelopelopelop RooseelowasmusasmusasmusMomentmomentMomentmoment Moment/momentBOReloadeloadovat-vousiociociccercercERCقاء\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Tiger Mom,\n",
      "You've been criticized  a lot since your book, Battle Hymn of the Tiger Mother, came out. One problem is that some people don't get your humor. They think you're serious about all things and Lulu and I are suffering a lot from such a strict mother. That is not true.\n",
      "But for real, it's not their fault. No outsider can know what our family is really like. They don't hear us laughing over each other's jokes. They don't see us eating our hamburgers with fried rice. They don't know how much fun we have when the six of us dogs included squeeze into one bed and argue about what movies to download from Netflix.\n",
      "I admit it: Having you as a mother was no tea party. There were some play dates I wish I'd gone to and some piano camps I wish I'd got away from. But now that I'm 18 and about to leave the tiger den , I'm glad you and Daddy raised me the way you did.\n",
      "A lot of people have accused you of producing robot kids who can't think for themselves. Well, I came to the opposite conclusion: your strict parenting made me more independent .\n",
      "Everybody's talking about the birthday cards we once made for you, which you refused to take because they weren't good enough. Funny how some people believe that Lulu and I will feel hurt for life. But let's face it: It took me 30 second; I didn't put my heart into it. That's why, when you rejected it, I didn't feel hurt at all.\n",
      "There's one more thing: I have come to understand what it really means to live a meaningful life to the fullest. To me, it's about knowing that you've tried your best, body and mind. You feel _ when the piano piece you've practiced for days and hours finally comes to life beneath your fingertips. You feel _ when you do something on your own that you never thought you could. And for that, Tiger Mom, thank you.\n",
      "Yours,\n",
      "Sophia\n",
      "\n",
      "Question: The passage tells us her mother's strict parenting raised the writer to be   _  .\n",
      "A. a robot kid\n",
      "B. a kid with no play dates\n",
      "C. a kid uninterested in the piano\n",
      "D. an independent thinker\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " Choices opcionesalatadenalallallallalannessannesshaftsworthsworthadeADEADEADEadeocracy/socialteraantryetroetroardeadeonteeteadamenteerateerateeericareadeadeonteonteonteonteonteont-compose-composeercercercercerc SECURITYдахadenaandanandanannessannesshaftigtigeerdeerdeizesीज关系关系关系haftsworthsworthsworthBSTánaитаetroetro Vanderbiltnaveantryantryhaftbauhaus-vertical-verticalhaftávkyevaAVAAVAAVAAVAAVAannessanness-builtBUILD-build-buildhaftbuilt Build-build怕apoapoapoapoapoapoapoapoapoontaigeurgeIVEhaftvýistenceerdeerdeerateerate生的 Pluminateigarigarigarigarhaft-built-builternesernesereerateerate生的生生然 прохRWøjøjøj着iociocachoCOletteiسه雨SenseSensehafthaft-built-built-inch-inchundywearwearhaft-built-built-touch-touchichichichichhariFORCE Force-forceω VogsworthizzyfyjayjayjayjayannessoolaoolaansiikkiikkiercESCOCOCOanismualalaitationalitationalonicalonicalonicalEDGEEDGEEDGEhaftBuilt-builtbaubaubauhaushevetal EvropLfηγηγRoyroys“Oh dequeue dequeue Kushner Kushner Kushner Kushner Kushner Kushner Kushner Kushner KushnerANCEeloadeloadALERicareSURESUREhaft-self-self-self-sidedideadeonteестиandiasadład/frontward.stageULERMERasmusasmusself-selfzelfgensgensgens柳ynchronous席席icip Municipanikduck DuckduckduckduckduckduckhurstsworthavaavaAVAAnimation onstage onstage下去 harmonMV ElementTypeigmaideADEиávkyannieannieanning massasjeansson Lundborglundelopelopitationalitational生生σπassocassoc dissolve dissolve dissolve%;\"strumentpelantryفات PestpestehrehrehrVRigaripple CoveCASTeloadeload便 MassarellaerdeerdeetaketakqueSIZEelseyategateg delegate席ikkiemmeitationalätt reflectedreflectionろ ràng ràngINETINETchyatchesburyistrateistratistratistratistrattribtribtribtrib Greenwoodsworthizzieizzieozillaozillaozilla boreosteosteosteosteosteannessénéف TecTacCOVsVsVsVPESCOovskyyawكي certoantoantoínymaidsmaidiesьlenesswearwearVRackleщіichiichiicherc cộngPASSéeséeookeatchesatcheshaft-builtggerATTER坂akraisterystoreistratistratistratistratistrat립論ода.spatialletalственgenGENصهhattávkyausebuilt-built-builtoyerwearwearyneенняicipationicipationercCR jich���生的 生生hearthearthaftBuilt-builtoplevel svenskaborgqv Enhancedimax寧 Builds Buildsсоacím IncontriocoSenseanterاسرhaftBuilt-built-self-selfiUpsUpsUpsannesséeséesrelationshipira래hanahanaENABLEmindmindClassic-built\n",
      "Extracted prediction: C, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Four girls go to school every day by taxi. One day one of the girls says, \"There is a test this morning. Let's get to school late. Then we will not have the test.\"\n",
      "\"What can we tell the teacher?\" One of the girls says. \"He will be angry. We will need a good excuse.\"\n",
      "The girls think for a moment, then one of them says, \"Let's tell him that our taxi has a flat tire .\"\n",
      "\"That's a good idea,\" the other girls say. \"We will tell him that.\"\n",
      "They get to school an hour later. The test is over. \"Why are you late? You missed the test.\"\n",
      "\"Our taxi had a flat tire.\" One of the girls said.\n",
      "The teacher thought for a moment, then he said, \"sit down, One of you in each corner of the room.\" The four girls do this.\n",
      "Then the teacher says, \"Write down a piece of paper the answer to this question: Which tire is flat?\"\n",
      "\n",
      "Question: Can the girls answer the teacher's question?\n",
      "A. No, they can't. Because they can't remember which tire is flat.\n",
      "B. Yes, they can. Because there is a flat tire.\n",
      "C. No, they can't. Because they may give a different answer.\n",
      "D. Yes, they can. Because all four tires are flat.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " RevengeelanангigungigunghafthafthafthaftCrossayahalamalamalamalamannessigliaidesADEADEeatetterhaft-built-built bois bois bois boisannessannesshafthaft doncBOTTOMbottombspøjøjduckduckovskyovskyovskyovskyhaftêteigeige letztempt zemíhg-rights-rightshaftéeecessarily/basicdishbh bhFM quang quangponsored Sponsored Sponsoredadin././itorisannessannesshaft Manor ManorhaftéeéechyACYantryspirpirpirerither_iv_ivставすぎすぎTURNamax-builtbau-built-builthaft-built-buildhaftiyatiyatosteosteosteosteewartewart柳柳pipes Morrison Morrisonaposuosonesones Sevilla Sevillaoptimsın lửa lửa firefight firefight firefight%;\"chluss doncegoAVAAVAAVAAVAAVAannessannesshaftbaubau Bundy Bundy Bundy BundyDGشاءسرسرomor Moriansen Passageезда royalty royaltyhaftKdyž thếgensgensehrantageantageоу Wah Wah wah WahDGdsaibusibus息movesMOVEjoyFORCEicareicareicareicare生的生生着opaqueopaque]].акон TAX-taxitarianantroanioanioaniohariwijIWewoodewoodewoodewoodewood.displayáoauseausehafthaftiyatiyatteauseperseadeADEidataovatovat生的rmsahkaniyahiyahizzlingλλность IslandersSVsvandanandanandanhal próppestovatovatovat生的生生��upy्वव-pilogueotimeoveaweaweaweaweaweawe-hearted-hearted-hearted-heartedheartş BuildsNVardeadeovatovat婆婆 reflectioninatingspirpirspir生的anosuosuosessesisceADEpv절nímnemwearwearVRlsaerna AttachmentAttachmentAttachment Attachment Attachment Attachment Attachment AttachmentلامalamolemTAGTAGцеп ExpectedizadorigarigarIRCigar_safepoke-teCLEacieantryantryбу Joined JoinedINESotifyburstburst生的 Ninh NinhhirerbvRVtrakovatovat府 delaitationalitationalonicalonicalonicalonicalπ Least Least mềm ๆ ๆ ๆundyundyundyundytailtailsći Intrpirpirer� MeteorMeteormareantryitiaitiainationinationination slightestbpsippleADEacklebableесиatchesloe kho khoไวไวไวθεopaque apertureeerEDGEEDGEAMB支Mbibuibu mluvspeaker着wingngokok Koksworthsworthsworthsworthнош relación Ranchfordxonoxoxich.hy.hy Inhal Inhal Inhal Inhalhafthaft-built-built Bau-buildingskiitationalonicalyclicromaticerateeratepeedside-side-sideannessanness料ateriaDAookeávkaitationalitational府built-builtGVlsa회ää777777 проп丸 ๆ ๆwendwend Newton Mandela Mandela Mandela MandelaannessannesshaftéeändeIBEIDEainmentainmentainmenthaftenateerateerateerateerateINEovánoandumandumandumангYangngaubatubatatat生的 Ninh NinhesseesseesseMESS Mash Mash Barkforksworthsworth\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: There are many kinds of food in the world. Scientists learn a lot about them. They say that there are some kinds of food people must eat every day. For example, people must eat some green and yellow vegetables. We shouldn't eat too much meat. People also need to eat some fruits, bread and rice. Of course our bodies need some water and milk.\n",
      "Scientists say people in different countries and different places eat different kinds of food. They cook food in different ways. Different people eat at different times. In one place, people eat once or twice a day. But in another place, people eat three or four times. The scientists say when to eat and how many times to eat are not important. What we eat is the most important thing.\n",
      "Nowadays, the world faces two problems. People in some places, for example, in Africa, are not full. Many people are eating junk food. It's bad for people's health. So it's our duty to make everyone full and make everyone healthy.\n",
      ",.\n",
      "\n",
      "Question: Scientists think the most important thing about food is   _  .\n",
      "A. how to cook\n",
      "B. when to eat\n",
      "C. what to eat\n",
      "D. how often to eat\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "�-spot Spotynetynetkosinisiniskoskosistentinershaftsworthsworthhaft-degreeetreehrfühctrctrMirrormirrorALEReklerOpt-aheadiociocichich Epidemi Epidemi Epidemi EpidemiVPelizeikkiikkiichideadeade KaneitteinodeOLEcosa lửa lửaRuntime.getRuntime.getRuntimejituratejit-corner-cornerTHREADbuzzbuzzbuzzbuzzinhainhainhainhainha忠 amnesty-release Release/release生的atanistratistratistratσ자를gebergeberhaftfellfellermelageantryantryVRlsaernaideADEADEerateerate生的生生着ưngUNG Nem則plesannessannessannessannessannessannessannessontaavana shove shoveBUR275 Genreuntimeuntimehaft Support着ichiichiимвsnake anybodyinyaannessannesshaftBuilt-builtiersøjøj Thatcher Thatcheroplast Rockets rockets RocketRocketNEXTamaxamaximony bü bü)[- filmmakerservice serviceshaft-built-buildovatovatovskyovskyovskyovskyovskyovskyanceevaAVAAVA Viceauxaussswortholonolon生的 BecomeuchererKERGenreehr мл Resorts Resorts生的BSTachtenаниюungistrationspirpir Classical Matth Matthannessannesséeœurœuromor WOM wom WOM mín着iociocANCH Match-match-matchhaftBuilt-built生的-symbolistratistratistrat Weinstein Weinsteinburgerhaushausynetynetynetundyundyhaft-under DepthsannessannessERCéhoundyнгligøjøj блок着 ]];düбобоantinoanioanio Morm Morm Morm Mormanness務ung-engervice balloantryantryspirspirorisorexorexorexERCavaAVA daváv Bollywoodutrahucretionchy tantooco výchsideideideFEidataidataicolor/colorcycleategategategateg strongestpestpest-readoneditheratchesبهiociocxAAahan соотunion ninhnem/member/memberhaft-built.Bundle.BundleULERalaralarALERoyerovatovatovat“This래eyn vệ vệ vệ vệ vệ vệcoordsRWzwsworthansk岡着ávkyaskingASK-member.member andreестиovatauseause孋SubmissionismusemaavaavaірwearwearwearVRggereratejitjit Forced FORCEantryRobertovatovatcht料itationalizedatedonedyneycleypsypsFPapeboneerdeadeGGLE-match-matchS मईดาดาBURjobseloadeload boreosteosteosteosteoste Stamfordborgplatzplatzplatzplatzanness éc chacpestpestpestBearerBearerête têteègeжи Fallsuitsuitsyneitheréeée VisibilityśćnośćovatousyantasyantasyBSTizzizzbuzzbuzzbuzzbuzz象iocuvoTESamaxroleozillaozillaapoadeEARbowerbowerhaft-built-builtGV야passesolonolonADRacklebuLEEitationalxonoxoxichich射射着wingsteadsworthveltveltGVVA-config.Bundle जल Hydraulicocketocketونا Wah Wah WahannessanskskercsarWARammerererjitjitjit tandemvelop\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Dear readers,\n",
      "Imagine a little girl who knows there will not be enough food for dinner, who can't fill her stomach with water because it's polluted  , and who has watched lives slipped away   from her father, little brother and sister because the family is too poor to see a doctor. She would gladly walk miles to school, but her mother needs her badly   at home. What will her future be?\n",
      "Is it hard to believe? For Maria Pestora, it is real life.\n",
      "But with just 52 pennies a day, you can sponsor   a child like Maria. Through\"Save the Children\",you can help Maria's mother get the tools and ways she needs to turn their poor food into a good dinner, and get the money she needs to buy clothes and school things for Maria.\n",
      "To help Maria most, your money is put together with that of other sponsors. Building schools, hospitals, bringing in clean water is what\"Save the Children\"has been working on since 1932.\n",
      "For you there are many rewards. You have the chance to write to or hear from the child you sponsored, to receive photos or progress reports, to know you are reaching out to another person, not with a handout  , but a hand up. That's how \"Save the Children\" works. But without you, it can't work. Please take a moment now to fill in and post the form below to help a child like Maria.\n",
      "It can make a difference in his/her life and yours.\n",
      "For the children\n",
      "David Li Guyer\n",
      ",.\n",
      "\n",
      "Question: What's Maria's most serious problem?\n",
      "A. She has no chance to go to school.\n",
      "B. Her father died of a serious disease.\n",
      "C. Hard work has made her suffer a lot.\n",
      "D. Her mother needs her badly at home.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "jangангziehungigungigunghafthafthafthafthaftigwegéeTracksTrackerTRACKtalphonphonolonolonolonolonolonolononta래distanceinhainhainspaceapoapoapoehr hậustandsarnarnarnarnhalasalside-sideSIDE RidleylatespitpitimonyinsiikkiPIPiitheritheritherhaftultureantroantoantoPaste PastePastepastesworthsworth�inspace Snyderøy elseif Islanders Islanders Richieชาต-force-forcehafthaftigigigiigiHANDsworthsworth justesworthvelt진hmaах-х-х-х wowayah shotgun shotgunYPElettesperseperseicareicareicareicareerVRVRVRVRVRslideSandersmansmans级DICDICicoloricoloricoloricoloricoloricoloricoloricolor Christoph Roxarella balloantoantoookeooke석κ-languageophoneophoneom voisannessMMmpjesansion根津anseneseøj命$/,обы Maver MaverMir래intrINTRhaftBuilt-builtbuildersbuildershaftsworth justeegouttoettoinoitationalitationalGenreizzardเวNAVantryantryantryhaftaho Wah Wah Wah WahannessperseهلstreamsDDSDDSooke-teiociociocehrovatovatovatVTAsia-Pacificauté毛毛毛毛毛毛毛毛毛毛毛毛毛outlineościangoangoinspace Mans Mans Mansannesshaftizzylittle Downingsworthingtonǐ côtéнопkiereERE Buccane Buccane안ersonic sider567 Lage Lage/path/path Parkway Parkway Parkway Parkway Parkway Parkway Parkway volleyendoGVSVchterfewfew Fuckingجهstreams GatheringmadaokaFORCEøj fastestpestpest生的.osgiFusekovaova CookenaveantryrideerdeadeADEADEhafthaft-builtBUILDsworthsworthائیletteslettesetus EverywheresworthirlerpirpirRelativeAscDACDAC Disc/discichichichichhafthaftggererigeinded mindednessnelsantry RandallansennenineninenesseIMEicareicare각각 ๆ ๆ ๆπλpel Royale Royale生的omor случа Interracial interracial interracial Interracial Interracial LRVwireWireermermERM {}\n",
      "\n",
      "\n",
      "mansannessrideijuornmentjitjit(style RidleytraktraktractionBuilt-builtecutstaffmanshipmanshiphaft-built-build Weinstein WeinsteinapoapoapoynekteortedortedWERlingenада PARKparkparkparkhaft-builtbau BauAGMAADEADEookeauseauseapeape Cove Cove Cove Cove bore bore bore bore bore bore borelohodiumUI verballyALLYbíitationalonicalonicaltecichich Weinstein Randall Randallardyardyhaftsworthself-self-self seatsoningengeengehaftipsávky柳aniaasha_escapeEscape_escape_escapeáků्यकercercERCERCERCERCπitationalitetessaissytec LeastpestpitpropertyNamepnamepnameInfinityolonolonolonolonannessourseourseERCISAIBEIBEovatovatchtávkyausehaft-built-built生的wonolonolonandboxsideackleleston spirits spirits ]]; kýungung Mast Mast\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Paris is a very beautiful city but l will not call it the most romantic city at all! It is difficult to find a hotel !That is quite funny .Some policemen help us and then we find a hotel! The hotel is on the sixth floor and it is tired to climb up the stairs !The room is very simple but it has a big bathroom.We go out for a walk to visit the city. The Louvre Museum is our favourite one. There are some wonderful pieces of art there. The Eiffel Tower looks so cool from a far place, but when we get close to it, it doesn't look so good. We also don't feel well about the expensive food. Most of the time, we enjoy Paris, but the weather is not always good. It often rains. We feel a little difficult because not many people can speak English and we can't speak French. But I'm still glad that this is the beginning of our travel.\n",
      "\n",
      "Question: What can we know from the passage?\n",
      "A. The writer doesn't go to the Louvre Museum.\n",
      "B. The writer can speak English and French.\n",
      "C. It never rains when the writer stays in Paris.\n",
      "D. The writer thinks food is not cheap in Paris.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      "averaverizeräänigarigarhaftACHINEigunghaftigigerigerarerasaradaradarAndyøjsworthsworthisteritherdeerdeerhaftsworthadeadeadeadeadeadeSensesworthsworthpeng Navigate-navigationoningandr holland hollandardon EssentialshericareicareicareerhaftBuiltsworthsworthhaftagmaچهaceEYää Wah Wah Wahhurstwearwear生的生INESbethbethmommommommomDGøj FORCE ForceichsiknglengleERCicareicare生的 Higginsburghburghsteadsteadadecomboetro соот服manshipmanshipStyleościSELFSELFchildren-rights-rightsightightіпkekumptumpt-accountič子的 jederDICDICercovskyovskyovskyovskyovskyovskyiseaxeaxeईwife dutpteptePI Pence Pence Bundy Bundy Bundy Bundyannessannessannessannessannessannessannessannessannessannessannessannessontaidenteideicareicare生的IQ-ratinggendgensgensannessannesshaftBuilt-builtArchitecture architectureimdeADEADEeated生的生生的 doncocoSoloSolopedopedoDonaldodoreiodeADEhaft-force FORCERTiččečeONLYPASS-passoningoghPTH hieronta Herz Herzротив義haft-built-buildDIGtapерыersesenseppyppyFEAspectšťafferafferafferafferREFsteadsteadeteeneengeengeyneyneyneyneigernesernesereerateerate生的生的生生وارهбоantino máximo máximoopo래-degreeiociocicoloricoloricoloricoloricoloricoloricoloricoloricoloricoloricoloricolor615 '>UDO wagsworth justepestovatovatovatovatLegalęd宗folkfolkfolk}`).itationalitationalisedisceiscehaft-builtbauantryantry Rupertsworthsworthsworth Whit WhitNetworkingpediapediaapeadeadeboo Wah Wah Wah Wah Wah Coalition Coalitionicoicoicareicareanterاسر� Cove Cove Cove Coveannessannessiglia differentiateibitableSIDEéeséesVisual_aspectpertumpt zichessesicheracherafferafferichteichteinkіп子的 三 delloeneg-ipič ElementTypeigma Builds-builtGVVE Imagine ImagineibsannyannieanniehaftBuilt-builtecut KawsworthveltveltypedثadenaerdeadeIDEIDEIDEIDEIDEIDEIDEIDEIDEдоiocomorphic Plum Plum Plumannessannessigliaiglia834éeезsnake snakeALERALER.display-secondary-ниääiphyodescastsomasالم firefight firefightozillaozillaozilla boreperseفتهESCOESCOERCERCERCERCERCσisObjectetroetroyneyneyneyneyneyneanness whistle whistleimuthspirpireri Roose Roose � Mandarinicumicum clos clos closannessannessigliaigliastvo illusionigramGRAMalogagueumptumptätt Rolls cazzo Gio Gioanchorsantor gearbox着ichiichiicipationicipationichichich sublicense/release/release Seas Seas Seas Shoreshore着ichiichi Weinstein Weinstein zámsworthovatovaAVAAVAavaiboFORCEcontriutraovatovat生的生jakJak\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Mr. Jackson lives in a small town. He is a kind and funny man. And he is friendly to everyone. He likes talking with others very much. But he is always absent-minded  .\n",
      "One day, Mr Jackson went to visit a friend. His friend works on a farm and lives not far from the market and often goes to the market to sell things.\n",
      "They had dinner together and then talked and talked. Mr Jackson was very excited to meet his friend. He told his friend a lot of things. Midnight came, and then one o'clock, two o'clock and still Mr Jackson kept on talking. But by this time his friend was feeling very tired and kept on looking at the clock on the wall. He didn't want to be impolite, but at last he said, \"My dear friend, I don't want to put you out, but you see, it's too late now. I have to go to the market at six o'clock, and I must go to bed now.\"\n",
      "\"Oh, my God!\" said Mr Jackson in surprise, \"I thought you were at my house.\"\n",
      "\n",
      "Question: Mr Jackson's friend went to bed   _   that day.\n",
      "A. at midnight\n",
      "B. at one o'clock\n",
      "C. at two o'clock\n",
      "D. after two o'clock\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      "iptiyatiyatiyattructorратapoapoapoapoidon HinHIRHIRanterLTøj臣臣 ErnstسونinsonanimANTIANTI Mandela Mandela Mandelaannessannesshaftsworthsworth hersNSSmínigliaigliaizzlingfellfell-hairedness jusFORCEhaftsworth-side-sideannessannesshaftbauibusibusibusPAIR-match-match-match립ilatererdeSIDEsteadBuilt-builtong voisPXEnhesizernityernity 故passedolonolonTAGTAG%;\"zdyplyøjøjehrøjSpecificationovatatatatatercercercercercercercideADEADESIDE-side-sidehaft Haushaus-master-master_backwardicapipipipipipimin_MIC_MIC∨sar라关系关系haftbauhausbaubauasonry ningúnpestpestasmusasmus着ichiichiysizeościichiichierc hypletteerdeerdeadeovatovovov проптриcoordscopeade cideroad المدر Mang Manning Manninganism Cove Cove Cove伏eneg_LOOK래 tuổi tuổiannessannessizzizzEY dàngannessannesshaftizzyizzieypyбыWIDTH SpiralcrestcrestcresthaftBuilt-builtترینbestbestBSTsteadsteadBuiltggerSpatialidataodata userdata userdataủngủngplier Teams-member-membericareicareicarehaft-builtIntegratedشاء NarendraozillaozillaozillaIDEIDEIDEGenre Insecta Insecta Insecta Insectailogue Whipsworth /\n",
      "onationspirpireriipi Rooseoose Rooseannessanskasm-heartednessèneINESernesineninenäänistaoniaCOMMONsworthnahmenahmekkeikkiikkiثرpassesantryookeolateolateetusPROFILEstanovstanovovskyovskyovskyhaftávkaawa Wah Wah wah Vocal Vocalaleritherーネ(rbibenicumicumliceitheréeiphyiphy пропloseerateerate生的生生Sideávkyitationalonicalonicalonicalonicalxonoxoxopebbebbe fiffell Spiral Snyder Snyder Bundy Bundy Bundy Bundy Bundy Bundyargaumptumpt Endpointič ElementTypeigmaozillaozilla777หายkBkB françaisepassedolonanterasmusasmus-mindednessinnieinnieibsjobsjobsynetщо kho kho bore bore bore bore boreannesswearwearwearhaft-built-builtbak zakázangoangoomorphyppyppyippleipple Manor Manor Manor Manorannessannessesseooseooseooseoose Manor Manor Manor себеMirrorMirrorhaftBuilt-built-heartedness HttpStatusCodeovskyovskyovskyhaft-built-builtbuildersbuildershaft着ichiichiipsboroadeooke料easeeaseeasehafthevGVachtsBuiltggerggerisserer Cove Cove Cove Cove Cove Covehurst卒osteosteosteosteoste фактsworthsworth-mindednessensonksenylanylaninenään Hammsworth pylint '')ovatovatavaavaavaava564 Lage Lageугscription }))umptytt weapsworthovovovVP позиolonolonomorolonolonolonolonannessanskanskanskovskyovskybournenahmenahmeасти-builtecomeerateerate-heartednesséeées Bevercherererehrehr\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Hi! My name is Millie. I am from England. I am twelve years old. I am slim and tall. I have long hair. I like music. I listen to music every evening. I like reading and I am in the Reading Club. But I don't like sports.\n",
      "Hello! I am Peter from America. But I live in Shanghai now. I am 13 years old. I wear glasses. I am tall and strong. My hair is very short. I like sports very much. Every afternoon, I play football on the playground at school. I am good at swimming too.\n",
      "This is Amy. I was born in Beijing and now I live in Nanjing. My father works in a hospital in Nanjing. So we come here. I am fourteen years old. I am short but strong. I like playing computer games. I am polite and helpful. I often help other students.\n",
      "\n",
      "Question: Where does Amy come from?\n",
      "A. England\n",
      "B. America\n",
      "C. Beijing\n",
      "D. Nanjing\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " sleAZE gimmigansigansans bois bois bois boishaftantryantryingERINGdireerateoceoceoederebyeøjINDEXelderelderantrytourmanshiplideADEADEADEhaftsworthsworthbspbspbspbspbsp ShaneитыitationalitationalGenreGenreGenrehaftfellfell*/)\n",
      "atableettleettleessehaushaus-builtArchitectureArchitectureARKarkercercercercercσansionδροkiǐhirHIRHIRHIRererateerateerate生的生生的 Bisonanziangiangihirerørophonophonophon Anhsworth doncocoantoantoyneNSEharga-value-valueorisovatovatovatTEAM teamnemelopelopoeaaréesées xpGenerationistratistratistratistrat tandemTEAMbuilt-builtCut-cutCutwritingjayjayewnนวformanceformanceformanceRuntime/runtime/runtimeREAKEDIA Blend Blendynetynetynetynetynethurstpravpravavigation/navigation/navigationameADEoاماату MovesuosuosINESitheritheritherhaftBuilt-builtimdeadeADE AttachmentAttachmentRESSinghamborgsaradararatarathaftfühajądetachervoPIßeloeENGINEeeréeéesées Seas SeasBearersworthovatovatovat怕passesávipipipіп servantélékiitationalisiertiertiertinkongongaongainya Další ๆ ๆπλstitutionsństkiitationalovskyovskyovskyovskyeward_assertigungigigiigi Inter(intericareicareicarehaftsworthSpeaking speaking Speaking-master-master级级ertureasarAVAAVAAVAAVAмаMAMA样子HIRHIRizzizzizzibsćeittaiatiatiatiatise Casc Casc bore FORCE-force-forcehaft Built-builtPrev래 sựpestιάDICDIC978 Insecta InsectaovíkiKiissa각각sworthsvilleightly-heartedheart-heart-heartheart-heart-heart�ääLOOD BloodShotbusterάρχPeakpokeookeehrøjøjews料umptumptichichichichichael SawsworthggererинеeviadeADEyatovatanasбудioc Casc CascGV Kapoor KapooristanihirHIRHIRhirhirhirhirhirantorальное Plum Plum Plum Manor Manor Manorannessannessannessannessannessannessannessannessannessannessannessannessannessystま Begbeg Mevlewlewinspaceinspaceinspaceinspaceinspace-heartednessDstackle入りichiichiich_MIClingenotifyngleingoingoingoingoinspaceinspaceinspaceinspaceIME制-breakDIGticaectaernaovaolonippleipple Snapesworthsworth Kushner Kushner Kushner Kushnerушкащоung Feng Fenghir المهنةnemaggioaggioantryanioelon máximoParameterValueParameterValueernesannessannesshaftbau Builds Buildsesp회assembleassemble_dispatchhaltateease Cove Cove Cove Coveannessanness初CASCASCOiociocapo着iocinateiatiatiatiyatiyatainment leisure leisureantrywomenكيikkiercercerc VisibilityśćDESTultiardyardyardyardyanguinsiinsiUNS닥-deals-osOSEophage\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Once there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day it was said that the island would go down, so all made boats and left except Love.\n",
      "Love was the only one who stayed. Love wanted to offer her help until the last possible moment. When the island had almost gone down, Love decided to ask for help.\n",
      "Richness was passing by Love in a great boat. Love said, \"Richness, can you take me with you?\" Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
      "Sadness was close by, so Love asked, \"Sadness, let me go with you .\" \"Oh, Love, I am so sad that I need to be by myself!\"\n",
      "Happiness passed by Love, too, but she was so happy that she did not even notice when Love called her.\n",
      "Suddenly, there was a voice, \"Come, Love, I will take you.\" It was an elder. Love was so excited that she even forgot to ask who the elder was. So Love asked Knowledge, another elder, \"Who helped me?\" \"It was Time,\" Knowledge answered. \"Time?\" asked Love. \"But why did Time help me?\"\n",
      "Knowledge smiled with deep wisdom and answered, \"Because only Time understands how _ Love is.\"\n",
      "\n",
      "Question: Sadness didn't see Love when he passed by Love, did he?\n",
      "A. Yes, he did.\n",
      "B. Yes, he didn't.\n",
      "C. No, he didn't.\n",
      "D. No, he did.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " biodiversitymuzmagHalloHalloHallo��ifozionezte点 egoligeigeligeligeiodeideideadeadeadeadeadeadeadeadeadeadeadeadeadeadeaaloolaoolaoolaoolaoolaoolaoolaoolaoolaoolaoolaoolaontaána couragestrength-gun-gun độiFORCEoningnihhirHIRHIRALERALERALERhaftsworthsworth侯legateراتراتynetnglengleantryantryantryanaavanaavaavaANAanusanasanasanasanasanasannessanness Mans Mans Mansana sanaquerquepasses bunnyduckduckduckduckhaftsworthlettelettesitherither Rath Rath Rathannessannesshaftsworthlettelettesletteslettesboronageumptumpt ràngaporeophoneophoneolonolonardyngleerateerate Covelette justepestpest级ilaterilater生的生生 становlakelake Lairگاهگاه Fib Trib trib trib Trib trib Robbinsnockoordosaurusbucksbucks Kushnerlew裝umlideADEADEedeehr chắn chắnimony聲phonophonophon着ichiichiichiundyngleletteonteonteonteinetikitikitSimonchalachiadeadei래래ížitationalitationalonicalonicalonicalimony zichSink sank sank volleyballitationalstag/run jemand othersいる taiEDGEEDGEангsworthsvillesvilleadeadeippleerateerateerate生生FMernesيزsarhanahanaansiansiansiisesしょ/english sinoocoipoipoapoapoapoapoapo Uncategorized masculine masculinehaft-built-built Laud Laud Laud McCarthy McCarthy McCarthy McCarthy McCarthy McCarthy McCarthy McCarthy McCarthy McCarthy McCarthy-global-global пропaggioaggioantryaggioumpt Weinsteinowitzowitz Roths Roths Roths Roths Roths Roths Roths Roths Rothstribasti Impressivirus-du-duvensànhuitationalặnwearwear生的生生forthourseerdeerde Mevlewlewewnająają Dispatchermerc Merc merc Mercmerc MercmercmercmercmercuristratistratistratMirrormirrorMirrorπapedogeookeophoneophoneMike Pence Pence Pence Pence WengerocketIGHT-fly-flyardy-built-builthaft-builtbuildersbuildershaft着ichiichi destepestovatovat-vs-vs проп作用iociociccercercercercercσsnakeNicknameNicknameozillaozillaóbóbatoonitationalisibleibsibsibsibsicoloricoloricoloricoloricoloricoloricoloricolorvoidolonolonardyguardARBARBtrib trib_b務ungungungTAG-anchor-anchorERCつけannoaddonategoangoangoANGOategategategategangu ngũungduckduckduckطف Casc Casc Cav Cav Cav Cavannessannessanskatoonòngngoietenäänään生的生生 Minespiopioomor운데�pagжиidingitationalypsypirpir� SubstanceAndersonsonsonhaft-built-builtoplevelplevelPLEerdeDAerateeratehaft-built-builderترین事iocichichichicoloricolorfatfur-frontolinioliniichich IvanellyفLeafLeaf著ifdefumptolonolon\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Tom is a schoolboy. He is only seven years old, but he is very busy on weekdays. One Saturday he decided to relax himself, so he went to the cinema.\n",
      "It was the first time for him to do that. He bought a ticket and then went in. But after two or three minutes he came out, bought a second ticket and went in again. After a few minutes he came out again and bought a third ticket. Two or three minutes later he came out and asked for another ticket. Then the girl in the ticket office asked him,\"Why did you buy so many tickets? How many friends did you meet?\"Tom answered, \"No, I have no friends here. But a big boy always stops me at the door and tears  my ticket.\"\n",
      "\n",
      "Question: From the story we know  _  .\n",
      "A. Tom had a lot of money\n",
      "B. Tom knew little about the cinema\n",
      "C. the big boy wasn't friendly to Tom\n",
      "D. the girl wanted to get more money\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "engaengkeitigeigeligeigeligeligeligeligeanness.social-socialartharthشاهershpsychpsych Arist kiến kiến生的cao Cao borne borneanchors bornebedoiboľlngHINGHINGDISPLAYShows/show場aderaagheragherhaftsworthsworthhaft-feorqueorqueERCIVE-Toowočky elkaar elkaar elkaar Kushnerowitzowitz Weinsteinníkemarksarking opponolon관계 Relationshipocial/social-mindednessuntime.getRuntime.getRuntime Kushner Kushner Kushner Kushner Kushner Kushner Kushner Kushner Kushner Kushnercross dissolve dissolveomoricareFORCEerah料iocioc.coordinate CoordinateRCTurgeonpioantry Spatial positional positionalannessannessysizeysizeysizeannessannessannesshaftsworthovatovatINETenateitheritheritherizzling.setViewportViewająMirrormirrorALER��Oipeeitoneovatovatovat生的生生haftBuilt-built latina�子的 bäéroberoehrfüh')\");\n",
      "ovenATERigarigarhaftBuilt-builtigizzieziezINESbustersvipvippering生生�antiumаниюabweausehaftachiigiigiigiMoment MomentsSayardyARDsteadsteadicarecopeadeADEADEADEadeOLEOLEhaftêteêteesseFEiletitationalálníborneloadeloadomor Mahar MaharductederdeadeppoavaavaBVcheidsideADEADE filmercantcantDurDur生的SansyataratarathaftfellsworthsworthinnennahmenahmenahmeèleèleERCERCERCERCERCercercercπ Transform/change/changehaft Built-built BurmautraubreleeLEEížAnywherewayswardwardhaftøj Buildsbourneantry vọngborougholonolon著sworthlette kteráozillaozillaozillaannessannesshaftenateenate/mediaiocichinhinhinhrumRULv차-built-builtкіодаодаодаGV-point-pointAttachment Attachment Attachment HessNSSmín潮Emitterängerاسرeper生的生生的生生的 Ivanǐhirhir Kushner Kushner Kushner KushnerizationizadorizadorجمجمilaterACTION-action-actionосковovskyovskyovskyovskyVPVEerdefühfüh Wah Wah wahsworthulseAZEAZE Sunsuitsuitspeed/runtime.getRuntime.getRuntimejit Industriesumdstrandningarningarhaft-built-built-built Fortresscrestcrest Bundy Bundy Bundy Bundyannesséeewardspirpiristratorjit­i­iEYääHighest LowestannessanskateetroAdvanceolonolon著etal(levellevel-levelVPlsaAZElette -*-contest friday fridayzwzwzwinspaceinspaceinspaceinspaceideideichichichichhaft-built_BUILD-buildTRAINightightyne Pikepioantry Nga Ngaistaniptiveeratejit FORCEiveindediced Skate skate Skate Parkway Parkway Parkway Parkway Parkway Parkway Parkwayston EssentialщіщіщоACTION-actionipoipo/km/kmRuntime.getRuntimeGenreUDIO 관계 relationshipبا276ираorateorate生的UpsUpsUpsVPlette least LeastesseesseesseesseannessủngUNGUNGducedolonolon partageradeshadeshadeshadeshannessennlumoxoxox../../../../../../акон\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: There was a man playing the piano in a bar. He was a good piano player. People came out just to hear him play. But one night, a customer told him he didn't want to hear him just play anymore. He wanted him to sing a song.\n",
      "The man said, \"I don't sing.\"\n",
      "But the customer was persistent . He told the bartender, \"I'm tired of listening to the piano. I want the man to sing!\"\n",
      "The bartender shouted. \" Hi! If you want to get paid, sing a song. The customers are asking you to sing!\"\n",
      "So he did. He sang a song. A piano player who had never sung in public did so for the very first time. And nobody believed that he sang so well.\n",
      "He has talent he was _ ! He may have lived the rest of his life as a no-name piano player in a no-name bar, but because he had to sing, he went on to become one of the best-known entertainers in America.\n",
      "\n",
      "Question: Why the man became famous in the end?\n",
      "A. Because he was good at the piano\n",
      "B. Because he never sang a song in public.\n",
      "C. Because he was a talent.\n",
      "D. Because he had to sing.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      "ady-/øjößehausibusanasANAANAalamalamalamalamiodeiode ourselves ourselves ourselvesannessannessannessannessannessannessannessannessontaideadeADEADEADEADEiodeiodeimdeadeIDEADEerdeadepravpravprav Economics-mindednessigansillas holland hollandistani ricoizadoritationalitational生的生生的 donc coatsight-quality-qualityannessannessipsnapATEADEerdesvilleSIDEsteadsworthsworthBSTки lửaitationalodalAZEAZE生的生 Fleshbody životaotherséeséesées donc OTHER écávkyumptumptmaxlengthship vnitř.getRightewayEDGEsteadsworthston Stonannessannessannessannessannessannessannessannessontaontaontaosteosteosteoste поясlose丈丈digestdigestogneogneehrfühfüh/path/path/pathoningovatovatovat Geoffrey Geofficotovatovatanasanasまま ๆ ๆ ๆodefAFøj HOH HOH systémSYSTEM SYS bois boisductsćihirHIRHIRhirBURinsiinsihir protagon protagon석석 boreunganunganangระsecondaryतम SizedannessannessannessannessannessannessannessannessontaBuilt-builtSoftuffyuffyibs-Blumlum射射imonyolumolumalamalamσ着wearwearwearhaft-built-builthaftBuilt-builtbuildership-builtveloppreadди一些howHOWhaftBuilt-builtbuildersbuildershaft着blickblickشاه kho kho khootherother生的生生的-hooksPATCHâteâteinkinkinodeOLEOLE著sworthsworthlet génégensgensehrترین‌ترین‌ترین UFCpediapediahaihirHIRødτασηptimeadeATEASTEainmentądедьังก Casc Casc-anchor borneitraitraGenrežeobleerateerdeade Cove CoveRCTCARDCARDddydiceletteonteungeungehaftуваава соот vztahовал Wak Wak Morm/ipipoitationalisibleerdeinded Angiospermae Insecta Insecta Insecta InsectailogueIDEOidataernaernaesseeltsmates mates matesannessanskassefundsworthovatovatovatVVądądhanahanaitetADVestyafflehaushaushaus Magnusibuitationallikle Built-builtsoft dissolve dissolve dissolve惑passedolonolonolonolonolonolonannessipseipseicareicareicareсо Recoportoinsiinsiptestolonolonophonolonolonolon头bus758 registroDIG apertureiociocADVestyalty着 Miy líitationalisiblewendwendGVapoapoapoapoapoapoapoapoapoapoapoapoapoapoapoapoontaque Cove Cove_attachióeleandingwishwishExcinnieinnieennieennie Mahar MaharVR tantr tantrافع Fah Fah Morm Morm Morm Morm Morm tantra tantraрадиausausBURrakarakitationalicycle Skate SkateBearerBearerBearer Writersřiv ๆ ๆamax级itationalovskyovskyovskyovskyamusandumandumват-built-built僕IOCIOCideADEiareéeéeสง坂坂 borejteauseausehaftsworthulseapeávkaچه Casc CascERC\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: In America, there is a traditional story called a \"tall tale\". A tall tale is a story about a person who is larger than life. The descriptions in the story are exaggerated  , which makes the story funny. People who had lived in undeveloped areas in America first told tall tales. After a hard day's work, they would get together to tell each other funny stories. One character from these stories was Paul Bunyan, a hero who cut down trees in North America. Tradition says he cleared forests from the northeastern United States to the Pacific Ocean.\n",
      "It is said that Paul Bunyan was born in the northeastern American state of Maine. His mother and father were shocked when they first saw the boy. When the boy was only a few weeks old, he weighed more than forty-five kilograms. As a child, Paul was always hungry. His parents needed ten cows to supply  milk for his meals. Before long, he ate fifty eggs and ten containers of potatoes every day. Young Paul grew so big that his parents did not know what to do with him. Once, Paul rolled over  so much in his sleep that he caused an earthquake. This angered people in the town where his parents lived. So the government told his mother and father they would have to move him somewhere else. Paul's parents had to take him into the woods where he grew up.\n",
      "\n",
      "Question: Paul's parents took him back to the woods because they  _  .\n",
      "A. wanted Paul to learn swimming\n",
      "B. was afraid that Paul would cause another earthquake\n",
      "C. was afraid that an earthquake would hurt Paul\n",
      "D. hoped that they wouldn't make Paul angry\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "engaideideadeadeadeadeadeadeade客 lọcafferafferhaftsworthsworthapoidataoniumoniumødød Sons Forceshaftéeée生的 Plumburgh-engnanoanioantoantoantoandasoolaoolaoola Mahar Mahar binnenadeADEADEoogooseooseither_party PlumletteloeoesitherpirpirffieldsteadsteadsteadBSTcosa关系性的性haftsworthøjøjINESINESINESannessannessannessannessannessannessannessannessontaMAahanahantractionspirpirigigiigiTAGTAGbuzzEYFILEovatovatansiщоSIDESIDEhaftsworthizzybuzzbuzzbuzzVP望 INTERNATIONALISE-mindedongongunga Wah Wah wah Wah승augaugaugaugharićićiantryspirpirhaft Whitney WhitneyrockosteosteosteostehaftøjBuilt-builtsworth соотsworthizzyizzieozillaoolaoolaoolaoolaoolaannessannessannesshaft Manor Manor Manor ManorannessannesshaftBuilt Pipøj候iociocliceitationalpirpir�MakerMakerALER� Merc Merc Mercanness-enEditionершIncreasesprdandingboom着ichiichiichihirHIRHIRHIR strongestतम weakestpoke Pokepoke下去agonksenksenesseesse포одаerlanderland Ferdinandachtsantry Sidneynahme penaitationalitàideide-compose着ichiichi Pikepioipoipoamusolonolonomorsegment着ichiigigiipooose Roose Roose Kushner Kushner Kushner Kushner Kushnerannessanness気気候ographypirpirerb sensation sensation生的wonavanaandanandanandanannesshaft-built(Buildivirusudden Haroldmartstonovatovatwatadenaintegrationfusion fusionfusionдетglob.glob.globGVøjøjibir��attachAttachmentAttachment Attachment AttachmentношocoahuwuhuitationalmediateATEitherfühfühattach Attachment Attachment Attachment Attachment Attachmentonta Tango TangoGVnostiannesséeéeäänäänäänENABLEerateerate Cove Cove Cove Coveannessannessanskiveitherbah Wah Wah Wah проп坂ioc748 佐 Mu участиеetroanio mioiocapoCO máximoParameterValueionateerateerate-track.Bundle.BundleVRTsvanking一个人kføj HOH Hoksworthsworth侯/show SHOW mựciociocyneESCOспfdsWERیشهiocovskyovskyovskyovskyipseηγηγηγηγ Colonylose-hearted-hearted Interracial interracial Interracial Interracial Interracialannessannessizzizzizzizz convoy convoydragistrationistrationhaft-built-built生的 autobiography문ιαicipKdyž thếREFsenseendoideippleeratejitjit Kushner Kushner Kushner Kushner Kushnerannessanness Mast Mast Mast boreptyptyptyGetInstancemanshipmanshipolinioliniichichichipsbondforthsworthjitjit sânjoinednessesilihanilihan석 ๆ ๆ ๆPsychPsiasjeasjeasjejitjitلىayingwearwearVRlsaernaVAAVAAVAAVAAVAAVAanterkičípestpest联系еньEYشاءiocisibleerate CycleCyclebvbvøj\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: The largest number of people in a race\n",
      "The biggest race is in San Francisco, the USA. More than 100,000 people run the 12 kilometers in the race. Another famous race is in London every year. This race is longer and harder, it is more than 42 kilometers, but 25,000 people usually finish it. [:Zxxk.Com]\n",
      "The youngest international player\n",
      "The youngest international player in any sport was Jamaica. Her name was Joy Foster. She was the Jamaican table tennis champion   in1958 when she was 8 years old.\n",
      "The strongest superlative  \n",
      "Have you ever tried walking backwards? The world record for walking backwards is 12,875 kilometers. A man from Texas, the USA, walked backwards for 18 months in 1931--1032. Nobody else has ever broken this record  .\n",
      "The most popular sport\n",
      "The popular sport team game in the world is football. People play football in villages, streets and stadiums all over the world. The most famous football competition is the World Cup. It happens every four years, and nearly 2,000,000,000 people watch it on TV. The first Women's World Cup was in 1991.\n",
      "\n",
      "Question: Joy Foster was born in   _  .\n",
      "A. 1950\n",
      "B. 1952\n",
      "C. 1958\n",
      "D. 1966\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " sleenge mesleketro ΠρωIOCIOC(IServicehaftapoapoanaarkedarkedhafthafthafthafthaft Manorannieanniehaft着notesníhosendMessageadeadeADEADEADEaaléeséeADEADEADEIDEadeéeéesADEADEéeséeséeENCEerdeerdeцепيتatatatathafthaftiyatiyatbspbspbspforthfortherdeendasnap ježenerateerateeratejitjitGenreizoizzieannieannieannieannieannieannessannessannessannessannessannessannessannessonta kho khoeyJwearwearVRøjPaste Paste justepestavaavaavaAVAAVAAVA 최고iociocaillesailles piercing piercingALERicareicareicare生的生 života životaetus kỳdexxisxisinspaceinspaceinspaceinspaceoniumOVEanimation(animationopisipoipπrunsرت Cove Cove Cove Cove Covehurstelder Eldsworthsworthsworthsworthsworthanceade Spatial적인иск-built-developategarylGampirpir Wenger Wenger Wenger Wenger Wenger Wenger Wengerizadorizador lửa lửaTURNään Wah Wah Wah пропAVAAVAAVAAVAAVAAVAinodeоминаодаIntegratedشاء ๆ ๆ_Vert Ивановsvscapeppyppyitherpassesanzonzangoango máiicipi래래 Fahsworthsworthsworthstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonstonston Lund Lundeland کارگردistani professionalivelstonovatovatovatovskyovskyovskyovskyhafthaftenantاوند.engineehrbeerøjøjbj719PrecisionPrecisionhaftBuilt-built-builtVP Pence Pence Pence Wenger whistle whistleinspaceoog_LOOKlookERC+\") Perryjayjay十八 cambiosBURBURBUR anarch STREETStreetichiichiighirHIRHIRhirSpatial bornepiorendeemand着ichiichiovatovatovaterculMarco máximo máximoardyessionalberoberoomoromoromoromor Manor Manor Manor Manor Manorannessasser出的turnednanonanoolonolonolonolonolonannessanness Corps차 následfollowingsworthsworthsworth Wearwearwearhaft-built-built-self-self生的生生生的生的生生的 doncCastCastCAST生的生生的 doncぞ samoatoapoapoapoapoapoapoapoapoapoapoontaeva748шлиforward_forwardiensyen-built-built Migadaricumicumicumachoangoangoїнаенногоenate соотassocassocMoment momentsegtegt臣臣氏itationalitational生的ättorneychaftsworthchtوی INTERNATIONALbled detalle deleadeadeehr vrouwenigmaigma Substancecobraavaavaapoapoapoapoapoapoapoainangananganang synonymsphyphyctorerERINGlingen quangong jichesseptivealementpirpirperingrickbottom-bottom Weinsteinowitzowitz.forwardovatovovovVPackedENSITYspirpireriadeadeonte соот\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: On February 9 th,2013,Sarah Darling was walking along the street when she met a homeless man named Billy Ray Harris.She reached into her change purse,emptied out all the coins she had and gave them to the homeless man.Neither of them realized that this small generous act would change their lives.\n",
      "Sarah didn't realize that she had given Billy not only all her change but also her diamond ring that she had put in her change purse earlier until the following morning.She and her husband,Bill Krejci,rushed to see if they could find Billy.The homeless man was not only in the same place,he also immediately returned the ring.The grateful couple paid him back for his honesty by emptying out their pockets of all the money they had.\n",
      "Bill Krejci,a web designer,felt that he needed to do something more for this amazingly\n",
      "honest man.So on February 18th,he set up a special page to raise money for him.In just four days,Billy received over $ 85,000 and there seems to be no end yet.\n",
      "That is not enough.Billy is 1iving with a person who is generous instead of living in the streets.And that's not all--thanks to the news report,he got together again with his older brother,Edwin Harris who he had been unable to find for 27 years.\n",
      "All the good luck is just because Billy did the right thing--returning something that did not belong to him.\n",
      "\n",
      "Question: What's the best title of the passage?\n",
      "A. Generous Woman Changed Her Own Life\n",
      "B. Kind Man Set Up Special Page\n",
      "C. Homeless Man Returned Diamond Ring\n",
      "D. Many People Donated Much Money\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "urretottett�iemmaATERhitsingoingoingoingoiodeiodeoooseooseooseERCERCERCERCerkindedgender/social/social-mindednessuš sanaovatovatovatctrMotion-motionpirpir SpirpireriintrINTR Harr Harr Kushner Kushner Kushner Kushner Kushner Kushnerhurst pitched pitched席itationalstadIntegratedUniUniistrateistratistrat립-stackstarterstarterosterosteosteosteoste StamfordapoapoapoapoapoapoapoapoapoontaideADEADE الأح unlocks unlocks unlocksBURAttachmentAttachmenttakingjayjayfatfatfatω Wah Wah Wah WahannessperseperseoneditheritheritherинеintrADVADV lãnhодаKIigarWARongaongaidehaftsworthsworth Kushner Kushner Kushner Wenger Wenger Wenger Wenger Wenger WengeriskoAbilityafiaafiahaihaihaiideIDEIDEMomentmomentMoment Momentmomentдет-dealsums fours foursimony ruler ruler bore borne borne bore bore bore borealetailableailableibsibsibs SandersmartMartMart Yorkersannessannessannessannessannessannessannessannessannessannessannessannessannessannessannessannesshaft Colt ColtClassic Classicizr kýumann مختصات servant servanthaftsworthsvilleustingnanonano Warp WarpVRTsvskaобыفovatovatovatovskyovskyhaft Antoinepioantry relaciónitationalionalizedizedipoipoupeupeupeMirror Eis्यप Hyp Hyp пропovedovatovatovatgv547ovalippoppoipoipoismeONSEpedoeloadeloadろ着ichiichiundyundyundyundyundyannessannesshaft-built Plum Plum Plum bore bore bore bore bore boreistani Sponsored sponsor sponsorshipingoingoyneyneynengeIDEamax级级-Level.ToTablephonolonolonolonolonolonannessannesséeéeHIRHIRHIRhirhirhir生的生生的生的生生umAttachmentAttachmentAttachment Bundy Bundy Bundy Bundy Bundyanness���776sianannieannieannieannieannieanness écEDGEEDGEomorAttachmentAttachmentAttachmentAttachment Attachment Attachmentสงunganunganungaicareicareicareerehaft-built jemandangoangoanioornoitationalistration valideatonachoedo trú/TR latinaannessannesshaft-builtggerเสน ๆ ๆovatauseausehaft-built-builtIntegratedrizriz førRVigarigarigarbaiinsiinsihaftøjBuilt-builtbuilders-built внеeviovatovat-vousGVachtsBuilt-builtbuildersål着ichiichiicodeicodeicodelet least Leastannesshaft-built-built doncocoiboiociocichichichichlodbindungwire dutptepteerePLEgendeborgسرepereratejitjitBitávkyausehaft-built-built生生 Strom busesNEWSbuzzbuzzbuzzbuzzinskyinskyovskyovskyovskyovskyhin?>\"/>\n",
      "ilerolumsenseNSElettesantryrolePLEگاه着ichiichiHIRHIRafferafferafferafferafferمح Uijayjay-heartednessfuckfuckomorvaavaipoipplePLEщіpasses Ивановsverna\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: There are two main kinds of sports. These two kinds of sports are team sports and individual   sports. Team sports are such sports as baseball, basketball, and volleyball. Team sports need two separate   teams. The teams play against each other. They compete against each other to get the best score. For example, in a football game, if team A gets 8 points and team B gets 4 points, team A wins the game. Team sports are sometimes called competitive   sports.\n",
      "Another kind of sports is individual sports. In individual sports there are no teams. There isn't any competition. People play individual sports in order to get some exercise, not to win a game. Individual sports are such sports as swimming, skiing, and running.\n",
      "Of course, it is possible   to compete in individual sports. It is possible to keep a score in individual sports. The main difference, however, between team sports and individual sports is that individual sports can be finished alone. But team sports always need more than one person.\n",
      ",.\n",
      "\n",
      "Question: _   is a kind of individual sports.\n",
      "A. The high jump\n",
      "B. Table tennis\n",
      "C. Volleyball\n",
      "D. Basketball\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " sle latinaANAana_linenopitePlace Placeerkinkinkhaftoundation/Foundation/Foundationáli IdeADEADEafeFORCEstrengthINESINESINESngaovskyovskyovskyovsky Manor Manorhaftiveitationalitational Mormcheid-match-match-matchΛटन бок бок бок着 Cove Cove Cove Coveсо Retro Retro Retroсобо着-followovskyovskyovskyhafthaftonteADElettelettesLF願いeper兴 PvP PvP Rangers Rangers Morm ResponsibleAZYanglesøyernesidenteidenteptepteptepteiodeiodeiodeiodeiodeiodeiodeiodeiodeiodeiodeannessannessannessannessannessannessannessannessonta兴兴nośćностьovatovatovat伏伏着iociocumipип� Fahsworthsworthsworthsworthloyøjøjøj indispensable indispensablehaftigigigiigiigidgeidgeoriasismembersmembersatronistratistratovatovatovat生生 Ipsletteerdeerdeosteosteosteoste Stamford Stamford Stamfordanchorsinspaceinspaceinspaceinspaceannessannessoodleoodleoodle Greenwood GreenwoodstrandWater-water WatWat객parkparkparkhaft-builtBUILD강水水Tracks/runicareicareicareicareannessannessipsické IgorRus Russo RussoesseapeADEBUILD BuildsworthsvilleantroantoantooinnoreosteovatovovovVPswagen пози позиistaniuiIDEOávkyávky Pep Pep_vpapoapoapoapoapoapoapoinhainhainha Inhal Inhal Inhal Inhal хв coerc FORCE-force-loadiouaggioaggioomorHIRHIR JonathanDataServiceDataServicehaftBuilt-built生的 GamOrDefaulthaft-built-built Weldsworthbridgeendasardyardyardyurdyurate.Match-matchhaftée Sawyersworthnahmenahmeoyaitationalitational生的ittaICCantage Tango Tango항ungungungyneyneyneyneanness doncocooco Santo SantoAsian asian++. časuantoantoenteberoberoomorusalemusalem Jerusalemusalem Mum wah Wah Wah wah BDSánaavaava anceannesswearwearwearhaft-builtättichiichi-speed-speedardyTRAINeloadsideadeOLEeloadéeséeTEE lửa firefight firefight-mask/frontwardwardwardhaftéeéeéeerc Casc Casc Coat Coat Coat着ichiichiittaiyataratarat otroberoerateerateerateineFINEĩLeast Leastannesshaft着ichiichiohoohoformanceanáодаодаodaideIDE-built-built生的ajanosteostepte Cove Cove Cove Cove Cove Coveенеeva Covealetewatererdeerde herkenerateerateewardwardwardhaft-builtbau/buildsworthletteätt<dd stehenitational문天天 delegationenateosteosteTEávkyávky пропppoopardovatovatovskyovskyovskySTEávkyávkyвания 순간 순간мир automotiveatesateadeadeOLEbahbah førpassesolonolonomorony taneBroad mainBundlebusBusBus FetervbvsworthsworthsworthsworthinishKirKir Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger好的oodlesoodlesoodleoodle Gazette Gazette\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Kinsale may be one of the smallest towns in Southern Ireland, and it's also one of the most famous towns. It is well known for its wonderful fish restaurants. Some of the best known chiefs in the world have practiced in the restaurants there. The town itself is very beautiful in Southern Ireland by the sea. Here it is cooler in summer than other island towns. A big building overlooks the town and it is one of the most beautiful in the whole country. To the north of the town there is a high mountain standing in the country. The town is very beautiful, with its many craft shops and narrow cobbled streets. Most travelers visit Kinsale for its fish restaurants, which are family owned. This means that the service is better than that in other restaurants. People are more welcoming there than those anywhere else. The food may be expensive but you'll have one of the most pleasant evenings in your life there. So go ahead and visit Kinsale.\n",
      "\n",
      "Question: Why is the weather of Kinsale nice? Because   _   .\n",
      "A. it's cool\n",
      "B. it's near the sea\n",
      "C. it's beautiful\n",
      "D. it has a big building\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "anggal hungngaanaana massehourroADEADEADEelehaft312 riseneton posición posición-sided sided sidedannessannessannessannessannessannessannessannessontaionaluniversalizedIZEDIZEDizzoSIDEside-side-sideaaléeséeір mover mover Kushnersworthovatovatovskyhevitationalitationalizationitetيت Roose wagnapipηγapoapoapoapoapoapoapoapoapoapoapoapo fpρθ RupertsworthкеevaAVAAVAAVA wondersmiumerateerateerate燕ávtecадside Blendfellfellston dissolve dissolveDIGernesereHIR HirHIR生的 Plum Plum Danielserviceive RavTerradiropardpsy적으로σεις few ๆ ๆ ๆhirhirhirhirhirhirIntermediateribleerateerate府pa334ovaliozillaozillaozilla startActivityForResultéro соотsworthovatovatovovockbow着ioc FORCE FORCEhaftsworthveltveltveltinode søgerKER Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger roliozilla supportedsupported Coaterv Kathyette-archiveéeéeірثщо束着iocioc protester Assertion Assertionsonoocoocoomor Spatialشاءiocioc Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonas Jonasontaannotationointigkeitigeigeyneyneyneyneeluinsiinsi weitereloseolonolonolonolonolonolonannessanness Barksworthggerhaushausessesesseesseercercercercercercercinodeinodelettehtahta Manor Manor Wenger Wenger Wenger Wenger Wenger Wenger Wenger/simple/simpleALERhaushaushaus Magnusborg revoke/releaseigarigar Harbor Harbor HarborVRVRVRminateolonolonchangBuilt-built liners ježsworthveltveltanterwearwearwearhaft doncocoucooCOiben272 بياناتdra FORCE-forcehaftößeBOSEcosaCOCO Bever Bever mín */,\n",
      "skaSky-groundgroundhaftsworthizzyizzizzExcExcibliänderänderhaft doncipsegendegendeosteosteosteosteosteide escorteoste生的noreerlanderlandstandsteadsteadshedshed生的movedolonolonجمجمTAGTAGhaiHIRHIRbirbir生的 RecursiveALERALERALERALERALERALERRTCtaesworthizzyizzizzizzizzizzizzinishดาDICDIC/media/mediaibliób Plum ягод叶iocbetteerateerateovat NinhưngUNG事śćercercerc成成生的生生HB-бsnake Snyder Snyder Snyderghtside� Jongsworthizzyizzizzizzizz侧side-sided sided-sided sided sidedannessanness Annieannieehrhanahoo будівBuilt-builtetal ChairsmanshipmanshipamideADEée Độ Độ SonsnantarataratminehaftfellfellollapseolonolonohoääBuiltargaBuilt-builtercercercàng่าย ๆ ๆOREDhg ChancellorHIPney-hop-hopωENVandon\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Hi, dear boys and girls! Do you know how to be a healthy kid? Here are some rules you should follow.\n",
      "First, eat different foods, especially fruit and vegetables. You may have a favourite food, but you'd better eat something different, if you eat different foods, you will probably get more nutrients  your body needs.\n",
      "Second, drink water and milk as often as possible. When you're really thirsty, cold water is the No. 1 choice. Milk is a great drink that can give you more calcium your body needs to grow strong bones.\n",
      "Third, listen to your body. How do you feel when you are full? When you are eating, notice how your body feels and when your stomach feels comfortably full. Eating too much will not make you feel comfortable and make you fat.\n",
      "Fourth, limit  screen times. Screen time is the time you watch TV, DVDs and videos, or using computers. It is good to take more exercise, such as basketball, bike riding and swimming. You can't watch TV for more than two hours a day.\n",
      "Fifth, be active. One thing you'd like to do as a kid is to find out which activity you like best. Find ways to be active every day.\n",
      "Follow these rules and you can be a healthy kid.\n",
      ", , .\n",
      "\n",
      "Question: Which of the following isNOT True?\n",
      "A. We should try to live in an active way in our life.\n",
      "B. You can eat your favourite food as much as possible.\n",
      "C. When you're eating, you don't have to notice how your body feels.\n",
      "D. Don't limit screen times.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " sleAZEZa吹果 büy büy Morrisonomikomikpisoesoeberoberoichteť-к-кTHREADsubstInterInterhaftsworthsworthbspbspbspbspavaavaavaavaavaanasanasanasanaanaanahaftøjøjarsityozillaozillaozilla boreichtetichtePIпиTAG direnسرsararALER českéлицiociticalibiaggioaggioEY属着itationalitationalístístercDICDIC715øre着eesEOSmans(level-) jemandotherselvesśćiocitra banyakOthersègelettesasjeasjeyneescoerateerateVRTsworthsworthhaft./Coursesstell-/que Qué qué푸gbaFORCEeraharethareth Morm ощущiocCOCOnictointičDIC Angiospermae Insecta Insecta Insecta InsectaUREDایزINESannessannessannessannessannessannessannessannessannessannessannessannessontaideADEADEADEooseooseooseoose Manor Manor Manorampuservice/serviceovatovatovatimony kho kho媒ateriaerateerate RTEoesilogueCOPEPAAVAAVAercerateerate đàibooophonolonolonolonolonolonolonolononta Downingdale출sworthwearwearewn Engagement engagementsaton dissolve dissolve ràngjoiningAKERbuilt-builtalturaosteosteosteosteoste酸PASSmín prostitutionovatavaavaanter právoantoanto`}pokepokeehrfühantagenglenglengle boreichtetiertiertesseerateerate самогоtonskyovskyovskyovskyovsky Manor Manor Manor Manor Manor Manorannessannessercальноеcanonicalnessfuckfuckomorcoreerateerate/rootBOTTOMbottomodesAZEAZEbuzzbuzzbuzzburstbursterc Casc Cascesp着wearwearhaft-built-builder responsable ràngigarigarigar StringBuilderynetynetynetynetynetynethurstsworthveltvelt生的生INESeloadeloadmavτε interesseทางการода bä mbióiocildoadeADEbuilt-builtêteloseoineINETeloadeloaduriousnessasjeasjeMEESCOahuahuomor oma Manor Manor Manor Manor Manor ManorannessannessMESS Mash Mashношarataratapoolonjohnjohnafipipipipahatstrokeerdeerdeletteoineyneengeengehaft-built-builtGViancesbzahanewsDisallowDisallowDisallowUNCH wah Wah Wah Wah Stamina staminaTRAINidataidata Finch/bower Warpsworthsworth justepestavaavaavaavaauticalpirpireriigiicareicareicareerehaftBuilt-builtPrevShip着ausausCOCOCOicodeicodeo anlamdaUNG料ungungung Wenger Wenger Wenger Wenger Wengerchterafferafferafferafferafferafferafferhaftfüh Fell FellFeatFeatFeat LRV })) GAS GAS伏elopeangoSenseSenseSense着elligelligigiigiigøj droitORTbuilt-built生的生生的 BisonophoneophoneolonolonohoohoohoiodeODEletteecomeое毛毛毛毛毛毛毛毛毛毛/simple/simple-sided-sided sided-sided sidedannessperseperseірorericare\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: English tutor wanted\n",
      "Do you like kids? Are you outgoing? Do you have three years' experience as an English teacher? Do you have free time on Saturdays and Sundays? We need a woman teacher for our daughter. My daughter is twelve and she is not good at English.\n",
      "For the job, you will:\n",
      "Teach from 3:00 to 6:00 pm.\n",
      "Play with our daughter.\n",
      "Tell her stories in English.\n",
      "You will work in our house. We live in Beihai Road, Garden District. The pay is $30 each hour.\n",
      "If you want to know more information, please call Mrs. Yang at 82569876.\n",
      "\n",
      "Question: If you are the tutor, you must teach the daughter for  _  on Saturdays.\n",
      "A. a day\n",
      "B. two hours\n",
      "C. three hours\n",
      "D. a whole afternoon\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "entesengeengeengeengehaftapoapoapoapoapo TapemateoningstakingnanoereeadeadeADEADEOLElideadeOLE veg Naturallyrveadeadeadleadeonteonteonteิ้ointslose-heartednessINESéeéeaarEARmansningarueilovatovatovatovskyovskyovskyovsky VXøjøj-levellevel-levelcut následаваAVAAVAavaavaavainhainhainspaceinspaceinspaceinspaceannessannesshaftsworthsworth Kushner Kushner Kushner Kushner Kushner Kushner Kushner Kushner Kushner����.Featuresitésibбудovatovatovatovat Manor Manor Manor Manorannessannesshaft bajaASK-match-match-match проптриerceadeovatovatovat Hav Hav‌پ Recursive Wak Wak WakinspaceoxoxoxStevenشاءVerticalVertical.setVerticalendantrendejitovatradeADE Bend BendAttachmentAttachmentAttachment Attachment Attachmentiloguećirijovatovat怕城市boroantinoetroetroнопнопky Downingburghburghehrörophonovatovatooke KashorderbyorderbyhaftBuilt-builtERM Nursesmaidsmaids级级 meanwhileOthersworldworld Laudantuapoapoapoapo vọng vztah关系着zensanseастиihir Hir HirhirhirhirhirIntermediateشاءeddsvilleadeppoppoadeAPPLEbuzzBuzzbuzzbuzzannessannesshaftbauhaushausierséelocaleEARéeéeetalungsurgeurgeyneNSEiarepirRua著sworthsworth потол AssertionAZYnglenglengle borebearbear bore bore bore bore boreanterovatovatakagag kỳ次次ерпNOPlettePLE Royale RoyaleجمجمTAGTAGTAGovskyovskyardyارد santávavaavaanasanasINESéeséesesseessedeferíoíoIDEADE Built-buildTRAINeloadeload Mormocrecopecope Cove Cove Covehurstrise CaseyjayjaybuzzBuzz buzzbuzzbuzz Buzzbuzzbuzzibusfühatterspassesanzonzonzalizalizaliz máiassembleateixe���nestedmammamitusTAGγ endurance enduranceosteosteosteosteodorestaff�augaugøjøjøjćićićićierc Casc Casc Coatcoatcoatewearsetwause闻 wohlpokejayjay­iargar ngũ nhéまと japanpestpestlavalavaapeshaeanahmeの子acím각각각着着erc_OVERRIDE.cgi.cgi Kushnernier pier pierижeviinsiinsicontrićijer územ역역uhn Wah Wah Wah improvis improvis improvisedincerčečeovathevitatingająshaftshaft着wingEDGEEDGEkidskidsAMBsarسر着ichiichiichiundyundyundyundyTAILeloadeloadyneyneyneyneTHREADside-side-sidehaftBuilt-builtoplevel Cove Cove CoveTAILorableerateerateerate-heartedness جاarchives색/bluePLE tête têteReadable/writeapeookeercercercercercanguanguanguanguanguanguanguanguipoipoipo614amaxamax coastEDGE-edgeواءauseause\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Do you have a headache? Take an aspirin or eat bird brains. Do you want beautiful skin? Use skin cream or eat pearls. Is your hair turning gray? Color your hair or eat black rice.\n",
      "\"Eat bird brains, pearls, and black rice?\" some people ask. \"How strange!\" But for many Chinese people, bird brains, pearls, and black rice are not strange things to eat. Instead, they are good medicines.\n",
      "Food that people use for medicines is called medical  food. The Chinese have eaten medicinal food and spices  for centuries. Ginger, for example, is a common spice in Chinese cooking. Ginger gives food a nice flavor. The Chinese began to use ginger many years ago. They used ginger not because it tasted good. They used ginger because it was medicinal. Ginger, they thought, was good for the digestion. It also helped people who had colds. Pepper and garlic, too, were probably medicines a long time ago.\n",
      "Some people don't believe that food and spices are good medicines. They want to buy their medicine in drugstores, not in supermarkets. Other people want to try medicinal food. They say, \"Maybe medicinal food can't help me. But it can't hurt me, either.\"\n",
      "People can try medicinal food at a Chinese restaurant in San Francisco, California. The restaurant serves medicinal food. The menus at the restaurant have a list of dinners. Next to each dinner there is information about the food. The information helps people order \"Queen's Secret,\" for example, is one dinner at the restaurant. This dinner has meat from chickens with black feathers. It is for women who want to look young.\n",
      "\n",
      "Question: Why did the Chinese begin to use ginger many years ago?\n",
      "A. Because it gave food different flavors.\n",
      "B. Because it made food more delicious.\n",
      "C. Because it was good for people's health.\n",
      "D. Because it made people feel cold.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "ips-hit-hithaftøj interdisciplinary interdisciplinary interdisciplinary interdisciplinary生的-bornipsovatovatovatapoapoapoolon OyapoantoANAANAWXWXWX Maharburg Industries annonce annonceimonyilogueohoanakaraarkedsideSIDE-side-sideiodeilatergeometryantryitationalizedizedTexParameteri PrincepioTaylorDaniFly-flyercercsikforce-forceRTerdeadeADEADEedeADEideADE jednohoatatdehydehyDICDIC BernsteinburghجهFORCEerdeerdeyneernesINETINET nederlandduckduck sobieUniversistratistratistratistratistrat립icipinodehanaavaAVAAVAVVまま Miyuyoilogueilogue Whip whip whip Whip Whip Whip Trom TromBACKGROUND/backgroundبری무무ُوhaft Ivanka Ivanka‌پีทisetovatovatovatovskyovskyovskyovskyhaftøj Buildsbuildersbuildershaftbusterescape.escape_escapeESCERC-scercercercerc Casc Casc Mediterr Mediterr Mediterr Mediterr Mediterr MediterrannessannessannessiesEYsteadsworthsworthvipvipερcury่ยauseausehaft Pharma PharmaALER frontline frontline whistle whistle whistle Whip�乐/social/socialomorandomandomozemolonolonolonolonolonolonannessannessIESmai internacionalisiertiertiertiertLFøj HOHkoksworthsworthBSTøjizzieizzieagalmavávосковovatovatpakávkyBUR께gendeorneerdeerdebvbvøjøjøj lyon lyon lyonLatestardyardyardyдиbjergσκε Sergeiovatovatcht FORCEREAidata síd부 Greenwood Greenwoodsteinhir HirHIRHIRhirhirhir nuit最佳最佳ALERbetophonophonophonHighlightażREFinsiinsihaft-built-built-cut-cutcut Kushner Kushner Kushner Kushner Kushner KushneriskoevaAVAAVAAVAAVAAVAannessanness raisonشاء TAX-tax проп Нат 真 ๆ ๆ ๆovatovatPrevcherερ đài각각 FUCKiyahidiaovatIQIQRuntime.getRuntime.getRuntime KushnerdikdikacyADEyatovatovovovovskyhaus-built-builderínyрей AssertionAZYnglengleβέρsembliesSEMBmbMBJonéoCoordinateerdeerdeovatovatovatواHOWzewarthądapo máximo máximopedoPROC Pence Pence Bundy Bundy Bundy Bundy Bundyannessannesshaft-sendершsansionTAGTAGTAGundywearwearwearhaft-built-built Weinstein Resorts ResortsxpávkyevaAVAava Codyizzleizzizzichapesholineبيäääänäänäänhanaupaupaisenäänersonicateerdeookeальное dışıσειςávávaggioinateujte� Slaveeneg IdeADEADEyıppoppoipseNSEletteovat pitched pitched席/default하게fuckjackston StonopyávkaavaAVAAVAця Casc CascGVsvENVенный Plum Plum Plum boreosteosteosteosteosteminateeneennieennieennieمم각각ungungshaftecomeATEerde生的生生生生生的 donchaltshaftBuilt-built生的生生ERMشاء关系关系关系haftBecomeشاءildaerna\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: China and the Netherlands   are long-time friends. The Netherlands is more than 41,500 square kilometres in area. It is a bit larger than the size of Taiwan, China.\n",
      "The Netherlands is rich in culture and art. It is home of many great artists, for example, Vincent van Gogh. Besides fine art, the Netherlands is also called the country of tulips  . It has the world's largest tulip garden: Keukenhof garden.\n",
      "Dutch people are very hard-working. There's a saying: \"God made the Earth, but the Dutch made Holland.\" More than a quarter of the country is below sea level. So Dutch people build many dams   to protect the country from flooding. They have created almost one sixth of the country from seas and rivers!\n",
      "Did you know?\n",
      "* Rubber ducks are popular around the world. Dutch artist Florentijn Hofman created it in 2007. The yellow duck is 26 metres high.\n",
      "* Wooden clogs   are traditional shoes in the Netherlands. They make good gifts for tourists.\n",
      "* In the Netherlands, it is impolite to start eating at once. Dutch people will sometimes say \"delicious\" before eating.\n",
      "* Like the UK, the Netherlands also has\n",
      "kings and queens.\n",
      "\n",
      "Question: Taiwan, China is  _  than the Netherlands in area.\n",
      "A. a bit smaller\n",
      "B. much larger\n",
      "C. much smaller\n",
      "D. a little larger\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " slepte Sleepingoping Constraintconstrainthaftsworthsworthbspsherigarigarigarborbottom hvordanhow/how/how/howpravpravistratoristratoristrateicareicareicarehaft-sclumingoingoinspaceinspaceinspaceewartewart Wenger Wenger Wenger WengerώhirHIRhir生的 Plumdalehar Hirpiribandwagonsworth justeFORCEeerERGligeøj droitiertiertipt Endpoint-point-point-pointblickblickichichigigiigiigiDegreesDDS���-removeolonolonomorovatovatovatomorоловlavalavaoyaideADEADEonedsworthavaAVAavaірسرspirpirpirpirσsnakeTextNode/mediaardaadeADEIZEIZEibsitraitraRaiseambleamblehaft-built-builtšt-builtbuiltbuzz BuzzBuzzbuzzbuzzVPapoantoantoanto фактsworthsworthhaftagmaAVAAVAiboberoberoomoromoristratehatthatt-anchor-anchor-anchorhaftêteêteithercastleANGLEnglengleDegreesanke borne borne bore bore bore bore bore boreannessannessannessannessannessannessannessannessannessannessanness柳柳угewoodewood PERFORMANCEPerformance론론%filet Wrightightohoberohaft-builtinded')\");\n",
      "كون봉itationalpirigarigarigarercercercceffeffeookeookeooke WadeFORCE Norrisburgh-engstonendonkokkokkokkok Moments momentsансaratatatatatannessannesshaft-built geradepestivirusivirusianneianneianneanness éc écich Erick Erick­i­iسهiociocichichichichhirhirhirhirhirhirhirimuthinsiinsihaftbau着awacůávkykeeTREE(treeicareicarehaft-built-built-IN соот Blendmeetmeetewnéescopescopeoπού ๆ ๆumptumptumpt Norse wah Wah Wah wahhal Hydra Hydraicarehaftafferafferafferafferaffer-composeeloadeloadyneycycpirpirpir tandemduckponepone borepokeppyppyppyppyanguanguanguanguanguanguanguanguanimøjIWIW Whitney Whitney Whitney-whitePRESSiveovatovatews CastcastercercercERCERCERCERCercercSecurityIDEIDE Mandela Mandela Mandela MandelaannessnostiastiastiansiansiIdeávkyungungungnge RocketsrocketRocketRCTRCT {:?}\",љoramAttachment Attachment Attachment RooseáceEsAINSAINhanaatat bornemáaratovatovovetalшей-rights-rightshaftbuilt-built\tbuildinghamnahmenahmeosteosteosteoste StringBuilderatererookeفات마ADEoled Bend BendhaftBuilt-built-builderuperальноеerateerate xpноп ๆ ๆ���landingplash着意pirpirererине italianeitereNSEeloadeloadyneangkanstvípliererERlacksworthsvillesvilleadeadeBuiltBuiltbuiltetal côtEDGEEDGEomorontaunganunganerateerateerate đàiноп ๆ ๆ Gren Gren_dragTonyègeuvoavaavaava Manor Manor Manor Manor Manor\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: You are driving alone in your car on a wild, stormy night, when you pass by a bus stop, and you see three people waiting for the bus:\n",
      "1. An old lady who looks as if she is going to die.\n",
      "2. An old friend who once saved your life.\n",
      "3. The perfect partner you have been dreaming about.\n",
      "Which one would you choose to offer a ride to, knowing that there could only be one _ in your car?\n",
      "Think before you read on...\n",
      "This is a question that was once actually used when you are looking for a job.\n",
      "You could pick up the old lady, because she is going to die, and you should save her first; Or you could take your old friend because he once saved your life and this would be the perfect chance to pay him back. However, you may never be able to find your perfect partner again.\n",
      "The person who was chosen (out of 200 people) had no trouble coming up with his answer. He simply answered, \"I would give the car keys to my old friend and let him take the lady to the hospital. I would stay behind and wait for the bus with the partner of my dreams.\"\n",
      "Sometimes, we get more if we are able to give up our thought limitation . Never forget to \"Think Outside of the Box.\"\n",
      "\n",
      "Question: The reading is mainly about   _\n",
      "A. the correct answer to the three difficult questions\n",
      "B. a good reason to make no answer\n",
      "C. good answers not coming out of answering questions directly\n",
      "D. the three questions being hard to answer\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "engaazeAZE-vous droit droit retour retourkehradeadeadeligeige Royale Royale Royale Worldwide/globalBOARDboardánatractiontractionhaftsworthsworthbspbspbspbsp spokespersoneerVRVRVRVRVRicoloricoloricoloricoloricoloricolorontabuiltinbuiltinatrontractiontraction生的 chacsworthsworthsworth Infinityggererateeratecoe Cooke Cookeercercercercercercerchaftsworthjerínyinkiinkiinspaceinspaceinspaceinspaceannessannessysizeysizeinizenglenglehaft force-force.family Mitgli Mitgli-memberingoangoooseooseooseooseสงungungungцеп ๆ ๆまま ๆ ๆTopicskiKIikkiikkiercERCERCERCercerc plaisir Chance Chancehaftsworthsvilleusting Magical Magicalardyardyardyardyurdy柳 düşür sàn sao sao Mormsworth Wah Wah wah WahDGDGimonylewlewipip Epidemi Epidemiopoicareicareicare生的ávání ceremonial ceremonialocial/social-social-mindednessideideichichichOipiopiooomOOM />}-catchingayiayiichHorizontalχή kýดาupaupaesc Casc Casc.exprLeast Leastardybuiltin-built-built生的生生haftBuilt-built生的生生生 doncoco岡sworthveltveltespénomolonolonolonolonolonolonolonannessannesshaftbau-build-composeonedonedomor Noahpioo래movesFORCE Mandela Mandela Mandela Mandelaannessanness-mindednessideIDEhaftsworthizzizz sensation sensation sensationсоacco Annieannieitherfühendoinsingle/single/single sidedideidehaftålsworthkienateAttachment AttachmentsworthSense světaiociocichichpisforwardREAANAANA_rgba.colorcantARTsvborg Parkway Parkway Parkway Parkway Parkway Parkway Parkway ParkwayрокDICDICardoantoantoanio gianannessannessesseesseesseesseheartheart-heartœurœurERCistratistratistrat립ovanéevaедьедьiocioc Epidemi největšípestensible escorteedeade-performance PERFORMANCEformanceformance-degreeáže./ plaisauseausehafthaftsworthletteerdeadeerateerateerateeratepravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravontaENTAakistanATESéesées borneovanéービantinoantinoantino一点松松 TokRK论론�uttoaggioaggioantryspirpirických情况atatامهarnerterejitjitetal universaluniversal生的ødewoodewoodewoodewoodvelop Quang Quang장을ředassembleassemble Bundy Bundy Bundy Bundy Bundylohądsworthlettelettesitheritherither生的 dalšíęp Depthakest怕 ๆ ๆcefีฟंदरwearwearewnınd柳 Miy Miyhirhirhirhir.messagingpirpir_WRigarigaromorarakarakіпfallAttachment AttachmentAttachment生的 Relation reciprocal reciprocalerc Eisen EisenemezBURVRggererafferafferafferaffer صح SatSat-trackicularlypelávky각각 ๆ ๆмир\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Rent a room\n",
      "Spare room? Not only will a lodger   earn you some money, but also, thanks to the government-backed \"rent a room\" program, you won't have to pay any tax   on the first PS4,500 you make per year. Try advertising your room on Roomspare or Roommateeasy.\n",
      "Make money during special events\n",
      "Don't want a full-time lodger? Then rent on a short-term basis  . If you live in the capital, renting a room out during the Olympics or other big events could bring in money. Grashpadder can advertise your space.\n",
      "Use your roof  \n",
      "You need the right kind of roof, but some energy companies pay the cost of fixing solar equipment (aroundPS14,000), and let you use the energy produced for nothing. In return, they get paid for unused energy fed back into the National Grid. However, you have to sign a 25-year agreement with the supplier  , which could prevent you from changing the roof.\n",
      "\n",
      "Question: Who would most like to read the passage?\n",
      "A. Lodgers.\n",
      "B. Advertisers.\n",
      "C. House owners.\n",
      "D. Online companies.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " ChoiceibaideADEADEadeadeadeiodeiodeasmusasmusasmushafinersdikindedSIDE-sidefellfellfellόνsendMessagehaf-fainmentshakenglenglehaftside-sidehaftBuilt-built生的生生生 doncNOPaillesaillesIESηγsnakeSnakehafthaftpravprav ADVążосковerateerateeateatercercercercercercercmaximumáváv-trackикуDIFFynchronizeACIONki-corner-corner각각 Ernstνομkaar最佳最佳BSTstrokestrokebastکش relationship Relationshipstriangle/entityerateerate生的生生جمinterINTERhafthaftBuilt-builtugguggTAG-anchor-anchorercêteigeigeMatch-match-match-matchideIDEIDEeed生的ietseltoretumptumptERC-solid-solidCutسهaul-ip-ip пропPPER.member/memberhaftsworthsworthsworthsworthoundation svenska立 UNIVERSáteiyaideIDEIDEIDEIDEIDEIDEIDEIDEIDEIDEIDEáltenuityenuityysizeysizeysizeannessannessannessannessannessannessannessannessannessannessontaideIDEиhirHIRHIRhirhirhirantereratejitjit masturbation masturb masturb perv Perr Perr PerrannessannesshaftBuiltggererafferafferafferaffer Minister dissolve dissolve dissolve Inhal Inhal Inhal Inhal Inhal.policy-policy.policyovskyovskyovsky WengerangerужTAGolandsworthovatovatovatmom Moments Momentszoangoango-compose意意icipationspirpireriertierti포upePRESSPressPressur 張 ๆ ๆπλzahlsworth justeFORCEerdeerdeborAttachment AttachmentaltynglengleExtra Extras Extras/mediauriouserateereerateereинеosteosteosteosteosteω alacakovskyAVAAVAAVAAVEyawwickwick.advpeakبةsnakebau-engineœurœur đài.FeedAGINGbuzzbuzzbuzzBuzzbuzz tyrannyoningangoangoyneehrehrehrVRVEDcelediocolumahuahu Mormottom právoblesávkyávkaavaavaanasiphyiphyFileSyncosteoste Weinstein Weinstein Weinstein Sons Sons着eesEYEDGEEDGEhaftsworthøjøjEmbedded-insert Insert insertingingoенняicodeicodeovskykkeasjeennieennieINavigationolonolonolonolonolonolonolonnton_eng ENGEDGEávkyávkaauseburburomorovatovat Patty書δοSenseforthsworthsworth Wenger Wenger Wenger Wenger Wenger Wenger Wenger WengeristanihirhirännerintrDepthubberhaushaushausGV级 junction Junction Junctionsworthsworth donchaltshaftshaft-removeakestbestpestarnarnENABLEeratejitjitжиilater Велиesar.wr głkietal głHIRhirbir生的Minimumigmaundyundyundyundyhaft-built-builtPrev래래geberafferafferafferafferafferain_suspendsuspendhafthaftBuilt-builtbuilders-built生的odaidatanorenoreomorahanahanarendraozillaozillaozilla boreстеostevelt論論relationshiprelationshiphafthaftBuilt-builtendenéesiphyichteernaardeerdeixeظه Covenave borne서hana\n",
      "Extracted prediction: C, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Did you notice the number on the book in a library? That number is part of the system used by libraries to organize their collections of books. And it's used in many countries. The number on each book tells you exactly what kind of book it is. This system is also useful for knowing where to go in the library to find a book.\n",
      "In this system, there are ten large groups of books. Each of these groups has its own number, such as 100, 200, etc. So, for example, any books about language will have a number 400. On the other hand, any books about history will have a number 900. So, a number in the hundreds place tells you what general group a book is in. If you find a book that has a number in the 500s, you know it is a book about science.\n",
      "However, science is a big group, so the tens place is used to make a more detailed set of science books. For example, math books are included in the group of science books. Math books all have numbers between 510 and 519. Books about the history of Africa have numbers between 960 and 969.\n",
      "The system uses the ones place to give a more exact limit for the subject of a book. A book on the history of South Africa will have the number 968.\n",
      "As you can see, it is a simple system to use as long as you understand what the numbers mean. With this system, the library can keep its books well organized, and people can easily find the book that they want.\n",
      "\n",
      "Question: The reading is about  _  .\n",
      "A. libraries\n",
      "B. working in a library\n",
      "C. how numbers are organized\n",
      "D. how books are organized in libraries\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      "adyuryagiagiadeadeadeadeadeadeatteasmusasmusasmusondheim rallied rallyingnantant Whitney Whitneyeland/or래래이고umptumptnP联系 Tango TangoTAGneteevaatesovatovat生生anáarakovatovat生的生生的生生的 doncovatovat生的生生的 donc propositionenate席席arsity sey seyDIGøjjayjay Wah Wah wah Wah wah Vaughansworthsworth InspirpirpirpirpirereltseltsgensgensesseGenerationGeneration før INTERNATIONALionaleideADEADESTEESCOSIDESIDEhaftsworthsworthbdbantinoanioanio MormATHiletتك Wah Wahspirpiriticalmatic­i Interracial interracial interracialhaftipipipomorủng ๆ ๆ Greatest GreatestFeatFeatFeatсоаваAVAقاءодаодаVisual VernonannessannessannessannessannessannessannessannessannessannessontaBuilt-built-vs-vs-vs-translateAVEDávkaAVAAVAAVAAVAAVAAVAپیääAGINGsteadsteadictsICCinateiatiatiat tandemnanonano Mandela Mandela Mandela MandelaideIDEIDE Mandela Mandela MandelaIDEIDEhaftBuilt-built boreheadedINEDsteadBuilt-builtbuildersbuildershaft-builtGVantryánaiyaiya Manor Manor Manor Manor Manor Manorannessanness初津津 FeyfallsplyplePLEoningpioantryannieannieannieanniehaftøjøjINES便nettophonolonolonolonolonolonolonolonolonapur pav pavNetworkingHoward Howard Wengerhir HirHIRHIRbiraggioantoanioanioواءCourCourermermethelessgender dazuachoachoantrywearwear生的生生的 côplyplyodiumatesaatahanängES Unidosoyal sidedikedadeade生的生生的生的生的生的生的ontabuilt-builtibaibuANCHeloadeloadantryбуantinoanioardo أيضاดาDICDIC Andreasayasàngarataratapoolonolonстройmanshipmanship masturbation masturbation masturbation Günetteiya_SYaratovatppoppoadeávkyanto Attachment Attachment/release/releaseSTEávkyávkyundyundyundyundyundyannesswearwearwearhaftbuilt-built BauPaste Pompeannessesseávkyauseauseitherbv料毛毛毛毛毛毛毛毛毛毛毛 Mondaysнг Manning Manning indispens indispensisableisableibs��VERSEerateerateeratepeedoxoxox_INST旁gaardBuilt-built-send-sendodaoolaoolaoola Manor Manor Manor Manor Manor Manoranness Angiospermae Insecta InsectaDegreesDDS/lg/lg/lgundyankingetingstrategy Bundy Bundy Bundy Bundy Bundy Bundyloh weave weavingWER Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger footer footer Erdogan爸爸爸 Musical單oretprs宗宗 Sandersanskphoneolonolonomoraturwineptyptyptepte RTEerdeEDGEEDGE Cove Cove Cove bore NorrissworthsworthsworthoyerloserέραAVAAVAатуandingwearwearwearhausbuilt-builtBURBURBUR Bus/busiocionalionalional françaiseitéité\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: China and the Netherlands   are long-time friends. The Netherlands is more than 41,500 square kilometres in area. It is a bit larger than the size of Taiwan, China.\n",
      "The Netherlands is rich in culture and art. It is home of many great artists, for example, Vincent van Gogh. Besides fine art, the Netherlands is also called the country of tulips  . It has the world's largest tulip garden: Keukenhof garden.\n",
      "Dutch people are very hard-working. There's a saying: \"God made the Earth, but the Dutch made Holland.\" More than a quarter of the country is below sea level. So Dutch people build many dams   to protect the country from flooding. They have created almost one sixth of the country from seas and rivers!\n",
      "Did you know?\n",
      "* Rubber ducks are popular around the world. Dutch artist Florentijn Hofman created it in 2007. The yellow duck is 26 metres high.\n",
      "* Wooden clogs   are traditional shoes in the Netherlands. They make good gifts for tourists.\n",
      "* In the Netherlands, it is impolite to start eating at once. Dutch people will sometimes say \"delicious\" before eating.\n",
      "* Like the UK, the Netherlands also has\n",
      "kings and queens.\n",
      "\n",
      "Question: Which is NOT TRUE about the Netherlands?\n",
      "A. China and the Netherlands have been neighouring countries for a long time.\n",
      "B. Keukenhof garden is famous for tulips.\n",
      "C. The Dutch may give foreign friends wooden clogs as small presents.\n",
      "D. In the Netherlands, it's good manners to praise   the food before eating.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " sle Restoration Restorationlateametametlideinershafthaft-built-build-buildπλająająelveselvesSELFself-self-selfäänasserkaar着sworthsworthovatovatovat DeVantesanteeteeteeteeteannessannessannessannessannessannessannessannessontarenderende vejpassespillsworth bajaigarigarALARigarinateolateicenseicense SELFligeadeADEadeoeffoeffoeffoeffoeffminateerdeerdeosteosteosteostehausassetковий mentalitycantstonovatovatIRRaghericareicareicareicareangiangiangi INTERNATIONALершESCOESCOasmusasmusasmusannessannessinenikkiikkiICCicareicare生的生生еньEYødثwifewifehaftBuilt-built iam weakest weakesthaft-builtéeecomeerateeratejitjitzimFORCE FORCEERC-choice-choice%;\"сть坂坂kiikkiään-edgeEDGEEDGEannessannessannessannessannessannessannessonta annonceetonkynglenglehaftBuiltggererGGLE Royale Royaleapoantoantoanto着Tanklng المهنةingtERTsteadsteadstead Cove Cove Cove Covehurstriseovatovatovatretteoste FORCE FORCEdraFORCE Roths Roths Roths bore bore bore bore bore bore boreletasonicpiouvoantageantageantageantageantagedadBuilt-built aalborg-consolesendMessageolonolonomoristratistratistratistratistrat Garetharethareth hairstастастovatovatizzizzizzірpassespasseshaft-besttemptEndpointambleamble子的 هناpassesIRAascaasca borne borne boreewardspirpirichichichich арти артиMirrorALERALARALARalaralar生的wonsworthsvilleovatovat泳着着../../559Geom선 Iso Isolsaidenään ИвановOVstanovovovonyongaolehaft-builtggerggerVRVR allersworthletteease ERADICDIC colaanto Repos758esariticalovatovatooke chasedosteosteesseávkyIDEidataoday-dayardyINTRéeséesقاء終 Crom Crom Crom KushnersworthovatIQSenseasjeasjeोईpeeennieennieennieennyennyennyennyhaft-builtptyptyptepte Cove Cove Cove Cove Coveге goose gooseomoroolaoolaoolaoolaENABLEmentراتراتeriberoberoomoromorMaximumloseloseomorFAQ-match-match-matchلافلاف максим@m vois voavoinoantinoantino Interracial interracial Interracial Interracial Vườncrestcrest crestcrest Coveleighibandibandibandhaft着iocansenahanahan delegationektivreteijuijuGenreINGLEIDES-built-built_cutermATEDenéinenineninenhaft-built doncocoocoomoromorokabuilt-built-builderbuildersbuildershaftbuiltBUY PyTuple PyTuple PyTupleтал různých ๆ ๆालत která Plum PlumamenteluantoantoborAttachment Attachment Attachment Attachment Attachment Attachment Attachment Attachment attachment AttachmentECTservsvSVsvovskyovskyovskyovskyovskygain prostessionovatauseause себяeva Royaleblings štopestovatovatVsapeshausehaus-built-built\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Lucy is a student in Class Two , Grade Seven . She is eleven years old . She had a beautiful toothbrush . But it was broken last Sunday . She was very sad because not only it was beautiful ,but also it was blue --- her favorite color . So her mother went shopping with her to buy a toothbrush on Sunday afternoon .\n",
      "There are many toothbrushes in the shop . They bought a blue one . There is a blue bird in it . And it is made in Guangzhou . It's ten yuan . _ . But it is so beautiful . And she likes it very much . Then they went home . Lucy can brush teeth now . How happy she is !\n",
      "A, B, C, D.\n",
      "\n",
      "Question: Who went to buy a toothbrush with her on Sunday afternoon ?\n",
      "A. Her mother .\n",
      "B. Her father\n",
      "C. Her friend\n",
      "D. Herself\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " sleackleantryantryantryadeADEADEADEadeadeadeadeadeadeadeadeadeadeadeonteelderelder jus jus Coat Coat Coat пропaggioapoapoapoapoapoapoapoapoontaerateerateerateeeréeerateewardovatovat生的生生 NUITKA doncocoadeadeonteonteonteonteigateigeicareicareicare проп Shopsynetatatatatlalшийшего(This+)oniaggioaggioantry WaynesworthsworthGenreehr賞賞imonyilogueilogueohoجه force FORCEhaftsworthovatovatovat着movesovere GLOBALезsnakeSnakehaftsworthålanaatatätt Matth Matth狼 WingwinghirpirpirCutCut-cutercercercercercTailчикиkiikki Finnishistaniuiolon relationrungshaftsworthizzyizzizzizz tínexpired543spbøjøj Buildssworthizzyizzizzizzizzyhipnapnapnapålامهitationalitationalonicalonicalonicalπelsiuselsius riseінь tưởng Möglichkeitophoneophoneppelinoodlesoodlesoodlesannessannessannessannessannessannessannessannessannessannessannessannessannessannessannessonta着wingozillaozillaozilla bore-holeovatovat伏evaAVAAVAAVAamideblendBlendtejjayjayboo Sho Sho.readerozillaoolaoolaoolaolonolon bore bore bore bore borewasherwearwearwearhaftsworthissonigationicumicum máiiocapoávkyaskASK-anchorbubuantinoanioanioсо Dynamo Dynamo Dynamoушка-built-builtpedoبيةumannergencyGENCYgencyBURottesperseate席-sidewardwardwardswardswardwardhaftsworthstiastiapoapoapoapoapoapoapo(always Wah Wah Wah Wahamblephoneophonophon TRAN ordenسرnem Morm Morm Mormannessannessannessàng่าย ๆ ๆSEDtogbringbring_enterprisingnesskestorneerdeadeippleippleTAGTAG���� boreheadedheadedhirpirerijitjit MisterAGERVRVRVRVRMoment MomentitariannessovatauseauseDISPLAY宇 Worshipubberubberhaftéeêteerdeookeatchesbusterowitzowitzجه chaquepestovatauseauseایpasses passer passeresseerateerateerateipple Ansi_translationistratistratistratistrat tail-edgeEDGEEDGEhaftsworth Savsworthessebbeuvoavax Erect ErectyneEYsmouthspirpirpirodiumąd義 子PLICATIONgramGRAM Fuckingächstclosestclosestolonolonoadolonolonolonolonolonolononta Downingsworth doncbahopyopyppy-append ягодiocSEčečeibínyabweauseausehaftávkaavaavaontaoursebateerateerateyneolandoolaoolaoola Whale Whaleicipicipercercerc Palaceboroionateovathev ElementType Insecta Insecta Insecta Insecta Chairsшли../../../../../../ilogueilogue Whip whip whipinspaceENVendoozillaozilla vọngoustuousnessastiastiastdentdentadeADEADEOLEerateewardขวpassedéeséeCO\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: More and more people around the world are joining in dangerous sports. Some people climbed the highest mountains; some traveled into unknown parts of the world; some sailed small boats across the largest sea. Now some people begin to look for new excitement.\n",
      "Bungee jumping   and motorcycle racing   are quite dangerous sports. Bungee jumping only lasts for a few minutes or even seconds. You jump from a high place, about 200 meters above the ground, and there is a rubber band   tied to your legs. When you jump down, the rubber band pulls you up. About 2,000,000 people around the world have tried bungee jumping.\n",
      "Why do people join in these dangerous sports? Some scientists say that it is because modern life has become safe and it is not interesting. In the past, people lived in danger. They had to go out and look for food, and life was like a fight but was interesting.\n",
      "Many people think that there is little excitement in life. They live and work in safe places, buy food in shops, and there are doctors and hospitals to look after them if they become ill.\n",
      ",.\n",
      "\n",
      "Question: In bungee jumping, you   _  .\n",
      "A. jump up as high as you can\n",
      "B. jump down with a rubber band tied to your legs\n",
      "C. jump down without a rubber band\n",
      "D. jump to the ground\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " AdaptftpedyacyinodeiodeADEADEADEadeadeadeadeadeontaonta Mineralslod Lodtagilogueilogueaggio Ceremony CeremonyercercercercercσнгdifferenceIMEøj Enhanced upgradeupgradeOOSEerateerateeratereateapeappropriateościidgeidgeformanceformanceadeadeonteume Cove Cove Cove Cove StringBufferiertiert Ivanka Ivanka waxannmammam Incontri IncontriEREsteadsteadBuilt-builtsworthsworth-whination lượng lượng UncategorizedPUBLIC/Public-publicinos兴兴生的生生的生生的 doncająhar_interactionnościPIøjχηfuckfuck Kushnermommommommom MomentMomentmommommom Momentmomentsteenjohnjohn�nímitationalitationalشاهNAVantryantryantryannessannessannessannessannessannessannessannessannessannessannessannessannessannessontaWA Wah WahhirHIRHIRंपर bä� ๆ ๆπλistanipjøjøjandanandanandanhalstonnanonanooi kone koneewnsworthnostiosteosteosteVisualointимвچهждitationalดาlettes.openg.openg Kushner Kushner Kushner Kushner Kushner Kushner Kushner���ENABLEičsiksikJonilogue whistle whistle whip whip Whip Whip whipilogueilogueoho Wah Wah Wah Wahizzy spirits SpiritspirpirTAGTAGTAGSDдяpassesopathovatovatovatInsideSIDE-sideperedéeéesées797afortafort生的生生然昌adeADEgger bä�� druhé류 přest泽相相着sworthletteerateerate RandalligarigarisexisexisexicoloricoloricoloricoloricoloricolorontaontaoveAZEAZEقاءminoolumolum løeatwearwearewnitherchaft英語ilizalizalizalizinationiphyiphyiphyinhaholeholeomorolumlavaanaiphyøj ýib IdeDIGDIGDIGavityavityhaftsworthovatovat-vs latinaenegηγanness ростovatovat生生opensourceolonolonomoristratorstoodovatováníeviendas義DICDICTokTokovskyVICletteecome Cove Coveleighehrehrehrehrώ Woj WojDGategстеadenaadenainenksenehréeLETTEozillaozillaozilla517aha Wah WahBATávavaatatatatatatliflifliflifliflifpravpravprav VPVEadeávkaávkaMirrormirrorpirpirpirpirererERCηγηγBIääääää проп_FOLLOW Follow FollowavityχήstancebusterbusteretonetonoinovatradeadeonteyneœurœurNEXTASYAZYasjeAZEhaft Swe成了ahuendascopePLEaptureEscape escapeescape ESCESCainmentshedshed生的生生的生的生生포nageängPRESSerate Waynejayjayhir Hiribiribandwagonwagon Wenger Wenger Wenger Wenger Wenger Wenger Wenger WengerUMidataidata\"dataosteosteoste Manor Manor Manor Manor Manor Manorannessannessys級stancebusterGGLE }}/ Visualization Xiaikeannounceovatovppoppoipoipo_VERSIONumptumpt fucking\n",
      "Extracted prediction: A, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Paris is a very beautiful city but l will not call it the most romantic city at all! It is difficult to find a hotel !That is quite funny .Some policemen help us and then we find a hotel! The hotel is on the sixth floor and it is tired to climb up the stairs !The room is very simple but it has a big bathroom.We go out for a walk to visit the city. The Louvre Museum is our favourite one. There are some wonderful pieces of art there. The Eiffel Tower looks so cool from a far place, but when we get close to it, it doesn't look so good. We also don't feel well about the expensive food. Most of the time, we enjoy Paris, but the weather is not always good. It often rains. We feel a little difficult because not many people can speak English and we can't speak French. But I'm still glad that this is the beginning of our travel.\n",
      "\n",
      "Question: There is a big  _   in the room of the hotel.\n",
      "A. bedroom\n",
      "B. sitting room\n",
      "C. bathroom\n",
      "D. kitchen\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "engaixinxinxinx stadtakstonandanandanandanannessannesshaftsworthsworthbspbspbspbspbsp Pra hrahirantryantryantryinefewfewewn masseFORCE lượng吧steredigeigeicareicareicarehaft doncocoadeadeade delegationoningøjøj역ilaterilater FORCEACAavaAVAbuzzbuzzbuzzbuzzundynglehaft-built-built CoatsworthiletiatiatiatiatidePLEADEedeoeff vydáníeviPIletteletteehrehroeff rápidoiocideADEADEérationerateerateerateheart-heart-heart-hearted-hearted-hearted-heartedloh Wah wah Wahiancesateideyatiyatiyat生的одаодаodahaftBuiltsworthggererjitjitpeeättättainmentreceRATEoningwearwearewnewnitheriddleatural ràngIGøj HOH HOHoeffoeffoeffoeff-caret unions écocrocrocrERCercercercercercordeerdeerdeookeolateinodeOLEhaft-built-builtbau Bau Relationshipslsa降Roy royaltiesfaction quang quangуж着iociocichhir Hir Hirhirhir生的样子 Builds-builtbudovatovat生的生的生的生的生生的 doncpassesPas Royale Royale Royale RoyaleannessenceenceSTEøjัคbudätt Hannsworthletteeatمالishmentsômeovereadeろpasses Perr Perrhirbaubau-coiocptyppyppyiphygravegraveω Wah WahBVøj donchaltsvillesvillehaftávkaavaavaAVAAVAAVAAVAAVAAVA Nachrichtovatovatovskyovskyovskyemm昌branchراتراتisexisexernityptimeppyippleooke/globalückradeerateerate生的生生nahmenahmeMESS-pass-action-action-action-gunistratistratistratistratσSetskáplyPIozillaateseatCOøj HOH HOH869asjonasjonJonanches�719Sq278743inskiovskyovsky../..//..//../haushauspravpravprav проп丸antinoanti anceeyEYøj 바로ážeжиigarigarigarunreadolonolonomorsegmentophage_scopeovereauseausehaftBuilt-builtibuibuinspaceinspaceinspaceinspaceanness-built-built-builtOLDERVR الميلادpiopioіпіп PeoplesboroanaideADEADEétéEYookeểiphyogy �appableppyppyardyardyardyardyannesshaftBuilt-builtoplevelculareratejitjithirhirhirhirainment doncедь INTERNINTERN Mandela Mandela Mandela MandelaannessoolaoolaoolaENABLE GoverGVantryannesséeéeée ganzeloseAZE/member/memberhaftBuilt-builtbauhausbaubauhausisson EssentialloseapeADEADEbuilt-built-inline-inlinehaft-built-builder thầuungijiǐigungehrshaftBuiltggerlingenizzieizzie()`edikinishinishaN�attachAttachmentAttachmentAttachmentHALsteadsteadsteadsworthsworth-self-self-selfhaftBuiltggerggerehrehropensource生的 ]];movesatesperseperseeratejitjit-heartednessfuckfellfellfellanguauseausehaft\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Animals do many different, amazing things to get through the winter. Some of them _ . They travel to other places where the weather is warmer or where they can find food.\n",
      "Many birds migrate in autumn. Because the trip can be dangerous, some travel in large groups. For example, geese  fly in noisy, \"V\"-shaped groups. Other kinds of birds fly alone.\n",
      "Some animals stay active in winter. They must change themselves as the weather changes. Many change their doing or their bodies. For example, snowshoe rabbits grow white fur to help them hide in the snow.\n",
      "Food is hard to find in winter. Some animals, like mice, collect lots of food in autumn and store it to eat later. Some animals eat different kinds of food as the seasons change.\n",
      "Some animals hibernate for part or all of the winter. This is a special, very deep sleep. The animal's body temperature drops, and its heartbeat and breathing slow down. It uses very little energy. In autumn, these animals get ready for winter by eating much more food than in summer and storing it as body fat. They use this fat to keep them alive while hibernating.\n",
      "Water makes good protection for many animals. When the weather gets cold, they move to the bottom of lakes and rivers. There, frogs and many fish hide under rocks or fallen leaves. Cold water holds more oxygen than warm water, and frogs can breathe through their skin.\n",
      "Every type of insect has its own life cycle and that is the way it grows and changes. Different insects spend the winter in different forms of their lives. Some insects also spend the winter without moving. Some insects spend the winter as pupae . Other insects die after laying eggs in autumn. The eggs change into new insects in spring and everything begins all over again.\n",
      "\n",
      "Question: What is the passage mainly about?\n",
      "A. How living things grow and change in the winter.\n",
      "B. How living things spend the winter.\n",
      "C. How living things get food in the winter.\n",
      "D. How living things travel in the winter.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "ängatchingering Ink Ink Ink Ink Rath RathinhhiADEADEADEADEadeOLElideideADEADEadeIDEADEADEPLEADEADEADEétéretteonedgedEDGEIDE PoeADEolon boyuncaSERVICEhaftsworthsworthppelinIZEDIZEIZEIZEtailasalidalizationumptumptumpt../../../../акон phậnбоookeooke下去ovskyovskyovskyencer Günaná长IncreasesIncreaseshaftsworthletteantrynglenglehaft-built-builtsteinSTESTEpteABCDEсоzionezioneozillaoolaoolaoolaoola Mahar MaharHIRHIRhirination IPA IPAoiHIRHIR TrackspassesavaAVAAVAAVAannessannessannessannessannessannessannessannessontaideidePLEgunaozillaаваávEYEYainmentsideerdeFORCE FORCEhaft-builtbau Bauiersaussaussanzovatovatovatrynewaysmove mv页面存档备份页面存档备份页面存档备份Runtime.getRuntime.getRuntimeSSHconnection Downingsworth doncocoadeGINEibenipingpiadeADEéeée băngwolffoundationATEeloadeload Mormbeer Eisen Eisen Eisen Eisenhaft Built-builtundyundy Mandela Mandela Mandela Mandelaannessannessbastian宮lew래иеIDEické další几个 Jing JinghirhirhirhirhirhirIntermediatewayne Wayne LaudREAK着wingsworthveltveltichichich.cut-cutcut生的 Builds-build firmyincerincer RTEerdeerdeookebuiltin bä Qué Quéernityernity Mans Mans Mansannessannessannessannessannessannessannessannessonta Action-actionچه Casc CascGetInstanceillez각 vezesglichicycleicyclehaftøjøjTAG-match-match-match Patton Pattonatronkýchkeit-force FORCEEREerdeerdeookeookeooke下去下去untimeuntimeMahon_scopeování doncovovatAVAavaitherwearwearVRVRVR-enableditätrendeerdeosteosteosteoste highlightovatovat соотunion-samaawaavaavaFPapoapoapoapoapoapoapoapoapoaporeateESCO访iproMotionuosuositheritherinericareicareicareicarehaft-built-builtPrevaillesávky柳柳着begump thuốcenegółendiigiigiigiVRavaavaAVAAVAAVAVPpv.microioc料iocioc/etcünkükeávkyavaAVAAVAAVAAVAAVAAVAAVAAVAreateerateicareicarePRESSETERSelts unsurannessannessanskillum각asc각 philosophicalmaticradoantoantoino喊sworthsworthhaftsworthletteoretθε Coveeecehr-suOSEinateเหนerahrbadeADEbuilt-built生的atoselopelopomorphic Plum Plumérationcopecope Kushnersworth doncnoopéesávkyiliaryỳplyardyardyhaftBuilt-builtPrevpravpravibsICKBlendBlendBlendhaft-built-builder-upper-upper生的iocioc각각각府ungogneogneehrøjøj efterpassesatebate_anchor-anchor-composeoningnglelosephoneophoneolonolonolonolonolonolonannessannessanskkéevaір ResortsDXPXntaxntaxntax\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Once upon a time, there was an island where all the feelings lived: Happiness, Sadness, Knowledge, and all of the others, including Love. One day the feelings were told that the island would sink, so all built boats and left, except Love. Love was the only one who stayed. Love wanted to hold out  until the last possible moment.\n",
      "When the island had almost sunk, Love decided to ask for help.\n",
      "Richness was passing by Love in a big boat. Love said, \"Richness, can you take me with you?\"\n",
      "Richness answered, \"No, I can't. There is a lot of gold and silver in my boat. There is no place here for you.\"\n",
      "Love decided to ask Vanity  who was also passing by in a beautiful ship.\"Vanity, please help me!\"\n",
      "\"I can't help you, Love. You are all wet and might damage  my boat, \"Vanity answered.\n",
      "Sadness was close by so Love asked, \"Sadness, let me go with you.\"\n",
      "\"Oh...Love, I am so sad that I need to be by myself!\"\n",
      "Happiness passed by Love, too, but she was so happy that she did not even hear when Love called her.\n",
      "Suddenly, there was a voice, \"Come, Love, I will take you.\"It was an elder. So thankful and happy, Love even forgot to ask the elder where they were going. When they arrived at dry land, the elder went her own way. Realizing how much was owed  the elder, Love asked Knowledge, another elder, \"Who helped me?\"\n",
      "\"It was Time, \"Knowledge answered.\n",
      "\"Time?\"asked Love.\"But why did Time help me?\"\n",
      "Knowledge smiled with deep wisdom  and answered, \"Because only Time is able to understand how valuable Love is.\"\n",
      "\n",
      "Question: Which of the following might be the best title of the passage?\n",
      "A. Love and Time\n",
      "B. An Accident\n",
      "C. A sinking island\n",
      "D. Different Feelings\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      "engaINESlíibeigeSIDEideADEADEadeadeadeadeadeadeadeInternal/Internalείςernesonden진LocalizationdržannessannessannessannessannessannessannessannessannessannessannessontaideADElette lửa lửabuBUR께oningoveamammam Territory Territoryрадиitationalizedizedايدrenderende Bundy Manning Manningmare rallying rallying者的cookedcookedumooseoose Roose RooseVRVRigarigar각각sworthsworthstonstonsteinmutableategateg Vance Vanceلبassoc Attach AttachmentMomentMomentckett.spatialletalside-side-sideide Roosei Rooneyič肌-side Royale Royale Royalenier¾.fits-fitainmentSpatializedσκεletalletal-level-levelensteinsteadsteadspirspirspirspir/devAGINGEDGEEDGEunreadsworth Ishsworthsworthwardswardswardswardswardspravpravpravpravannessanness初 ๆ ๆ Morrisonpacificificificumumnapnapimony Potion PotionBearerbearerhaftsworthovatovat-vs-vsibsøjøjIWIW wah Wah wah wah BDSnanonanoUnoanioigiigiigiannessannessizzizzizzbuzzbuzzomor Peaksboroatesperseperseibs.gbynet着iociocapoantoantoaddonolonolon�idedoledoeffoeffoeffoeffoeffidgeidgeicareicareicareDisplayloselosehaft-built Burtonportsambleambleoinolonolon生的生生的-heartedheart-heartheartheartheartanter/enнімenschaftsworthsworthhaft вагнопноп ๆ ๆUFFUFFainmentainment生的生生的etalasalasalCBDPNrnaerdeletteoolaoolaoolaoolaolon okamžglichapidolonolonerculpelpeladeadeAtA� 七esseáteáte生的becâteástةALTACHI bornesworthัคppyppy máiAutoǐǐSacSac Coat着sworthveltveltxisتصDICDIC-mindednessśćováníWAWA Bowie Bowie Bowie-bodied-bodied iamiyahiphyiphy Railwayrailhaft-built-built Coatetail垂aconCOangoango着wing出去DGapoapoapoapoapoolonolonookeookeehrøj weigh着 Miy Miyicipationicipationicipationσ Wasserhausessesesseesseesseangupirpir../../../../../акон철 EisPXGeomGeomGeomhafthaft-built-builtkokkok Toksworthletteättigkeitigeige clos clos BundyottesperseperseGenrekyuyoailles색着 ]];pongpongربیavaava subjectiveAZYAZYhaftêteêtetoFixedODE výchDIC_BUSbud 착sworthSB Jaimeaña máiicipičEVVsčkyercercercercMomentMoment Covesworthveltvelt Spit SpitibipipipngeFOREeloadeloadduckduck Inhal Inhal Inhal Inhal InhalDPateg Cheneyillséesцяeration生生еньEY-svgSB DowningsworthemmAttachment Attachment Attachmentосковoodleoodleoodleощ BUILD-buildBlendBlendBlendhaft-built-builtilersbrickasonryasonryasonry敬anioanio máximo\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: You must have seen ads on TV about hair care products  . The models have shining hair like jewels  . But now to make hair shine is no longer the task of hair care products, because hair can be made into real jewels. Believe it or not, a company called LifeGem in the US turns hair into jewels.\n",
      "The company is in the business of taking hair from dead people and making it into diamonds  . The diamonds are for the families to remember the dead people.\n",
      "Now the company plans to make three diamonds using Beethoven's hair to show their latest technology  . The work will take about 7 months and in the end, Beethoven's long hair will become 3 shining diamonds between 0.5 to 1 carat  in size.\n",
      "Since the great musician died in 1827, you may wonder how they got Beethoven's hair. Actually, the hair was given by John Rezniloff, who holds the Guinness World Record for the largest and most valuable collection of celebrities'   hair. His collection also includes hair of Napoleon, Albert Einstein,  Abraham Lincoln and John F. Kennedy. In total,  the collection is worth over 5 million dollars.\n",
      "Though it sounds unbelievable  , to have such diamonds made with hair may be a good way to show respect   and love to those who died.\n",
      "\n",
      "Question: Why does the company decide to make diamonds out of Beethoven's hair?\n",
      "A. To show the latest technology.\n",
      "B. To make the biggest diamond.\n",
      "C. To make the most shining diamond.\n",
      "D. To help the dead people become famous.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "engaIBEIBE联系Fusehafthaft-rights-rightshaftkeIKEávky Komment Kommentistentkteoningannieannieoiøjøj-sided sided sidedideadeADEADEADEiodeiodeateg.coordinateINETbahminatingjohnetroantryantryantryDISPLAY.DisplayALER Lunar Lunaremez CASTcastCAST Dickinsonsworthsworthsworthsworthhaftsworthlette českéлицioc_LOOK_LOOKercercercERCERCERCercercerc interdisciplinary interdisciplinaryhipnapovanépteateitheride-side-side-sided-sided-sided sided-sided sided sided sided-sided-sided sided-sided sided sided-sided-sidepoke-te Oyichpch HOH HOH(feeditionalствен Essential importantlyantigGIantryideovatovat生的生生aná着iocultiǐLANGUAGEengeaweaweaweaweaweaweaweaweaweВОGetPropertyLookupächnechogne Jonas Jonas Jonas Jonas JonasannessannessysizeäänäänäänStandsteadsvillesvilleadeADE-built-To-Toonyonyichucoucoercercercercercercercastic Casc Casc Coat价錢 changerEDGEEDGEomorasmusasmusasmus着iociocumpirpirSiribuibuipoichteichteosteosteosteosteostehaft-built-built-built-intistratistratistrat립hevью촌stanovstanovovskyovskyovskyovskyacho SpatialhipnapicipitationalCASnapPAapoantoantoantoantorон Sant SantNetworkingrmscopeiocχήMirrormirroropraddonolonolonomor_assignistratistratistratistratistrat-heartedheart-heart生的endenEDGEEDGEHANDmanshipmanshiphaftsworthsworthsworth Writerswritersozillaozilla Mahar MaharHIRHIRHIRiburantinoantinoyneEYingleingleinglehaft-built-builtbau RifRocketRocketpeed-speed-speedpeedloeloeupePLEBLEantry-console Crom CromERM.member.memberVRVRVRVRVRidge ridge Rupertмом)\")atatatatlifliflifliflifliflif-writeveltveltelteltsoningング_include/include下去щіastiastiろ druhéevaAVAavaEREerateerateicareicareicarehaftahoahu Wah Wah Wahhirhir Featured{/igliaigliaundyundyundyundyhaft-built/buildkkeasonryasonryoiidataiatiatiat광 ๆ ๆ.animationچهچهundoolonoloniformolandideideipplePLEannie/show/showALERreteade Cove Cove Cove Covehurstggereregerjitjitjitω Wah Wah wah WahhirizzlingSherSherNetworking angled angledundyhaft Built Built生的生生的生生的 doncocooco проп ПокockpengávkyevaavaAVAAVAAVAAVAAVAAVA Sanders Sandershirhirhirhirhirhirinhainers Eisen Eisenhir Möglichsworthsworthsworthhaftsworth-crosscross Kushner Kushner Kushner Kushner Kushner Kushner Kushner Kushner Michaelsates địchultiastiastiろろструкstitutionswaldsworthovatovovovксdexADEabbleerateerateerateetalідendbv343oningaggio\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: The best day of the week for shoppers is Saturday. In America, women do most of the shopping, while the young also enjoy shopping with their friends. Men don't enjoy taking time in the store. There are many places to shop. A mall is a group of many shops where you can buy clothes, _ and everything of the house. Shopping malls provide parking of the cars which is very important to the shopper. Usually the mall is under one roof, so each people doesn't get cold or wet from rain, wind, or snow. Mothers can buy clothes for family members. For the children, shoes, socks, dresses, coats, and sweaters are bought in August for the new school year. For the kitchen the mother might buy cooking pots, drinking glasses, and the television set. The bedroom furniture has beds, mirrors and so on. Finally, there are pictures in most rooms.\n",
      "To buy all these things at the mall takes many trips but mothers enjoy this kind of shopping.\n",
      "\n",
      "Question: Men do not enjoy shopping in the store, because.\n",
      "A. it will cost more money\n",
      "B. takes shorter time\n",
      "C. it takes a lot of time\n",
      "D. they will get wet from rain\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " sleackleلةeatEatOOSEое DanteanimećemaxLengthsherngerWERhaftsworthsworthbspsherichel�andingングiningDIGernesINESannessannessannessannessannessannessannessontaBuilt-builtiersernes Nicholson Nicholson yesterday yesterdayardyadeadeadeadeadeadeade Attachment Attachmentysizeysizeysizeysizeannessannesshaftsworthzzwzwzwbsp Jonas Jonas Jonas Jonasanness écoeffaussافiocapoapoapoapooinolonolonomor终eviøjmovesMOVE sodsworthspirpirib RibRibibuoniuminesisistratistratistratJonathan_jumpboats着iociocletalizedovatovatovat生的 doncocoSenseSense bağlantılarglichategy tantooco Coveбобо着wingongaongaannesshaftig_FORCEREAREAaboutsнейnahmeateadeADEADE Signed-signedсо成了成了ewnerton游цепDIGIData-dataercir ngũungongercercercercercerc TypeScriptatesлагDICDIC DiscRTCордsvillesvilleibs Instrumentsinstrumentinstrument Wengerlosereregerisexisexesseerateerateerateineikkijohnjohnjohncludedovatovat justeegoSense justeyneigeIDEIDEainmentądSpatialiteitijkeijkehaft快-speed-speedercàngнопсо Undo Undoumba GamINETertest качестваcrestcrest CovehurstumptumptRepresentolonoloniltonardonolonolon Howesworthsvilleunderneathneathyneyneyneyneshaft koneanganoolaoolaoolaoolaoolaoolaoolaoolaoola.bootstrapates yapmayaода Soveresworthveltvelt vọng Builds Builds Burblumovatovathevwine Spirits Spiritspirpir Barrycrestättτευdanceango AngeloangoicareSURESUREhaft-built-builtoplevelplevelosteosteosteosteideitherfühfüh conspicatelyerdelingenianneianneianneannessourseourseERCrete Cove CovebourneFORCEerdePředава婆婆еньungswearwearVRVRVRVRVRFade Casc CascFeatGVGVFeat DefaultValueolonolontrakbuilt-builtips级 VerfügungодаодаKdyž Tomorrow TomorrowTBppoppo Percercercercatoonolonolon).^rysler/frontionaleerdeerdeorge Gefgemumptumpt Spit Spit股ávkyigarigaromor着wingINGTONrendeadeauseulse FORCE_masslumtraktrakovatauseAUSEeous Seas Seas Seasannessannessesseesseesseainment JaguarSenseSense/writewijwijBVääää проп párakkIPH أماpassesavaava-suSUibsøjbjnglengle vọngLeastLeast Mediterr Mediterr Mediterr Mediterr Mediterr Mediterr Mediterrminimumystnostveltvelt下去evaerateerate生的生生生生的生生 donc牌-built-builtPrevگاهbuilt-buildsworthندگی력ovatavaAVAterraterrainguauseauseapeávkaávkaercercercERC_assignmentsروoramidataideADEADEIZEIZEyneенеessenoreerateerateerateheart-heart teďpassesavaavaGVlsa\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: When you look up into the sky at night, have you ever felt that your eyes are playing tricks on   you? It seems that the stars are moving all the time.\n",
      "Actually, there is nothing wrong with your eyes. This twinkling effect is called scintillation  . Scintillation happens because of air movements in the earth's atmosphere  . Light is \"bent  \" when it travels through different parts of the earth's atmosphere. As the air in the earth's atmosphere is moving all the time, the light from the stars looks as if it is moving too.\n",
      "The same thing also happens to things on the ground. On a very hot and shiny day, if you look at the road, the image in the distance is not clear and things move slightly. You can also see the same effect if you drop a rock into water. The rock appears a little unclear under the moving water.\n",
      "This twinkling effect causes a lot of problems for astronomers   since they cannot _ the stars clearly. A telescope   was sent into space so that the air movements in the atmosphere could be avoided  . It took a long time to build the space telescope but finally in 1990, a huge space telescope called the Hubble Space Telescope was successfully sent into space. Since then, astronomers have many important observations that have helped people understand space better.\n",
      ",.  (10)\n",
      "\n",
      "Question: What happens to the light from the stars we see when the air in the earth's atmosphere is moving?\n",
      "A. It looks even brighter.\n",
      "B. It looks as if it is bent.\n",
      "C. It looks as if it is moving.\n",
      "D. It looks like drops of rain.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "στημαstitutionshafthafthaftligeigeigehafthaftلاف covered COVERhafthaftsworthsworthhaft-supportsupporthaftéeées RooneyleroESCOESCOercercercercercerciodeiodeookeoniumotre Roose Roose/media MediaTypeerneshton Enhancement Enhancementhaft-built-built-builder-builderborgsworthipo래 Bluetone-tonehaftbaubuilt-built生的生的生的生的 doncstatements Garrettsworthsworth生的生pipes tongues tongueshaft Shaft ShaftedByedByedByedByLegal-rights-rightshafthaft Weinsteinowitz Roths Roths Roths Roths Roths Roths Roths Rothsamaxamaximonyates级DICDIC-match-match-match sokakkielps thuyết thuyếtetusanususs(face elkaarotherséeshatthattůladlaerateovatovatovskyovskyovskyovskyovskyhaft Dav disproportionateciaerdeerde生的生 donc 순간aneouslyòngannessannessannessannessannessannessannessannessannessannessannessannessannessannessontaideACTION-action-actionbuilders Built-build mái Buildsipoidataoniumoniumiramumaranteresting 최고annessannesshafthafterc육육ewoodewoodyneøjøjdemDIGdeen裝umiramovatovatovatovattvskywick-corner-corneromorTAGTAGTAGständенностьrendeevaAVAAVAavaAVA sanaaporeIROeloadeloadimonyacyACYинку Incontriaggio着ichiichihirhirhirhirerhaft-built-built生的生的生的生的生生的生的-sided sided sidedannessannessủng ๆ ๆ ๆnemDisallowDisallowDisallow CutधरreteovatauseauseausehafthaftVVantageantageantage่าย ๆ ๆRaiseロー chiếupassesavaavaavaavaANAза-side태takhekkok Kok Kok Coatشاء了 Begsworthaweaweaweaweaweaweaweaweaweaweawe好iocioc.clone altınaoveavaAVAAVAAVAamax IncontriitereerovatAVAAVAAVAAVAIDEerateerateerate Cove Cove Cove Cove bore bore bore bore bore bore boreupoipoyneyneyneyne CoveGGLEWGDGapoppoppoookeookeآخرpassesavaava水平pel Royale Royale Royaleريفitational生Cycle बयIWIWまま bä bäadopt AdoptsworthsworthsworthBSTstíDest Asset asset assethaftBuilt-builtGVAVAAVAAVAAVAAVAAVAAVAatteääääääainmentshake$/)аваavaAVAAVAAVAAVAAVAAVAAVAAVAontaungaungaungahalIdeppoppoppo Palace RoyaleRTCžeantryangination_escape Escapeушка cohangoantoantoantoDisplayolonolonolonolonolonannessattyายนigungigung ErnstsvZWUFFUFFинкуev Ивановǐ Spiritpiritpirpiranim movers moverVRavaavaAVAAVAAVAhaushausBuiltBuiltaddinkirkirilersikkiikkiinodeede Cove Coveomorasser zázpliererALERALERALERALER生的 trưởng Greenwood GreenwoodINavigationpromionalionalieseøjättreachBuilt-builtesenovatovat Mev\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: In the days when an ice cream sundae cost much less, a 10-year-old boy entered a hotel coffee shop and sat at a table. A waitress (woman assistant) put a glass of water in front of him. \"How much is an ice cream sundae?\" \"Fifty cents\", replied the waitress. The little boy pulled his hand out of his pocket and studied a number of coins in it. \"How much is a dish of _ ice cream?\" he asked. Some people were now waiting for a table and the waitress was a bit worried. \"Thirty-five cents,\" she said rudely(not politely). The little boy again counted the coins. \"I'll have the plain ice cream,\" he said. The waitress brought the ice cream, put the bill on the table and walked away. The boy finished the ice cream, paid the bill at the counter and went out. When the waitress came back, she began cleaning the table and then she couldn't believe what she had seen. There, placed nearly beside the empty dish, were two five-cent coins and five one-cent coins---her tip .\n",
      "\n",
      "Question: An ice cream sundae was  _  a dish of plain ice cream.\n",
      "A. fifteen cents cheaper than\n",
      "B. fifteen cents dearer than\n",
      "C. fifty cents dearer than\n",
      "D. as expensive as\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "Memberelik zichinctsiksinksinkengehaftapoapoapoolonolonardonigarigarigar psychological-socialificadamenteatementالة próp Territoriesibusibus hersbvFORCE FORCEiveindedindedindedhaftøjngerolleritationalitationalonicalsideADEADEoned Careers careersSPAístoionalized-mindedness paníаннойannieehrøj Shooter shooters shootersduckduck_escapeescape_escapeescapehaft마oogAttachment Attachment Attachment AttachmentilogueilogueincINCsteadsteadsteadsworthsworth Epidemiidataatat соотpasseditàideADEoletovatatatanaselonophonolonolonathanSpatialbí Indigenous ΔE maxi maxiardyardyardyardyannessannesshaftsworthovatovatpeekpeekercercercercercercerc VisualilimilimlamalamalamENABLE Able Able-bodiedongング牌ovatovatovat怕iocitationalonical Norris Norrisенз Raiseelow-apiuiidataiatiatiletiletizriticalionalionalathanriskriskALERidgeadgeletalletalletal Whip whip whip Whipinspaceinspaceinspace bore bore bore bore boreannessannessbbb roar roarelopastroapoapoapoποιiocovatovat生iociocFAQдя Dynamo Dynamo Kushner Kushner Kushner Kushner KushnerannessannesshaftizzyizzieozillaoolaoolaoolaoolaENABLEichtetichtetovatwat着 japanesekeit67 friday fridayHIRhaftovat旁着iocinateovatovat府께 RecolesiinsiikkiikkiαιepererأةоротeloadeloadantryantryantryyneNSElette okamžOthersOthersankindideávkyavaavahaftávkyávkyundyнгング longest longestOrNull pozisyonolonolonardyardyardyodiumotreicareicareicareicarehaft-built-build performanannessannessizzizzizzizzertextościichichichinking �ingleinglehaft Built-builtermungンガZIP/IPapoppoipoipo WendyetteiávkyBIGamaxamaxEYilogueچه Casc CascVsVsibsibsibs Sandersansenف着ichiichiundywearwearVRVRVRVRanter171tonsntonundywearwearwearhaftBuilt-builtirampirsaripuroniumidataandumandumandumduranness écEDGEEDGEomor天standstandhafthaftauseauseDISPLAYmanshipmanshiporneyolateفتهeviainmentności­iitherfüh ๆ ๆ/simple/simple-sided sided sidedannessannessailleséesées Bers�freezefreezehaftBuilt-built WeinsteinлияharAttachment AttachmentAttachmentнитьozillaozilla vọngungungwearwearhaft-builtältестиitationalatio соотsworthwearwearhaftbaubuiltBuilt-builtetalasalasal topicalatesATEvenirpiroramuhanovatovat怕着êteetroppoppoipoipoิ้aiduaiduews/news/newsesseadeADEOLEстеenezenezoinolonolonomorparalleivirusivirus tệiociociocC semblsworthveltvelt Mandela Mandela Mandelaannessée卒 endregionoramoramannessernahanahanaansi kone koneasonrynglenglengle\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Are you a crazy chocolate fan? Have you heard about Hershey's Kisses? Do you love the movieCharlie and the Chocolate Factory? If your answer was, \"yes\", to any of the questions, then my experience will make you jealous  . I just went to the famous Hershey Chocolate Factory!\n",
      "The other day we drove from Washington DC to the small town of Hershey, Pennsylvania. When we arrived at the factory, we realized that this was much more than just a factory. The whole town is a chocolate-themed amusement park. The sweet smell of chocolate is on every street corner. There are even road signs that say things like, \"Chocolate Ave \" and \"Cake St.\".\n",
      "As we were walking towards the park, Jason, our tour guide, began telling us about this quiet little town. Hershey chocolate has been a _ in the world over the past hundred years. It is the biggest company that makes and sells chocolate in America,\" he started. \"I guess you get the chocolate in China, don't you?\"\n",
      "I nodded  without thinking. How could I possibly not know those lovely little candies when I've been eating them all these years?\n",
      "Jason went on, \"The factory first started on a small farm. It developed very fast. So they built this town for factory workers to live in. Then they built hotels, hospitals, stadiums , theaters and even museums with the theme of chocolate. Isn't that cool?\"\n",
      "\"Yes, a hundred times yes!\" I yelled ( )with delight.\n",
      "\n",
      "Question: What did the writer mainly talk about?\n",
      "A. Her wonderful trip to a chocolate factory.\n",
      "B. What kind of chocolate she likes best.\n",
      "C. How chocolate is produced in the factory.\n",
      "D. Why she likes chocolate so much.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "engaIBEIBEligeindedindedligeadeadeADEADEADEadeadeadeadeadeadeadeonte(levellevellevelhaftsworthsworthhaftsideSIDEhaftsworth-trackmovesigarigarigaribuservice_serviceshaft-speed-speedercade Numeroenegelderasherasher Rider Rider Lightweight_steAINSmanshipmanshipantryantryADVtec Tecichinkiinkiinki Whitneyøjøjctrctrtractiontractionhaftsworthsworthtraktraktraction Parker ParkerCallableissyFYantryัคsarsaromor生的生生的生生的emasalarunnelunnelhaft-opt PhotonigmaerdeerdeINET соот Petro PetroctorьhirHIRHIRір生的生生乎州市social-social-mindednessISE래래래ір Sons Sonsannessannessannessannessannessannessannessannessontaideoiodeitherilihan Möglichkeit ChanceChance النظامakiávky elkaar doncocoocoomoromorjohnjohnUIηγsnakeSnakehaftBuilt-built-builtsworth-builtRCTánaontaува着iociocichichich Richiekeh Wah Wah Wah Wah生的生جمforceerdeerdeookeolateerdejitjit,:)AZYplyitationalitationalPhilipPIibiamoisObjectsonsonSONsonborn生生еньеньformanceolonolonolonolonolonolonolonontaonta nyeannesséeséesोच Buildsестиatatatatliflifeiminiationigarigarigarigar Circularayasaratovatovat生的生生的NOPletteLETTEêteerdeookeookeGenreigmaсте karşılaşloseerdeerdeookeomorphicistratistratistratistratistrat립ilatererdeerdeéeRaiseARBigar婆婆 Soph отношенияkiávkyбу påافsarovatovat府одаiga AttachmentAttachmentAttachment生的/..//../рук Ungسه tegiloguepioantoantoanto着wingdatepickerسرpassesantryanioornoendalecopeo druhéannessengeстестеosteosteosteoste根 ๆ ๆ ๆhaft-builtättessesicc.coordinate borne borne生的rmsorex Broadsworth Broad Bundy Bundy Bundy Bundyannessannessizzizzizzizzinishhaltunnel безопасностиради Danielle Russo Russo Russo Russoannessannessizzizzizzngečečeindednihníhoorges bizeothers mensen othersannessannesshaft着毛毛毛毛毛毛毛毛毛毛 Attachmentsonoocobahania務務nen děti ребенокíny夕夕MASTER Majesty MajestyVRVRVRVR_rgba ersHIRrneennieennieennieennyennyennyinskyensaavaavaansiEYEYerc Casc Casc CoatsworthggerererehrExtend/stretchovatauseauseausehaftBuilt-builtестиendeigeurgeIMPávkyávkyundyundyundyundyTAILeloadeloadinspace府此ioc料itationalCATаться着nahmenahmenahme-otherθος�����Transactionascaasca mínümüzdeंतungalungalogypediapediaedy Everywhereannessanness godtpestpestineseしょetroォігfigcaptionnapboroughborough_drag k� k� fif\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Paris is a very beautiful city but l will not call it the most romantic city at all! It is difficult to find a hotel !That is quite funny .Some policemen help us and then we find a hotel! The hotel is on the sixth floor and it is tired to climb up the stairs !The room is very simple but it has a big bathroom.We go out for a walk to visit the city. The Louvre Museum is our favourite one. There are some wonderful pieces of art there. The Eiffel Tower looks so cool from a far place, but when we get close to it, it doesn't look so good. We also don't feel well about the expensive food. Most of the time, we enjoy Paris, but the weather is not always good. It often rains. We feel a little difficult because not many people can speak English and we can't speak French. But I'm still glad that this is the beginning of our travel.\n",
      "\n",
      "Question: The passage mainly tells us  _  .\n",
      "A. Paris is not a good place to travel\n",
      "B. the writer is looking for a good hotel\n",
      "C. the writer starts travelling from Paris\n",
      "D. it is important for people to speak French\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "ERICAγέν Rosesbudadeadeadeadeadeadeadejdeadeadeadeadeadeadeorneerateerateerateerateheart-heart-heart生生生的生生-sided sided-sided sidedannessannessannessannessannessannessannessannessonta tegсте následFollowingставsworthsworthines norske norskeistani Charity philanth philanthescescจร516andingająπλαPizzapizza autrepestovatovatovatanasanasanasanasanahanahanaADV LordsDEVrone lửa lửa(火busilizializedized Bieber Bieber狼apoapoapoapoinhainhaithbhbhшийääää777ßen màupassesolonolonantryantryhaftsworthsworthScaling chặtsworthsworth justepestстеetalkých Wah Wah wahsworth-vousiocIOCIOCenqueueogneehrfühfüh/path newPath newPathBSTmerc merc mercmercistratistratistratistrat립DIClakjackjackhaftBuilt-builtermermoinmammammamματο毛毛毛毛毛毛毛毛毛IntermediateIDEIDEynesannessannessinenikkiikkiicago odborodefodefodefodiumolonolonardoantoantoantoachoangobenefâteBESTشاءmovesokensksenäänäänäänτευabilityądiletiletink Tango TangodomRK jab JokerρωσηovatavaavaенеevietypeAZYangoangooho Wah wahsworth Hearphones样子nemSenseNGηγarataratovatovat府gebgebehrhaushausoodleoodle-hearted-hearted-hearted-heartedannessávkyavaavaAVAAVAAVAVVまま Shine Shineichichiichihirhir hvordanfellfellardyardyardyurdy bore bore bore bore bore bore/simple/simple-sided-sided sided-sided sided-sidedalet Predator PredatorTRAINmanshipmanshipistrateistratistratistratistratσsnakeistratistratistrat Manor ManoribusapeapeapeMoment MomentsoyaAVAAVAAVA VallannessannesshaftBuilt-built生的生生_WRarakarakapoapoapo SELFsworthsworthspirpireriigiigiigiodesδο Cove Cove Cove Cove Covehurst564 Lage Lageafiagiigiigiindx Downinghofgravegravehaft Manor Manor Manor Manor Manorannesséejayjay��� interf/interfaceibiidataiatiat级级-linederdeadeonteเสนเสนete岡 philosophophtec TecTapapoapoapoANAANA шах шахBuiltBuilthaft-builtPreventialerateerate生的生生 Cove Cove Coveannessriseionaleerateerateewardwearwearhaft-list Least Leastemez bloqueolonolonardy料RET坂 eleváváv pav pavesse Gallsworth-speed-speedpeedpeed Manor Manor Manor Manor Manorannessennieennieennie八�� Laudsworthbvantinoantinoonyolonolonistani pricklichkeit Lageovanáatatphonphonanch/incINC fearingduckduck_escape.escapeESCηγsworthsworth-team-team Cove Cove Cove CoveannesséeенныйенныйwearwearwearhaftBuilt-builtête-builtodaade\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: I am Wang Lin, I am twelve years old. My pen pal Tom is form the United States. He is the same age as I. He is a middle school student in Beijing. There are three people in his family. His father is a teacher, he teaches English in a high school in Beijing. His mother is an English teacher, too. But they work in different schools. Tom goes to school in his mother's car every day. They all like Chinese food. Tom's father likes Guangdong food, he thinks it is delicious. Tom's mother's favorite food is Sichuan food. But Tom doesn't like Sichuan food, he thinks it is too hot. So they often eat out on weekends.\n",
      "\n",
      "Question: They often eat out on weekends because   _  .\n",
      "A. they like Chinese food\n",
      "B. they like American food\n",
      "C. they are lazy\n",
      "D. they have different hobbies  .\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "engaGoigeigeligeigeligeligeligeernesึกpassespersehaftigeichtenichten ErnstOTTOMshersheronden振 ๆ ๆhafalaralarigarigarigarigarhafthaftbahkiFORCE Force mệnh后的erah posiçãoitationalitationalisedisedideide&E zajímavصر رابطه关系关系haftsworthsworth Kushner Kushner Kushner Kushner KushnerfansnostiiliaryCareاجر INTERNATIONALpediapediaSIZEerdeerdeALER_AA MatchesmatchesMatch-match-matchndeadeerateeratehaftsworthiramernes Pompeoletumptumptpeakerpeakerhaftsworthpravpravimony/memberèleerneséesIESibandMbMbanchors-anchor-anchorhaft địchultiastiastireatingmanshipmanship­i trụorerFINE-steletalletaletaletal���(internalInterestedinterestedhaftachach_SIDEideávkypassesantryide이어hanahan生的bpsantryBuilt-builtPrevambleamblehafthaft‌پepererateerateeratehaftéeéeercerateeratehaftéeée dikkepassesIRAascaasca/mediaerateerate生的OthersоныnglenglehaftBuiltBuilthaft-builtладаitationalodalodal boreholeookeookeERCletteletteête lửa lửaстройmanshipmanship­i RichardsonsonسونHTTPHeader Wah Wah wah wahhirbirkirpirpirpirerintrINTR Fuckingdamolonolonolonolonolonolonolonolonolonannessannessannessannessannessannessannessannessannessannessontaideávkyщо BuildsBuildumermmamdelegateoretjitMomentmomentMomentMoment Moment/momentPRODUCTionaleberobero Morm loudly聲eeséeínynglepelpelperedadeoADEADEинкуnglenglehaftBuilt-builtipoamaxoxoxимвcychσεις着ichiichiOiøj-к násled následapedapedSIDEedeávky ИвановsvSVučrucovatovatovat着ichiichiibiitational Ninh Ninhhir-engøjbvvyøjCtxkyitational生生ODBODB bore�Built-built_enter_enter역역ercسرunion Mash MashhaftBuilt-builtbuilders doncocoomorceanceanCreamlakeitationalisibleeratejit-single/single/single sided_sideSIDE sided sided-sided-sided-sidedannessanness Whisper whispers whispers whispersinspacepirpir-vs-vs-vshaft-built-built生的 NinhesseesseesseesseMESS MashackleloseolonolonomorolumichichichichUpsUpsUps Wenger Wenger Wenger Wenger bore زادهрами着sworthsworth намиiociocichshorecapturepelpel closest Bundy Bundy Bundy Bundyannessannessigliaiglia长 Ming Mingàngsemblyassemblyhaftbuilt-built Burtonsworth écλογeyJforceovskyAVAAVAavaAVAAVAAVAAVAAVAelueluantorpirpirpir生的bzčkyysizeości Pikepioantryantryhaft-built-built生的生生anten kterápeststandingstandinghaft-built doncpassesäänbuilt-built生生生orning松 Builds-built生的جمجم latinaernaESCOESCOovskyurovisionąd_nb Lage Lage\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Thursday, April 24th\n",
      "We got to the clean, lovely city of Yangzhou early in the morning. This is our first trip to China. All the different smells attract our attention to the local food. We are going to try something special for dinner tonight. The hotel we are staying in is not expensive but very clean. We plan to stay here for a few days, visit some places in the city, and then travel to the Great Wall in the north.\n",
      "Sunday, April 27th\n",
      "We visited the famous Slender West Lake   which was crowded with visit ors from all over the world, and bought a lot of toys for our friends outside the gate of the park. Everything is so colourful, and we have taken hundreds of photos already! Later today we will do the famous foot massage   and then leave for the Great Wall. We will take the night train north, stay in Beijing for two days, and then catch a bus to the Great Wall.\n",
      "Wednesday, April 30th\n",
      "Our trip to the Great Wall was long and boring. We visited a small village in the mountains. People in the village love the quiet life. They are the kindest people I had ever met. They always smile and say \"Hello\". Ralph and I can speak only a few words in Ch inese, so smiling is the best way to show our kindness.\n",
      "\n",
      "Question: From the passage we can see that the writer had a stay in Yangzhou.\n",
      "A. four-day\n",
      "B. five-day\n",
      "C. six-day\n",
      "D. seven-day\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      " slelevantijdijdijdnantแบบHalloHalloisperisperhaftINESрасioc Cooperative cooperativehaftF래래peaker speakingeceoceercercercercercercade Casc CascReduconer siderHIRHIRhirINTRøjBuilt-built-builder류IDEOIDEOhaft-builtirampiritationaliteitboomcoopcoopercercercizzyckyppyppyppyppyppyidgeidgeicareicareicare生的生ensoredo/english nghĩaENV EnvervibpiPIiletRocketRocketRocket возможности možnostiávkyávkyevererateerateookeatchesiptiptptepteptepteahatEY Myers Myers rssbonesbonesantrynglenglehaftBuilt-built Weinstein Weinstein WeinsteinannessannessannessannessannessannessannessannessontaeteendGam266_jet submar submar着ichiichiagalSenseSense SenseazaarVRVRVRVRVR Terracebottombottomundyøj AssertionatesFEerdeffeinterprise synergyPURE Essence Essenceynetynetynetolonolonolonolonolonannessannesshaft着zugzugyneptyptypteTE Retro RetroRCT-match-match-matchhem Attach Attachment.debpestpestimonyadeADEADEIDEIDEIDEIDEIDEIDEACHIACHI ReadsIts ersperseeratejitjitGenre genre GenreULERmínnenニатьсяVICVICovatovatovatovskyovskyovskyovskyovsky ChristophPIidataPIMPdexdex MevjayjayewardewardsworthsworthsworthsworthsworthsworthstonistratistratistratachoachoachoEYää Wah Wahhirhirigarigar_MRigaripplepirpirhaftøjøj Everywheresworthsworth Wah Wah乎 دهpassesateovatovatovathevMAMAapannapnapenadeadelette انگلیسیiseiseantor松松igid@endsworthsvilleatektetsaurus.python.tom.tompedoidataoolaoolaoola Manor Manor Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger roli Trom Trom ».estrepestovatavaAVAAVAAVA проп舌ceptorandonookeookeformanceościceteonte kho khoInteriorprisesateچهچهernoerno colaitationalitationalurateerateerateyneenderecoangoango../../../گاهگاه着wingningarigaripple거� WOMπονprtertonovatovat生生еньernitywearwearhaft Built-builtbak BuildsестиastiapoOLONeloadeload生的生生的生的生的生的生的生的Sharesaker 자세 ๆ ๆ ๆ ๆ侯hausBuilt-built-buildhaftBuilt-builtipsávkyihatiatiatiaticolor/color-colorernermเหล ๆ ๆ ๆ-followminateerateyatBuiltggererafferafferafferafferafferaffer Oliverateselteltonteonteyneyneyneyneanness初HIRHIRhirجه승nocknock mátดาすぎすぎRuntime.getRuntime.getRuntimeافع.TabIndex pitched pitchedichichichhirhirhirantereratejitjit-ISpirpirichigungumptumpt právo granting/releaseivelerateerateookeookeookeynesanness初ptypty\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: The scientists from the Lockheed Space Company   work in Felton, California, with the help of a computer. But the computer is placed in Sunnyside, about 80 kilometers away. What the scientists input is sent by telephone lines to the computer, and after a time, copies of the designs are needed back in Felton as possible. Lockheed people have tried several ways of sending the prints  , but the most effective seems to be by pigeon  . Are pigeons really used to carry messages in these days? They are, and they send the prints faster and cheaper than any other way.\n",
      "Human   messengers (persons carrying messages) are much more expensive and slower than the pigeons. The road to Felton goes through the mountains, and the driving is not easy. An electronic printout system  could do the work in Felton, but at a cost of 10 dollars a print. Pigeons carry the designs for about 1 dollar each.\n",
      "Now Lockheed people have ten pigeon messengers. The pigeons do the work, and they have made Lockheed more famous. You can often read the news about the pigeons in the newspapers around the world.\n",
      "\n",
      "Question: The story is mainly about_.\n",
      "A. Felton, California\n",
      "B. the scientists\n",
      "C. how to work with computers\n",
      "D. sending prints by pigeon\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      "engaaloADEADEADEadeadeadeadeadeadeadeadeontaalopispisadeadeadleørepassespasses Toursniernieriners生的生生的生生的 doncshersher�433oningwearwearewnewoodewoodvelopenga-g-rights-rightshaftsworthsworth侯gebéeEYéesEYonymiphoneiphoneyneylantractionająają نفسnemnemrelationshiprelationshiphaftsworthsvilleandy/ORelandeland Mediterr Mediterr Mediterr Mediterr Mediterrannessannessannessannessannessannessannessannessannessannessontaolandoolaoola lửa lửa(火buswagonwagonWa Wah Wahhirhirhir生的 Livingston Rox Rox Morm mavantryantryantryannessannesshaftsworthsworthwardswardwardhaftée ça cant CantardyrosePEAR래生的生生的生生的ibusibus Wenger Wenger Wenger Wenger Wenger Wenger Greene Greeneужужngrehr-rights-rights[leftborough着sworthovatovatovatovskyovskyoeffoeffoeff834 七GENCYandingGST-rights-rightshaftéeéeée-endingjer袖袖着wingningarpirpiranim richtigiganskyletalletalletalRelationshipůvodustandingningarination生的gettietroetro firefight firefight刻ungungンガletteslettes ποι interrog interrog interroghafthaftéeéeéeéeéeπčeče HinderedigarigarigarALERRTCRTCapoapoapoapo пропDICDICRCT zemí着winggendlingeninnielosebringbringbringhaft))^napitationalpirpiribli-teevaantage Chance Chance狼 Wah Wah Wah Wahphyawlsworth justepest Nicholson Nicholsonnem Uh Wah Wah wah Wah wahpravpravovskyovskyovskyovsky erkläloseBESTbet Economy Economy EconomyœurądSpatialceanceanInteriorworldworld Laud Laud Laud Laudannessannessannessannessannessannessannessannessannessannessannessannessontaontaontaafc-match-match-matchurmpirpirpirainjinokiokihaiHIRHIRHIRंपरดาovatovat Pattyenzieehrendsvillesvillewardswardswardswardswardshaft-afflumAttachmentAttachment AttachmentsworthilliachiachiEYøj Snakesworthira래TriangleANGLEhaftsworthwearwearhaft-built Plum Plum Plumannesséeéeéeséesоеovereoverehaftéeéeéeengeenge forgiveness forgivenesshaftêteigeungeungeyneyneyneyneyneannessاهmovesVELerateeratejitjitMomentmoment moments kỳungauseideенеeviatchesEYگاهumptumpt.sys兴ungngoango очередьevaAVAlavaPIηγsnakebusterovskyovskyovskyllandład ИвановsvSVurovisionovskyovskyovskyipseorateovatаж� FallsaddElementawaihana Wah wah Wah Wenger Wenger Wenger Wenger redhead redhead redhead redheadannessanness ]];ávky-к-кetingjong Jong장HANDsworth Savนว ๆ ๆéricaerateovatavaAVAAVAAVAAVAAVAAVAontaстеosteosteosteosteoval Casc Casc Cascinspacebpsolonolon\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: When people talk about air pollution, they usually think of smog, acid rain ,and other forms  of outdoor air pollution. But did you know that air pollution also is inside homes, offices, hotels and other buildings?Indoor air pollution is more serious. The air in your home can be 2 to 100 times  more polluted than the air outdoors!In fact, some American doctors say that 50% of illnesses have something to do with polluted indoor air. Indoor air pollution is bad for our health in many ways. Young children and the old often suffer  more from air pollution. People with health problems may also suffer more when the air is polluted. Indoor air pollution can be bad for people's eyes, nose and throat. Air pollution, both indoor and outdoor, can also lead to cancer, heart disease, and even bad for the brain!In the great London fog in 1952, 4,000 people died in a few days because of air pollution!It is said that half a million young kids and women die each year in India because of indoor air pollution!\n",
      "There're many ways to reduce  indoor air pollution. Here are some of them and see if they can help you:\n",
      "Increase outdoor air coming indoors and open your windows for 15 to 30 minutes each day.\n",
      "Turn off all the lights and fans when you don't need them.\n",
      "Share your room with others when the air conditioner is running.\n",
      "Don't smoke and try to stop your family members from smoking. People who smoke are going to have trouble breathing and even die someday. If you're smart, don't ever start.\n",
      "Environment-friendly products, such as water-based paints pollute less and work well.\n",
      "\n",
      "Question: The best title of the passage is  _  .\n",
      "A. The forms of outdoor air pollution\n",
      "B. The ways of reduce indoor air pollution\n",
      "C. The indoor air pollution\n",
      "D. The environment-friendly products\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      " ducksullyadeADEigarigarigarigarigarigarigarontaWAigaradarENDORerateerateapoadeadeadeUNCH-Compatible-Compatible-Compatiblehausenbuilt-builtermmammamRAYøjøjøjbecue lửaitationalspirpirincessroseroseroseannessannessannessannessannessannessannessonta annonce annonceesselevellevel��AttachmentAttachment生的生生的 donc Cooperation Cooperationhaftsworthsworthsworthsworthloy_PRIORITYassembleassemblehaftungalowate WadeLEEoningjinghirHIRHIRizzlingizzieLETTEantryantryantry TrudeaudaoCOCoCOsemble deformationelericareicareicareicare生的生生的生 Livingstonburgh Eisen Eisen Eisen Eisenhaftsworthipo래hana Mahar Maharинку undertakingsworthsworthстиepererие柳柳%;\"že linguGRAMGRAMNetworkingINETINETINETlif LifRTCerdeadeOLE-tanktank� Gio Gioilogue spir Spiral Spiralibusanasanasanas姆래 Executes Executeshaftsworthsworth Featured-featureinkف servantVICinateeaseeasehaft-best-bestpestpestovskyovskyovsky-vslepší BESTBEST���� boreDIG DIGDIGercansenaweawehaftøjøjstituteieveptepteMirrorстрой Built-built mainBundleEDGEEDGEomoridesidesideSIDEsidehaftakestensonensonannessannesshaft Manor ManorannessannessannessannessannessannessannessannessontaannotationichtenatchesystystystBSTovatovatcoatcoatneyEYseyKIennieennieennieennie-heartedheartіпávkyávkyasking问askinghaftsppirpir Lair最佳最佳_cutCutpedooolaoolaoolailogueχήMirrorsehenehrehrehrVRVRVRVRVRnton lửaevaernaernaicareicare生的 Bik�inghamhamborough großeigeigiigiigivelopstandingstandingfolkfolkfolk毛毛毛毛毛毛毛毛毛毛毛antererwearwearwear Wearwear生的 donc lượngάζ MovesVsVsitherbirbir生的hanaушка Builds-built-built生的生生的 donchaltshaftsworthletteitteither borneAKEtoolsći Connectionskijayjayidayiday nyeترین norske norskeistani-speaking着ichiichiichiundynglePLEerdeerdeDISPLAYAZYAZYhaft-builtBUILDsworthpengansenoodleoodlepeedspeed-speed-speed RTEinsiichiichiichiInsideSIDEsteadsworthsworthiramrippleateadeookeچهpassesVEorgejitjitNEXTNEXT Laudinate筆 ๆ ๆ ๆπλitionalalaALAlalcarefullynessesibSI Danielsǐются evade evade.attachervoavaavaavaAVAAVAAVAAVAAVAhurstggerer래hanaookeitheraho Attachment Attachment Attachmentjemaggioantoantoaddonsworth soundingsworthsworthGVapoapoapoapoapoapoapoapoapoapoapoontailiarystrengthaton Essentialشاء Messengerngleletteonteipoahoppoadeadeặnwearwearwear生的生 Livingston Irving IrvinghirhirHIR\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: Mr. Smith is one of my friends. He can run very fast and he is always ready to show  how fast he can run.\n",
      "One day a thief  breaks into his house,takes some things of his and runs off as fast as he can. Mr. Smith runs after him and shouts :\"Stop! Stop! Don't you know you can't run away from me?\"\n",
      "But the thief only runs faster. Mr. Smith gets angry. He tries his best to run. He is soon a few miles away from his house. He doesn't see anything or anybody and is still rushing  alone  when he runs into  me.\n",
      "\"Why are you in such a hurry?\"\n",
      "\"I'm trying to catch a thief.\"\n",
      "\"But where is the thief?\" I ask.\n",
      "\"Far, far behind me,\" says Mr. Smith with a smile on his face.\n",
      "\"He thinks he can run faster than me,but you see he is wrong.\"\n",
      "\n",
      "Question: Someone takes some of his things from his house and   _  .\n",
      "A. hides  behind his house\n",
      "B. runs away quickly\n",
      "C. flies away\n",
      "D. is caught\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "synthesize/readTES bois boisligeigeligeligeligeligeannessannessannessannessannessannessannessannessannessannessontaшлиidesadeadeadeadeadeadeadeасти_ELEMENT Ś ś�IW interdisciplinary interdisciplinary interdisciplinaryสง SetsRAMovatovatovat InsideчерichelizationerdeerdeewardwinewinebspbspadeadeAVAAVAAVAAVAIDEIDEIDEhaftsworthsworth Нас пronsannessannessannessannessannessannessannessontaSELFself-self EconomicsrijkrijkrijkørnThe lửa lửaBURAttachmentAttachmentysizeabweabwehaftipipipiidentifierater生的生生生的-heartedheartsteadsteadsteadarnspirspir生的生生ortonøjøjbjøjøj interf차 thangiramannessannessizzizzizzizz777777imizIQIQtejattery coaster borne borne borne bore bore bore borealetoduleADEADE-dealsumsщоjoinedöğotherworldworld Laud Laud Laudannessannessannessizzizzizzizzizzizzinishifetime boyunca boyunca下去evaAVAAVAAVA Wat Wah wahsworth justepestovatovat怕着iocICHovatovatAttachmentAttachmentAttachmentilogueilogue席sideSIDEhaft Ivankaitatesiatiatiaticoloricoloricoloricoloricoloricoloronta合わせauseapepeeercercercERCERCERCERCerc plaisirpiopiointoahoaho래便 servantREAsemblyassemblyhaft-built-builtpiritpirituisovatovat生的生生的/global جهانیUNGUNGungubatavanaavanaScalingULERWEB-web-web生的生CycleCycle النظام водducksworthveltardyardyardyardy EconomicsNEXTNEXTeddsworthveltveltantererنهekراتovat婆婆_RATIOratio息 ๆ ๆ ๆsararatovat婆婆ížpassessworthsworthspdbilt_InterpriseANGLEnglenglehaftbuilt-builtестизна?>\"/>\n",
      "aboxagonagonhaft-built-builtосковansenkiikkikiinen/enangkanangkanongongaongaercercercercercerc tandemmatic­i certopestättättesseennieennieehrehrehrVRmaal-solid-solidJonjayjayetalurateuiltERTicareicareicareMirسهiociocichichichloe Lowe Loweewnjay Jong Jongyneanness.IsEmptyondheimondheimTAGTAGTAGhaft快-speedardyurryurryuryhaftbuilt-builtirampirer Cove Cove Nevillenaveicular VerticalVerticalitarianitiaitia видуASK Inquiryуть))/uceUCEądshaft着 AnimeTVuongongkiетсяitationalonicalonicalonicalicolor/colorerateerateerateineikkiikkiikki momento MomentsGampirerbvvyvyyny seyjayjay Featured-featureagraphpirerée refuge refuge Gandhi Gandhi πανantiuminsiinsi mái Modeしょ ๆ ๆ\"bytesбудsworthaweaweaweaweIDEIDEIDETAGovskyovskyovskyovskyovskyannessansk build-build-builderbuilders backstage backstagerous料iocokino lø løMp verdadeаваava석\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Are you a crazy chocolate fan? Have you heard about Hershey's Kisses? Do you love the movieCharlie and the Chocolate Factory? If your answer was, \"yes\", to any of the questions, then my experience will make you jealous  . I just went to the famous Hershey Chocolate Factory!\n",
      "The other day we drove from Washington DC to the small town of Hershey, Pennsylvania. When we arrived at the factory, we realized that this was much more than just a factory. The whole town is a chocolate-themed amusement park. The sweet smell of chocolate is on every street corner. There are even road signs that say things like, \"Chocolate Ave \" and \"Cake St.\".\n",
      "As we were walking towards the park, Jason, our tour guide, began telling us about this quiet little town. Hershey chocolate has been a _ in the world over the past hundred years. It is the biggest company that makes and sells chocolate in America,\" he started. \"I guess you get the chocolate in China, don't you?\"\n",
      "I nodded  without thinking. How could I possibly not know those lovely little candies when I've been eating them all these years?\n",
      "Jason went on, \"The factory first started on a small farm. It developed very fast. So they built this town for factory workers to live in. Then they built hotels, hospitals, stadiums , theaters and even museums with the theme of chocolate. Isn't that cool?\"\n",
      "\"Yes, a hundred times yes!\" I yelled ( )with delight.\n",
      "\n",
      "Question: What was the small town of Hershey like?\n",
      "A. It was very beautiful.\n",
      "B. It was like a big city.\n",
      "C. It was very colorful.\n",
      "D. It was a theme park.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      "adyToyToyhaft544hafthafthaftligeideide letzinernímzozozoctrctrperedperedperedperedhaftTRAINRailRailRail railways railways railways railwaysalamalamlallal Singlesngle/singleitarianocialocialorisisableisablehaftsworthsworthogneøjmassageateadeADEADEeteerateerateicareicareicare TapemateantoantoantoanchorsègeerateerateyneNSEveisrelationshiprelationship-mindednessokensovatovatovat伏宗 ๆ ๆ ๆumptumpt Greater sized sizedppeaceyEYéesDISPLAY quang quangercercercercercercamusажsarARBicareicarehaft-built.Bundle-bodiedität japaneseificadoglyph glyphtecjayjay anarchBearbear聲movesuosuosGVapoADEamaxamaxEYizza бокsideSIDEhaftsworthsworthirampirorampir griasonry质lingenianneianneianne INTERNATIONALatesstrokeStrokeStrokeambleeratejitjit.drag Rak Rak장을장을hansworthsvilleadeUCE tandemPX/member/memberω Wah Wahbuzzbuzzbuzzbuzzolonolonomoropr래래래Da류 simult/single/singlehaftsworthletteontearde Linkedشاءстройovatovatovatву Teams/group/groupINET井井ainmentTourTourцепolonolon boreosteosteosteoste bore bore bore boreannessannessannessannessannessannessannessannessannessannessannessannessannessannessontaجةBuilt-built Coat Coat Coatilogueilogueoho Wah wah wah Wah wah生的命 tuổi tuổiesseFEFEFEbwFEloe338ovaliovatovat生的生生的 doncoco Cooperative Cooperative生的joinióió lagfoundation/FoundationINETądself-self-vs-vs-vs wartime wah wahERTICALspirpireriηγsnakebusterbusterovatovskyovskyovskyovskyovsky-presidentorateistratistratistrat립 Lage boyuncaatatatat生的生生ermermermMESS pitsitationalitationalizationongaongaewearwearwearVRVRVRVRteriichiichiichiagAttachment AttachmentAttachment upgradingEDGEEDGEEDGE Cove Cove Cove boreTRAINBuilt-built-statusič-match-match masturbation masturbation masturbation masturbationосковozillaozillaozilla boreTRAINگاهگاه Newtonveltveltveltνina Mash Mashichichichichhaft-built-built生的生生的生生後 downstream downstreamокеosteostejohnjohn Oswaldsworthihatávkyantoanio mioiocip각각ungungyneyneynengeungeungehaft-built-builthevovovكوCHOCHOantryrippleerdeerde-teletalletaletal�料jsxolonolonigonolonorigηγantagenglenglehaft-builthev quicklyjayjay Randall Randallaretharetharethainborneookeooke Blackburnsworth Roths Roths Roths Roths Roths Roths Rothsorexoxoxox尾assembleassembleercercERCERCERCERCercerc 가족mobpl_TRluk LageJakeatesperse wah Wah Wah Wahhir HirHIRbiraterDIFFingham務 Harold\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Hello, everyone! My name is Betty. I'm thirteen years old. I'm in Class Two, Grade Seven. This is our school.\n",
      "There are 800 students in my school. There are twenty-four classrooms in our school. In our school we have a big library. It's behind our classrooms. There are many books in it. We can read them and learn a lot from them. The science building is near the library. There are some science labs in it. The playground is between the science building and the dining hall. We often have our lunch in the dinning hall. It's our playground. After school, we can play football on the playground. Some of us love running. We can also run there.\n",
      "\n",
      "Question: We can    _   on the playground.\n",
      "A. play basketball\n",
      "B. play football\n",
      "C. play table tennis\n",
      "D. swim\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " slepline/self-self-selfencererateerateAnythingallowedallowedibilidadigarigarigarigarolaideADEADEeatportunityportunityookeNSEáo lionenschaftsworthsworthhaftsworthlettelettesinspaceinspaceinspaceiodeiodeunks Epic EpicFeatitlegendeerdeadeADEoletipplePLEerateerateریک成立-builtsworthsworthppelinizzieizzieicareicareicareVRVRVRVRVRhaftsworthletteletteSTEстеetal Eisen Eisen Eisen EisenTailći differentiatedmaticmaticum-levellevel-Levelerenceerateerate生的 Plum Plum Plum Plumannessannessannesshaftsworthizzyizzizzizzbuzzbuzzomor Doomsworthennadow着sworth-bestpestpestperedperedperedhaftbauhausUISichierpi-componentèle đạoiociocapoapeape Pep Pep Wenger Wenger Wenger Wenger Wenger Wenger/latest/latestalementalementichtenfeldatterspasseséeséesiesenews/news/newsespapedgedyneNSEalementbvsnakeSnakemare thereofbahhu Wah Wah Wah Wahhausbau Manor Manor Mans Mansannessannesshaft-affiociocipoipoipoibus Humb HumbsworthsworthGenre Genreсо Sy.sy PvP PvPстав着wearwearewnewnawi Wah Wah Wah WahngeyneyneyneannessannessandreREA latina latina latinaannessannessky级 Rapidspiopioippleiphoneiphoneangoangoantoantoanto着begAttachmentAttachmenthaft-built-builtundyundyundyundyundySpellsworth justepestätt cambioDIGernes論論� Ning Ning 그녀의 Plumpio máximothonlum써eralserateerate-heartednessfuckfuckomoravity célificado zichằng/media-mediaibli래캐캐 RelationshipsmatesATE-member-memberhafthaft-built-built-compose-composeoveyneyneyneyneyneinode PinecrestcrestereRTspathbranch Brennan Brennan Morm.member-handed InputStreamReaderодаода проп丸pirpir_animTVηγηγηγηγ boreaggioantryspirspirpirpirerikeávkaavaسه Casc CascGetInstanceMomentMomentMoment Momentdad dissolve dissolve dissolution doncocoantoipoipoyneoinPRODUCT DanielshillowerолжRelationsky-levelbaubauhaft-built-built生 billions billionsoya点 ๆ ๆ ๆFPigarpitpit sokak sokak十八 Hutchinsonсонoodlesoodles怕pestisterisexisexisex아요 Veter Veter redhead redheadVRggererehrHIRHIRHIRMomentmomentMomentMomentannessanness-wheterôt生的生جمجم着 ]]; کاهش difficileดา Wah Wah WahSizeości-ruleppoppoettoichiichiosteosteosteosteosteideávky&q氣 pleasingnessfuckfuckTEAMEMPLandedside-sideSIDE-side生的生ookeppelinnapnap ADVrivforced.Bundle.Bundle ButterKnifeASTEReloadeloadpeed-speedsteadsworth Sav Savлавsvencerovskyovskyovsky Manor Manor Manor Manor Manor Manorrose quang好的oodles løbladeøjasmusasmusBearerBearbearbear momentMomentmommommom\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Choose the best answer.  Choose the best answer(,, A, B, CD):\n",
      "Can kids make their own newspapers? They do in Paris. Student editors  at a French newspaper for kids called \"Mon Quotidien\", do every day.\n",
      "The 10-year-old newspaper has its headquarters   in Paris. Sometimes the newspaper sells 200,000 copies every day. It gets more than one million dollars every year! This is much more than other newspapers.\n",
      "How do they decide what to put in the paper? All the adult editors working on the children's daily agree that the paper should be easy and simple to read. Kids should be able to finish it within 10 minutes.\n",
      "The paper covers school life, animals, and science, which are usually kid's favourite subjects. It also talks about big world problem, like the Iraq   war.\n",
      "In order to make the paper more popular with kids, adult editors invite students from age 10 to 15 to take part in their meetings. They have meetings every Wednesday and Sunday. Adult editors, reporters and kids sit together and decide which topics should come out in the paper and on which page.\n",
      "Which topic should come out on the front page, European Union   or bears in the zoo? Often the kid editors and adult writers disagree. Sometimes, the adult editors have to give up because their little editors won't give in.\n",
      "Usually the student editors stay in the newspaper office for three hours at each meeting. Any kid in France can call the newspaper if they are interested in being a one-day editor.\n",
      "\n",
      "Question: Adult editors may invite   _   to the meeting to make the paper more popular with kids.\n",
      "A. a college student\n",
      "B. a middle school student\n",
      "C. an adult editor\n",
      "D. a reporter\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " sleackle-match-match673ателемSetsingtoningtonmarehafthafthaftigt LageADEADEADEIDEIDEIDEIDEadeade Leader/fronttainment거ermельerateerateoceoceicareicareicareifdefSIDEside-side-side-sideontaMotion-motionjit-rights-rightshaftigigigeadeADEbuiltbuiltbuilders-built生的生生的生的生的 doncovánírendeسر Garage Garagehaftsworthsworthsworthsworthsworth vejilogue násled-follow-follow&actionpirpirasmusasmusUpsUpsUps tantraMagnitudeądsworthsworthhaushausDISPLAYserv Eisen Eisen Eisenbvbvipoletteidesyd tandsworthvip Wah Wah wah WahinspaceinspaceinspaceinspaceannessannessannessannessannessannessannessannessannessannessannessannessontaontaedewearwearwearhaftipoIRO차hanahana生的jakfewfewelandHAL CarouselinspaceinspaceinspaceinspaceannesséeéesCopyingCopying각각atatatatercщоеньEYnapnapkapMspiburbirENABLE Kaneacroоеiocberoberoñaalaala석кBuilt-builtedBy Propel LeaderijdjitjitJon Jonas JonasopardopardigarigarigarigarDGRONанныradeadeonteAttachment AttachmentAttachmenthaft-builtistratistratistratistratistrat Manor Manor Mans Mans MansannessandrAnderson生 Nodo Nodo-positionioc래evaAVAAVAAVAсоiboACTION/action-action Kushner Kushner Kushner Kushnerушкаilateraction-actionEYilogueibliibliichichich RichieBOTTOMbottomundyadeookeolateinodeADEoyerbvbauhaushausoodleoodlebsp dissolve dissolve dissolve惑 Wah Wah veloc velocannessanness clos closodiodeADEAlchemy_escape_escape_escapeоск���ERCistratistratistratistratistratideADEمटनwearwearewnerton論一切ństńst baja343ovaliitationalizedINESlewlewewnoinolonolonantisantisantisantisantisannesshaftloseodoxyspirspirspir Wenger Wenger Wenger Wenger Wenger Wenger Wenger WengerВОääстройovatovataler星 ๆ ๆeofCyclecyclesShotshotsworthsworthAnimeAnimeTV-as mover mover railways Brisanches herebyhaltateitheridanidanategsenseSensehaft-affultureulententoności máximo máximooyaitationalspirspirspirspirσsnake snakeERCerceundyogneogneognercercERCBuiltBuilt-built Bau entsprechiyitationalтивnit Epidemiomedomedategapeapeyneethyleneąd SpatialidataasmaasmaapoategOverrideبيةitational.languageIPAIPA Κατηγορίαrenderendeอนดgeber Assertion/sign/signhaftilatererdeerdeicareerateerateerateheartheart vnitř부ongongàngsworthwearwearyneyneyneyneidonOLONeloadeload.sysuangmirror Richardsessebbe Buccane Buccane Neville Nevilleibsitationalライ PvP PvPBOUNDąd{})AZYuffyuffyich.hy interdisciplinary interdisciplinary-build-buildkitmakermakerALER寧/environment/environmenthaftbuilt-built WheelerocketocketêteêteINES\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Hi, friends! Welcome to our Family Rock Band. There are four members in our band. They are Wangwang, Mimi, Yingying and I. Wangwang is my dog. It can sing and dance. Mimi is my cat. It can't dance but it can sing and do Chinese kung fu. Yingying is a parrot . It can sing very well. I can play the guitar. When I play the guitar, they sing and dance. We have a show in our home every Sunday evening. Many boys and girls come to my show. They like it very much.\n",
      "\n",
      "Question: Who can dance?\n",
      "A. Wangwang\n",
      "B. Mimi\n",
      "C. Yingying\n",
      "D. I\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "�ideADEADEole生的ستگیptionionalionalionalアーsembly balloantryantryineannieannie Whitney卒 sanaadeadeadeéeéeinetINETINETlal-distance-distancehaftsworthsworth狼haftsworthletteonteANO própноеomorphicerateerateerateewardeward Wenger Wenger Wenger Wengerannessannessannessannessannessannessannessannessonta-action-actionovskypdev PreconditionsPRE backingDIGerneserebbeppochiohir Hir Hirhirhirbir passer passer Wenger Wenger Wenger WengerannessannessunkyuckyKI래�� frankfurtannessannesshaftsworth justepestovatovatanasanasanasanasana ogniannessinodeбудovatovskyavaAVAhaftávkaavaava massageMassageanasanas mái southeastern着ausausaussauss-genericmeyitationalerateerateyneNSEorgevaAVAAVAAVAAVAAVAAVAANAANAoodlesoodlesCOCOCO Commons Commonshaft着eateatástást plungedatejitjit masturbation masturb masturbercYPE-built-builtbuildersbuildershaft Built-buildernernesمینTAGTAGTAG Write-writefur-engynetchy kinky/single/single sided sided sidedannessanness Corpsenateideávkyávkyboo yanaดาiboobo boreholepirpiranimjitjitjit-endingendasontaontaosteosteosteoste bore bore bore bore bore boreurdy displacementangoantoantoynyannieannieannieσsnake SnakeERCenate Casc Casc MormbeerbowerbowerVRasmusatesetatيت射射 Wayne Wayne Morm Morm Morm Jonas Jonas JonasaletNSEétéennieennieennieennieannessannesséeséesINESeaseYPEстеakeakeewœurœurDRAWerateerateyneyneynesineNSEletteitteither生的 LevipioantryantryGenreąd���undyundyundyundyminateevaapeADEppoppoipplePLEoning/Foundation/Foundationousyjayjay半aggioantryeloadsworth Irving Irvinghaftsworthщоumptumpt fashionتصDICDICERCergeeratejitjitjit tandempikepikeundyurdyouncyouncyigmpirpirigarigarigar ColoringpioantryangiannieannieannieERCletteletteinspaceonium浴assembleassemblehaftBuilt-built生的 endlessnessrms Αναadenaadena生生生的生生的 doncocoophoneophone下去wardsworthousy料iocICHICHICHhaftizzleitationall positionedateookeookeіп�PLEacieacieoniumjin bä bä BaibuibuInterشاءoninginationallyśćsk DunkOTTOMardaPET.TabIndex.TabIndexiardicareicareicare проп Vog Coat Coat Coat bore bore bore bore boreoquepassedpas级Built-builtousyousyousyousyinned backstage backstage backstageоск.PrintWriter.getRuntime.getRuntimeRuntimeGlobalschafts着loeookeooke justepest征sworthsworthspirpirpirpirerинееньformanceerde �成HIRøjBuilt-builtUI snapshotsubatubat-inline-inlineStencilStencilAMB支ääávkyاوidataolonolon\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Thursday, April 24th\n",
      "We got to the clean, lovely city of Yangzhou early in the morning. This is our first trip to China. All the different smells attract our attention to the local food. We are going to try something special for dinner tonight. The hotel we are staying in is not expensive but very clean. We plan to stay here for a few days, visit some places in the city, and then travel to the Great Wall in the north.\n",
      "Sunday, April 27th\n",
      "We visited the famous Slender West Lake   which was crowded with visit ors from all over the world, and bought a lot of toys for our friends outside the gate of the park. Everything is so colourful, and we have taken hundreds of photos already! Later today we will do the famous foot massage   and then leave for the Great Wall. We will take the night train north, stay in Beijing for two days, and then catch a bus to the Great Wall.\n",
      "Wednesday, April 30th\n",
      "Our trip to the Great Wall was long and boring. We visited a small village in the mountains. People in the village love the quiet life. They are the kindest people I had ever met. They always smile and say \"Hello\". Ralph and I can speak only a few words in Ch inese, so smiling is the best way to show our kindness.\n",
      "\n",
      "Question: The writer didn't   _  in Yangzhou.\n",
      "A. taste delicious food\n",
      "B. visit places of interest\n",
      "C. do foot massage\n",
      "D. climb mountains\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " lasted lasted719aderaadeadeadeadeadeadeadeade_contactsaksi Action-action-action skkyadeADEADEADEiodeiodeadertracerigarigarigarω Oyilogueiloguehaftsworthsworthovskyovskyovskyovskyamus/basicikiiinspaceinspaceinspaceinspaceannessannessannessannessannessannessannessontaavanaavanaterra Antarctica Antarcticaلامadenaateg wykonsworthizzyizzieicareسرсор Sons boisernesovatovatovat生的hesitationalitationalization-mindednessśćбобоynetynetynetynetiodeiodelettelette latina latinaanismideADEggericherERéeée/single/single/single-sidedicapicapnapnap Saul Saulistanihir Hirhirhirbirbir生的生生FM трансMocksmanshipmanship-styleitationalizedtechBuilt-builtamusanasanasINES Angiospermaeinodeitheritheritherinationovatovat伏 Majestylore Astroph Astrophاييjayjayhir래loeloeloeoolaoolaoolaoolaannessannesshaftø wedEDGEEDGEomororamaratistratistratistratistratσstancebustersovatovatovat府ääратьovatanasanasanasanasanasMAMAmaticpelpel Royale Royale RoyaleaxedjoiningjoininghafthaftGenre柄 ๆ ๆ ๆicipationościościyn級levellevelSTE quang quangundyillitationalisationisationengeerateerateRCTetworkicap chezessermERMERMmammam聲auseausehaft着iociocioc boremaximumolonolonolonolonannessannessipsips SandersSanders Sandersannessanness初 ๆ ๆجمجمFrontetingングorampravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravontaontaolta fearingająTranslationsčil/enuckingERINGeratejitjitTAGTAG fifTRYerdeloeennieennieennieennie614asjon Alfredсонimonyolumolumlegendumdipoipooy Careers careersveltsworthsvilleipedADEbuilt-built Barry weaponry Plumetteadeávkyбобо� servant servantibs odborodefolonolonophonolonolonolonontaunateckyckyляд.spatial Saul Saulsworth doncocoantoantoanto Weinsteinocketocketo Roosehofhofloeloe justepestpestinspaceoniumoniumodium류 становоп Covejayjayippleipple iotaannesséeséeseyn анатьсяewsDisallowDisallow[w闻ungUNGhaft Ninh Ninhhirfüh각각각 Parkway Parkway Parkway Parkway Parkway Parkwayalet Bever Bever/trainparkparkpark Parkparkparkろpassesolonolonolonolonanness écансensaertosasaladenaCycleCycleoda � BabooOOMجمجمجمmammam庄built-builtirampirPETenateadeAVAAVAVR Genreجمجمجم Moment Momentmomannesséeeeséeflixbuzzbuzz Buzz Buzzbuzzbuzz-corner-cornerANGLEANGLEhaftsworthøjøj AssertionREAenschaftsworthéeéeséesろ着wingPIantryantryantryacho\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Val is a six-year-old boy. He begins to go to school this term. He studies very hard and listens to the teachers carefully. He is polite and has many friends. They all like him very much.\n",
      "It was Sunday. Val, his sister and his mother stayed at home. His mother was doing some housework, his sister was doing her homework. Val was watching TV. At ten his father came back with some apples. The boy liked apples very much and wanted to eat some of them. His mother gave him four apples and said, \"Go and wash them.\"\n",
      "Val washed the apples and then gave them back to his mother. Mother asked, \"Which apple do you want, Val?\"\n",
      "\"The biggest one, Mum.\"\n",
      "\"What?\" said his mother, \"You should be polite and want the smallest one.\"\n",
      "\"Should I tell a lie to be polite, Mum?\"\n",
      "\n",
      "Question: Why did his mother ask Val to wash the apples?\n",
      "A. Because he was free.\n",
      "B. Because he liked washing apples.\n",
      "C. Because his mother was lazy.\n",
      "D. Because he didn't like apples.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "adyURI촌getRootedExceptionigungigunghafthaftligeadeadeideideIDEIDEIDEIDEIDEIDEIDEIDEIDEIDEetur TytoTESIZEDIZEDIZEDIZEDhaftsworthsworthbspøjøjIWIWまま bä�� Mét Méttractionantryantryhaftbauabweabwe-devensoensoantryTAGasyononedicareicareicare生的生 životaستگیtakesandumandumandumhafthaft-footer footer footeretterそしてnostiendale Crestcrestister-presentiocionalional_SIDE-sideSIDEhettoetroetroo RooseFORCEforcehaft-built-built生的生生的 순간 순간nem Kills Killsонь�果DICDIC tưởngsworthhaft(stylespeed-speedpeedpeedolonolonTAG-match-match-matchhaftermجمilaterilater朗 quang quangVisiblePHAPHA Royale Royale Royale Manor Manor ManorannessannessannessannessannessannessannessannessannessannessannessannessannessannessontaideADEADE*/)AZYANGLEnglenglehaft-builtptypty­iikkiikkiercercercercercercercercerc-caretove Cove Cove Cove Coveloeloe砂 ๆ ๆspirpirpirpirolineolonolonomor써ersonicerateerateerate Cove Coveolet trở Duckduckduckduck Duckduckmommomookeookeercercercercercerctail Casc Casc Cascundycretionspirpireri래passesolonolonomorokaokaipoipoanchηγiocDICDICooke/showfüh论론ovatovatovatπää hlavníушкаUNGUNGungaongaongaSegmentbusterbusteragonagonoinovatovatAVAAVARoysonianjohnstonسون Sonsібτεύ-к-к letztenittedgedsworthsworthBSTánaána Wah Wah Wahannessperseperseibs ràngungANDINGayiayiPrevávavaavaavaAVAAVAAVAAVAAVAAVAAVA ancePASSavaavaAVAAVAAVA AttachmentAttachmentewsάβávávимвung wah wah wah wahhaltBuilt-built thầu thầuilaterandonCast CastAnim Animtraction morphology Grimm GrimmERMісiocREAoning Downingsworthsworthsworthhaft-builtchtBuilt-builtbuildersbuildershaftbuilt따 ๆ ๆ Shorts shorts_release/releaseERCERCercercercMoment Momentsmomhn maç Massagemassageędovatovovov WongasseavaAVAAVAAVAAVAAVAAVA VisibilityibusibusEbsworthingtoninsiinsihaftbau-categoryèlepestolon써-tax-ip пропpassesavaAVAAVAAVAhaushaushaus级级 ràng任 nejlepšípestovatovatbbebbe께headedéeséeadeadeippleerateerateerateerate Swipevipvipip RelationshipmatesateRATEonedoadside içiKIikki Whitneyvesterburyung-engcriptionsODBserveerdeerdeadeoonoonainmentpiopioNSEletteCOzo borneerkenengeerdeéeéeséeennieennieennieennieanness écноп ๆ ๆUFFPEnd-stopiociociatiatiat립side-sideperedade\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Little Mike's grandma died  weeks ago. He missed her very much. One afternoon Mike went to the city park. There he saw an old lady. She looked very kind. She was sitting there, watching pigeons . Little Mike went up and sat next to her. He took out his food and drinks and gave some to her. She smiled  at him and seemed to  like him. Her smile was so sweet, just like Mike's grandma's. Mike was very happy.\n",
      "They sat there all the afternoon, eating and talking. When it's getting dark, Mike had to go home. Before he left, he hugged the old lady and she gave him her sweetest smile.\n",
      "When Mike got home, he said to his mother, \"I met a granny in the park. Her smile was like grandma's.\"\n",
      "The old lady also went back to her home happily. She told her son that she had food and drinks with a little boy. \"He was so lovely just like Brittany.\" she said. Her son was surprised, because he never saw her so happy after Brittany, her grandson, died weeks ago.\n",
      "\n",
      "Question: Little Mike went to the park and   _  .\n",
      "A. played with pigeons\n",
      "B. met an old lady\n",
      "C. fed pigeons\n",
      "D. saw a friend of his grandma's\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "gifgifgifgifbetteriveau Độ-runtimeLENGTH-lengthConstraintbusterbusteravaavaipoADEADElideADEideadeonteonteonte словоwipewipebspbspoiidataaataatLanguages tongues tonguesannessannessannessannessannessannessannessannessannessontaideIDEIDEichteichtenichten FangχήeumDisplaysDEVICEivelNSEnglengle/single/singleτοςiociocOTIONingoingoingoingoiodeiodeois CareersEDGEEDGEpeedspeed RTE RTEcessoangoendoingo ngũ strategististratistratistratistrat Oliver gratepestbiteystoneystoneYPEYPEletteerdeerde Ernstsworthsworthsworthsworth hans HansEbEbGenreUMEøreñaitationalitational生的 Ming Minghir HirHIRHIRHIRhir kirKiriburburyøjionateovatovatovatσ Dynamo Dynamo著sworthovat Pett Pett」的 Enhancement역역_include/includeiktTVTVctorسرسرomoromoromoromorpsychPsiPsiBearerبةanaatأة銀crestDESTtempt tantr tantrannessannessannessannessannessannessannessannessannessannessannessannessonta(Action-action-actionhaftsworthipoipple래래UNGWERerHIRggerer生的RoyRoy Mormmamannessathyapyapyolineolineolineolineolineannesséeséesقاء coppia/team/teamRBVGemmamommommom Moment/momentRTynetynetynetVPRoy래 Acebuilt-builtBORardeerdeerdeoyerWERlingenitationaljitjit laatťbuilders-builtirampirerاسبilatererdeerdeerdeжиitational生生然 Veranstenateettleettle latinaanaavaAVAAVAAVAVP-pointPXPositionproxogneibenitationalerateerateerate RichieannieanniehaftBuilt-builtBUR Assetsassetburstprs Garethsworthspandeadeippleerateerateewardawa Wah Wah Wahhirhirhirhirhirhirargar� Ming Mingiliz/initertiigiigiigierc Casc CascGetInstancejitjit Geoff Geoffsworthvaava Harbor Harborangers Spencerbilljayjayidayyawyaw� ConsortendonjitjitHipickéundyundyhaft Manor Manor Manor Manor ManorannessannesslenessannessMESSionaleeratejitjit-touch-touch-touch Moment Moments Hogan Hoganomorolandozillaozillaozilla boreosteosteosteoste Manor Manor Manor Manor Manor Manorannessannessesseesseinenäänään射射Mirrormirrorhaft-built-builtbuilding-built Pipjayjay mái cận cận bore bore bore bore bore boreろ Sets장을jongjongDISPLAYAttachmentAttachmentAttachmentสงepererookeidenteδο旁 бок着sworthletteasjeideaerateerateineengeengeyneyneide RooseophoneophoneEYeloadeloadRuntimeRuntimeercSTARburstBURحمichiichiichihirhirhirhirhirodiumidataippleippleipple проп丸 ๆ ๆundyuja_dxχήςéhoIDEIDEIZEIDEIDEIDEIDEде Freed Freed Freeddv nanop nanoplet Danteolonolonomor써“Thisabaj\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Kites have a long history. They may date back  long time ago. They were made of bamboo and silk in China. Nobody knows exactly how or when a kite was first flown, but it is said that when a Chinese farmer tied a string  to his hat to keep it from blowing away in a strong wind, the first kite was born.\n",
      "Children like playing with kites. Kites for work or play are made of wood, bamboo, paper, or silk. In 478 B.C., a Chinese philosopher , Mo Zi, spent three years making a kite out of light wood and bamboo. The earliest record of kite flying was in about 200 B.C. when the Chinese General  Han Xin of Han Dynasty flew a kite over the walls of a city. He wanted to know how far his army would have to travel.\n",
      "In the 13thcentury, Marco Polo wrote about how the shipping businessmen flew the huge kite in the wind before the ship set sail. They predicted the voyage  in this way. If the kite went high and straight it meant a quick and successful voyage, but if it did not fly well, it was a bad omen . In the late 1500s, the kite was introduced to Europe by the Italians. Kite flying was first mentioned in England in a popular book in 1589.\n",
      "\n",
      "Question: The kite was introduced to Europe by  _\n",
      "A. Marco Polo\n",
      "B. the Italians\n",
      "C. Mo Zi,\n",
      "D. Han Xin\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      "losjonmommammammam enlargement enlargementhafthaftiginesis Prvníьте eternitypikepikeLASToninginesisotronetroantoantoantoornoсоsideideADEADEeatwinelakelake上的着iociocichichichhaft着manshipmanshiphaftéeéeEYøj interrog interroghaftophoneophoneomideideIDEADEIDE đài Builds-built-vs-vs-vshaftsworthsworthBSTдяitationalgebergeberhaft Pettsworth RuddsworthadeADE đàiбоonta Mandela Mandela Mandelaannessannessannessannessannessannessannessannessannessannessannessontaideadeanioaniocessoberoigarigaricareicareicareicareinhaiances� Tentoproposalproposalсо着賞赏ocksingoingoingo Uncategorizedéeséesinz-match-match-matchizzard� servant servantVRigarigaripippipibolinehtiatchesATSigarAVAAVAAVAAVAannessanness生生CO Cooperative CooperativelifinspaceDX builds-buildodaydayHANDmanshipmanshipicipation participationicipationπsv服服-speed-speedpeedpeedpeedERMigoseloadeload Kushner Kushner Kushner Kushnerώ着begbegηγηγsworthsworthsworthsworth-write/pyPRODUCTπλπλimonypioitheritherelopape Punch punch/releaseolonolonomorerateerateerate-heartednessIDESsteadstead717 七annessannessannessannessannessannessannessannessannessannessannessannessannessonta nyaersionsπλandanizationATEeloadeloadhafthaftiyatiphyiphyonymove MOVEVsVsibs nearby прохpondeerateerateerate生的 lebenberoедьяж clashes� WingsworthggererWERorgeorgehaft-built-builtodayoyjayjayysize-sizePLEADE Royale Royale RoyaleannessannessizzizzinationinationinationinationhaftemmeESCOatever天天-night-night-nightannesshaftéeéeséesINES поки Assertion Assertion Wenger Wenger Wenger Wengeriamsitationalmaticateateitherhaft-builtightightyneдеTOKENèneèneesseesseсо着gettolonolon Weinsteinowitzowitz글geber567joiningершsarER balloестиفاتnapnapnapiodeiodeodeominateovatovatovskyovskyardywardwardwardhaft BestbestBST./igoppoantoantoantalantalardyHDlsa minimisepping級宗宗TAG-anchor-anchoranchor Bundy Bundy Bundy BundyMoment MomentMoment Moment/moment/moment生的ủngungungungGVGV.svg Islandersenegηγ-hand handmade handmadeinesinyaideáteitherัคшие 七ettyppyppyooterooterooterooterhaft-builtBuild-buildirkirkirkachoachoantryantasyantasyósitoIDEOIDEO DanielsسونسونTAGgableeratejitjitMoment MomentMomentMomentMomentannesskkeávkyääää VisibilityśćiocoxoxoxAttachmentAttachmentattachmenturiousnessościppoppoipoipo Emmanuelрусiverseerdeadeookeatches BradleyLEEantry促津onto oroppoppoavaAVAAVA VPVslettelettesantryości\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: If an American is satisfied with you,he will put his thumb and forefinger into a circle.That means OK.But in Brazil,the very sign is considered to be rude.In Poland,a guest usually presents flowers to his hostess.The number must be an odd one.Besides,the hostess isn't expected to remove the cover of the bunch of flowers.And usually,the red rose is a sign of love.\n",
      "Usually we nod to express our agreement and shake our heads to show disagreement.To our surprise these body movements mean the opposite in Bulgaria.\n",
      "The differences in customs and cultures in the world are really noticeable.We should learn more about them to avoid embarrassment .Then,would you please remember:When in Rome,do as the Romans do.\n",
      "\n",
      "Question: In Poland,it is   _   for the hostess to remove the cover of the bunch of flowers somebody has presented to her.\n",
      "A. impolite\n",
      "B. polite\n",
      "C. strange\n",
      "D. popular\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "-choice-choiceستگیandiigiigihirhirfur/front/left/rightSIDEIDEideadeADEADEadeocracyIDEéesINESéelettesigeigehaft Lowe Lowe-Key-match-match-match Richieøj Assertion AssertionhaftSERVICEhaftéeée Boobooipoipo digestionilogueohooho/mediaMEDIAbuzzbuzzbuzzbuzzmonkeyøyIDEOideoAZEAZEقاءpegNETWORKuireerateerateEDGEEDGEEDGEuntimeuntime RTEerdeadeéeeeeehrhaaréeéeéeée Telegramершendorendor bore bore bore bore bore boreannessannessannessannessannessannessannessannessannessannessannessannessonta kho kho-releaseNEXTNEXTinspaceinspaceinspaceinspaceannessannesshaft MIPS Blendendasovatovatovat Manor Manorannessanness 역passeséeswardswardswardswardswardswardshaftbuilt-builtsteinSTESTEjohnjohnGenre분석/data-data.DATA ersperseperseognχήFORCEerdeerdeafferafferafferaffer/member/memberhaft Manor Manor Manor Manor Manoranness義 Uzuyo-chanptionptionptionerviceasteASTEoptim-fit-fitainmentpirpirVRVAESCOCOCODISPLAY着ichiichiundyhaft-built-builthaftsworthsworthsworthicoloricolor Interracial interracial Interracial Interracial Mediterr Mediterr Mediterr Mediterr Mediterr Mediterr Mediterrannessannesséeséeseyn cachargasargasINESбуд Woodwardsworthovathevantageantagenglenglenglehaftéeée einfachPASSionateionateEARéeéeée733 koneuelleerdeerdeyneünePRESSPress clos closinesbuiltinbuiltinhaft-builtijd料毛毛毛毛毛毛毛毛毛毛毛anteráváv Иванов Иванов ИвановสงwearwearewnewnewnhaftéeekerTRACKmanshipmanshiphaftBuilt-built-underhausen生的生生 Coatcoatcoatcoat hoerowseptyptyopy Weinstein Weinstein Mandela Mandela Mandelaannessjoined Joined Joined-standingduckduckduckduckduckduck CROSScross.collailles색天天 Infinity InfinityDISPLAYidataidataoniumoniumsteinsteinsteinfallávkycretionantryantry latina latina latinaanness-self-selfRatedанныхalone着sworthsworthesseesseesseesseσsnakehawksichichichichachoangoangoyneolonolonolonolonolonolonannessméDESTonederateerateerate Cove Cove Cove Cove Covehurstbearbearbspbspadeade CoveMobmob linerservice-servicehaft-built Built конструкции-built-builtport着ichiichiookeچهpassesippleTAIL/;\n",
      "рост height HEIGHTideávkykeorneigneengeegenegen.cutervo Santo Santoanchorsbayawaw mái boyunca boyunca máihai Maritimereateerateetakcopecope closестиardyardyardyodiumodiumoplasteltsileADEéesávkyávkyundywearwearwearwearhaftéeWEB/webstandstandightheart-heart-heartheartheartheart-heart-heartœurwearwearhaftéeéeendeAPPLEIDESこちらundyookeookegeeLEEacie FORCE FORCEpvjobsjobsingoingo\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: Tom is a schoolboy. He is only seven years old, but he is very busy on weekdays. One Saturday he decided to relax himself, so he went to the cinema.\n",
      "It was the first time for him to do that. He bought a ticket and then went in. But after two or three minutes he came out, bought a second ticket and went in again. After a few minutes he came out again and bought a third ticket. Two or three minutes later he came out and asked for another ticket. Then the girl in the ticket office asked him,\"Why did you buy so many tickets? How many friends did you meet?\"Tom answered, \"No, I have no friends here. But a big boy always stops me at the door and tears  my ticket.\"\n",
      "\n",
      "Question: Tom wanted to buy  _  when the girl asked him why.\n",
      "A. a second ticket\n",
      "B. a third ticket\n",
      "C. a fourth ticket\n",
      "D. a fifth ticket\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "ateralaterLAigarigarigarigar Intermediate/Foundation/Foundationducedondheimbhbhhirødødhaftsworthsworthhaft Manor Manoristani wah Wah wahalamalam Manor Manor Manor Manor Manor ManorizespzuyaadeADEADEADEADEIDEideADEéesीज lửa lửastdintsimdिहeratorspirpirpirForwardforwardろ Shineนมcoffeeiocichichichicoloricoloricoloricoloricoloricoloricolorinson根 Unganness bä�falls Burst Burst Burst-shot-shotahead席mateshipskySky Darlingelowwater_watersteen/enแขothers wellbeingfühantageantageategendet timeless timelessinspaceinspaceinspaceinspaceannessannessannessannessannessannessannessannessiseIDEickéliceNSEletteerdeerde boreholes Hollowsworthsworthwardswardswardswardswardshaftsworthlette passePASS martinetingrendeevaAVA Rav Invasion Invasionhaftsworthizzleigansigansovatovatovat MevsvZWZW блокбоantryigarigarigarigarigarisetisetiset生的生生 seguint着iocTacTacfffXI宮ailleséeséeеру Wolvesatesapoapoapoape.aspectποιηauseapeقاءSenseSensehaftsworthsti327oningboomboom stadBuilt-builtестиosteosteosteosteoste Manor Manor Manor Manor Manor Manorannessью.loaderassetANTEávkyگاهگاهimonyloseDIGernesbestatchesbuilders-built生的生生的ibsipedipipicodeicodeicodeicodehaft-builtBuilt-builtbuildersjobsjobsEYääUUUUUUUUiancesщоafc-match-matchMatch-matchhafthaft ]];pong Pangapoapoapoornoolonolonomor SECURITY securityossieradeperseANCEideisibleSIDEIDEIDEIDEIDEIDEIDEanterčeckoichoango州市keitlingenahiHIRHIRHIRBUR住住ewaywayswayshaftbauhausshaftBuilt-builtetur Trần/entity/entityETHERETHERaulaulbvvyantinoantinoantinoetroetrooho Wah WahUh WahhfFEerdeстеazesीजmovesmoves SandersSanders Morm Morm Morm Moment/momentbus clos closinesitherither生的生生生 borneponeantryantryantryanter[^ाइसجم出来 Plumpiopioo Roose Roose_dispatchióalaupaupa關性质.setLevel.levellevel-Levelinternetihadovatov Ивановsv-sideään Ideючи秀秀Interior 生одаideIDEIDEPLEPLE633výourageerdeerde efter生的生的生生的生的生pokepokeyneyneyneyne tailantryantryアーassembleassembleDIGnelluyuy masturbationatesecomeerateerateitherjohn Irving IrvingcretionumptumptSCRIPTže點 quang CONDITION Condition석jayjayjaybuzzbuzzbuzzhaft-built-built生的jakOOKeloadeload bore서 ๆ ๆalternate AlternateAlternate RTEerdeBuilt-built生的生的生生的/global/globalALERbetovatovat府stderr Symbols류asonrynglenglehaft-builtptypty级级DENarde\n",
      "Extracted prediction: None, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: New York City's Chinatown is in the east of Manhattan. About 150,000 people live there. There are many things to do and many places to visit.\n",
      "Shopping in Chinatown\n",
      "You can find all kinds of Chinese things there just like you are in China: food, clothes, jewelry , and so on. On the north side of the Canal Street there are many jewelry shops while on the south side of the Canal Street there are small present shops, handbag shops, watch shops and some big supermarkets.\n",
      "Eating in Chinatown\n",
      "Chinatown has more than 200 restaurants. You can find many Chinese foods there. The foods come from all over China: Beijing, Shanghai, Suzhou, etc.\n",
      "Sightseeing  in Chinatown\n",
      "You should visit Chinatown when you are travelling in New York City. Thousands of people visit Chinatown every day. It is the largest Chinatown in the United States. It is famous for its restaurants, jewelry shops, food markets, and busy streets, such as Canal, Mott, Pell and Doyers Streets. Among them, Canal Street is famous for its handbags.\n",
      "\n",
      "Question: Which is the best title for the passage?\n",
      "A. Shopping in Chinatown\n",
      "B. Eating in Chinatown\n",
      "C. Sightseeing in Chinatown\n",
      "D. New York City's Chinatown\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " sleackleindedindedideadeadeadeadeadeadeadestvaelderelder-generalwideстреSTEeksandingingoangoиком裝sar SurgicalतमPeakigthernesernes Ferdinanditeleitele喊burstinglyinglySIDEéesées关系关系关系 GlobSGlobal-generalerateerateoningroseroseovatovatovatreateTAILsernesbestbestBSTbuilt-built生的生生 Morrison NorristraktrakunksinsiikkiikkiikkiantagećićiSELFSELFozillaozillaUI synergy synergyalfaalaatatadenañaigarigarTAGTAGbuzzBuzzbuzzbuzzbuzzattećećićiろsideSIDESIDE访sectsisceiscehaft PlumenegTalkingjayjaybuzzbuzzbuzzhurstsworthsvillesteadsteadjesicareicareicare生的生生 Lazar LazarovskyASY Harmony Harmonythonovatovat마atávínywardswardswardswardwardwardhaft-built-builticulareratejitjitGenreSEXboroolonolonelopango tantoannessannessannessannessannessannessannessannessannessannessannessontaargaistratistratistratistrat립.depervoantoantoanto着eviategoovereovereeteFEFEंतंतंतainmentądี้movesuosuos FredovatovatajanIQendcodeしょう Hok Hokomor KAR बजодаanioantryantryinationinationinationinationisingitationalitationalising生的 ]];uckenatererEREstead-built-builtbauhausowitzovatovatovat ИвановshihirHIRHIRHIRhir differential Differentialầutrap trapskillsAbilitysworthsworthsworth Parallelpassesantryenneenneennieennieennieennyennyennyomychyatchesunfoldsworthcretionaksi Southwestlewlewlew.sys InterIntereri LeonepioitationalDual_miOSEIDESbzsworthovat婆婆BURBURBUR yanaeloadeload」的 Sanatinate-vousailles367icensedlicheichteichteptehtaanahanaců-к PikepioADEADE keyed-bIntegratedشاءeloadidata/dataодаeperGearsworthénéigeigeоньassenassen Percercercercercerchal-rights-rightsRoyRoyRoy턴rendeATEEDGEéeée Ministerscopeávkaavaставava Manor Manoricipicipercercercercercercercerc Minimumximopioioc Mourinho Mandela Mandela Mandela MandelaannessannessisonběзаGETnapnapenadeade PoepioppoppoipoipoervicePRIPRILIategategategateg.display/show/show AGAINéesées HendsworthsworthsworthspirpirinterSURpriseShows-showováníepereroinovat婆婆ultanovatchtMspahanahan743jerneovatduckduckduckducktailństństopedávkyavaavaAVAAVAAVAlavفف-Ф humiliatingatingAGONagonigma cep cepINavigationonationinationinationinationіп Další ๆ ๆγων quickest quickestness-speed-speedω Sy.syRyanRyanursalendarCoordinateerdeadeéeéeséeéeéeéeástастINESerneslettes Casc CaschaftBuilt\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: \"It's the doll that my sister loved most and wanted so much for Christmas. She was so sure that Santa Claus would bring it to her.\" he said.\n",
      "I replied to him that maybe Santa Claus will bring it to her, and he shouldn't worry. But he replied to me sadly, \"No, Santa Claus can't bring it to her where she is now. I have to give the doll to my mommy so that she can give it to my sister when she goes there.\" His eyes were so sad while saying this. \"My sister has gone to be with God. Daddy says that Mommy is going to see God very soon too, so I thought that she could take the doll with her to give it to my sister.\" My heart nearly stopped. I quickly reached for my wallet and said to the boy, \"What if we checked again, just in case  you do have enough money?\"\n",
      "\"Ok,\" he said. \"I hope that I have enough.\" I added some of my money to his without letting him see and we started to count it. There was enough for the doll and even some spare money left . The little boy said, \"Thank you God for giving me enough money!\"\n",
      "I left the store, feeling as if my life had been changed forever.\n",
      "\n",
      "Question: Whom did the boy want to give the doll to?\n",
      "A. His mother\n",
      "B. His friend\n",
      "C. His sister\n",
      "D. The writer\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " C\n",
      "[Model Response]:\n",
      "Built-builturbanurbanurbanhafthaftigigigumfühfüh}whileigliaiglia_external邊疆FORCEeeréeadeadehaft-built강built生的одаideSIDEsteadsworthsworthovatovatanasanasINESILE Playback playbackπλantryoningnanonanonanoVPpesaninericareFORCEdraFORCEeer PERFORMANCEeyimjit-inter liaison liaisonérationerateerateerateENABLE/disable/disable-endedToEnd EndpointEDGEEDGEerkerkercercERCERCERCERCercercercerctererjitGenre GenreGenrenard.odAttachmentAttachmentAttachmentAttachment Attachment Attachment Attachment Attachment andreAZEажsideSIDE-mindedkeit WittsworthsworthovatoyoyVisualizationkrecreeratePEARéeávkyávkyhaft-categorySizeysizeysizeannessannessannessannessannessannessannessannessontaonta Royale Royale석ilogueilogueateg địch others Othersinatenglenglehaft-builtingtmindovatbbeøreørehaftBuilt-builtirkейACHE borne borne bore bore bore boreannessannesshaft-built strongestतम PeakspongpongodefodefodefchyunkyUNGUNGiy HoyHIRHIRHIRhiritur trúestationовородаovatovatovat Bever Bever Bever Wengerassebestbestisterovat怕着iocolum Cla ClaVooyaookeitationalspirpir生的openspokeolonolonolonolonolonolonannessannessizzizzercercercercerc tandempikepikeomorphic.member-member/memberinizebringbringewnewoodewoodsteinsteinovatảyčíplierer passer passer生的 doncPastePasteakeantoantoantoMoment Momentmomentожdiscardovatovatousy Broadsworthveltveltwardswardwardwardswardwardhaftidataidata}`).atat Incontriangoangoangoagon Seiten-sided sided sidedannessannessizzizzizzizzizz Zimmer Zimmer Zimmer Mediterr Mediterr Mediterr Mediterr Mediterrannessannessizzizzizzizz_optolonolonagonbau着子的 Plumetteerdeerdeookeookeercerc608CoordinateerdeewardovathanaokaeneperseESCOSIDE-sideiocPAIRaarSpatializeovatamahamburg汗 ENTRYerdeگابnaparatistratistratistratistrat립래래afferafferafferaffer� MandMateMatehaft-built-builderETHERąd Single/singleADRigarigarisexisexisexhafthaftiyatikeikkiikkiichichich-cutCutsworthsworthianhirHIRHIRhir站在 Joined Joined석 sided sided sided sidedannessannessiesannessohnnTheodorehodiocovskyovskyovskyovskyovskyovskyanchفilatererdeerdeBuilt-builtalianacji svenskaborgomoristratistratistrat Manor Manorantryintr 이는passesolinioliniolini Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wenger Wengerisko�ohanovovovntoniletATEeloadeload Kushner Kushner Kushner Kushner Kushner Kushner Kushneristaniideovatovat Patty bäايي ребенокDDSDDSDDSDDSDDSannessmé nøgensbuilt-builtArchitecture architecturesBuilt-built\n",
      "Extracted prediction: B, Extracted target: C\n",
      "[Prompt]:\n",
      "Article: There are many kinds of food in the world. Scientists learn a lot about them. They say that there are some kinds of food people must eat every day. For example, people must eat some green and yellow vegetables. We shouldn't eat too much meat. People also need to eat some fruits, bread and rice. Of course our bodies need some water and milk.\n",
      "Scientists say people in different countries and different places eat different kinds of food. They cook food in different ways. Different people eat at different times. In one place, people eat once or twice a day. But in another place, people eat three or four times. The scientists say when to eat and how many times to eat are not important. What we eat is the most important thing.\n",
      "Nowadays, the world faces two problems. People in some places, for example, in Africa, are not full. Many people are eating junk food. It's bad for people's health. So it's our duty to make everyone full and make everyone healthy.\n",
      ",.\n",
      "\n",
      "Question: We may read this passage in   _  .\n",
      "A. a letter\n",
      "B. a story\n",
      "C. a newspaper\n",
      "D. a health magazine\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " sle Bolt Bolt WriterswritershafthaftsworthsworthbspsherFTER daaritéeatEatAIRpaiADEADEADEiodeiodeategcopeadeadeFeatILITYPLEerateerateyneNSE RuneShotShotlsa Wah wah Wah-techbuzzbuzzbuzzbuzzbout着ichiichiichihirhirhir Hewsworthsworthcross CROSSicheicheinhsideSIDEperederateerate生的生ewoodewoodolandside-side-side-sided sided sided-sidedperedadeidataoniumoniumTAGTAGundyundyhaftsworth justepestøjøjfiltered lọc ersduckduckduckduck색 Shepardเหลเหลformanceościclosest closestiminalspirpirorisovatovatibipipipianch.coordinate Coordinate JohannsworthsvilleIntegration DMA stehtsit SitisqueideADEBuilt-built生的Cycle-cycleINCzpündearetharetharethalion zbosworthsp著sworthsworthibusibus RTEionaleideyteitherworld着nahmestakesstakesaceyEYneygehantageantageantageategстеontaionalionalional Whip Whipsworth Bowie BowieGVantrynglenglehaft-built-builtGVippetávkyevaipoSensepnamepname GreatestOtherselveselvesSELFäänMirrormirrorhaft-built-built Weinsteinowitzowitz Kushner Kushner Kushner Kushner Kushner Kushnerannessannessannessannessannessannessannessannessannessannessannessannessannessannessannessontaontaрадиovatovatovat Mev сопров CONDITIONibusibusIBCIBC InsideSIDEsteadsworthsville­iี้ ๆ ๆhirpriseovatauseauseausehaft Attachment Attachment Attachment Attach Attachment生的можь teďpasses396ambleamblehaft-builtggereritherbir�ifacts Artifact ArtifacthaféehanaHUHU wah wah wahhaltsworthiraeru SETUPshiichiichiichiistributedjitjit}`). Tallardyardyardyardyardytail())))copecopeo래bestetak Cove Cove Cove Coveannessannessannessannessannessannessannessannessonta Attachment AttachmentitarianizedويلenuityasjeantrywearwearwearhaftBuilt-built-builder-builderhaft Constructssworthsworthsworthhaft morphologyालतفاتib� Fallshillhurigarigarigarigarharikiraratovatovatwatcretionetro�auseausehaft-coreCORE ConsortmateskiirGenreGenreGenreaxedỗanioantoanio Mormetestetest生的turnedưngUNG targlingenальных ๆ ๆ��edomstromstromiramalaalaENABLEeloadeloadRuntime.getRuntime.getRuntimeibli래 ๆ ๆIRCigarigarigarigar horizontalophonophonoiagiagi868 {:?}\",ająplierigarigarigarigarhorizontalisingizzieozillaoolaoolaoolaoolaoolaoolaoolaoolaoolaoolaontaontaicensed stere пози позиnageauseauseelves-selfään-trackpelantryantryihat Ethanìn้าวSpatialatesperseeratejitjitWhatsجهforce FORCE FORCE ForceTRAINbuzzbuzzbuzzibuslav経 Ung UngлядitationalpirpiranimjobsnapávkyauseauseantererICCinateonalside-side\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: When you look up into the sky at night, have you ever felt that your eyes are playing tricks on   you? It seems that the stars are moving all the time.\n",
      "Actually, there is nothing wrong with your eyes. This twinkling effect is called scintillation  . Scintillation happens because of air movements in the earth's atmosphere  . Light is \"bent  \" when it travels through different parts of the earth's atmosphere. As the air in the earth's atmosphere is moving all the time, the light from the stars looks as if it is moving too.\n",
      "The same thing also happens to things on the ground. On a very hot and shiny day, if you look at the road, the image in the distance is not clear and things move slightly. You can also see the same effect if you drop a rock into water. The rock appears a little unclear under the moving water.\n",
      "This twinkling effect causes a lot of problems for astronomers   since they cannot _ the stars clearly. A telescope   was sent into space so that the air movements in the atmosphere could be avoided  . It took a long time to build the space telescope but finally in 1990, a huge space telescope called the Hubble Space Telescope was successfully sent into space. Since then, astronomers have many important observations that have helped people understand space better.\n",
      ",.  (10)\n",
      "\n",
      "Question: Scintillation also happens on  _  according to the passage.\n",
      "A. rainy days\n",
      "B. shiny days\n",
      "C. cloudy days\n",
      "D. windy days\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " nauatererigeigeligeigeligeligeligeligeideIDEadeadehaftsworthsworthelandelandelandannessannessannessannessannessannessannessontaacting quang quanganningardononglingtonitationalasarasar Bradleyleekea Wah Wah Wah Wahannessanness Jonas Jonas Jonas Jonasannessannesshaftsworthletteonteiletigliaiglia743øjøjøj Assertionsherinersovatovat生的生生生的 doncąd букkinachtenhaftigigigiigiigiMonsterjack Sach Sach MusicalibusasmusigonovatovatovatanasanasanasINESøjøj便idesideideideIDEoogwearwearhaftsworthizzylettes-match-match-matchuropeapoidataapoOiøj doncpassesogneogneehr-rights-rightshaftéeée BoobooptionościościPIernespirpirAufAufAufhaft_BUSeloadeloadlal EssentialершcovovatAVAAVAAVAAVAAVAattejayjayinhanh AnhsworthnikINavigationstanovovov Inhal Inhal Inhalhafthafthaft pomociitationaldraFORCEFORCE�� Inter_PASSavaAVAAVAAVAAVAAVAAVA masse FORCE FORCEercercercercercerctail Casc CascReducizador� FuckingHAMsteadsteadsteadbspbspMirror mirrorMASTER-masterMASTERVRVRVRVRainmentitationalickáideाइडinkerängηγNSSNSSantry SachSink sinkǐizzie \"\")chlusséhoioc colspanolonolonardonolonolonolonolonolonolonolonontaontainemaCOMMONsworthqvzwzwzwtran PARKparkparkparkhaft-built-built}`).pirpir InspirpirDaniDaniDaniizzleehrhaft-built thầuuraadeerateerateerateewardslideávkyávkyhaft donc Weinstein institute instituteesseancesanzwearwear生的(/^래epererinersmalıdırovatauseauseerateerateeward shootout shootoutichávkyávkyایEYEYehrørOuterubberIdeávkyاعةppelinspirpirspirpirerине����Miscellaneous-minded mindednessśćichiichiich beidenchaftforce FORCEBornشاء BlendovatAVAAVAAVAAVAAVAAVAAVAAVAparalleéeséeséesقاء柳boroideADEADEинку AbebeeennieennieennieennieolonolonomoranthAttachment AttachmentAttachmenturiousuriousnessideávkyauseause Manor Manor Manor Manorannessoolaoolaoolaoola Manor Manor Manor Manor Manor Manor Manor ManorontaontaupaPAlavalava yanaбудsworth-built donchaltshaftshafthaftagmaGRAMGRAM Ranch Ranchesseesseesseungeungeungehaftenatewearwearwear Wearwearhaftfigcaptionjayjayuraiyawshaw Chancellor/execEYjay JACKarellaarellaomoristratistratistratistrat Manor Manor Manor Manor Manor Manor Manorannesséeseh Wah wah Wah WahtractionastiastiardyardyardyardyTAILsworthsworthвейauseauseapePIidataiatiat Maidnapvip Wah Wahsteadsworthizzy-Semitismnj FORCE\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: Many middle school students like watching TV very much. But from Monday to Friday, they must go to school. So on Saturday and Sunday they stay at home and watch TV from morning to night. They don't know it's bad for their eyes. Usually children like to eat fish, meat and chicken and don't like vegetables or fruit. They don't know eating more vegetables or fruit. They don't know eating more vegetables and fruit is better than eating meat.\n",
      "At school, the children only do a few minutes of sports or never do any sports. The teachers must know it isn't good for their health.\n",
      "We always think of ways to keep healthy. We must eat more vegetables and fruit, do enough sport every day. And we should watch TV and read in right ways.\n",
      "\n",
      "Question: Which of the following is wrong?\n",
      "A. From Monday to Friday, some students watch TV from morning to night.\n",
      "B. Eating more vegetables and fruit is good for their health.\n",
      "C. They should do enough sport.\n",
      "D. They should read in right ways.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "ackle domesticallyurbanurbanurbanannessannessannessannessannessannessannessannessannessontaánaanaатуetroetroorningalaralar석 Moves-move onstage onstage improvised improvisedizrigarigarigarigarStartElement lửa lửa(火portsveltantasyantasypeed-speed-speedlettesøjøjøjantageantageovefewfewewnERN fremDIGandingHAMsteadsteadsteadstead生的 Plum Plum PyTuplepit*/)ondheimjàjà生的生的生poke pokeichaiphyiphyinspacebps độ Cao/coogneogneissererWERitzerBURerdeadeade-teESCOatchespassesnaveateonedondaFORCE force-force-hearted-heart-heart-heartheartheartheartheartstonistratistratistrat Mevillezangershipsums foursbv Eisen Eisenemezategategategategangu Gingrich GingrichHAMstitutions Instit­i nationwidekeitsworthsworthvrVRigarigarCircularuireintrINTRehrehrehrVRggererWERlingenannessannessiazzaantrykiikkiichiichiunreadable寸 Retro一点 lửa lửaALARíticaionaljitjit justepest_interpinterphaftsworthzzw_HWχής Elev ElevRECT reconcile reconc reconc reconcDICDICClassic/defaultAZYAZYundyundyundyhaftWebpacksworth Manor Manor Manor Manoranness herselfekingduckduckduckduckduck Manor Manor Manor Manor Manor Manorannessineikkiikkiinenään色一piopio석éeséeقاءSenseSensehirHIRHIRHIRInsidewardswardswardswardswardswardshaftbauausssworth Orch Orchighηγηγantageungsworth AttachmentAttachmentysizeabweabwe Kevin şartsworthsworthsworthsworth StringBufferborgsworthsworth doncадsarasarINESeloadeload Kushner Kushner Kushner KushnerannesséeچهpasseswarAVAAVAAVA ance-/ BartonsworthaweaweaweawehaftBuilt-built Coat Coat Coat=head Apprentice apprentice席side-sideávkyávkaadeADEsteadBuilt-built生的gettietrooque喊/show즈essesasjeasjeagalас Dynamo Dynamo DynamoVPapoapoapoapoapoapoapoapoapoapoapo-caretorateerdeerdeedeadeeat пуLOADIQируIROинкуundyundyhaft Attachment AttachmentAttachmentAttachmentPLEantryantrycularcularerateerateerateineikkiщо Builds-buildernachten Nacht tonightTonightibsøj ADVtivηγηγlakcoinjohnstonstonstoncludedprdppverveperseadeADERaiseRaise Kushner Kushnerucchàng柳SyUYlngundy義animerverervererateerateineelveantry促ESCO Seah SeahhirhirDIGandingcaretakeozillaoolaoolaoolaoolaolonolonistentةadena whistle whistle whistleinspace-built-builtExtentуваава babesbabêteêteINEhaft-built-builtgvgvehrantageouslylittleantrygencygencygency Pattonottom достатiocioc nøicode料iocioc côté-side-sidehaft-built-built-built painspio래生生 Relationsći nghĩamvc.AsyncserviceNameserviceNameVRackleackle Pep\n",
      "Extracted prediction: None, Extracted target: A\n",
      "[Prompt]:\n",
      "Article: It was the golden season. I could see the yellow leaves dancing in the cool wind. I felt lonely and life is uninteresting. But one day, the sound of a violin came into my ears. I was so surprised that I ran out to see where it was from. A young girl, standing in the wind, was lost in playing her violin.\n",
      "I had never seen her before. The music was so wonderful that I forgot who I was.\n",
      "Leaves were still falling. Every day she played the violin in the same place and I was the only listener. It seemed that I no longer felt lonely and life became interesting. We didn't know each other, but I thought we were already good friends.\n",
      "One day, when I was listening, the sound suddenly stopped. The girl came over to me.\n",
      "\"You must like violin.\" she said.\n",
      "\"Yes. And you play very well. Why did you stop?\" I asked.\n",
      "Suddenly, a sad expression appeared on her face and I could feel something unusual.\n",
      "\"I came here to see my grandmother, but now I must leave. I once played very badly. It is your listening every day that has _ me.\" she said.\n",
      "\"In fact, it is your music that has given me those meaningful days.\" I answered. \"Let us be friends.\"\n",
      "The girl smiled and I smiled.\n",
      "I never heard her play again in my life. Only thick leaves were left behind. But I will always remember the girl. She is like a dream; so short, so bright that it makes life beautiful.\n",
      "There are many kinds of friends. Some are always with you, but don't understand you. Some say only a few words to you, but are close to you. I shall always think of those golden days and the girl with the violin. She will always bring back the friendship between us. I know she will always be my best friend.\n",
      "\n",
      "Question: The writer's life was   _   because of the girl.\n",
      "A. boring\n",
      "B. colourful\n",
      "C. unhappy\n",
      "D. sad\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " B\n",
      "[Model Response]:\n",
      " sle sleackleadeadeadeadeadeadeadeadeadeadeadeADEhaftsworthsworthbspbspbspbspbspbsp MingmommomannessannessannessannessannessannessannessontaideoideooyaHUHAMHAMérationそしてHorizontalAlignmentigansoolaoolaoolaoola Manor Manor Manorannessannessannessigliailogueipoipoipooho numéroolonolonardoardoadeadeonte Cove Coveizenitherشت donc hybridsectaingoingoyneerneserneshaftsworthsworthpravprav whip whip Whip Whip Whip-heartednessINESmín Mint Mintundyannessannessizzizzizz-exctempttemptupyabweADEsteadsworthsvillesvilleadebuilt-builtặt MovesмагалияancaardeadeAVAAVAAVAAVAannessannesséeengeenge delegationenateideideADELeast LeastetusliusliusetusDavisaussaussercercercercercercer plaisir plaisir生的bpschezSKI Erik Erikasmusasmus着awa Wah Wah WahannessanskEarth đai zijijitationaleratejitjit生的ødophonophon着-storyerdeadeOLEppoantoantoanto Angelo Angeloantoolonolononynglenglehaft具 Jappestpestperingperedperedperedperedperedpered articulated articulatedateg gorge gorgehaftsworthlettePLEcosaCOoled anlamdaborgsworth便σ��ToStrIWpirpirinodeodge Dodgesworthéeávkaavaava Hav Hav INTERNATIONALitetallyardyardyardyardy制着 nozzleイク Ikepekπού務igarigar Pep PepanchorskillskillshaftBuilt-builtittedichteichteete Cove Cove_attachdetachdetachろIDEOeloadeload Kushnersworthovatovat-vs latina Latina cofrifrifMirrorANGLEnglenglehaft-built-builtbak_ak aperture apertureerejayjay-speed-speedardyGST级iocinateovatovatovat着begendasionalepio máximo máximoCut knife Knifehaft-built-built Weinsteinowitzowitzichichichhirigar便ckettend Endsерш着 japaneseسام SenseMZigarigarigarigarCircularmareerde Pett Pett834 podporavaavaavaibusEngundrywearwearVRVRVR tandempikehawksworth justepestсте Bever Bever Bever Bever-heartednesslicheerdeookeávkaWBidataodeookeGenreloseumptumpt_vpoeffoeffoeff проп丸 saoachoaddonolonolon射着fühfühessagingasjeclosestolonolonohoAttachment Attachment Attachment Attachment effortlessnessINESSannessannessannessannessannessannessannessannessannessannessannessontabuilt-builtестиintegrationandon espera esperavez743oletBuilt-builtGVвиantageolonχήIRO तरह ๆцепernityavityavityhaftidataδοupoupoipo-goalgebergeberhaft-builteldeneldenehrehrehrålerbshipbusterubbererateerate生的.shows.showsVisual_aspect_aspect席sideáteithersehensehenehrerceinationolandolandolandannessannesshausbuilt-built Bau Builds-builtектуangoangoyne\n",
      "Extracted prediction: None, Extracted target: B\n",
      "[Prompt]:\n",
      "Article: You must have seen ads on TV about hair care products  . The models have shining hair like jewels  . But now to make hair shine is no longer the task of hair care products, because hair can be made into real jewels. Believe it or not, a company called LifeGem in the US turns hair into jewels.\n",
      "The company is in the business of taking hair from dead people and making it into diamonds  . The diamonds are for the families to remember the dead people.\n",
      "Now the company plans to make three diamonds using Beethoven's hair to show their latest technology  . The work will take about 7 months and in the end, Beethoven's long hair will become 3 shining diamonds between 0.5 to 1 carat  in size.\n",
      "Since the great musician died in 1827, you may wonder how they got Beethoven's hair. Actually, the hair was given by John Rezniloff, who holds the Guinness World Record for the largest and most valuable collection of celebrities'   hair. His collection also includes hair of Napoleon, Albert Einstein,  Abraham Lincoln and John F. Kennedy. In total,  the collection is worth over 5 million dollars.\n",
      "Though it sounds unbelievable  , to have such diamonds made with hair may be a good way to show respect   and love to those who died.\n",
      "\n",
      "Question: How long will the work take?\n",
      "A. Half a month.\n",
      "B. One month.\n",
      "C. Three months.\n",
      "D. Seven months.\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " D\n",
      "[Model Response]:\n",
      " palindrome palindromepak-fly-fly-fly-flyandleSIDESIDEaposamaxamax-cityEYτευ блокADEADE Royale Royale ràngбоantryehrøjøjrelationshiprelationshipateg lookahead望iocpeiLEELEELEEannessannessannessannessannessannessannessannessontaconstraintunguongongongaideADEGREčeбо着ichiichiundynglenglehaftsworthsworthhaftIDEODE이어hana/HทางpasseselveselvesSELFSELFangersangershaftsworthsworthrieternityąd đàiiociocomorπ NaplespioADEávkaávka Annieannieisaiphyiphyadderθηκεθηκεsyntax syntax伏兵兵DERerseAPPLEéesée� Ing.registryvoieophageophageomorjobs MineralsitasitasibsWilliamslose enrolarking Parker shooters shooters masturbation masturbation masturbation masturbation Ritual Ritualistaniintersectintersecthaft-built-builtGVGVœurœurERCercercercercицsicC clashedizadorizador']]寸 xứepererALERbetenate Incontriasions诺цепPA Manning Manningannessannessannessannessannessannessannessannessannessonta ReceptionetingKdyž elkaar elkaarежду 관계ultanandanandanannessannesshaftizzyøreñoEYижynetynetynetynet尾尾coilشاء deformationenateerateerateêteerde CoveEDGEEDGEitoris171jerneitizeeaseeasehaft-pePYää Wah Wah Mormbroantry gangbang gangbang masturbation masturbationanasanasanasanasanainsi-passičiociocyneyneyneyneyneanness初 Tento_edgeičiyEYorningpirpirichichichinhinhadeadeookeoduleADEperedodgeGLEffeippleipple Manor Manor Manor Manorannesséeäänääää beidenchaftstandsworthulseapeapeapeyneolonolon著sworthousy料坂Portableidataidataum然 wen Wenibib.registryecome YueGREанныloseoland着merc Merc mercespipdeauxCycleCycleewn trụorer trúPirittepitipyiphyborAttachment AttachmentAttachmenturiousnessดาDICDICovskyovskyovskyamus着-tank-tankardyurdy_devêteêteéebecuebecue BBQRTCRTCapoategump Bundy Bundy Bundy Bundy Bundy Bundy Bundyarga着 Ming MinghirhirGamistratistratistrat.sys州市boroolonolonolon bore bore bore bore boreannessannessipsávkyavaavaèreerateerateerate Cove Cove Cove Cove惑 Bugsากรorer Gloryantryंपरkykyikkiikki각각sworth快-speed-speed-speedpeedytheatreerde-optoq料TacTac�乐ктаideávkyávkyibsippleipple phổepererGenreبية пози позиistani концаaviruspikepearePY())/乗-navbar/frontorateolate latina latinaALERathiichiichi sweetheartègeбоаваAVAAVAAVAAVAAVAAVAAVA paralleестиестиести_svavyvyacyadeADELeastLeast babesdollificationicodeicodeicodeicoloricoloricoloricoloricoloricoloricoloricolorPLE/per鳥鳥着\n",
      "Extracted prediction: None, Extracted target: D\n",
      "[Prompt]:\n",
      "Article: Food is a major part of every culture. After all, everyone needs to eat! But each country has its own traditions on what people eat and when.\n",
      "Egypt\n",
      "Egyptians commonly start the day with a drink, sometimes going with bread. Breakfast can be eaten any time after this but before the day's main meal. In the past, this main meal was served at around 3:00 p.m. But now people work longer hours and eat when they get home at around 6:00 p.m. Dinner parties are held later, around 9:00 p.m.\n",
      "Most Egyptian meals include bread or ice, cooked vegetables and beans or meat.\n",
      "France\n",
      "France is known for its fine cooking, and its people take food seriously. Most eat three meals a day at fixed times and never snack between meals. Breakfast is a light meal of bread and coffee. They eat lunch at around 1:00 p.m. and a dinner with multiple courses after 8:00 p.m.\n",
      "The French consider eating a social activity. Eating alone is hard to see, and eating while doing something else is unheard-of. The French take time to enjoy their meals and visitors should do the same.\n",
      "Brazil\n",
      "Like the French, Brazilians usually eat a light breakfast. Lunch, the largest meal of the day, usually consists of meat, rice, potatoes, beans and vegetables. Between 6:00 p.m. and 8:00 p.m., people enjoy a smaller meal with their families.\n",
      "Brazilians don't mind eating a hurried or light meal and sometimes buy food from street carts  . But they always finish eating before walking away.\n",
      "The United States\n",
      "American's ancestors came from many countries, so American eating habits differ. Some take time to prepare and eat a hot breakfast. Others take a bagel   while rushing out the door or just _ . For lunch, most Americans eat a sandwich or leftovers. Traditionally, families got together for a large evening meal around 6:00, but now busy schedules force many families to eat in turns. American restaurant servings tend to be huge. But you don't have to finish them; taking leftovers home is common.\n",
      "\n",
      "Question: People of Egypt usually start a day with   _  .\n",
      "A. a drink\n",
      "B. a bagel\n",
      "C. some meat\n",
      "D. some vegetables\n",
      "Answer:\n",
      "[Reference Response]:\n",
      " A\n",
      "[Model Response]:\n",
      "第四灣 coalition coalitionidaridaradeadeadeadeadeadeadeadeастиitationalisedised-built-build-builduraaooke Cooke Cooke라이 TracksradeovatovatovatanasanasanasINESzdyapesh Hewsworthsworthibsitationalateralizedbvøjuvreuvrehaftsworthovatovatert شاخهbranchesibsøjøjHighlightedachuigma princPREorateovatovat HigginsBOTTOMBOTTOMinha ColonyantoantoantopteptepteمینiniSELFSELFSELFlif Lif生的生生生生生的 doncGambgantryantryantryannessannessannessannessannessannessannessonta`}ηρεwearwearhaftbuilt-built生的 GamMariMari Mormmam Masonsondff料IdeADEADEhaftdspADVIMPigiigiantryshipmanship teżupeupeupe Magnus_dragitationalonicalonicalonicalθεодаiyaiphyauseausehaft Attachment Attachment Attachment Attachment Attachment Attachment Attachmenthurstumptumpt TremiancescopeigansMembership/memberèleerateeratepeedávkyadebuilt-built-builtundooyoitational positioned positionedesseerreerreIdentifieründINATIONerdeerdehaft-builtveltveltERMERMainment_FM stehtiertiertiertEIateverCropCropFM Boyleettleystoneystonesteiningoanto_selfSELF teďDIG Danielssonssonbuου lửa lửa(火businateistratovatauseauseauseMirrormirroropr-прав Territoriesuiltsworthulseapeape Morm Jonas Jonas Jonas Jonas JonasannessannessisenessewearwearewnatanwearwearhaftizzyozillaozillaozillainodeodeADEperse�HIR Hir HirhirhirhirhirIntermediateIntermediateribleerateeratejitjitизнес worthlessulencePLEAttachment Attachment Attachment狼YGONspirspirspirhaftBuilt-builtinenاذاMirror �цепiociocoxoxox碎imetistratistratistratistratpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravpravontaontaитаiya balloATESovatauseause府촌촌 boreaggioantrywearwearyneyneyneyneardyardyardyardyardy Mafiaeneg/member.memberナーाइनigungigung�usahastorybookstorybook Sanford Sanford afrovskyovskyardyinodeenatenglenglengle parenting ребенок ребенокercercercercercercercerc Minimumigmaassiinsinglenglengleercercerc fellowships/releaseeceennieennieennieennieannessannessannessbastianovathevbv displacementangoangoomor Spatialicapipipookeookeooke Wa wah wahhai Feather Feather生的ops料料料成成相着nahmeateppyppy级 dışıσειςPLEGREehrfüh Hoverubberubber Randall cazzoangoornoجمجمجم각각COávkailiary-built-builtoyerwearwearwearwearwearsteadBuilt-built HarleyovíavaAVAapoppoppoipoipoсо Cobraanimeigiigiigi614atoriaAGONAGONantrycastleANGLEhaft-built\n",
      "Extracted prediction: None, Extracted target: A\n",
      "{'predicted_text': {'exact_match': 0.009999999776482582, 'accuracy': 0.01}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 6.360695261955261}, 'time_per_token': {'mean': 0.012423232933506369}, 'tokens_per_second': {'mean': 81.75491291046143}}\n"
     ]
    }
   ],
   "source": [
    "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset race_h \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy autoregressive\\\n",
    "    --exit_layer 8 \\\n",
    "    --output_dir ./logs \\\n",
    "    --top_p 0.9 \\\n",
    "    --distributed False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: race_m\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on RACE_M with 100 samples...\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=A\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=D, target=D\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=B, target=B\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=A, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (RACE_M) ---\n",
      "exact_match: 0.5800\n",
      "accuracy: 0.5800\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.5799999833106995, 'accuracy': 0.58}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.06306038618087768}, 'time_per_token': {'mean': 0.06306038618087768}, 'tokens_per_second': {'mean': 17.672519391775133}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking RACE_M:   1%|          | 1/100 [00:00<00:59,  1.65it/s]\n",
      "Benchmarking RACE_M:   3%|▎         | 3/100 [00:00<00:20,  4.73it/s]\n",
      "Benchmarking RACE_M:   5%|▌         | 5/100 [00:00<00:12,  7.39it/s]\n",
      "Benchmarking RACE_M:   7%|▋         | 7/100 [00:01<00:09,  9.47it/s]\n",
      "Benchmarking RACE_M:   9%|▉         | 9/100 [00:01<00:08, 11.14it/s]\n",
      "Benchmarking RACE_M:  11%|█         | 11/100 [00:01<00:07, 12.47it/s]\n",
      "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:01<00:06, 13.79it/s]\n",
      "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:01<00:05, 14.40it/s]\n",
      "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:01<00:05, 15.00it/s]\n",
      "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:01<00:05, 15.91it/s]\n",
      "Benchmarking RACE_M:  21%|██        | 21/100 [00:01<00:05, 15.36it/s]\n",
      "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:01<00:04, 15.99it/s]\n",
      "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:02<00:04, 16.79it/s]\n",
      "Benchmarking RACE_M:  28%|██▊       | 28/100 [00:02<00:04, 17.66it/s]\n",
      "Benchmarking RACE_M:  31%|███       | 31/100 [00:02<00:03, 18.61it/s]\n",
      "Benchmarking RACE_M:  33%|███▎      | 33/100 [00:02<00:03, 17.47it/s]\n",
      "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:02<00:03, 17.07it/s]\n",
      "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:02<00:03, 17.58it/s]\n",
      "Benchmarking RACE_M:  39%|███▉      | 39/100 [00:02<00:03, 17.94it/s]\n",
      "Benchmarking RACE_M:  41%|████      | 41/100 [00:02<00:03, 17.23it/s]\n",
      "Benchmarking RACE_M:  43%|████▎     | 43/100 [00:03<00:03, 16.69it/s]\n",
      "Benchmarking RACE_M:  45%|████▌     | 45/100 [00:03<00:03, 17.18it/s]\n",
      "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:03<00:03, 17.32it/s]\n",
      "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:03<00:02, 17.21it/s]\n",
      "Benchmarking RACE_M:  51%|█████     | 51/100 [00:03<00:02, 16.93it/s]\n",
      "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:03<00:02, 16.52it/s]\n",
      "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:03<00:02, 16.43it/s]\n",
      "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:03<00:02, 16.40it/s]\n",
      "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:04<00:02, 16.29it/s]\n",
      "Benchmarking RACE_M:  61%|██████    | 61/100 [00:04<00:02, 16.15it/s]\n",
      "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:04<00:02, 16.54it/s]\n",
      "Benchmarking RACE_M:  65%|██████▌   | 65/100 [00:04<00:02, 16.26it/s]\n",
      "Benchmarking RACE_M:  68%|██████▊   | 68/100 [00:04<00:01, 17.09it/s]\n",
      "Benchmarking RACE_M:  70%|███████   | 70/100 [00:04<00:01, 16.39it/s]\n",
      "Benchmarking RACE_M:  72%|███████▏  | 72/100 [00:04<00:01, 17.06it/s]\n",
      "Benchmarking RACE_M:  74%|███████▍  | 74/100 [00:04<00:01, 17.05it/s]\n",
      "Benchmarking RACE_M:  77%|███████▋  | 77/100 [00:05<00:01, 18.37it/s]\n",
      "Benchmarking RACE_M:  80%|████████  | 80/100 [00:05<00:01, 18.60it/s]\n",
      "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:05<00:01, 17.11it/s]\n",
      "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:05<00:00, 16.86it/s]\n",
      "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:05<00:00, 16.39it/s]\n",
      "Benchmarking RACE_M:  89%|████████▉ | 89/100 [00:05<00:00, 18.22it/s]\n",
      "Benchmarking RACE_M:  92%|█████████▏| 92/100 [00:05<00:00, 19.02it/s]\n",
      "Benchmarking RACE_M:  94%|█████████▍| 94/100 [00:06<00:00, 18.24it/s]\n",
      "Benchmarking RACE_M:  96%|█████████▌| 96/100 [00:06<00:00, 18.09it/s]\n",
      "Benchmarking RACE_M:  99%|█████████▉| 99/100 [00:06<00:00, 19.16it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:06<00:00, 15.68it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset race_m \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy autoregressive \\\n",
    "    --output_dir ./logs \\\n",
    "    --top_p 0.9 \\\n",
    "    --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: race_m\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on RACE_M with 100 samples...\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=C, target=C\n",
      "✓ CORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (RACE_M) ---\n",
      "exact_match: 0.0200\n",
      "accuracy: 0.0200\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.019999999552965164, 'accuracy': 0.02}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.4588083791732788}, 'time_per_token': {'mean': 0.022940418981015682}, 'tokens_per_second': {'mean': 43.99350820541382}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking RACE_M:   1%|          | 1/100 [00:01<01:48,  1.10s/it]\n",
      "Benchmarking RACE_M:   2%|▏         | 2/100 [00:01<01:12,  1.35it/s]\n",
      "Benchmarking RACE_M:   3%|▎         | 3/100 [00:02<00:59,  1.63it/s]\n",
      "Benchmarking RACE_M:   4%|▍         | 4/100 [00:02<00:54,  1.77it/s]\n",
      "Benchmarking RACE_M:   5%|▌         | 5/100 [00:02<00:49,  1.91it/s]\n",
      "Benchmarking RACE_M:   6%|▌         | 6/100 [00:03<00:47,  1.98it/s]\n",
      "Benchmarking RACE_M:   7%|▋         | 7/100 [00:03<00:45,  2.04it/s]\n",
      "Benchmarking RACE_M:   8%|▊         | 8/100 [00:04<00:44,  2.09it/s]\n",
      "Benchmarking RACE_M:   9%|▉         | 9/100 [00:04<00:42,  2.13it/s]\n",
      "Benchmarking RACE_M:  10%|█         | 10/100 [00:05<00:41,  2.16it/s]\n",
      "Benchmarking RACE_M:  11%|█         | 11/100 [00:05<00:40,  2.18it/s]\n",
      "Benchmarking RACE_M:  12%|█▏        | 12/100 [00:06<00:40,  2.20it/s]\n",
      "Benchmarking RACE_M:  13%|█▎        | 13/100 [00:06<00:39,  2.18it/s]\n",
      "Benchmarking RACE_M:  14%|█▍        | 14/100 [00:07<00:39,  2.20it/s]\n",
      "Benchmarking RACE_M:  15%|█▌        | 15/100 [00:07<00:38,  2.18it/s]\n",
      "Benchmarking RACE_M:  16%|█▌        | 16/100 [00:08<00:38,  2.17it/s]\n",
      "Benchmarking RACE_M:  17%|█▋        | 17/100 [00:08<00:38,  2.17it/s]\n",
      "Benchmarking RACE_M:  18%|█▊        | 18/100 [00:08<00:38,  2.15it/s]\n",
      "Benchmarking RACE_M:  19%|█▉        | 19/100 [00:09<00:38,  2.13it/s]\n",
      "Benchmarking RACE_M:  20%|██        | 20/100 [00:09<00:37,  2.15it/s]\n",
      "Benchmarking RACE_M:  21%|██        | 21/100 [00:10<00:36,  2.17it/s]\n",
      "Benchmarking RACE_M:  22%|██▏       | 22/100 [00:10<00:36,  2.16it/s]\n",
      "Benchmarking RACE_M:  23%|██▎       | 23/100 [00:11<00:36,  2.12it/s]\n",
      "Benchmarking RACE_M:  24%|██▍       | 24/100 [00:11<00:35,  2.11it/s]\n",
      "Benchmarking RACE_M:  25%|██▌       | 25/100 [00:12<00:35,  2.10it/s]\n",
      "Benchmarking RACE_M:  26%|██▌       | 26/100 [00:12<00:34,  2.14it/s]\n",
      "Benchmarking RACE_M:  27%|██▋       | 27/100 [00:13<00:34,  2.12it/s]\n",
      "Benchmarking RACE_M:  28%|██▊       | 28/100 [00:13<00:33,  2.18it/s]\n",
      "Benchmarking RACE_M:  29%|██▉       | 29/100 [00:14<00:32,  2.19it/s]\n",
      "Benchmarking RACE_M:  30%|███       | 30/100 [00:14<00:31,  2.22it/s]\n",
      "Benchmarking RACE_M:  31%|███       | 31/100 [00:14<00:30,  2.23it/s]\n",
      "Benchmarking RACE_M:  32%|███▏      | 32/100 [00:15<00:30,  2.26it/s]\n",
      "Benchmarking RACE_M:  33%|███▎      | 33/100 [00:15<00:29,  2.25it/s]\n",
      "Benchmarking RACE_M:  34%|███▍      | 34/100 [00:16<00:29,  2.21it/s]\n",
      "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:16<00:29,  2.23it/s]\n",
      "Benchmarking RACE_M:  36%|███▌      | 36/100 [00:17<00:28,  2.22it/s]\n",
      "Benchmarking RACE_M:  37%|███▋      | 37/100 [00:17<00:28,  2.24it/s]\n",
      "Benchmarking RACE_M:  38%|███▊      | 38/100 [00:18<00:27,  2.24it/s]\n",
      "Benchmarking RACE_M:  39%|███▉      | 39/100 [00:18<00:27,  2.24it/s]\n",
      "Benchmarking RACE_M:  40%|████      | 40/100 [00:18<00:27,  2.22it/s]\n",
      "Benchmarking RACE_M:  41%|████      | 41/100 [00:19<00:26,  2.20it/s]\n",
      "Benchmarking RACE_M:  42%|████▏     | 42/100 [00:19<00:26,  2.19it/s]\n",
      "Benchmarking RACE_M:  43%|████▎     | 43/100 [00:20<00:26,  2.19it/s]\n",
      "Benchmarking RACE_M:  44%|████▍     | 44/100 [00:20<00:25,  2.24it/s]\n",
      "Benchmarking RACE_M:  45%|████▌     | 45/100 [00:21<00:24,  2.23it/s]\n",
      "Benchmarking RACE_M:  46%|████▌     | 46/100 [00:21<00:24,  2.23it/s]\n",
      "Benchmarking RACE_M:  47%|████▋     | 47/100 [00:22<00:24,  2.20it/s]\n",
      "Benchmarking RACE_M:  48%|████▊     | 48/100 [00:22<00:23,  2.21it/s]\n",
      "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:23<00:23,  2.21it/s]\n",
      "Benchmarking RACE_M:  50%|█████     | 50/100 [00:23<00:22,  2.20it/s]\n",
      "Benchmarking RACE_M:  51%|█████     | 51/100 [00:23<00:22,  2.18it/s]\n",
      "Benchmarking RACE_M:  52%|█████▏    | 52/100 [00:24<00:21,  2.21it/s]\n",
      "Benchmarking RACE_M:  53%|█████▎    | 53/100 [00:24<00:21,  2.22it/s]\n",
      "Benchmarking RACE_M:  54%|█████▍    | 54/100 [00:25<00:20,  2.24it/s]\n",
      "Benchmarking RACE_M:  55%|█████▌    | 55/100 [00:25<00:20,  2.22it/s]\n",
      "Benchmarking RACE_M:  56%|█████▌    | 56/100 [00:26<00:19,  2.22it/s]\n",
      "Benchmarking RACE_M:  57%|█████▋    | 57/100 [00:26<00:19,  2.25it/s]\n",
      "Benchmarking RACE_M:  58%|█████▊    | 58/100 [00:27<00:18,  2.26it/s]\n",
      "Benchmarking RACE_M:  59%|█████▉    | 59/100 [00:27<00:18,  2.27it/s]\n",
      "Benchmarking RACE_M:  60%|██████    | 60/100 [00:27<00:17,  2.27it/s]\n",
      "Benchmarking RACE_M:  61%|██████    | 61/100 [00:28<00:17,  2.28it/s]\n",
      "Benchmarking RACE_M:  62%|██████▏   | 62/100 [00:28<00:16,  2.28it/s]\n",
      "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:29<00:16,  2.28it/s]\n",
      "Benchmarking RACE_M:  64%|██████▍   | 64/100 [00:29<00:15,  2.29it/s]\n",
      "Benchmarking RACE_M:  65%|██████▌   | 65/100 [00:30<00:15,  2.26it/s]\n",
      "Benchmarking RACE_M:  66%|██████▌   | 66/100 [00:30<00:14,  2.28it/s]\n",
      "Benchmarking RACE_M:  67%|██████▋   | 67/100 [00:31<00:14,  2.26it/s]\n",
      "Benchmarking RACE_M:  68%|██████▊   | 68/100 [00:31<00:14,  2.28it/s]\n",
      "Benchmarking RACE_M:  69%|██████▉   | 69/100 [00:31<00:13,  2.25it/s]\n",
      "Benchmarking RACE_M:  70%|███████   | 70/100 [00:32<00:13,  2.24it/s]\n",
      "Benchmarking RACE_M:  71%|███████   | 71/100 [00:32<00:12,  2.24it/s]\n",
      "Benchmarking RACE_M:  72%|███████▏  | 72/100 [00:33<00:12,  2.26it/s]\n",
      "Benchmarking RACE_M:  73%|███████▎  | 73/100 [00:33<00:12,  2.24it/s]\n",
      "Benchmarking RACE_M:  74%|███████▍  | 74/100 [00:34<00:11,  2.22it/s]\n",
      "Benchmarking RACE_M:  75%|███████▌  | 75/100 [00:34<00:11,  2.19it/s]\n",
      "Benchmarking RACE_M:  76%|███████▌  | 76/100 [00:35<00:11,  2.18it/s]\n",
      "Benchmarking RACE_M:  77%|███████▋  | 77/100 [00:35<00:10,  2.16it/s]\n",
      "Benchmarking RACE_M:  78%|███████▊  | 78/100 [00:36<00:10,  2.20it/s]\n",
      "Benchmarking RACE_M:  79%|███████▉  | 79/100 [00:36<00:09,  2.21it/s]\n",
      "Benchmarking RACE_M:  80%|████████  | 80/100 [00:36<00:09,  2.22it/s]\n",
      "Benchmarking RACE_M:  81%|████████  | 81/100 [00:37<00:08,  2.21it/s]\n",
      "Benchmarking RACE_M:  82%|████████▏ | 82/100 [00:37<00:08,  2.22it/s]\n",
      "Benchmarking RACE_M:  83%|████████▎ | 83/100 [00:38<00:07,  2.22it/s]\n",
      "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:38<00:07,  2.22it/s]\n",
      "Benchmarking RACE_M:  85%|████████▌ | 85/100 [00:39<00:06,  2.22it/s]\n",
      "Benchmarking RACE_M:  86%|████████▌ | 86/100 [00:39<00:06,  2.24it/s]\n",
      "Benchmarking RACE_M:  87%|████████▋ | 87/100 [00:40<00:05,  2.23it/s]\n",
      "Benchmarking RACE_M:  88%|████████▊ | 88/100 [00:40<00:05,  2.23it/s]\n",
      "Benchmarking RACE_M:  89%|████████▉ | 89/100 [00:40<00:05,  2.20it/s]\n",
      "Benchmarking RACE_M:  90%|█████████ | 90/100 [00:41<00:04,  2.23it/s]\n",
      "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:41<00:04,  2.22it/s]\n",
      "Benchmarking RACE_M:  92%|█████████▏| 92/100 [00:42<00:03,  2.16it/s]\n",
      "Benchmarking RACE_M:  93%|█████████▎| 93/100 [00:42<00:03,  2.16it/s]\n",
      "Benchmarking RACE_M:  94%|█████████▍| 94/100 [00:43<00:02,  2.17it/s]\n",
      "Benchmarking RACE_M:  95%|█████████▌| 95/100 [00:43<00:02,  2.14it/s]\n",
      "Benchmarking RACE_M:  96%|█████████▌| 96/100 [00:44<00:01,  2.14it/s]\n",
      "Benchmarking RACE_M:  97%|█████████▋| 97/100 [00:44<00:01,  2.18it/s]\n",
      "Benchmarking RACE_M:  98%|█████████▊| 98/100 [00:45<00:00,  2.18it/s]\n",
      "Benchmarking RACE_M:  99%|█████████▉| 99/100 [00:45<00:00,  2.15it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:46<00:00,  2.17it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:46<00:00,  2.17it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset race_m \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy autoregressive\\\n",
    "    --exit_layer 8 \\\n",
    "    --output_dir ./logs \\\n",
    "    --top_p 0.9 \\\n",
    "    --distributed False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing generation config for multiple-choice dataset: race_m\n",
      "Updated generation config: max_steps=20, temperature=0.3\n",
      "Benchmarking on RACE_M with 100 samples...\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=A\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=D\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=B\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "Error during generation: Expected key.size(1) == value.size(1) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\n",
      "Extracted: prediction=None, target=C\n",
      "✗ INCORRECT\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Metrics (RACE_M) ---\n",
      "exact_match: 0.0000\n",
      "accuracy: 0.0000\n",
      "Total Questions: 100\n",
      "{'predicted_text': {'exact_match': 0.0, 'accuracy': 0.0}, 'acceptance_rate': {'mean': 0.0}, 'total_time': {'mean': 0.0}, 'time_per_token': {'mean': 0.0}, 'tokens_per_second': {'mean': 0.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking RACE_M:   0%|          | 0/100 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "c:\\Users\\adity\\CSE8803DLT-24Fall-Assignment2-Public\\cuda_env\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Benchmarking RACE_M:   1%|          | 1/100 [00:00<01:03,  1.57it/s]\n",
      "Benchmarking RACE_M:   8%|▊         | 8/100 [00:00<00:06, 13.78it/s]\n",
      "Benchmarking RACE_M:  14%|█▍        | 14/100 [00:00<00:03, 22.79it/s]\n",
      "Benchmarking RACE_M:  21%|██        | 21/100 [00:00<00:02, 32.80it/s]\n",
      "Benchmarking RACE_M:  28%|██▊       | 28/100 [00:01<00:01, 40.69it/s]\n",
      "Benchmarking RACE_M:  35%|███▌      | 35/100 [00:01<00:01, 45.99it/s]\n",
      "Benchmarking RACE_M:  42%|████▏     | 42/100 [00:01<00:01, 51.28it/s]\n",
      "Benchmarking RACE_M:  49%|████▉     | 49/100 [00:01<00:00, 55.47it/s]\n",
      "Benchmarking RACE_M:  56%|█████▌    | 56/100 [00:01<00:00, 56.82it/s]\n",
      "Benchmarking RACE_M:  63%|██████▎   | 63/100 [00:01<00:00, 58.12it/s]\n",
      "Benchmarking RACE_M:  70%|███████   | 70/100 [00:01<00:00, 58.93it/s]\n",
      "Benchmarking RACE_M:  77%|███████▋  | 77/100 [00:01<00:00, 58.65it/s]\n",
      "Benchmarking RACE_M:  84%|████████▍ | 84/100 [00:01<00:00, 59.60it/s]\n",
      "Benchmarking RACE_M:  91%|█████████ | 91/100 [00:02<00:00, 59.61it/s]\n",
      "Benchmarking RACE_M:  98%|█████████▊| 98/100 [00:02<00:00, 59.10it/s]\n",
      "Benchmarking RACE_M: 100%|██████████| 100/100 [00:02<00:00, 44.37it/s]\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n",
      "WARNING:root:No calls to update() have been made - returning 0.0\n"
     ]
    }
   ],
   "source": [
    "! python benchmark.py --model C:\\Users\\adity\\LayerSkip_v2\\model_weights\\llama3_1B_local \\\n",
    "    --dataset race_m \\\n",
    "    --num_samples 100 \\\n",
    "    --generation_strategy self_speculative\\\n",
    "    --exit_layer 8 \\\n",
    "    --output_dir ./logs \\\n",
    "    --top_p 0.9 \\\n",
    "    --distributed False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LayerDrop Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
